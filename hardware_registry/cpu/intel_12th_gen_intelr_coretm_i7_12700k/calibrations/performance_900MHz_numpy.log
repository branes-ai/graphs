================================================================================
Hardware Calibration: 12th Gen Intel(R) Core(TM) i7-12700K
================================================================================

Running pre-flight checks...

======================================================================
PRE-FLIGHT CHECKS
======================================================================

✓ CPU Governor: performance
    Current:  performance
    Expected: performance
✓ CPU Frequency: 1920 MHz idle (intel_pstate will boost under load)
    Current:  1920 MHz (idle)
    Expected: Up to 4900 MHz under load
✓ Turbo Boost: Enabled
✓ System Load: 0.1% (idle)
    Current:  0.1%
    Expected: < 5%
✓ Thermal State: 28°C (cool)
    Current:  28°C
    Expected: < 80°C

RESULT: PASSED
  System is ready for calibration.======================================================================
System Information:
  CPU: x86_64
  Cores: 12 physical, 20 logical
  Memory: 31.1 GB
  Python: 3.11.14
  NumPy: 2.2.6
  PyTorch: 2.7.1+cu126

Target Device: CPU
Framework:     NUMPY

Querying CPU clock frequencies...
  CPU Freq: 900 MHz (18% of max 4900 MHz)
  Governor: performance
  Turbo:    Enabled

Running calibration benchmarks...

1. STREAM Memory Bandwidth Benchmark
--------------------------------------------------------------------------------
Framework: NumPy (CPU-only)

STREAM Benchmark Suite:
--------------------------------------------------------------------------------

COPY (a[i] = b[i]):
  Memory ops: 2, FLOPs/element: 0
  Size     8 MB...    60.7 GB/s  (67.7%)    0.28 ms
  Size    16 MB...    70.2 GB/s  (78.3%)    0.48 ms
  Size    32 MB...    54.9 GB/s  (61.3%)    1.22 ms
  Size    64 MB...    48.4 GB/s  (54.0%)    2.77 ms
  Size   128 MB...    44.9 GB/s  (50.1%)    5.98 ms
  Size   256 MB...    51.8 GB/s  (57.9%)   10.36 ms
  Size   512 MB...    52.1 GB/s  (58.1%)   20.62 ms

SCALE (a[i] = q * b[i]):
  Memory ops: 2, FLOPs/element: 1
  Size     8 MB...    61.3 GB/s  (68.4%)    0.27 ms  |  7.7 GFLOPS
  Size    16 MB...    25.8 GB/s  (28.8%)    1.30 ms  |  3.2 GFLOPS
  Size    32 MB...    31.6 GB/s  (35.3%)    2.12 ms  |  3.9 GFLOPS
  Size    64 MB...    29.1 GB/s  (32.5%)    4.61 ms  |  3.6 GFLOPS
  Size   128 MB...    27.7 GB/s  (31.0%)    9.68 ms  |  3.5 GFLOPS
  Size   256 MB...    26.6 GB/s  (29.7%)   20.17 ms  |  3.3 GFLOPS
  Size   512 MB...    27.0 GB/s  (30.1%)   39.76 ms  |  3.4 GFLOPS

ADD (a[i] = b[i] + c[i]):
  Memory ops: 3, FLOPs/element: 1
  Size     8 MB...    46.0 GB/s  (51.3%)    0.55 ms  |  3.8 GFLOPS
  Size    16 MB...    33.5 GB/s  (37.4%)    1.50 ms  |  2.8 GFLOPS
  Size    32 MB...    35.3 GB/s  (39.3%)    2.86 ms  |  2.9 GFLOPS
  Size    64 MB...    33.4 GB/s  (37.3%)    6.03 ms  |  2.8 GFLOPS
  Size   128 MB...    32.4 GB/s  (36.2%)   12.43 ms  |  2.7 GFLOPS
  Size   256 MB...    32.3 GB/s  (36.1%)   24.92 ms  |  2.7 GFLOPS
  Size   512 MB...    32.0 GB/s  (35.7%)   50.37 ms  |  2.7 GFLOPS

TRIAD (a[i] = b[i] + q * c[i]):
  Memory ops: 3, FLOPs/element: 2
  Size     8 MB...    16.2 GB/s  (18.1%)    1.55 ms  |  2.7 GFLOPS
  Size    16 MB...    14.1 GB/s  (15.8%)    3.56 ms  |  2.4 GFLOPS
  Size    32 MB...    12.4 GB/s  (13.8%)    8.12 ms  |  2.1 GFLOPS
  Size    64 MB...    11.6 GB/s  (13.0%)   17.34 ms  |  1.9 GFLOPS
  Size   128 MB...    11.4 GB/s  (12.8%)   35.24 ms  |  1.9 GFLOPS
  Size   256 MB...    11.6 GB/s  (13.0%)   69.37 ms  |  1.9 GFLOPS
  Size   512 MB...    11.5 GB/s  (12.9%)  139.88 ms  |  1.9 GFLOPS

================================================================================
STREAM Summary:
--------------------------------------------------------------------------------
Kernel            Best BW    Latency   Efficiency Description
------------------------------------------------------------------------------------------
COPY               70.2 GB/s     0.48 ms       78.3%  a[i] = b[i]
SCALE              61.3 GB/s     0.27 ms       68.4%  a[i] = q * b[i]
ADD                46.0 GB/s     0.55 ms       51.3%  a[i] = b[i] + c[i]
TRIAD              16.2 GB/s     1.55 ms       18.1%  a[i] = b[i] + q * c[i]

STREAM Score (minimum): 11.4 GB/s
================================================================================
STREAM Score (minimum bandwidth): 11.4 GB/s

2. BLAS Compute Benchmark Suite
--------------------------------------------------------------------------------
Testing precisions: fp64, fp32, fp16, fp8, fp4, bf16, tf32, int64, int32, int16, int8, int4

Framework: NumPy (CPU-only)

BLAS Benchmark Suite:
==========================================================================================

BLAS Level 1: DOT
------------------------------------------------------------------------------------------
  Size     1K:
    fp64                                           3.0 GFLOPS    0.00ms
    fp32                                           4.8 GFLOPS    0.00ms
    tf32                                              SKIPPED  (NumPy does not support this precision)
    fp16        ⚠ SLOW (   0.8 GFLOPS < 1.0 GFLOPS threshold)    0.00ms
    fp8                                               SKIPPED  (NumPy does not support this precision)
    fp4                                               SKIPPED  (NumPy does not support this precision)
    bf16                                              SKIPPED  (NumPy does not support this precision)
    int64                                           2.6 GIOPS    0.00ms
    int32                                           2.7 GIOPS    0.00ms
    int16                                           2.7 GIOPS    0.00ms
    int8                                            2.7 GIOPS    0.00ms
    int4                                              SKIPPED  (NumPy does not support this precision)
  Size    10K:
    fp64                                          13.2 GFLOPS    0.00ms
    fp32                                          21.0 GFLOPS    0.00ms
    tf32                                              SKIPPED  (NumPy does not support this precision)
    fp16                                           1.2 GFLOPS    0.02ms
    fp8                                               SKIPPED  (NumPy does not support this precision)
    fp4                                               SKIPPED  (NumPy does not support this precision)
    bf16                                              SKIPPED  (NumPy does not support this precision)
    int64                                           5.9 GIOPS    0.00ms
    int32                                           6.0 GIOPS    0.00ms
    int16                                           5.9 GIOPS    0.00ms
    int8                                            6.3 GIOPS    0.00ms
    int4                                              SKIPPED  (NumPy does not support this precision)
  Size   100K:
    fp64                                          58.0 GFLOPS    0.00ms
    fp32                                          30.4 GFLOPS    0.01ms
    tf32                                              SKIPPED  (NumPy does not support this precision)
    fp16        ⚠ SLOW (   0.8 GFLOPS < 1.0 GFLOPS threshold)    0.25ms
    fp8                                               SKIPPED  (NumPy does not support this precision)
    fp4                                               SKIPPED  (NumPy does not support this precision)
    bf16                                              SKIPPED  (NumPy does not support this precision)
    int64                                           4.8 GIOPS    0.04ms
    int32                                           4.2 GIOPS    0.05ms
    int16                                           4.3 GIOPS    0.05ms
    int8                                            4.3 GIOPS    0.05ms
    int4                                              SKIPPED  (NumPy does not support this precision)
  Size     1M:
    fp64                                          36.9 GFLOPS    0.05ms
    fp32                                          19.7 GFLOPS    0.10ms
    tf32                                              SKIPPED  (NumPy does not support this precision)
    fp16        ⚠ SLOW (   0.8 GFLOPS < 1.0 GFLOPS threshold)    2.46ms
    fp8                                               SKIPPED  (NumPy does not support this precision)
    fp4                                               SKIPPED  (NumPy does not support this precision)
    bf16                                              SKIPPED  (NumPy does not support this precision)
    int64                                           4.5 GIOPS    0.44ms
    int32                                           7.1 GIOPS    0.28ms
    int16                                           7.1 GIOPS    0.28ms
    int8                                            7.3 GIOPS    0.27ms
    int4                                              SKIPPED  (NumPy does not support this precision)
  Size    10M:
    fp64                                          11.0 GFLOPS    1.83ms
    fp32                                           9.6 GFLOPS    2.08ms
    tf32                                              SKIPPED  (NumPy does not support this precision)
    fp16                                           1.2 GFLOPS   16.17ms
    fp8                                               SKIPPED  (NumPy does not support this precision)
    fp4                                               SKIPPED  (NumPy does not support this precision)
    bf16                                              SKIPPED  (NumPy does not support this precision)
    int64                                           3.5 GIOPS    5.69ms
    int32                                           5.5 GIOPS    3.62ms
    int16                                           6.7 GIOPS    2.96ms
    int8                                            7.3 GIOPS    2.74ms
    int4                                              SKIPPED  (NumPy does not support this precision)

BLAS Level 1: AXPY
------------------------------------------------------------------------------------------
  Size     1K:
    fp64                                           1.4 GFLOPS    0.00ms
    fp32                                           1.7 GFLOPS    0.00ms
    tf32                                              SKIPPED  (NumPy does not support this precision)
    fp16        ⚠ SLOW (   0.3 GFLOPS < 1.0 GFLOPS threshold)    0.01ms
    fp8                                               SKIPPED  (NumPy does not support this precision)
    fp4                                               SKIPPED  (NumPy does not support this precision)
    bf16                                              SKIPPED  (NumPy does not support this precision)
    int64                                           1.5 GIOPS    0.00ms
    int32                                           1.8 GIOPS    0.00ms
    int16                                           1.9 GIOPS    0.00ms
    int8                                            2.1 GIOPS    0.00ms
    int4                                              SKIPPED  (NumPy does not support this precision)
  Size    10K:
    fp64                                           4.3 GFLOPS    0.00ms
    fp32                                           6.8 GFLOPS    0.00ms
    tf32                                              SKIPPED  (NumPy does not support this precision)
    fp16        ⚠ SLOW (   0.4 GFLOPS < 1.0 GFLOPS threshold)    0.05ms
    fp8                                               SKIPPED  (NumPy does not support this precision)
    fp4                                               SKIPPED  (NumPy does not support this precision)
    bf16                                              SKIPPED  (NumPy does not support this precision)
    int64                                           3.7 GIOPS    0.01ms
    int32                                           6.9 GIOPS    0.00ms
    int16                                          10.1 GIOPS    0.00ms
    int8                                           14.7 GIOPS    0.00ms
    int4                                              SKIPPED  (NumPy does not support this precision)
  Size   100K:
    fp64                                           2.0 GFLOPS    0.10ms
    fp32                                           7.8 GFLOPS    0.03ms
    tf32                                              SKIPPED  (NumPy does not support this precision)
    fp16        ⚠ SLOW (   0.4 GFLOPS < 1.0 GFLOPS threshold)    0.55ms
    fp8                                               SKIPPED  (NumPy does not support this precision)
    fp4                                               SKIPPED  (NumPy does not support this precision)
    bf16                                              SKIPPED  (NumPy does not support this precision)
    int64                                           2.5 GIOPS    0.08ms
    int32                                           7.5 GIOPS    0.03ms
    int16                                          17.0 GIOPS    0.01ms
    int8                                           32.8 GIOPS    0.01ms
    int4                                              SKIPPED  (NumPy does not support this precision)
  Size     1M:
    fp64                                           1.7 GFLOPS    1.16ms
    fp32                                           3.6 GFLOPS    0.55ms
    tf32                                              SKIPPED  (NumPy does not support this precision)
    fp16        ⚠ SLOW (   0.4 GFLOPS < 1.0 GFLOPS threshold)    5.52ms
    fp8                                               SKIPPED  (NumPy does not support this precision)
    fp4                                               SKIPPED  (NumPy does not support this precision)
    bf16                                              SKIPPED  (NumPy does not support this precision)
    int64                                           2.0 GIOPS    1.02ms
    int32                                           5.0 GIOPS    0.40ms
    int16                                          10.0 GIOPS    0.20ms
    int8                                           19.4 GIOPS    0.10ms
    int4                                              SKIPPED  (NumPy does not support this precision)
  Size    10M:
    fp64        ⚠ SLOW (   1.0 GFLOPS < 1.0 GFLOPS threshold)   20.76ms
    fp32                                           2.0 GFLOPS    9.91ms
    tf32                                              SKIPPED  (NumPy does not support this precision)
    fp16        ⚠ SLOW (   0.4 GFLOPS < 1.0 GFLOPS threshold)   55.60ms
    fp8                                               SKIPPED  (NumPy does not support this precision)
    fp4                                               SKIPPED  (NumPy does not support this precision)
    bf16                                              SKIPPED  (NumPy does not support this precision)
    int64        ⚠ SLOW (   0.9 GIOPS < 1.0 GFLOPS threshold)   21.15ms
    int32                                           2.0 GIOPS    9.94ms
    int16                                           6.1 GIOPS    3.28ms
    int8                                           14.8 GIOPS    1.35ms
    int4                                              SKIPPED  (NumPy does not support this precision)

BLAS Level 2: GEMV
------------------------------------------------------------------------------------------
  Size     32:
    fp64                                           1.0 GFLOPS    0.00ms
    fp32                                           1.1 GFLOPS    0.00ms
    tf32                                              SKIPPED  (NumPy does not support this precision)
    fp16        ⚠ SLOW (   0.5 GFLOPS < 1.0 GFLOPS threshold)    0.00ms
    fp8                                               SKIPPED  (NumPy does not support this precision)
    fp4                                               SKIPPED  (NumPy does not support this precision)
    bf16                                              SKIPPED  (NumPy does not support this precision)
    int64        ⚠ SLOW (   0.9 GIOPS < 1.0 GFLOPS threshold)    0.00ms
    int32        ⚠ SLOW (   1.0 GIOPS < 1.0 GFLOPS threshold)    0.00ms
    int16        ⚠ SLOW (   0.9 GIOPS < 1.0 GFLOPS threshold)    0.00ms
    int8                                            1.0 GIOPS    0.00ms
    int4                                              SKIPPED  (NumPy does not support this precision)
  Size     64:
    fp64                                           4.1 GFLOPS    0.00ms
    fp32                                           4.2 GFLOPS    0.00ms
    tf32                                              SKIPPED  (NumPy does not support this precision)
    fp16        ⚠ SLOW (   0.9 GFLOPS < 1.0 GFLOPS threshold)    0.01ms
    fp8                                               SKIPPED  (NumPy does not support this precision)
    fp4                                               SKIPPED  (NumPy does not support this precision)
    bf16                                              SKIPPED  (NumPy does not support this precision)
    int64                                           2.4 GIOPS    0.00ms
    int32                                           2.7 GIOPS    0.00ms
    int16                                           2.3 GIOPS    0.00ms
    int8                                            2.8 GIOPS    0.00ms
    int4                                              SKIPPED  (NumPy does not support this precision)
  Size    128:
    fp64                                          11.6 GFLOPS    0.00ms
    fp32                                          12.5 GFLOPS    0.00ms
    tf32                                              SKIPPED  (NumPy does not support this precision)
    fp16                                           1.1 GFLOPS    0.03ms
    fp8                                               SKIPPED  (NumPy does not support this precision)
    fp4                                               SKIPPED  (NumPy does not support this precision)
    bf16                                              SKIPPED  (NumPy does not support this precision)
    int64                                           4.2 GIOPS    0.01ms
    int32                                           4.4 GIOPS    0.01ms
    int16                                           4.1 GIOPS    0.01ms
    int8                                            4.5 GIOPS    0.01ms
    int4                                              SKIPPED  (NumPy does not support this precision)
  Size    256:
    fp64                                          24.4 GFLOPS    0.01ms
    fp32                                          30.1 GFLOPS    0.00ms
    tf32                                              SKIPPED  (NumPy does not support this precision)
    fp16                                           1.2 GFLOPS    0.11ms
    fp8                                               SKIPPED  (NumPy does not support this precision)
    fp4                                               SKIPPED  (NumPy does not support this precision)
    bf16                                              SKIPPED  (NumPy does not support this precision)
    int64                                           5.3 GIOPS    0.02ms
    int32                                           5.9 GIOPS    0.02ms
    int16                                           5.8 GIOPS    0.02ms
    int8                                            6.1 GIOPS    0.02ms
    int4                                              SKIPPED  (NumPy does not support this precision)
  Size    512:
    fp64                                          19.3 GFLOPS    0.03ms
    fp32                                          51.1 GFLOPS    0.01ms
    tf32                                              SKIPPED  (NumPy does not support this precision)
    fp16                                           1.2 GFLOPS    0.43ms
    fp8                                               SKIPPED  (NumPy does not support this precision)
    fp4                                               SKIPPED  (NumPy does not support this precision)
    bf16                                              SKIPPED  (NumPy does not support this precision)
    int64                                           5.2 GIOPS    0.10ms
    int32                                           6.6 GIOPS    0.08ms
    int16                                           6.3 GIOPS    0.08ms
    int8                                            6.9 GIOPS    0.08ms
    int4                                              SKIPPED  (NumPy does not support this precision)
  Size     1K:
    fp64                                         123.8 GFLOPS    0.02ms
    fp32                                         180.3 GFLOPS    0.01ms
    tf32                                              SKIPPED  (NumPy does not support this precision)
    fp16        ⚠ SLOW (   0.8 GFLOPS < 1.0 GFLOPS threshold)    2.62ms
    fp8                                               SKIPPED  (NumPy does not support this precision)
    fp4                                               SKIPPED  (NumPy does not support this precision)
    bf16                                              SKIPPED  (NumPy does not support this precision)
    int64                                           4.0 GIOPS    0.52ms
    int32                                           4.2 GIOPS    0.49ms
    int16                                           5.8 GIOPS    0.36ms
    int8                                            7.2 GIOPS    0.29ms
    int4                                              SKIPPED  (NumPy does not support this precision)
  Size     2K:
    fp64                                          43.2 GFLOPS    0.19ms
    fp32                                         127.0 GFLOPS    0.07ms
    tf32                                              SKIPPED  (NumPy does not support this precision)
    fp16                                           1.2 GFLOPS    7.24ms
    fp8                                               SKIPPED  (NumPy does not support this precision)
    fp4                                               SKIPPED  (NumPy does not support this precision)
    bf16                                              SKIPPED  (NumPy does not support this precision)
    int64                                           4.4 GIOPS    1.92ms
    int32                                           6.8 GIOPS    1.24ms
    int16                                           6.7 GIOPS    1.26ms
    int8                                            7.4 GIOPS    1.14ms
    int4                                              SKIPPED  (NumPy does not support this precision)

BLAS Level 3: GEMM
------------------------------------------------------------------------------------------
  Size     32:
    fp64                                          11.4 GFLOPS    0.01ms
    fp32                                           6.4 GFLOPS    0.01ms
    tf32                                              SKIPPED  (NumPy does not support this precision)
    fp16        ⚠ SLOW (   0.5 GFLOPS < 1.0 GFLOPS threshold)    0.14ms
    fp8                                               SKIPPED  (NumPy does not support this precision)
    fp4                                               SKIPPED  (NumPy does not support this precision)
    bf16                                              SKIPPED  (NumPy does not support this precision)
    int64                                           3.4 GIOPS    0.02ms
    int32                                           2.5 GIOPS    0.03ms
    int16                                           1.5 GIOPS    0.04ms
    int8                                            2.4 GIOPS    0.03ms
    int4                                              SKIPPED  (NumPy does not support this precision)
  Size     64:
    fp64                                          34.1 GFLOPS    0.02ms
    fp32                                          21.5 GFLOPS    0.02ms
    tf32                                              SKIPPED  (NumPy does not support this precision)
    fp16                                           1.0 GFLOPS    0.51ms
    fp8                                               SKIPPED  (NumPy does not support this precision)
    fp4                                               SKIPPED  (NumPy does not support this precision)
    bf16                                              SKIPPED  (NumPy does not support this precision)
    int64                                           4.6 GIOPS    0.11ms
    int32                                           5.3 GIOPS    0.10ms
    int16                                           4.2 GIOPS    0.12ms
    int8                                            3.4 GIOPS    0.15ms
    int4                                              SKIPPED  (NumPy does not support this precision)
  Size    128:
    fp64                                          70.3 GFLOPS    0.06ms
    fp32                                         112.4 GFLOPS    0.04ms
    tf32                                              SKIPPED  (NumPy does not support this precision)
    fp16                                           1.1 GFLOPS    3.67ms
    fp8                                               SKIPPED  (NumPy does not support this precision)
    fp4                                               SKIPPED  (NumPy does not support this precision)
    bf16                                              SKIPPED  (NumPy does not support this precision)
    int64                                           4.1 GIOPS    1.02ms
    int32                                           4.3 GIOPS    0.99ms
    int16                                           5.6 GIOPS    0.75ms
    int8                                            5.9 GIOPS    0.71ms
    int4                                              SKIPPED  (NumPy does not support this precision)
  Size    256:
    fp64                                          91.1 GFLOPS    0.37ms
    fp32                                         203.9 GFLOPS    0.16ms
    tf32                                              SKIPPED  (NumPy does not support this precision)
    fp16                                           1.2 GFLOPS   28.08ms
    fp8                                               SKIPPED  (NumPy does not support this precision)
    fp4                                               SKIPPED  (NumPy does not support this precision)
    bf16                                              SKIPPED  (NumPy does not support this precision)
    int64                                           3.8 GIOPS    8.93ms
    int32                                           4.1 GIOPS    8.18ms
    int16                                           4.2 GIOPS    7.98ms
    int8                                            4.1 GIOPS    8.09ms
    int4                                              SKIPPED  (NumPy does not support this precision)
  Size    512:
    fp64                                         231.6 GFLOPS    1.16ms
    fp32                                         407.6 GFLOPS    0.66ms
    tf32                                              SKIPPED  (NumPy does not support this precision)
    fp16                                           1.2 GFLOPS  223.25ms
    fp8                                               SKIPPED  (NumPy does not support this precision)
    fp4                                               SKIPPED  (NumPy does not support this precision)
    bf16                                              SKIPPED  (NumPy does not support this precision)
    int64                                           1.1 GIOPS  233.71ms
    int32                                           2.9 GIOPS   94.03ms
    int16                                           4.0 GIOPS   66.63ms
    int8                                            4.2 GIOPS   63.34ms
    int4                                              SKIPPED  (NumPy does not support this precision)
  Size     1K:
    fp64                                         274.1 GFLOPS    7.84ms
    fp32                                         567.0 GFLOPS    3.79ms
    tf32                                              SKIPPED  (NumPy does not support this precision)
    fp16                                              SKIPPED  (Timeout: GEMM benchmark exceeded 5s timeout)
    fp8                                               SKIPPED  (NumPy does not support this precision)
    fp4                                               SKIPPED  (NumPy does not support this precision)
    bf16                                              SKIPPED  (NumPy does not support this precision)
    int64                                             SKIPPED  (Timeout: GEMM benchmark exceeded 5s timeout)
    int32                                             SKIPPED  (Timeout: GEMM benchmark exceeded 5s timeout)
    int16                                             SKIPPED  (Timeout: GEMM benchmark exceeded 5s timeout)
    int8                                              SKIPPED  (Timeout: GEMM benchmark exceeded 5s timeout)
    int4                                              SKIPPED  (NumPy does not support this precision)
  Size     2K:
    fp64                                         284.1 GFLOPS   60.47ms
    fp32                                         647.4 GFLOPS   26.54ms
    tf32                                              SKIPPED  (NumPy does not support this precision)
    fp16                                              SKIPPED  (Skipped (poor performance at size 1K: Timeout (>5s)))
    fp8                                               SKIPPED  (NumPy does not support this precision)
    fp4                                               SKIPPED  (NumPy does not support this precision)
    bf16                                              SKIPPED  (NumPy does not support this precision)
    int64                                             SKIPPED  (Skipped (poor performance at size 1K: Timeout (>5s)))
    int32                                             SKIPPED  (Skipped (poor performance at size 1K: Timeout (>5s)))
    int16                                             SKIPPED  (Skipped (poor performance at size 1K: Timeout (>5s)))
    int8                                              SKIPPED  (Skipped (poor performance at size 1K: Timeout (>5s)))
    int4                                              SKIPPED  (NumPy does not support this precision)

==========================================================================================
BLAS Suite Complete: 24 calibrations
==========================================================================================

Building precision capability matrix...

================================================================================
Hardware Calibration: 12th Gen Intel(R) Core(TM) i7-12700K
Date: 2025-11-28T09:32:42.466487
================================================================================

Framework: NUMPY
Device:    CPU

Theoretical Specifications:
  Peak GFLOPS (FP32): 1280.0
  Peak Bandwidth:     89.6 GB/s

STREAM Memory Bandwidth Benchmark:
  Kernel           Size (MB)    Bandwidth    Latency   Efficiency Description
  -----------------------------------------------------------------------------------------------
  COPY                    16       70.2 GB/s     0.48 ms       78.3%  a[i] = b[i]
  SCALE                    8       61.3 GB/s     0.27 ms       68.4%  a[i] = q * b[i]
  ADD                      8       46.0 GB/s     0.55 ms       51.3%  a[i] = b[i] + c[i]
  TRIAD                    8       16.2 GB/s     1.55 ms       18.1%  a[i] = b[i] + q * c[i]

  STREAM Score (minimum): 11.4 GB/s

BLAS Performance Summary (Highest Throughput by Precision):
  Operation          fp64       fp32       tf32       fp16        fp8        fp4       bf16      int64      int32      int16       int8       int4   Best Precision
  ------------------------------------------------------------------------------------------------------------------------------------------------------------------
  AXPY                4.3        7.8        N/A        0.4        N/A        N/A        N/A        3.7        7.5       17.0       32.8        N/A             int8
  DOT                58.0       30.4        N/A        1.2        N/A        N/A        N/A        5.9        7.1        7.1        7.3        N/A             fp64
  GEMV              123.8      180.3        N/A        1.2        N/A        N/A        N/A        5.3        6.8        6.7        7.4        N/A             fp32
  GEMM              284.1      647.4        N/A        1.2        N/A        N/A        N/A        4.6        5.3        5.6        5.9        N/A             fp32

BLAS Compute Performance (by Operation and Precision):
========================================================================================================================

Level 1: Vector-Vector (O(n))
------------------------------------------------------------------------------------------------------------------------

AXPY:
  Precision   Best Size Highest Throughput    Latency       AI   Efficiency
  --------------------------------------------------------------------------------
  fp64              10K         4.3 GFLOPS     0.00ms     0.08        0.7%
  fp32             100K         7.8 GFLOPS     0.03ms     0.17        0.6%
  fp16             100K         0.4 GFLOPS     0.55ms     0.33        0.0%
  int64             10K          3.7 GIOPS     0.01ms     0.08        0.0%
  int32            100K          7.5 GIOPS     0.03ms     0.17        0.0%
  int16            100K         17.0 GIOPS     0.01ms     0.33        0.0%
  int8             100K         32.8 GIOPS     0.01ms     0.67        0.0%

DOT:
  Precision   Best Size Highest Throughput    Latency       AI   Efficiency
  --------------------------------------------------------------------------------
  fp64             100K        58.0 GFLOPS     0.00ms     0.12        9.1%
  fp32             100K        30.4 GFLOPS     0.01ms     0.25        2.4%
  fp16              10M         1.2 GFLOPS    16.17ms     0.50        0.0%
  int64             10K          5.9 GIOPS     0.00ms     0.12        0.0%
  int32              1M          7.1 GIOPS     0.28ms     0.25        0.0%
  int16              1M          7.1 GIOPS     0.28ms     0.50        0.0%
  int8               1M          7.3 GIOPS     0.27ms     1.00        0.0%

Level 2: Matrix-Vector (O(n²))
------------------------------------------------------------------------------------------------------------------------

GEMV:
  Precision   Best Size Highest Throughput    Latency       AI   Efficiency
  --------------------------------------------------------------------------------
  fp64               1K       123.8 GFLOPS     0.02ms     0.25       19.3%
  fp32               1K       180.3 GFLOPS     0.01ms     0.50       14.1%
  fp16              512         1.2 GFLOPS     0.43ms     1.00        0.0%
  int64             256          5.3 GIOPS     0.02ms     0.25        0.0%
  int32              2K          6.8 GIOPS     1.24ms     0.50        0.0%
  int16              2K          6.7 GIOPS     1.26ms     1.00        0.0%
  int8               2K          7.4 GIOPS     1.14ms     2.00        0.0%

Level 3: Matrix-Matrix (O(n³))
------------------------------------------------------------------------------------------------------------------------

GEMM:
  Precision   Best Size Highest Throughput    Latency       AI   Efficiency
  --------------------------------------------------------------------------------
  fp64               2K       284.1 GFLOPS    60.47ms   170.67       44.4%
  fp32               2K       647.4 GFLOPS    26.54ms   341.33       50.6%
  fp16              512         1.2 GFLOPS   223.25ms   170.67        0.0%
  int64              64          4.6 GIOPS     0.11ms     5.33        0.0%
  int32              64          5.3 GIOPS     0.10ms    10.67        0.0%
  int16             128          5.6 GIOPS     0.75ms    42.67        0.0%
  int8              128          5.9 GIOPS     0.71ms    85.33        0.0%

Precision Support Summary:
  Supported:   fp64, fp32, fp16, int64, int32, int16, int8
  Unsupported: tf32, fp8, fp4, bf16, int4

