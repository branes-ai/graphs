
================================================================================
Using Hardware from Registry: jetson_orin_nx_16gb_cpu
================================================================================
  Vendor:   NVIDIA
  Model:    Jetson Orin NX 16GB (CPU)
  Type:     cpu
  Arch:     Cortex-A78AE


================================================================================
EXECUTION DEVICE
================================================================================
  Requested device: CPU
  Actual device:    CPU
  Framework:        NUMPY

================================================================================
Hardware Calibration: Jetson Orin NX 16GB (CPU)
================================================================================

Running pre-flight checks...
======================================================================
PRE-FLIGHT CHECKS
======================================================================

[OK] CPU Governor: schedutil (Jetson default)
    Current:  schedutil
    Expected: schedutil or performance
[OK] CPU Frequency: 960 MHz idle (DVFS will boost under load)
    Current:  960 MHz (idle)
    Expected: Up to 1190 MHz under load
[-] Turbo Boost: Could not determine (not Intel pstate)
[X] System Load: 54.4% (high - will affect results)
    Current:  54.4%
    Expected: < 5%
    Fix: Close other applications or wait for background tasks
[OK] Thermal State: 42°C (cool)
    Current:  42°C
    Expected: < 80°C

RESULT: FAILED
  Calibration aborted. Fix issues above or use --force to override.

  Fix commands:
    Close other applications or wait for background tasks
======================================================================

[!] WARNING: Proceeding with calibration despite failed pre-flight checks.
  Results will be flagged as non-representative of peak performance.

System Information:
  CPU: aarch64
  Cores: 4 physical, 4 logical
  Memory: 15.3 GB
  Python: 3.10.12
  NumPy: 1.26.4
  PyTorch: 2.4.0a0+3bcc3cddb5.nv24.07

Execution Device:
  Running on: CPU
  Framework:  NUMPY
              (CPU-only, real-world signal processing performance)

Querying CPU clock frequencies...
  CPU Freq: 960 MHz (81% of max 1190 MHz)
  Governor: schedutil

Running calibration benchmarks...

1. STREAM Memory Bandwidth Benchmark
--------------------------------------------------------------------------------
Framework: NumPy (CPU-only)

STREAM Benchmark Suite:
--------------------------------------------------------------------------------

COPY (a[i] = b[i]):
  Memory ops: 2, FLOPs/element: 0
  Size     8 MB...    12.6 GB/s  (12.4%)    1.33 ms
  Size    16 MB...    12.6 GB/s  (12.3%)    2.67 ms
  Size    32 MB...    12.0 GB/s  (11.8%)    5.57 ms
  Size    64 MB...    12.7 GB/s  (12.4%)   10.59 ms
  Size   128 MB...    12.6 GB/s  (12.4%)   21.24 ms
  Size   256 MB...    12.6 GB/s  (12.4%)   42.58 ms
  Size   512 MB...    12.6 GB/s  (12.4%)   85.00 ms

SCALE (a[i] = q * b[i]):
  Memory ops: 2, FLOPs/element: 1
  Size     8 MB...    12.7 GB/s  (12.4%)    1.32 ms  |  1.6 GFLOPS
  Size    16 MB...    12.6 GB/s  (12.4%)    2.66 ms  |  1.6 GFLOPS
  Size    32 MB...    12.5 GB/s  (12.3%)    5.37 ms  |  1.6 GFLOPS
  Size    64 MB...    12.6 GB/s  (12.4%)   10.65 ms  |  1.6 GFLOPS
  Size   128 MB...    12.5 GB/s  (12.3%)   21.40 ms  |  1.6 GFLOPS
  Size   256 MB...    12.6 GB/s  (12.3%)   42.64 ms  |  1.6 GFLOPS
  Size   512 MB...    12.6 GB/s  (12.4%)   85.05 ms  |  1.6 GFLOPS

ADD (a[i] = b[i] + c[i]):
  Memory ops: 3, FLOPs/element: 1
  Size     8 MB...    10.6 GB/s  (10.4%)    2.38 ms  |  0.9 GFLOPS
  Size    16 MB...    10.5 GB/s  (10.3%)    4.79 ms  |  0.9 GFLOPS
  Size    32 MB...    10.6 GB/s  (10.4%)    9.48 ms  |  0.9 GFLOPS
  Size    64 MB...    10.6 GB/s  (10.4%)   18.91 ms  |  0.9 GFLOPS
  Size   128 MB...    10.7 GB/s  (10.5%)   37.71 ms  |  0.9 GFLOPS
  Size   256 MB...    10.7 GB/s  (10.5%)   75.40 ms  |  0.9 GFLOPS
  Size   512 MB...    10.7 GB/s  (10.5%)  150.65 ms  |  0.9 GFLOPS

TRIAD (a[i] = b[i] + q * c[i]):
  Memory ops: 3, FLOPs/element: 2
  Size     8 MB...     5.4 GB/s   (5.3%)    4.66 ms  |  0.9 GFLOPS
  Size    16 MB...     5.3 GB/s   (5.2%)    9.44 ms  |  0.9 GFLOPS
  Size    32 MB...     4.0 GB/s   (3.9%)   25.33 ms  |  0.7 GFLOPS
  Size    64 MB...     4.1 GB/s   (4.0%)   49.40 ms  |  0.7 GFLOPS
  Size   128 MB...     4.1 GB/s   (4.1%)   97.47 ms  |  0.7 GFLOPS
  Size   256 MB...     4.2 GB/s   (4.1%)  193.84 ms  |  0.7 GFLOPS
  Size   512 MB...     4.2 GB/s   (4.1%)  385.91 ms  |  0.7 GFLOPS

================================================================================
STREAM Summary:
--------------------------------------------------------------------------------
Kernel            Best BW    Latency   Efficiency Description
------------------------------------------------------------------------------------------
COPY               12.7 GB/s    10.59 ms       12.4%  a[i] = b[i]
SCALE              12.7 GB/s     1.32 ms       12.4%  a[i] = q * b[i]
ADD                10.7 GB/s   150.65 ms       10.5%  a[i] = b[i] + c[i]
TRIAD               5.4 GB/s     4.66 ms        5.3%  a[i] = b[i] + q * c[i]

STREAM Score (minimum): 4.0 GB/s
================================================================================
STREAM Score (minimum bandwidth): 4.0 GB/s

2. BLAS Compute Benchmark Suite
--------------------------------------------------------------------------------
Testing precisions: fp64, fp32, tf32, fp16, fp8, fp4, bf16, int64, int32, int16, int8, int4

Framework: NumPy (CPU-only)

BLAS Benchmark Suite:
==========================================================================================

BLAS Level 1: DOT
------------------------------------------------------------------------------------------
  Size     1K:
    fp64      [!] SLOW (   0.7 GFLOPS < 1.0 GFLOPS threshold)    0.00ms
    fp32      [!] SLOW (   0.9 GFLOPS < 1.0 GFLOPS threshold)    0.00ms
    tf32                                              SKIPPED  (NumPy does not support this precision)
    fp16      [!] SLOW (   0.2 GFLOPS < 1.0 GFLOPS threshold)    0.01ms
    fp8                                               SKIPPED  (NumPy does not support this precision)
    fp4                                               SKIPPED  (NumPy does not support this precision)
    bf16                                              SKIPPED  (NumPy does not support this precision)
    int64      [!] SLOW (   0.6 GIOPS < 1.0 GFLOPS threshold)    0.00ms
    int32      [!] SLOW (   0.6 GIOPS < 1.0 GFLOPS threshold)    0.00ms
    int16      [!] SLOW (   0.5 GIOPS < 1.0 GFLOPS threshold)    0.00ms
    int8       [!] SLOW (   0.6 GIOPS < 1.0 GFLOPS threshold)    0.00ms
    int4                                              SKIPPED  (NumPy does not support this precision)
  Size    10K:
    fp64                                           1.8 GFLOPS    0.01ms
    fp32                                           3.7 GFLOPS    0.01ms
    tf32                                              SKIPPED  (NumPy does not support this precision)
    fp16      [!] SLOW (   0.3 GFLOPS < 1.0 GFLOPS threshold)    0.07ms
    fp8                                               SKIPPED  (NumPy does not support this precision)
    fp4                                               SKIPPED  (NumPy does not support this precision)
    bf16                                              SKIPPED  (NumPy does not support this precision)
    int64                                           1.3 GIOPS    0.02ms
    int32                                           1.3 GIOPS    0.01ms
    int16                                           1.2 GIOPS    0.02ms
    int8                                            1.3 GIOPS    0.02ms
    int4                                              SKIPPED  (NumPy does not support this precision)
  Size   100K:
    fp64                                           1.8 GFLOPS    0.11ms
    fp32                                           3.7 GFLOPS    0.05ms
    tf32                                              SKIPPED  (NumPy does not support this precision)
    fp16      [!] SLOW (   0.3 GFLOPS < 1.0 GFLOPS threshold)    0.65ms
    fp8                                               SKIPPED  (NumPy does not support this precision)
    fp4                                               SKIPPED  (NumPy does not support this precision)
    bf16                                              SKIPPED  (NumPy does not support this precision)
    int64                                           1.5 GIOPS    0.13ms
    int32                                           1.6 GIOPS    0.13ms
    int16                                           1.5 GIOPS    0.14ms
    int8                                            2.0 GIOPS    0.10ms
    int4                                              SKIPPED  (NumPy does not support this precision)
  Size     1M:
    fp64                                           1.1 GFLOPS    1.79ms
    fp32                                           2.5 GFLOPS    0.81ms
    tf32                                              SKIPPED  (NumPy does not support this precision)
    fp16      [!] SLOW (   0.3 GFLOPS < 1.0 GFLOPS threshold)    6.47ms
    fp8                                               SKIPPED  (NumPy does not support this precision)
    fp4                                               SKIPPED  (NumPy does not support this precision)
    bf16                                              SKIPPED  (NumPy does not support this precision)
    int64                                           1.2 GIOPS    1.70ms
    int32                                           1.5 GIOPS    1.29ms
    int16                                           1.6 GIOPS    1.22ms
    int8                                            2.0 GIOPS    0.99ms
    int4                                              SKIPPED  (NumPy does not support this precision)
  Size    10M:
    fp64                                           1.0 GFLOPS   19.65ms
    fp32                                           2.1 GFLOPS    9.53ms
    tf32                                              SKIPPED  (NumPy does not support this precision)
    fp16      [!] SLOW (   0.3 GFLOPS < 1.0 GFLOPS threshold)   64.77ms
    fp8                                               SKIPPED  (NumPy does not support this precision)
    fp4                                               SKIPPED  (NumPy does not support this precision)
    bf16                                              SKIPPED  (NumPy does not support this precision)
    int64                                           1.0 GIOPS   19.43ms
    int32                                           1.6 GIOPS   12.36ms
    int16                                           1.6 GIOPS   12.42ms
    int8                                            2.0 GIOPS    9.89ms
    int4                                              SKIPPED  (NumPy does not support this precision)

BLAS Level 1: AXPY
------------------------------------------------------------------------------------------
  Size     1K:
    fp64      [!] SLOW (   0.3 GFLOPS < 1.0 GFLOPS threshold)    0.01ms
    fp32      [!] SLOW (   0.3 GFLOPS < 1.0 GFLOPS threshold)    0.01ms
    tf32                                              SKIPPED  (NumPy does not support this precision)
    fp16      [!] SLOW (   0.1 GFLOPS < 1.0 GFLOPS threshold)    0.04ms
    fp8                                               SKIPPED  (NumPy does not support this precision)
    fp4                                               SKIPPED  (NumPy does not support this precision)
    bf16                                              SKIPPED  (NumPy does not support this precision)
    int64      [!] SLOW (   0.2 GIOPS < 1.0 GFLOPS threshold)    0.01ms
    int32      [!] SLOW (   0.3 GIOPS < 1.0 GFLOPS threshold)    0.01ms
    int16      [!] SLOW (   0.3 GIOPS < 1.0 GFLOPS threshold)    0.01ms
    int8       [!] SLOW (   0.3 GIOPS < 1.0 GFLOPS threshold)    0.01ms
    int4                                              SKIPPED  (NumPy does not support this precision)
  Size    10K:
    fp64      [!] SLOW (   0.5 GFLOPS < 1.0 GFLOPS threshold)    0.04ms
    fp32                                           1.1 GFLOPS    0.02ms
    tf32                                              SKIPPED  (NumPy does not support this precision)
    fp16      [!] SLOW (   0.1 GFLOPS < 1.0 GFLOPS threshold)    0.31ms
    fp8                                               SKIPPED  (NumPy does not support this precision)
    fp4                                               SKIPPED  (NumPy does not support this precision)
    bf16                                              SKIPPED  (NumPy does not support this precision)
    int64      [!] SLOW (   0.5 GIOPS < 1.0 GFLOPS threshold)    0.04ms
    int32                                           1.1 GIOPS    0.02ms
    int16                                           1.6 GIOPS    0.01ms
    int8                                            2.3 GIOPS    0.01ms
    int4                                              SKIPPED  (NumPy does not support this precision)
  Size   100K:
    fp64      [!] SLOW (   0.6 GFLOPS < 1.0 GFLOPS threshold)    0.36ms
    fp32                                           1.0 GFLOPS    0.20ms
    tf32                                              SKIPPED  (NumPy does not support this precision)
    fp16      [!] SLOW (   0.1 GFLOPS < 1.0 GFLOPS threshold)    3.05ms
    fp8                                               SKIPPED  (NumPy does not support this precision)
    fp4                                               SKIPPED  (NumPy does not support this precision)
    bf16                                              SKIPPED  (NumPy does not support this precision)
    int64      [!] SLOW (   0.5 GIOPS < 1.0 GFLOPS threshold)    0.37ms
    int32                                           1.0 GIOPS    0.20ms
    int16                                           1.6 GIOPS    0.13ms
    int8                                            3.5 GIOPS    0.06ms
    int4                                              SKIPPED  (NumPy does not support this precision)
  Size     1M:
    fp64      [!] SLOW (   0.5 GFLOPS < 1.0 GFLOPS threshold)    4.36ms
    fp32      [!] SLOW (   1.0 GFLOPS < 1.0 GFLOPS threshold)    2.06ms
    tf32                                              SKIPPED  (NumPy does not support this precision)
    fp16      [!] SLOW (   0.1 GFLOPS < 1.0 GFLOPS threshold)   30.32ms
    fp8                                               SKIPPED  (NumPy does not support this precision)
    fp4                                               SKIPPED  (NumPy does not support this precision)
    bf16                                              SKIPPED  (NumPy does not support this precision)
    int64      [!] SLOW (   0.5 GIOPS < 1.0 GFLOPS threshold)    4.35ms
    int32      [!] SLOW (   1.0 GIOPS < 1.0 GFLOPS threshold)    2.03ms
    int16                                           2.1 GIOPS    0.95ms
    int8                                            4.4 GIOPS    0.45ms
    int4                                              SKIPPED  (NumPy does not support this precision)
  Size    10M:
    fp64      [!] SLOW (   0.3 GFLOPS < 1.0 GFLOPS threshold)   57.60ms
    fp32      [!] SLOW (   0.7 GFLOPS < 1.0 GFLOPS threshold)   28.87ms
    tf32                                              SKIPPED  (NumPy does not support this precision)
    fp16      [!] SLOW (   0.1 GFLOPS < 1.0 GFLOPS threshold)  302.63ms
    fp8                                               SKIPPED  (NumPy does not support this precision)
    fp4                                               SKIPPED  (NumPy does not support this precision)
    bf16                                              SKIPPED  (NumPy does not support this precision)
    int64      [!] SLOW (   0.3 GIOPS < 1.0 GFLOPS threshold)   59.10ms
    int32      [!] SLOW (   0.7 GIOPS < 1.0 GFLOPS threshold)   29.69ms
    int16                                           1.8 GIOPS   11.23ms
    int8                                            3.6 GIOPS    5.55ms
    int4                                              SKIPPED  (NumPy does not support this precision)

BLAS Level 2: GEMV
------------------------------------------------------------------------------------------
  Size     32:
    fp64      [!] SLOW (   0.2 GFLOPS < 1.0 GFLOPS threshold)    0.01ms
    fp32      [!] SLOW (   0.2 GFLOPS < 1.0 GFLOPS threshold)    0.01ms
    tf32                                              SKIPPED  (NumPy does not support this precision)
    fp16      [!] SLOW (   0.1 GFLOPS < 1.0 GFLOPS threshold)    0.02ms
    fp8                                               SKIPPED  (NumPy does not support this precision)
    fp4                                               SKIPPED  (NumPy does not support this precision)
    bf16                                              SKIPPED  (NumPy does not support this precision)
    int64      [!] SLOW (   0.2 GIOPS < 1.0 GFLOPS threshold)    0.01ms
    int32      [!] SLOW (   0.1 GIOPS < 1.0 GFLOPS threshold)    0.01ms
    int16      [!] SLOW (   0.1 GIOPS < 1.0 GFLOPS threshold)    0.01ms
    int8       [!] SLOW (   0.1 GIOPS < 1.0 GFLOPS threshold)    0.01ms
    int4                                              SKIPPED  (NumPy does not support this precision)
  Size     64:
    fp64      [!] SLOW (   0.6 GFLOPS < 1.0 GFLOPS threshold)    0.01ms
    fp32      [!] SLOW (   0.6 GFLOPS < 1.0 GFLOPS threshold)    0.01ms
    tf32                                              SKIPPED  (NumPy does not support this precision)
    fp16      [!] SLOW (   0.2 GFLOPS < 1.0 GFLOPS threshold)    0.04ms
    fp8                                               SKIPPED  (NumPy does not support this precision)
    fp4                                               SKIPPED  (NumPy does not support this precision)
    bf16                                              SKIPPED  (NumPy does not support this precision)
    int64      [!] SLOW (   0.5 GIOPS < 1.0 GFLOPS threshold)    0.02ms
    int32      [!] SLOW (   0.5 GIOPS < 1.0 GFLOPS threshold)    0.02ms
    int16      [!] SLOW (   0.4 GIOPS < 1.0 GFLOPS threshold)    0.02ms
    int8       [!] SLOW (   0.4 GIOPS < 1.0 GFLOPS threshold)    0.02ms
    int4                                              SKIPPED  (NumPy does not support this precision)
  Size    128:
    fp64                                           1.8 GFLOPS    0.02ms
    fp32                                           2.0 GFLOPS    0.02ms
    tf32                                              SKIPPED  (NumPy does not support this precision)
    fp16      [!] SLOW (   0.3 GFLOPS < 1.0 GFLOPS threshold)    0.13ms
    fp8                                               SKIPPED  (NumPy does not support this precision)
    fp4                                               SKIPPED  (NumPy does not support this precision)
    bf16                                              SKIPPED  (NumPy does not support this precision)
    int64      [!] SLOW (   0.9 GIOPS < 1.0 GFLOPS threshold)    0.03ms
    int32      [!] SLOW (   1.0 GIOPS < 1.0 GFLOPS threshold)    0.03ms
    int16      [!] SLOW (   0.6 GIOPS < 1.0 GFLOPS threshold)    0.05ms
    int8       [!] SLOW (   0.7 GIOPS < 1.0 GFLOPS threshold)    0.05ms
    int4                                              SKIPPED  (NumPy does not support this precision)
  Size    256:
    fp64                                           3.7 GFLOPS    0.04ms
    fp32                                           5.0 GFLOPS    0.03ms
    tf32                                              SKIPPED  (NumPy does not support this precision)
    fp16      [!] SLOW (   0.3 GFLOPS < 1.0 GFLOPS threshold)    0.47ms
    fp8                                               SKIPPED  (NumPy does not support this precision)
    fp4                                               SKIPPED  (NumPy does not support this precision)
    bf16                                              SKIPPED  (NumPy does not support this precision)
    int64                                           1.3 GIOPS    0.10ms
    int32                                           1.3 GIOPS    0.10ms
    int16      [!] SLOW (   0.7 GIOPS < 1.0 GFLOPS threshold)    0.18ms
    int8       [!] SLOW (   0.8 GIOPS < 1.0 GFLOPS threshold)    0.17ms
    int4                                              SKIPPED  (NumPy does not support this precision)
  Size    512:
    fp64                                           1.5 GFLOPS    0.34ms
    fp32                                           2.8 GFLOPS    0.19ms
    tf32                                              SKIPPED  (NumPy does not support this precision)
    fp16      [!] SLOW (   0.3 GFLOPS < 1.0 GFLOPS threshold)    1.78ms
    fp8                                               SKIPPED  (NumPy does not support this precision)
    fp4                                               SKIPPED  (NumPy does not support this precision)
    bf16                                              SKIPPED  (NumPy does not support this precision)
    int64                                           1.4 GIOPS    0.37ms
    int32                                           1.4 GIOPS    0.36ms
    int16      [!] SLOW (   0.8 GIOPS < 1.0 GFLOPS threshold)    0.67ms
    int8       [!] SLOW (   0.8 GIOPS < 1.0 GFLOPS threshold)    0.67ms
    int4                                              SKIPPED  (NumPy does not support this precision)
  Size     1K:
    fp64                                           2.1 GFLOPS    0.99ms
    fp32                                           3.3 GFLOPS    0.64ms
    tf32                                              SKIPPED  (NumPy does not support this precision)
    fp16      [!] SLOW (   0.3 GFLOPS < 1.0 GFLOPS threshold)    7.01ms
    fp8                                               SKIPPED  (NumPy does not support this precision)
    fp4                                               SKIPPED  (NumPy does not support this precision)
    bf16                                              SKIPPED  (NumPy does not support this precision)
    int64                                           1.5 GIOPS    1.37ms
    int32                                           1.5 GIOPS    1.37ms
    int16      [!] SLOW (   0.8 GIOPS < 1.0 GFLOPS threshold)    2.66ms
    int8       [!] SLOW (   0.8 GIOPS < 1.0 GFLOPS threshold)    2.65ms
    int4                                              SKIPPED  (NumPy does not support this precision)
  Size     2K:
    fp64                                           2.5 GFLOPS    3.37ms
    fp32                                           5.3 GFLOPS    1.57ms
    tf32                                              SKIPPED  (NumPy does not support this precision)
    fp16      [!] SLOW (   0.3 GFLOPS < 1.0 GFLOPS threshold)   27.77ms
    fp8                                               SKIPPED  (NumPy does not support this precision)
    fp4                                               SKIPPED  (NumPy does not support this precision)
    bf16                                              SKIPPED  (NumPy does not support this precision)
    int64                                           1.5 GIOPS    5.59ms
    int32                                           1.6 GIOPS    5.38ms
    int16      [!] SLOW (   0.8 GIOPS < 1.0 GFLOPS threshold)   10.62ms
    int8       [!] SLOW (   0.8 GIOPS < 1.0 GFLOPS threshold)   10.61ms
    int4                                              SKIPPED  (NumPy does not support this precision)

BLAS Level 3: GEMM
------------------------------------------------------------------------------------------
  Size     32:
    fp64                                           1.6 GFLOPS    0.04ms
    fp32                                           2.8 GFLOPS    0.02ms
    tf32                                              SKIPPED  (NumPy does not support this precision)
    fp16      [!] SLOW (   0.2 GFLOPS < 1.0 GFLOPS threshold)    0.30ms
    fp8                                               SKIPPED  (NumPy does not support this precision)
    fp4                                               SKIPPED  (NumPy does not support this precision)
    bf16                                              SKIPPED  (NumPy does not support this precision)
    int64      [!] SLOW (   0.7 GIOPS < 1.0 GFLOPS threshold)    0.09ms
    int32                                           1.0 GIOPS    0.06ms
    int16      [!] SLOW (   0.7 GIOPS < 1.0 GFLOPS threshold)    0.10ms
    int8       [!] SLOW (   0.8 GIOPS < 1.0 GFLOPS threshold)    0.08ms
    int4                                              SKIPPED  (NumPy does not support this precision)
  Size     64:
    fp64                                           5.3 GFLOPS    0.10ms
    fp32                                           6.5 GFLOPS    0.08ms
    tf32                                              SKIPPED  (NumPy does not support this precision)
    fp16      [!] SLOW (   0.2 GFLOPS < 1.0 GFLOPS threshold)    2.51ms
    fp8                                               SKIPPED  (NumPy does not support this precision)
    fp4                                               SKIPPED  (NumPy does not support this precision)
    bf16                                              SKIPPED  (NumPy does not support this precision)
    int64                                           1.1 GIOPS    0.49ms
    int32                                           1.1 GIOPS    0.47ms
    int16      [!] SLOW (   0.9 GIOPS < 1.0 GFLOPS threshold)    0.58ms
    int8       [!] SLOW (   0.9 GIOPS < 1.0 GFLOPS threshold)    0.56ms
    int4                                              SKIPPED  (NumPy does not support this precision)
  Size    128:
    fp64                                           1.1 GFLOPS    3.93ms
    fp32      [!] SLOW (   0.2 GFLOPS < 1.0 GFLOPS threshold)   26.61ms
    tf32                                              SKIPPED  (NumPy does not support this precision)
    fp16      [!] SLOW (   0.3 GFLOPS < 1.0 GFLOPS threshold)   14.96ms
    fp8                                               SKIPPED  (NumPy does not support this precision)
    fp4                                               SKIPPED  (NumPy does not support this precision)
    bf16                                              SKIPPED  (NumPy does not support this precision)
    int64      [!] SLOW (   0.4 GIOPS < 1.0 GFLOPS threshold)    9.65ms
    int32                                           1.2 GIOPS    3.56ms
    int16      [!] SLOW (   0.7 GIOPS < 1.0 GFLOPS threshold)    5.82ms
    int8       [!] SLOW (   0.9 GIOPS < 1.0 GFLOPS threshold)    4.87ms
    int4                                              SKIPPED  (NumPy does not support this precision)
  Size    256:
    fp64                                           6.7 GFLOPS    5.04ms
    fp32                                           9.9 GFLOPS    3.41ms
    tf32                                              SKIPPED  (NumPy does not support this precision)
    fp16      [!] SLOW (   0.3 GFLOPS < 1.0 GFLOPS threshold)  116.70ms
    fp8                                               SKIPPED  (NumPy does not support this precision)
    fp4                                               SKIPPED  (NumPy does not support this precision)
    bf16                                              SKIPPED  (NumPy does not support this precision)
    int64      [!] SLOW (   0.5 GIOPS < 1.0 GFLOPS threshold)   66.36ms
    int32      [!] SLOW (   0.6 GIOPS < 1.0 GFLOPS threshold)   59.31ms
    int16      [!] SLOW (   0.6 GIOPS < 1.0 GFLOPS threshold)   58.46ms
    int8       [!] SLOW (   0.7 GIOPS < 1.0 GFLOPS threshold)   48.80ms
    int4                                              SKIPPED  (NumPy does not support this precision)
  Size    512:
    fp64                                           3.3 GFLOPS   82.48ms
    fp32                                          23.1 GFLOPS   11.63ms
    tf32                                              SKIPPED  (NumPy does not support this precision)
    fp16                                              SKIPPED  (Skipped (poor performance at size 256: 0.3 GFLOPS < 1.0 GFLOPS))
    fp8                                               SKIPPED  (NumPy does not support this precision)
    fp4                                               SKIPPED  (NumPy does not support this precision)
    bf16                                              SKIPPED  (NumPy does not support this precision)
    int64                                             SKIPPED  (Skipped (poor performance at size 256: 0.5 GFLOPS < 1.0 GFLOPS))
    int32                                             SKIPPED  (Skipped (poor performance at size 256: 0.6 GFLOPS < 1.0 GFLOPS))
    int16                                             SKIPPED  (Skipped (poor performance at size 256: 0.6 GFLOPS < 1.0 GFLOPS))
    int8                                              SKIPPED  (Skipped (poor performance at size 256: 0.7 GFLOPS < 1.0 GFLOPS))
    int4                                              SKIPPED  (NumPy does not support this precision)
  Size     1K:
    fp64                                           9.9 GFLOPS  217.01ms
    fp32                                          21.4 GFLOPS  100.33ms
    tf32                                              SKIPPED  (NumPy does not support this precision)
    fp16                                              SKIPPED  (Skipped (poor performance at size 256: 0.3 GFLOPS < 1.0 GFLOPS))
    fp8                                               SKIPPED  (NumPy does not support this precision)
    fp4                                               SKIPPED  (NumPy does not support this precision)
    bf16                                              SKIPPED  (NumPy does not support this precision)
    int64                                             SKIPPED  (Skipped (poor performance at size 256: 0.5 GFLOPS < 1.0 GFLOPS))
    int32                                             SKIPPED  (Skipped (poor performance at size 256: 0.6 GFLOPS < 1.0 GFLOPS))
    int16                                             SKIPPED  (Skipped (poor performance at size 256: 0.6 GFLOPS < 1.0 GFLOPS))
    int8                                              SKIPPED  (Skipped (poor performance at size 256: 0.7 GFLOPS < 1.0 GFLOPS))
    int4                                              SKIPPED  (NumPy does not support this precision)
  Size     2K... ALL PRECISIONS FAILED

==========================================================================================
BLAS Suite Complete: 23 calibrations
==========================================================================================

Building precision capability matrix...

Calibration saved to: /home/lanner/dev/branes/clones/graphs/hardware_registry/cpu/jetson_orin_nx_16gb_cpu/calibrations/pending_numpy.json

================================================================================
Hardware Calibration: Jetson Orin NX 16GB (CPU)
Date: 2026-01-28T09:47:19.785042
================================================================================

Framework: NUMPY
Device:    CPU

Theoretical Specifications:
  Peak GFLOPS (FP32): 243.2
  Peak Bandwidth:     102.0 GB/s

STREAM Memory Bandwidth Benchmark:
  Kernel           Size (MB)    Bandwidth    Latency   Efficiency Description
  -----------------------------------------------------------------------------------------------
  COPY                    64       12.7 GB/s    10.59 ms       12.4%  a[i] = b[i]
  SCALE                    8       12.7 GB/s     1.32 ms       12.4%  a[i] = q * b[i]
  ADD                    512       10.7 GB/s   150.65 ms       10.5%  a[i] = b[i] + c[i]
  TRIAD                    8        5.4 GB/s     4.66 ms        5.3%  a[i] = b[i] + q * c[i]

  STREAM Score (minimum): 4.0 GB/s

BLAS Performance Summary (Highest Throughput by Precision):
  Operation          fp64       fp32       tf32       fp16        fp8        fp4       bf16      int64      int32      int16       int8       int4   Best Precision
  ------------------------------------------------------------------------------------------------------------------------------------------------------------------
  AXPY                0.6        1.1        N/A        0.1        N/A        N/A        N/A        0.5        1.1        2.1        4.4        N/A             int8
  DOT                 1.8        3.7        N/A        0.3        N/A        N/A        N/A        1.5        1.6        1.6        2.0        N/A             fp32
  GEMV                3.7        5.3        N/A        0.3        N/A        N/A        N/A        1.5        1.6        0.8        0.8        N/A             fp32
  GEMM                9.9       23.1        N/A        0.3        N/A        N/A        N/A        1.1        1.2        0.9        0.9        N/A             fp32

BLAS Compute Performance (by Operation and Precision):
========================================================================================================================

Level 1: Vector-Vector (O(n))
------------------------------------------------------------------------------------------------------------------------

AXPY:
  Precision   Best Size Highest Throughput    Latency       AI   Efficiency
  --------------------------------------------------------------------------------
  fp64             100K         0.6 GFLOPS     0.36ms     0.08        0.5%
  fp32              10K         1.1 GFLOPS     0.02ms     0.17        0.5%
  fp16              10M         0.1 GFLOPS   302.63ms     0.33        0.0%
  int64            100K          0.5 GIOPS     0.37ms     0.08        0.4%
  int32             10K          1.1 GIOPS     0.02ms     0.17        0.5%
  int16              1M          2.1 GIOPS     0.95ms     0.33        0.4%
  int8               1M          4.4 GIOPS     0.45ms     0.67        0.5%

DOT:
  Precision   Best Size Highest Throughput    Latency       AI   Efficiency
  --------------------------------------------------------------------------------
  fp64             100K         1.8 GFLOPS     0.11ms     0.12        1.4%
  fp32             100K         3.7 GFLOPS     0.05ms     0.25        1.5%
  fp16               1M         0.3 GFLOPS     6.47ms     0.50        0.1%
  int64            100K          1.5 GIOPS     0.13ms     0.12        1.2%
  int32             10M          1.6 GIOPS    12.36ms     0.25        0.7%
  int16              1M          1.6 GIOPS     1.22ms     0.50        0.3%
  int8              10M          2.0 GIOPS     9.89ms     1.00        0.2%

Level 2: Matrix-Vector (O(n²))
------------------------------------------------------------------------------------------------------------------------

GEMV:
  Precision   Best Size Highest Throughput    Latency       AI   Efficiency
  --------------------------------------------------------------------------------
  fp64              256         3.7 GFLOPS     0.04ms     0.25        3.1%
  fp32               2K         5.3 GFLOPS     1.57ms     0.50        2.2%
  fp16               2K         0.3 GFLOPS    27.77ms     1.00        0.1%
  int64              1K          1.5 GIOPS     1.37ms     0.25        1.3%
  int32              2K          1.6 GIOPS     5.38ms     0.50        0.6%
  int16              2K          0.8 GIOPS    10.62ms     1.00        0.2%
  int8               2K          0.8 GIOPS    10.61ms     2.00        0.1%

Level 3: Matrix-Matrix (O(n³))
------------------------------------------------------------------------------------------------------------------------

GEMM:
  Precision   Best Size Highest Throughput    Latency       AI   Efficiency
  --------------------------------------------------------------------------------
  fp64               1K         9.9 GFLOPS   217.01ms    85.33        8.1%
  fp32              512        23.1 GFLOPS    11.63ms    85.33        9.5%
  fp16              256         0.3 GFLOPS   116.70ms    85.33        0.1%
  int64              64          1.1 GIOPS     0.49ms     5.33        0.9%
  int32             128          1.2 GIOPS     3.56ms    21.33        0.5%
  int16              64          0.9 GIOPS     0.58ms    21.33        0.2%
  int8               64          0.9 GIOPS     0.56ms    42.67        0.1%

Precision Support Summary:
  Supported:   fp64, fp32, fp16, int64, int32, int16, int8
  Unsupported: tf32, fp8, fp4, bf16, int4


================================================================================
Calibration Complete!
================================================================================

Calibration file: /home/lanner/dev/branes/clones/graphs/hardware_registry/cpu/jetson_orin_nx_16gb_cpu/calibrations/schedutil_960MHz_numpy.json

Next steps:
  1. Review the calibration results above
  2. View calibration efficiency:
     ./cli/show_calibration_efficiency.py --id jetson_orin_nx_16gb_cpu

  3. Use in analysis (calibration auto-loaded from registry):
     ./cli/analyze_comprehensive.py --model resnet18 --hardware jetson_orin_nx_16gb_cpu

