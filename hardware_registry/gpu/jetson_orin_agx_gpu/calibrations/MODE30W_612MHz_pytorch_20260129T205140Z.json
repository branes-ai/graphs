{
  "metadata": {
    "hardware_name": "Jetson Orin AGX (GPU)",
    "calibration_date": "2026-01-29T20:46:36.380214",
    "calibration_tool_version": "1.0.0",
    "cpu_model": "aarch64",
    "cpu_count": 8,
    "total_memory_gb": 61.32390213012695,
    "python_version": "3.8.10",
    "pytorch_version": "2.1.0a0+41361538.nv23.06",
    "numpy_version": "1.24.4",
    "num_warmup_runs": 3,
    "num_measurement_runs": 10,
    "device_type": "cuda",
    "platform_architecture": "aarch64",
    "framework": "pytorch",
    "gpu_clock": {
      "sm_clock_mhz": 612,
      "query_method": "sysfs_under_load",
      "max_sm_clock_mhz": 612,
      "nvpmodel_mode": 30,
      "power_mode_name": "MODE_30W"
    },
    "cpu_clock": {
      "current_freq_mhz": 1216.0,
      "query_method": "sysfs",
      "min_freq_mhz": 1728.0,
      "max_freq_mhz": 1728.0,
      "base_freq_mhz": 2201.6,
      "per_core_freq_mhz": [
        1728.0,
        1728.0,
        1728.0,
        1728.0,
        1728.0,
        1728.0,
        1728.0,
        1728.0,
        192.0,
        192.0,
        192.0,
        192.0
      ],
      "governor": "schedutil",
      "driver": "tegra194",
      "nvpmodel_mode": 30,
      "power_mode_name": "MODE_30W"
    },
    "preflight": {
      "timestamp": "2026-01-29T20:46:32.793675",
      "passed": true,
      "forced": false,
      "checks": [
        {
          "name": "CPU Governor",
          "status": "passed",
          "message": "schedutil (Jetson default)",
          "current_value": "schedutil",
          "expected_value": "schedutil or performance"
        },
        {
          "name": "CPU Frequency",
          "status": "passed",
          "message": "1216 MHz idle (DVFS will boost under load)",
          "current_value": "1216 MHz (idle)",
          "expected_value": "Up to 1728 MHz under load"
        },
        {
          "name": "Turbo Boost",
          "status": "skipped",
          "message": "Could not determine (not Intel pstate)"
        },
        {
          "name": "System Load",
          "status": "passed",
          "message": "0.3% (idle)",
          "current_value": "0.3%",
          "expected_value": "< 5%"
        },
        {
          "name": "Thermal State",
          "status": "passed",
          "message": "41\u00b0C (cool)",
          "current_value": "41\u00b0C",
          "expected_value": "< 80\u00b0C"
        },
        {
          "name": "GPU Power Mode",
          "status": "warning",
          "message": "MODE_30W (unknown mode)",
          "current_value": "MODE_30W",
          "expected_value": "Known mode (MAXN, 7W, 15W, 25W, etc.)"
        }
      ]
    }
  },
  "theoretical_peak_gflops": 5325.0,
  "theoretical_bandwidth_gbps": 204.8,
  "best_measured_gflops": 5627.315754605452,
  "avg_measured_gflops": 220.81269652054584,
  "worst_measured_gflops": 0.008192386677873257,
  "measured_bandwidth_gbps": 128.00424830653924,
  "bandwidth_efficiency": 0.6250207436842736,
  "best_efficiency": 0.6250207436842736,
  "avg_efficiency": 0.24121422430116274,
  "worst_efficiency": 6.413963937509037e-07,
  "operation_profiles": {
    "stream_copy_device=cuda_flops_per_element=0_framework=pytorch_kernel=copy_num_arrays=2_num_memory_ops=2_size_mb=8": {
      "operation_type": "stream_copy",
      "measured_gflops": 0.0,
      "efficiency": 0.3020210196889887,
      "achieved_bandwidth_gbps": 61.85390483230489,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.0,
      "batch_size": 1,
      "input_shape": [
        2097152
      ],
      "output_shape": [
        2097152
      ],
      "mean_latency_ms": 0.27123939944431186,
      "std_latency_ms": 0.0034915972866962474,
      "min_latency_ms": 0.2666889922693372,
      "max_latency_ms": 0.2768010017462075,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 8,
        "kernel": "copy",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 2,
        "num_memory_ops": 2,
        "flops_per_element": 0
      },
      "precision_results": {}
    },
    "stream_copy_device=cuda_flops_per_element=0_framework=pytorch_kernel=copy_num_arrays=2_num_memory_ops=2_size_mb=16": {
      "operation_type": "stream_copy",
      "measured_gflops": 0.0,
      "efficiency": 0.3480802134432818,
      "achieved_bandwidth_gbps": 71.28682771318412,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.0,
      "batch_size": 1,
      "input_shape": [
        4194304
      ],
      "output_shape": [
        4194304
      ],
      "mean_latency_ms": 0.4706961030024104,
      "std_latency_ms": 0.003058708078624033,
      "min_latency_ms": 0.4663059953600168,
      "max_latency_ms": 0.47510600415989757,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 16,
        "kernel": "copy",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 2,
        "num_memory_ops": 2,
        "flops_per_element": 0
      },
      "precision_results": {}
    },
    "stream_copy_device=cuda_flops_per_element=0_framework=pytorch_kernel=copy_num_arrays=2_num_memory_ops=2_size_mb=32": {
      "operation_type": "stream_copy",
      "measured_gflops": 0.0,
      "efficiency": 0.37524693842479157,
      "achieved_bandwidth_gbps": 76.85057298939732,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.0,
      "batch_size": 1,
      "input_shape": [
        8388608
      ],
      "output_shape": [
        8388608
      ],
      "mean_latency_ms": 0.873238303756807,
      "std_latency_ms": 0.010368991028733026,
      "min_latency_ms": 0.8668829977978021,
      "max_latency_ms": 0.902147003216669,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 32,
        "kernel": "copy",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 2,
        "num_memory_ops": 2,
        "flops_per_element": 0
      },
      "precision_results": {}
    },
    "stream_copy_device=cuda_flops_per_element=0_framework=pytorch_kernel=copy_num_arrays=2_num_memory_ops=2_size_mb=64": {
      "operation_type": "stream_copy",
      "measured_gflops": 0.0,
      "efficiency": 0.39178415402137845,
      "achieved_bandwidth_gbps": 80.2373947435783,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.0,
      "batch_size": 1,
      "input_shape": [
        16777216
      ],
      "output_shape": [
        16777216
      ],
      "mean_latency_ms": 1.6727578011341393,
      "std_latency_ms": 0.0035683937551285417,
      "min_latency_ms": 1.669702003709972,
      "max_latency_ms": 1.6815419949125499,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 64,
        "kernel": "copy",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 2,
        "num_memory_ops": 2,
        "flops_per_element": 0
      },
      "precision_results": {}
    },
    "stream_copy_device=cuda_flops_per_element=0_framework=pytorch_kernel=copy_num_arrays=2_num_memory_ops=2_size_mb=128": {
      "operation_type": "stream_copy",
      "measured_gflops": 0.0,
      "efficiency": 0.3947724932639282,
      "achieved_bandwidth_gbps": 80.8494066204525,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.0,
      "batch_size": 1,
      "input_shape": [
        33554432
      ],
      "output_shape": [
        33554432
      ],
      "mean_latency_ms": 3.320190799422562,
      "std_latency_ms": 0.00421588332271656,
      "min_latency_ms": 3.3143159962492064,
      "max_latency_ms": 3.3280760108027607,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 128,
        "kernel": "copy",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 2,
        "num_memory_ops": 2,
        "flops_per_element": 0
      },
      "precision_results": {}
    },
    "stream_copy_device=cuda_flops_per_element=0_framework=pytorch_kernel=copy_num_arrays=2_num_memory_ops=2_size_mb=256": {
      "operation_type": "stream_copy",
      "measured_gflops": 0.0,
      "efficiency": 0.34355479986440046,
      "achieved_bandwidth_gbps": 70.36002301222922,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.0,
      "batch_size": 1,
      "input_shape": [
        67108864
      ],
      "output_shape": [
        67108864
      ],
      "mean_latency_ms": 7.630340199102648,
      "std_latency_ms": 0.008475086759057306,
      "min_latency_ms": 7.6135309936944395,
      "max_latency_ms": 7.6418829994509,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 256,
        "kernel": "copy",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 2,
        "num_memory_ops": 2,
        "flops_per_element": 0
      },
      "precision_results": {}
    },
    "stream_copy_device=cuda_flops_per_element=0_framework=pytorch_kernel=copy_num_arrays=2_num_memory_ops=2_size_mb=512": {
      "operation_type": "stream_copy",
      "measured_gflops": 0.0,
      "efficiency": 0.34503370757811486,
      "achieved_bandwidth_gbps": 70.66290331199792,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.0,
      "batch_size": 1,
      "input_shape": [
        134217728
      ],
      "output_shape": [
        134217728
      ],
      "mean_latency_ms": 15.19526899792254,
      "std_latency_ms": 0.015507824007772356,
      "min_latency_ms": 15.173620995483361,
      "max_latency_ms": 15.21608499751892,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 512,
        "kernel": "copy",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 2,
        "num_memory_ops": 2,
        "flops_per_element": 0
      },
      "precision_results": {}
    },
    "stream_scale_device=cuda_flops_per_element=1_framework=pytorch_kernel=scale_num_arrays=2_num_memory_ops=2_size_mb=8": {
      "operation_type": "stream_scale",
      "measured_gflops": 7.8333049698574495,
      "efficiency": 0.3059884753850566,
      "achieved_bandwidth_gbps": 62.666439758859596,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.5,
      "batch_size": 1,
      "input_shape": [
        2097152
      ],
      "output_shape": [
        2097152
      ],
      "mean_latency_ms": 0.2677225013030693,
      "std_latency_ms": 0.1902051497334711,
      "min_latency_ms": 0.20105700241401792,
      "max_latency_ms": 0.8079389954218641,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 8,
        "kernel": "scale",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 2,
        "num_memory_ops": 2,
        "flops_per_element": 1
      },
      "precision_results": {}
    },
    "stream_scale_device=cuda_flops_per_element=1_framework=pytorch_kernel=scale_num_arrays=2_num_memory_ops=2_size_mb=16": {
      "operation_type": "stream_scale",
      "measured_gflops": 12.762314407505588,
      "efficiency": 0.498527906543187,
      "achieved_bandwidth_gbps": 102.0985152600447,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.5,
      "batch_size": 1,
      "input_shape": [
        4194304
      ],
      "output_shape": [
        4194304
      ],
      "mean_latency_ms": 0.32864759996300563,
      "std_latency_ms": 0.0017194962659768816,
      "min_latency_ms": 0.3266259882366285,
      "max_latency_ms": 0.3327370068291202,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 16,
        "kernel": "scale",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 2,
        "num_memory_ops": 2,
        "flops_per_element": 1
      },
      "precision_results": {}
    },
    "stream_scale_device=cuda_flops_per_element=1_framework=pytorch_kernel=scale_num_arrays=2_num_memory_ops=2_size_mb=32": {
      "operation_type": "stream_scale",
      "measured_gflops": 14.357947689486995,
      "efficiency": 0.5608573316205857,
      "achieved_bandwidth_gbps": 114.86358151589596,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.5,
      "batch_size": 1,
      "input_shape": [
        8388608
      ],
      "output_shape": [
        8388608
      ],
      "mean_latency_ms": 0.5842484024469741,
      "std_latency_ms": 0.004338933688804505,
      "min_latency_ms": 0.5796180048491806,
      "max_latency_ms": 0.5938899994362146,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 32,
        "kernel": "scale",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 2,
        "num_memory_ops": 2,
        "flops_per_element": 1
      },
      "precision_results": {}
    },
    "stream_scale_device=cuda_flops_per_element=1_framework=pytorch_kernel=scale_num_arrays=2_num_memory_ops=2_size_mb=64": {
      "operation_type": "stream_scale",
      "measured_gflops": 15.431709756881409,
      "efficiency": 0.60280116237818,
      "achieved_bandwidth_gbps": 123.45367805505127,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.5,
      "batch_size": 1,
      "input_shape": [
        16777216
      ],
      "output_shape": [
        16777216
      ],
      "mean_latency_ms": 1.0871910024434328,
      "std_latency_ms": 0.005950367296420984,
      "min_latency_ms": 1.0820189927471802,
      "max_latency_ms": 1.102884009014815,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 64,
        "kernel": "scale",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 2,
        "num_memory_ops": 2,
        "flops_per_element": 1
      },
      "precision_results": {}
    },
    "stream_scale_device=cuda_flops_per_element=1_framework=pytorch_kernel=scale_num_arrays=2_num_memory_ops=2_size_mb=128": {
      "operation_type": "stream_scale",
      "measured_gflops": 15.849827512604051,
      "efficiency": 0.6191338872110957,
      "achieved_bandwidth_gbps": 126.79862010083241,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.5,
      "batch_size": 1,
      "input_shape": [
        33554432
      ],
      "output_shape": [
        33554432
      ],
      "mean_latency_ms": 2.117021902813576,
      "std_latency_ms": 0.00368375666092791,
      "min_latency_ms": 2.113383001415059,
      "max_latency_ms": 2.1261509973555803,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 128,
        "kernel": "scale",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 2,
        "num_memory_ops": 2,
        "flops_per_element": 1
      },
      "precision_results": {}
    },
    "stream_scale_device=cuda_flops_per_element=1_framework=pytorch_kernel=scale_num_arrays=2_num_memory_ops=2_size_mb=256": {
      "operation_type": "stream_scale",
      "measured_gflops": 14.478284179902587,
      "efficiency": 0.5655579757774448,
      "achieved_bandwidth_gbps": 115.8262734392207,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.5,
      "batch_size": 1,
      "input_shape": [
        67108864
      ],
      "output_shape": [
        67108864
      ],
      "mean_latency_ms": 4.635139300080482,
      "std_latency_ms": 0.004066480097530339,
      "min_latency_ms": 4.626959998859093,
      "max_latency_ms": 4.640592000214383,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 256,
        "kernel": "scale",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 2,
        "num_memory_ops": 2,
        "flops_per_element": 1
      },
      "precision_results": {}
    },
    "stream_scale_device=cuda_flops_per_element=1_framework=pytorch_kernel=scale_num_arrays=2_num_memory_ops=2_size_mb=512": {
      "operation_type": "stream_scale",
      "measured_gflops": 14.630046066070568,
      "efficiency": 0.5714861744558816,
      "achieved_bandwidth_gbps": 117.04036852856454,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.5,
      "batch_size": 1,
      "input_shape": [
        134217728
      ],
      "output_shape": [
        134217728
      ],
      "mean_latency_ms": 9.17411520058522,
      "std_latency_ms": 0.011797491140032508,
      "min_latency_ms": 9.151456004474312,
      "max_latency_ms": 9.192896002787165,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 512,
        "kernel": "scale",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 2,
        "num_memory_ops": 2,
        "flops_per_element": 1
      },
      "precision_results": {}
    },
    "stream_add_device=cuda_flops_per_element=1_framework=pytorch_kernel=add_num_arrays=3_num_memory_ops=3_size_mb=8": {
      "operation_type": "stream_add",
      "measured_gflops": 8.242465754754589,
      "efficiency": 0.4829569778176516,
      "achieved_bandwidth_gbps": 98.90958905705506,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.3333333333333333,
      "batch_size": 1,
      "input_shape": [
        2097152
      ],
      "output_shape": [
        2097152
      ],
      "mean_latency_ms": 0.25443260092288256,
      "std_latency_ms": 0.0017383639196772054,
      "min_latency_ms": 0.2517120010452345,
      "max_latency_ms": 0.25667299632914364,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 8,
        "kernel": "add",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 3,
        "num_memory_ops": 3,
        "flops_per_element": 1
      },
      "precision_results": {}
    },
    "stream_add_device=cuda_flops_per_element=1_framework=pytorch_kernel=add_num_arrays=3_num_memory_ops=3_size_mb=16": {
      "operation_type": "stream_add",
      "measured_gflops": 9.497730156559173,
      "efficiency": 0.5565076263608891,
      "achieved_bandwidth_gbps": 113.9727618787101,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.3333333333333333,
      "batch_size": 1,
      "input_shape": [
        4194304
      ],
      "output_shape": [
        4194304
      ],
      "mean_latency_ms": 0.4416111987666227,
      "std_latency_ms": 0.001712675145981118,
      "min_latency_ms": 0.4388499946799129,
      "max_latency_ms": 0.44393799907993525,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 16,
        "kernel": "add",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 3,
        "num_memory_ops": 3,
        "flops_per_element": 1
      },
      "precision_results": {}
    },
    "stream_add_device=cuda_flops_per_element=1_framework=pytorch_kernel=add_num_arrays=3_num_memory_ops=3_size_mb=32": {
      "operation_type": "stream_add",
      "measured_gflops": 10.237962908391923,
      "efficiency": 0.5998806391635894,
      "achieved_bandwidth_gbps": 122.8555549007031,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.3333333333333333,
      "batch_size": 1,
      "input_shape": [
        8388608
      ],
      "output_shape": [
        8388608
      ],
      "mean_latency_ms": 0.8193629997549579,
      "std_latency_ms": 0.0014025797586344113,
      "min_latency_ms": 0.8173469977919012,
      "max_latency_ms": 0.8216350106522441,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 32,
        "kernel": "add",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 3,
        "num_memory_ops": 3,
        "flops_per_element": 1
      },
      "precision_results": {}
    },
    "stream_add_device=cuda_flops_per_element=1_framework=pytorch_kernel=add_num_arrays=3_num_memory_ops=3_size_mb=64": {
      "operation_type": "stream_add",
      "measured_gflops": 10.667020692211604,
      "efficiency": 0.6250207436842736,
      "achieved_bandwidth_gbps": 128.00424830653924,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.3333333333333333,
      "batch_size": 1,
      "input_shape": [
        16777216
      ],
      "output_shape": [
        16777216
      ],
      "mean_latency_ms": 1.5728117985418066,
      "std_latency_ms": 0.0010583901201580502,
      "min_latency_ms": 1.571749002323486,
      "max_latency_ms": 1.574724999954924,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 64,
        "kernel": "add",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 3,
        "num_memory_ops": 3,
        "flops_per_element": 1
      },
      "precision_results": {}
    },
    "stream_add_device=cuda_flops_per_element=1_framework=pytorch_kernel=add_num_arrays=3_num_memory_ops=3_size_mb=128": {
      "operation_type": "stream_add",
      "measured_gflops": 10.465358119332787,
      "efficiency": 0.6132045773046554,
      "achieved_bandwidth_gbps": 125.58429743199342,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.3333333333333333,
      "batch_size": 1,
      "input_shape": [
        33554432
      ],
      "output_shape": [
        33554432
      ],
      "mean_latency_ms": 3.2062382975709625,
      "std_latency_ms": 0.005566779579467042,
      "min_latency_ms": 3.1925549992593005,
      "max_latency_ms": 3.2116590009536594,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 128,
        "kernel": "add",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 3,
        "num_memory_ops": 3,
        "flops_per_element": 1
      },
      "precision_results": {}
    },
    "stream_add_device=cuda_flops_per_element=1_framework=pytorch_kernel=add_num_arrays=3_num_memory_ops=3_size_mb=256": {
      "operation_type": "stream_add",
      "measured_gflops": 10.572640839322274,
      "efficiency": 0.6194906741790394,
      "achieved_bandwidth_gbps": 126.87169007186728,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.3333333333333333,
      "batch_size": 1,
      "input_shape": [
        67108864
      ],
      "output_shape": [
        67108864
      ],
      "mean_latency_ms": 6.347407901193947,
      "std_latency_ms": 0.009831482452474892,
      "min_latency_ms": 6.334581994451582,
      "max_latency_ms": 6.365558001562022,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 256,
        "kernel": "add",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 3,
        "num_memory_ops": 3,
        "flops_per_element": 1
      },
      "precision_results": {}
    },
    "stream_add_device=cuda_flops_per_element=1_framework=pytorch_kernel=add_num_arrays=3_num_memory_ops=3_size_mb=512": {
      "operation_type": "stream_add",
      "measured_gflops": 10.618868008068869,
      "efficiency": 0.6221992973477852,
      "achieved_bandwidth_gbps": 127.42641609682642,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.3333333333333333,
      "batch_size": 1,
      "input_shape": [
        134217728
      ],
      "output_shape": [
        134217728
      ],
      "mean_latency_ms": 12.639551400206983,
      "std_latency_ms": 0.007873647237454493,
      "min_latency_ms": 12.626572002773173,
      "max_latency_ms": 12.65070000954438,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 512,
        "kernel": "add",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 3,
        "num_memory_ops": 3,
        "flops_per_element": 1
      },
      "precision_results": {}
    },
    "stream_triad_device=cuda_flops_per_element=2_framework=pytorch_kernel=triad_num_arrays=3_num_memory_ops=3_size_mb=8": {
      "operation_type": "stream_triad",
      "measured_gflops": 10.51399538528427,
      "efficiency": 0.3080272085532501,
      "achieved_bandwidth_gbps": 63.08397231170562,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.6666666666666666,
      "batch_size": 1,
      "input_shape": [
        2097152
      ],
      "output_shape": [
        2097152
      ],
      "mean_latency_ms": 0.398925798072014,
      "std_latency_ms": 0.0020184656852727297,
      "min_latency_ms": 0.3959689929615706,
      "max_latency_ms": 0.40214500040747225,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 8,
        "kernel": "triad",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 3,
        "num_memory_ops": 3,
        "flops_per_element": 2
      },
      "precision_results": {}
    },
    "stream_triad_device=cuda_flops_per_element=2_framework=pytorch_kernel=triad_num_arrays=3_num_memory_ops=3_size_mb=16": {
      "operation_type": "stream_triad",
      "measured_gflops": 11.752767060954712,
      "efficiency": 0.3443193474889076,
      "achieved_bandwidth_gbps": 70.51660236572828,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.6666666666666666,
      "batch_size": 1,
      "input_shape": [
        4194304
      ],
      "output_shape": [
        4194304
      ],
      "mean_latency_ms": 0.7137559994589537,
      "std_latency_ms": 0.0023918913883743615,
      "min_latency_ms": 0.7112340099411085,
      "max_latency_ms": 0.7178910018410534,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 16,
        "kernel": "triad",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 3,
        "num_memory_ops": 3,
        "flops_per_element": 2
      },
      "precision_results": {}
    },
    "stream_triad_device=cuda_flops_per_element=2_framework=pytorch_kernel=triad_num_arrays=3_num_memory_ops=3_size_mb=32": {
      "operation_type": "stream_triad",
      "measured_gflops": 12.482319489171724,
      "efficiency": 0.36569295378432787,
      "achieved_bandwidth_gbps": 74.89391693503035,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.6666666666666666,
      "batch_size": 1,
      "input_shape": [
        8388608
      ],
      "output_shape": [
        8388608
      ],
      "mean_latency_ms": 1.3440783994155936,
      "std_latency_ms": 0.00168889540519946,
      "min_latency_ms": 1.3411569962045178,
      "max_latency_ms": 1.3461810012813658,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 32,
        "kernel": "triad",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 3,
        "num_memory_ops": 3,
        "flops_per_element": 2
      },
      "precision_results": {}
    },
    "stream_triad_device=cuda_flops_per_element=2_framework=pytorch_kernel=triad_num_arrays=3_num_memory_ops=3_size_mb=64": {
      "operation_type": "stream_triad",
      "measured_gflops": 12.848497518544068,
      "efficiency": 0.3764208257385957,
      "achieved_bandwidth_gbps": 77.0909851112644,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.6666666666666666,
      "batch_size": 1,
      "input_shape": [
        16777216
      ],
      "output_shape": [
        16777216
      ],
      "mean_latency_ms": 2.6115451983059756,
      "std_latency_ms": 0.0065484871316790465,
      "min_latency_ms": 2.604392997454852,
      "max_latency_ms": 2.6235929981339723,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 64,
        "kernel": "triad",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 3,
        "num_memory_ops": 3,
        "flops_per_element": 2
      },
      "precision_results": {}
    },
    "stream_triad_device=cuda_flops_per_element=2_framework=pytorch_kernel=triad_num_arrays=3_num_memory_ops=3_size_mb=128": {
      "operation_type": "stream_triad",
      "measured_gflops": 12.749847671598845,
      "efficiency": 0.37353069350387236,
      "achieved_bandwidth_gbps": 76.49908602959306,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.6666666666666666,
      "batch_size": 1,
      "input_shape": [
        33554432
      ],
      "output_shape": [
        33554432
      ],
      "mean_latency_ms": 5.2635031985118985,
      "std_latency_ms": 0.0028794482959650534,
      "min_latency_ms": 5.257905999314971,
      "max_latency_ms": 5.268594002700411,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 128,
        "kernel": "triad",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 3,
        "num_memory_ops": 3,
        "flops_per_element": 2
      },
      "precision_results": {}
    },
    "stream_triad_device=cuda_flops_per_element=2_framework=pytorch_kernel=triad_num_arrays=3_num_memory_ops=3_size_mb=256": {
      "operation_type": "stream_triad",
      "measured_gflops": 12.400067507550437,
      "efficiency": 0.3632832277602667,
      "achieved_bandwidth_gbps": 74.40040504530263,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.6666666666666666,
      "batch_size": 1,
      "input_shape": [
        67108864
      ],
      "output_shape": [
        67108864
      ],
      "mean_latency_ms": 10.823951395286713,
      "std_latency_ms": 0.008509791209430193,
      "min_latency_ms": 10.810149993631057,
      "max_latency_ms": 10.841925992281176,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 256,
        "kernel": "triad",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 3,
        "num_memory_ops": 3,
        "flops_per_element": 2
      },
      "precision_results": {}
    },
    "stream_triad_device=cuda_flops_per_element=2_framework=pytorch_kernel=triad_num_arrays=3_num_memory_ops=3_size_mb=512": {
      "operation_type": "stream_triad",
      "measured_gflops": 12.451935382326441,
      "efficiency": 0.36480279440409497,
      "achieved_bandwidth_gbps": 74.71161229395865,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.6666666666666666,
      "batch_size": 1,
      "input_shape": [
        134217728
      ],
      "output_shape": [
        134217728
      ],
      "mean_latency_ms": 21.55772960250033,
      "std_latency_ms": 0.009031959802154852,
      "min_latency_ms": 21.546347008552402,
      "max_latency_ms": 21.57201101363171,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 512,
        "kernel": "triad",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 3,
        "num_memory_ops": 3,
        "flops_per_element": 2
      },
      "precision_results": {}
    },
    "blas1_dot_best_precision=tf32_blas_level=1_device=cuda_framework=pytorch_operation=dot_size=1000": {
      "operation_type": "blas1_dot",
      "measured_gflops": 0.028039363100113037,
      "efficiency": 2.6328040469589706e-06,
      "achieved_bandwidth_gbps": 0.11215745240045215,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.25,
      "batch_size": 1,
      "input_shape": [
        1000
      ],
      "output_shape": [
        1000
      ],
      "mean_latency_ms": 0.07132829632610083,
      "std_latency_ms": 0.004019537216260198,
      "min_latency_ms": 0.06351999763865024,
      "max_latency_ms": 0.07534783354236102,
      "num_trials": 10,
      "extra_params": {
        "size": 1000,
        "operation": "dot",
        "blas_level": 1,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "tf32"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.026647906765585497,
          "efficiency": 0.00016052955882882829,
          "mean_latency_ms": 0.07505279936594889,
          "std_latency_ms": 0.0027560994870647598,
          "min_latency_ms": 0.07116798951756209,
          "max_latency_ms": 0.07780889885301365,
          "speedup_vs_fp32": null,
          "test_size": 1000,
          "num_trials": 10,
          "arithmetic_intensity": 0.5,
          "achieved_bandwidth_gbps": 0.053295813531170994
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.02785689962872251,
          "efficiency": 5.231342653281222e-06,
          "mean_latency_ms": 0.07179549866123125,
          "std_latency_ms": 0.0036945380118772893,
          "min_latency_ms": 0.06640100036747754,
          "max_latency_ms": 0.07549003667310854,
          "speedup_vs_fp32": 1.0,
          "test_size": 1000,
          "num_trials": 10,
          "arithmetic_intensity": 0.25,
          "achieved_bandwidth_gbps": 0.11142759851489004
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.028039363100113037,
          "efficiency": 2.6328040469589706e-06,
          "mean_latency_ms": 0.07132829632610083,
          "std_latency_ms": 0.004019537216260198,
          "min_latency_ms": 0.06351999763865024,
          "max_latency_ms": 0.07534783354236102,
          "speedup_vs_fp32": 1.006550027957971,
          "test_size": 1000,
          "num_trials": 10,
          "arithmetic_intensity": 0.25,
          "achieved_bandwidth_gbps": 0.11215745240045215
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.027336633327150188,
          "efficiency": 1.2834100153591637e-06,
          "mean_latency_ms": 0.07316189876291901,
          "std_latency_ms": 0.0022057958660968045,
          "min_latency_ms": 0.07062499935273081,
          "max_latency_ms": 0.07536769462901581,
          "speedup_vs_fp32": 0.9813236107209904,
          "test_size": 1000,
          "num_trials": 10,
          "arithmetic_intensity": 0.5,
          "achieved_bandwidth_gbps": 0.054673266654300376
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.02755603044820193,
          "efficiency": 1.2937103496808416e-06,
          "mean_latency_ms": 0.07257939432747662,
          "std_latency_ms": 0.002290815257408288,
          "min_latency_ms": 0.06979198951739818,
          "max_latency_ms": 0.07487020958488491,
          "speedup_vs_fp32": 0.9891994735763645,
          "test_size": 1000,
          "num_trials": 10,
          "arithmetic_intensity": 0.5,
          "achieved_bandwidth_gbps": 0.05511206089640386
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Long'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Int'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Short'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Char'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas1_dot_best_precision=tf32_blas_level=1_device=cuda_framework=pytorch_operation=dot_size=10000": {
      "operation_type": "blas1_dot",
      "measured_gflops": 0.29273918329533666,
      "efficiency": 2.748724725777809e-05,
      "achieved_bandwidth_gbps": 1.1709567331813466,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.25,
      "batch_size": 1,
      "input_shape": [
        10000
      ],
      "output_shape": [
        10000
      ],
      "mean_latency_ms": 0.06832020153524354,
      "std_latency_ms": 0.0013105536247087451,
      "min_latency_ms": 0.06544000643771142,
      "max_latency_ms": 0.06963075515995229,
      "num_trials": 10,
      "extra_params": {
        "size": 10000,
        "operation": "dot",
        "blas_level": 1,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "tf32"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.27167896322216867,
          "efficiency": 0.00163662026037451,
          "mean_latency_ms": 0.07361629977822304,
          "std_latency_ms": 0.0019796258920649684,
          "min_latency_ms": 0.07036900206003338,
          "max_latency_ms": 0.075595925670288,
          "speedup_vs_fp32": null,
          "test_size": 10000,
          "num_trials": 10,
          "arithmetic_intensity": 0.5,
          "achieved_bandwidth_gbps": 0.5433579264443373
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.26973299286479757,
          "efficiency": 5.0654083167098134e-05,
          "mean_latency_ms": 0.07414739957312122,
          "std_latency_ms": 0.004063963263422024,
          "min_latency_ms": 0.06998500612098724,
          "max_latency_ms": 0.07821136283654324,
          "speedup_vs_fp32": 1.0,
          "test_size": 10000,
          "num_trials": 10,
          "arithmetic_intensity": 0.25,
          "achieved_bandwidth_gbps": 1.0789319714591903
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.29273918329533666,
          "efficiency": 2.748724725777809e-05,
          "mean_latency_ms": 0.06832020153524354,
          "std_latency_ms": 0.0013105536247087451,
          "min_latency_ms": 0.06544000643771142,
          "max_latency_ms": 0.06963075515995229,
          "speedup_vs_fp32": 1.085292459725425,
          "test_size": 10000,
          "num_trials": 10,
          "arithmetic_intensity": 0.25,
          "achieved_bandwidth_gbps": 1.1709567331813466
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.27030423494871963,
          "efficiency": 1.2690339668953973e-05,
          "mean_latency_ms": 0.07399070163955912,
          "std_latency_ms": 0.004410506766521483,
          "min_latency_ms": 0.0695040071150288,
          "max_latency_ms": 0.0784012084060806,
          "speedup_vs_fp32": 1.0021178057524776,
          "test_size": 10000,
          "num_trials": 10,
          "arithmetic_intensity": 0.5,
          "achieved_bandwidth_gbps": 0.5406084698974393
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.2806328217693993,
          "efficiency": 1.3175249848328606e-05,
          "mean_latency_ms": 0.07126750133465976,
          "std_latency_ms": 0.0018267139351900365,
          "min_latency_ms": 0.06918399594724178,
          "max_latency_ms": 0.07309421526984979,
          "speedup_vs_fp32": 1.040409698453408,
          "test_size": 10000,
          "num_trials": 10,
          "arithmetic_intensity": 0.5,
          "achieved_bandwidth_gbps": 0.5612656435387986
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Long'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Int'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Short'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Char'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas1_dot_best_precision=bf16_blas_level=1_device=cuda_framework=pytorch_operation=dot_size=100000": {
      "operation_type": "blas1_dot",
      "measured_gflops": 2.7618091191556293,
      "efficiency": 0.0001296623999603582,
      "achieved_bandwidth_gbps": 5.523618238311259,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.5,
      "batch_size": 1,
      "input_shape": [
        100000
      ],
      "output_shape": [
        100000
      ],
      "mean_latency_ms": 0.07241630082717165,
      "std_latency_ms": 0.00388187242355802,
      "min_latency_ms": 0.06470399966929108,
      "max_latency_ms": 0.07629817325072967,
      "num_trials": 10,
      "extra_params": {
        "size": 100000,
        "operation": "dot",
        "blas_level": 1,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "bf16"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 2.64080799717456,
          "efficiency": 0.01590848191069012,
          "mean_latency_ms": 0.07573439652333036,
          "std_latency_ms": 0.002628809740805085,
          "min_latency_ms": 0.07030399865470827,
          "max_latency_ms": 0.07836320626413544,
          "speedup_vs_fp32": null,
          "test_size": 100000,
          "num_trials": 10,
          "arithmetic_intensity": 0.5,
          "achieved_bandwidth_gbps": 5.28161599434912
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 2.7120849398951106,
          "efficiency": 0.0005093117258018986,
          "mean_latency_ms": 0.07374400302069262,
          "std_latency_ms": 0.0054512654272321735,
          "min_latency_ms": 0.06598400068469346,
          "max_latency_ms": 0.0791952684479248,
          "speedup_vs_fp32": 1.0,
          "test_size": 100000,
          "num_trials": 10,
          "arithmetic_intensity": 0.25,
          "achieved_bandwidth_gbps": 10.848339759580442
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 2.7236563897398067,
          "efficiency": 0.0002557423840131274,
          "mean_latency_ms": 0.0734307017410174,
          "std_latency_ms": 0.003849521333930585,
          "min_latency_ms": 0.0665279949316755,
          "max_latency_ms": 0.07728022307494799,
          "speedup_vs_fp32": 1.0042666251615053,
          "test_size": 100000,
          "num_trials": 10,
          "arithmetic_intensity": 0.25,
          "achieved_bandwidth_gbps": 10.894625558959227
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 2.7403754887736365,
          "efficiency": 0.00012865612623350406,
          "mean_latency_ms": 0.07298269920283929,
          "std_latency_ms": 0.003234374306656168,
          "min_latency_ms": 0.06771199696231633,
          "max_latency_ms": 0.07621707350949546,
          "speedup_vs_fp32": 1.0104312916097753,
          "test_size": 100000,
          "num_trials": 10,
          "arithmetic_intensity": 0.5,
          "achieved_bandwidth_gbps": 5.480750977547273
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 2.7618091191556293,
          "efficiency": 0.0001296623999603582,
          "mean_latency_ms": 0.07241630082717165,
          "std_latency_ms": 0.00388187242355802,
          "min_latency_ms": 0.06470399966929108,
          "max_latency_ms": 0.07629817325072967,
          "speedup_vs_fp32": 1.0183343001279457,
          "test_size": 100000,
          "num_trials": 10,
          "arithmetic_intensity": 0.5,
          "achieved_bandwidth_gbps": 5.523618238311259
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Long'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Int'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Short'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Char'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas1_dot_best_precision=fp16_blas_level=1_device=cuda_framework=pytorch_operation=dot_size=1000000": {
      "operation_type": "blas1_dot",
      "measured_gflops": 17.09705596033174,
      "efficiency": 0.0008026786835836498,
      "achieved_bandwidth_gbps": 34.19411192066348,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.5,
      "batch_size": 1,
      "input_shape": [
        1000000
      ],
      "output_shape": [
        1000000
      ],
      "mean_latency_ms": 0.11697920417645946,
      "std_latency_ms": 0.0015134041706187655,
      "min_latency_ms": 0.11488000745885074,
      "max_latency_ms": 0.11849260834707823,
      "num_trials": 10,
      "extra_params": {
        "size": 1000000,
        "operation": "dot",
        "blas_level": 1,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "fp16"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 9.06977249294969,
          "efficiency": 0.05463718369246801,
          "mean_latency_ms": 0.22051269770599902,
          "std_latency_ms": 0.005342304036204327,
          "min_latency_ms": 0.2166399935958907,
          "max_latency_ms": 0.22585500174220335,
          "speedup_vs_fp32": null,
          "test_size": 1000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.5,
          "achieved_bandwidth_gbps": 18.13954498589938
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 12.46878898115002,
          "efficiency": 0.0023415566161784076,
          "mean_latency_ms": 0.16040050104493275,
          "std_latency_ms": 0.0020847491398877406,
          "min_latency_ms": 0.15616101154591888,
          "max_latency_ms": 0.1624852501848205,
          "speedup_vs_fp32": 1.0,
          "test_size": 1000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.25,
          "achieved_bandwidth_gbps": 49.87515592460008
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 12.532050683011535,
          "efficiency": 0.0011767183739916935,
          "mean_latency_ms": 0.15959080046741292,
          "std_latency_ms": 0.001994365155104149,
          "min_latency_ms": 0.15641699428670108,
          "max_latency_ms": 0.16158516562251707,
          "speedup_vs_fp32": 1.005073604337771,
          "test_size": 1000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.25,
          "achieved_bandwidth_gbps": 50.12820273204614
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 17.09705596033174,
          "efficiency": 0.0008026786835836498,
          "mean_latency_ms": 0.11697920417645946,
          "std_latency_ms": 0.0015134041706187655,
          "min_latency_ms": 0.11488000745885074,
          "max_latency_ms": 0.11849260834707823,
          "speedup_vs_fp32": 1.3711881712152327,
          "test_size": 1000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.5,
          "achieved_bandwidth_gbps": 34.19411192066348
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 14.888352427577672,
          "efficiency": 0.0006989836820459001,
          "mean_latency_ms": 0.13433319836622104,
          "std_latency_ms": 0.0025849324084354993,
          "min_latency_ms": 0.13116899935994297,
          "max_latency_ms": 0.13691813077465653,
          "speedup_vs_fp32": 1.1940495945585,
          "test_size": 1000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.5,
          "achieved_bandwidth_gbps": 29.776704855155344
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Long'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Int'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Short'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Char'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas1_dot_best_precision=fp16_blas_level=1_device=cuda_framework=pytorch_operation=dot_size=10000000": {
      "operation_type": "blas1_dot",
      "measured_gflops": 23.704956733157232,
      "efficiency": 0.0011129087668148936,
      "achieved_bandwidth_gbps": 47.409913466314464,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.5,
      "batch_size": 1,
      "input_shape": [
        10000000
      ],
      "output_shape": [
        10000000
      ],
      "mean_latency_ms": 0.8437053998932242,
      "std_latency_ms": 0.001954767790421459,
      "min_latency_ms": 0.8401950035477057,
      "max_latency_ms": 0.8456601676836457,
      "num_trials": 10,
      "extra_params": {
        "size": 10000000,
        "operation": "dot",
        "blas_level": 1,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "fp16"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 14.402830880359765,
          "efficiency": 0.0867640414479504,
          "mean_latency_ms": 1.3886159023968503,
          "std_latency_ms": 0.006191031625721052,
          "min_latency_ms": 1.3809009979013354,
          "max_latency_ms": 1.3948069340225713,
          "speedup_vs_fp32": null,
          "test_size": 10000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.5,
          "achieved_bandwidth_gbps": 28.80566176071953
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 22.333395395534115,
          "efficiency": 0.004194064863011102,
          "mean_latency_ms": 0.8955198994954117,
          "std_latency_ms": 0.00431157592601566,
          "min_latency_ms": 0.8877789950929582,
          "max_latency_ms": 0.8998314754214273,
          "speedup_vs_fp32": 1.0,
          "test_size": 10000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.25,
          "achieved_bandwidth_gbps": 89.33358158213646
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 22.352565023775814,
          "efficiency": 0.002098832396598668,
          "mean_latency_ms": 0.8947518988861702,
          "std_latency_ms": 0.003316789489943677,
          "min_latency_ms": 0.8893469930626452,
          "max_latency_ms": 0.8980686883761139,
          "speedup_vs_fp32": 1.0008583391778185,
          "test_size": 10000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.25,
          "achieved_bandwidth_gbps": 89.41026009510325
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 23.704956733157232,
          "efficiency": 0.0011129087668148936,
          "mean_latency_ms": 0.8437053998932242,
          "std_latency_ms": 0.001954767790421459,
          "min_latency_ms": 0.8401950035477057,
          "max_latency_ms": 0.8456601676836457,
          "speedup_vs_fp32": 1.0614130235610022,
          "test_size": 10000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.5,
          "achieved_bandwidth_gbps": 47.409913466314464
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 23.62699688529722,
          "efficiency": 0.0011092486800609023,
          "mean_latency_ms": 0.8464892976917326,
          "std_latency_ms": 0.003975946374219307,
          "min_latency_ms": 0.841827000840567,
          "max_latency_ms": 0.8504652440659519,
          "speedup_vs_fp32": 1.0579222938049886,
          "test_size": 10000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.5,
          "achieved_bandwidth_gbps": 47.25399377059444
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Long'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Int'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Short'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Char'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas1_axpy_best_precision=int16_blas_level=1_device=cuda_framework=pytorch_operation=axpy_size=1000": {
      "operation_type": "blas1_axpy",
      "measured_gflops": 0.013661743186894249,
      "efficiency": 6.413963937509037e-07,
      "achieved_bandwidth_gbps": 0.04098522956068274,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.3333333333333333,
      "batch_size": 1,
      "input_shape": [
        1000
      ],
      "output_shape": [
        1000
      ],
      "mean_latency_ms": 0.1463942026020959,
      "std_latency_ms": 0.005024442001994954,
      "min_latency_ms": 0.14115299563854933,
      "max_latency_ms": 0.15141864460409085,
      "num_trials": 10,
      "extra_params": {
        "size": 1000,
        "operation": "axpy",
        "blas_level": 1,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "int16"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.013177261632773135,
          "efficiency": 7.938109417333214e-05,
          "mean_latency_ms": 0.15177660243352875,
          "std_latency_ms": 0.003887743247563168,
          "min_latency_ms": 0.14684899360872805,
          "max_latency_ms": 0.15566434568109191,
          "speedup_vs_fp32": null,
          "test_size": 1000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 0.039531784898319405
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.012974030517957657,
          "efficiency": 2.4364376559544897e-06,
          "mean_latency_ms": 0.15415410016430542,
          "std_latency_ms": 0.007761916684353092,
          "min_latency_ms": 0.14569600170943886,
          "max_latency_ms": 0.1619160168486585,
          "speedup_vs_fp32": 1.0,
          "test_size": 1000,
          "num_trials": 10,
          "arithmetic_intensity": 0.16666666666666666,
          "achieved_bandwidth_gbps": 0.07784418310774595
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.013050162168015338,
          "efficiency": 1.22536733971975e-06,
          "mean_latency_ms": 0.15325480053434148,
          "std_latency_ms": 0.0029994604886648397,
          "min_latency_ms": 0.14851299056317657,
          "max_latency_ms": 0.15625426102300632,
          "speedup_vs_fp32": 1.0058680030043328,
          "test_size": 1000,
          "num_trials": 10,
          "arithmetic_intensity": 0.16666666666666666,
          "achieved_bandwidth_gbps": 0.07830097300809204
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.013161999152814349,
          "efficiency": 6.179342325264953e-07,
          "mean_latency_ms": 0.15195260057225823,
          "std_latency_ms": 0.00365252725193981,
          "min_latency_ms": 0.1466249959776178,
          "max_latency_ms": 0.15560512782419805,
          "speedup_vs_fp32": 1.014488067882723,
          "test_size": 1000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 0.03948599745844304
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.013126891413735615,
          "efficiency": 6.162859818655219e-07,
          "mean_latency_ms": 0.1523589962744154,
          "std_latency_ms": 0.0065807344503796125,
          "min_latency_ms": 0.14291200204752386,
          "max_latency_ms": 0.158939730724795,
          "speedup_vs_fp32": 1.0117820669194804,
          "test_size": 1000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 0.03938067424120684
        },
        "int64": {
          "precision": "int64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.013350671478320015,
          "efficiency": 0.0,
          "mean_latency_ms": 0.14980519918026403,
          "std_latency_ms": 0.0025076769831298544,
          "min_latency_ms": 0.14473599730990827,
          "max_latency_ms": 0.15231287616339387,
          "speedup_vs_fp32": 1.0290303741648397,
          "test_size": 1000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 0.040052014434960044
        },
        "int32": {
          "precision": "int32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.013483149042475263,
          "efficiency": 2.5320467685399554e-06,
          "mean_latency_ms": 0.14833330060355365,
          "std_latency_ms": 0.004792002461103638,
          "min_latency_ms": 0.14297699090093374,
          "max_latency_ms": 0.1531253030646573,
          "speedup_vs_fp32": 1.0392413540119951,
          "test_size": 1000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 0.04044944712742579
        },
        "int16": {
          "precision": "int16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.013661743186894249,
          "efficiency": 6.413963937509037e-07,
          "mean_latency_ms": 0.1463942026020959,
          "std_latency_ms": 0.005024442001994954,
          "min_latency_ms": 0.14115299563854933,
          "max_latency_ms": 0.15141864460409085,
          "speedup_vs_fp32": 1.0530068638257566,
          "test_size": 1000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 0.04098522956068274
        },
        "int8": {
          "precision": "int8",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.013190062938595846,
          "efficiency": 3.0962589057736727e-07,
          "mean_latency_ms": 0.15162929921643808,
          "std_latency_ms": 0.008033758374198431,
          "min_latency_ms": 0.14265699428506196,
          "max_latency_ms": 0.1596630575906365,
          "speedup_vs_fp32": 1.0166511417048985,
          "test_size": 1000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 0.03957018881578754
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas1_axpy_best_precision=fp64_blas_level=1_device=cuda_framework=pytorch_operation=axpy_size=10000": {
      "operation_type": "blas1_axpy",
      "measured_gflops": 0.13637597231951526,
      "efficiency": 0.0008215420019247907,
      "achieved_bandwidth_gbps": 0.4091279169585457,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.3333333333333333,
      "batch_size": 1,
      "input_shape": [
        10000
      ],
      "output_shape": [
        10000
      ],
      "mean_latency_ms": 0.14665339986095205,
      "std_latency_ms": 0.005428338305002965,
      "min_latency_ms": 0.1403520000167191,
      "max_latency_ms": 0.15208173816595502,
      "num_trials": 10,
      "extra_params": {
        "size": 10000,
        "operation": "axpy",
        "blas_level": 1,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "fp64"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.13637597231951526,
          "efficiency": 0.0008215420019247907,
          "mean_latency_ms": 0.14665339986095205,
          "std_latency_ms": 0.005428338305002965,
          "min_latency_ms": 0.1403520000167191,
          "max_latency_ms": 0.15208173816595502,
          "speedup_vs_fp32": null,
          "test_size": 10000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 0.4091279169585457
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.1320427479661645,
          "efficiency": 2.4796760181439343e-05,
          "mean_latency_ms": 0.15146609948715195,
          "std_latency_ms": 0.001896265130501551,
          "min_latency_ms": 0.148768987855874,
          "max_latency_ms": 0.1533623646176535,
          "speedup_vs_fp32": 1.0,
          "test_size": 10000,
          "num_trials": 10,
          "arithmetic_intensity": 0.16666666666666666,
          "achieved_bandwidth_gbps": 0.792256487796987
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.13047974329471987,
          "efficiency": 1.2251619088706091e-05,
          "mean_latency_ms": 0.15328049776144326,
          "std_latency_ms": 0.008112607684974899,
          "min_latency_ms": 0.14476898650173098,
          "max_latency_ms": 0.16139310544641816,
          "speedup_vs_fp32": 0.9881628889468043,
          "test_size": 10000,
          "num_trials": 10,
          "arithmetic_intensity": 0.16666666666666666,
          "achieved_bandwidth_gbps": 0.7828784597683193
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.1296245210717562,
          "efficiency": 6.085658266279634e-06,
          "mean_latency_ms": 0.1542917947517708,
          "std_latency_ms": 0.007170141288005023,
          "min_latency_ms": 0.14697699225507677,
          "max_latency_ms": 0.16146193603977582,
          "speedup_vs_fp32": 0.9816860302314524,
          "test_size": 10000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 0.38887356321526867
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.13168654920214964,
          "efficiency": 6.182467098692472e-06,
          "mean_latency_ms": 0.15187579992925748,
          "std_latency_ms": 0.0023141333303698,
          "min_latency_ms": 0.1482239895267412,
          "max_latency_ms": 0.1541899332596273,
          "speedup_vs_fp32": 0.9973023981286263,
          "test_size": 10000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 0.3950596476064489
        },
        "int64": {
          "precision": "int64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.13575981498830786,
          "efficiency": 0.0,
          "mean_latency_ms": 0.14731899864273146,
          "std_latency_ms": 0.004649339157698739,
          "min_latency_ms": 0.13654399663209915,
          "max_latency_ms": 0.1519683378004302,
          "speedup_vs_fp32": 1.028150482168819,
          "test_size": 10000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 0.40727944496492363
        },
        "int32": {
          "precision": "int32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.13160059191225668,
          "efficiency": 2.471372618070548e-05,
          "mean_latency_ms": 0.15197500033536926,
          "std_latency_ms": 0.008998010331788563,
          "min_latency_ms": 0.1420479966327548,
          "max_latency_ms": 0.16097301066715783,
          "speedup_vs_fp32": 0.9966514173574975,
          "test_size": 10000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 0.39480177573677
        },
        "int16": {
          "precision": "int16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.13249349977448266,
          "efficiency": 6.220352102088388e-06,
          "mean_latency_ms": 0.15095080161700025,
          "std_latency_ms": 0.005191941677700436,
          "min_latency_ms": 0.1429760013706982,
          "max_latency_ms": 0.15614274329470068,
          "speedup_vs_fp32": 1.0034136809121366,
          "test_size": 10000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 0.397480499323448
        },
        "int8": {
          "precision": "int8",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.13284534862837244,
          "efficiency": 3.1184354138115597e-06,
          "mean_latency_ms": 0.15055099938763306,
          "std_latency_ms": 0.003430451711064178,
          "min_latency_ms": 0.1434880105080083,
          "max_latency_ms": 0.15398145109869724,
          "speedup_vs_fp32": 1.0060783395875221,
          "test_size": 10000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 0.3985360458851174
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas1_axpy_best_precision=fp64_blas_level=1_device=cuda_framework=pytorch_operation=axpy_size=100000": {
      "operation_type": "blas1_axpy",
      "measured_gflops": 1.358130069435225,
      "efficiency": 0.008181506442380873,
      "achieved_bandwidth_gbps": 4.074390208305675,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.3333333333333333,
      "batch_size": 1,
      "input_shape": [
        100000
      ],
      "output_shape": [
        100000
      ],
      "mean_latency_ms": 0.14726130029885098,
      "std_latency_ms": 0.00357865372949376,
      "min_latency_ms": 0.13875200238544494,
      "max_latency_ms": 0.15083995402834474,
      "num_trials": 10,
      "extra_params": {
        "size": 100000,
        "operation": "axpy",
        "blas_level": 1,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "fp64"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.358130069435225,
          "efficiency": 0.008181506442380873,
          "mean_latency_ms": 0.14726130029885098,
          "std_latency_ms": 0.00357865372949376,
          "min_latency_ms": 0.13875200238544494,
          "max_latency_ms": 0.15083995402834474,
          "speedup_vs_fp32": null,
          "test_size": 100000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 4.074390208305675
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.310927845453555,
          "efficiency": 0.0002461836329490244,
          "mean_latency_ms": 0.15256369806593284,
          "std_latency_ms": 0.00856550261565959,
          "min_latency_ms": 0.13939299969933927,
          "max_latency_ms": 0.16112920068159242,
          "speedup_vs_fp32": 1.0,
          "test_size": 100000,
          "num_trials": 10,
          "arithmetic_intensity": 0.16666666666666666,
          "achieved_bandwidth_gbps": 7.865567072721329
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.3109286957237027,
          "efficiency": 0.00012309189631208475,
          "mean_latency_ms": 0.1525635991129093,
          "std_latency_ms": 0.002222147371539431,
          "min_latency_ms": 0.14851200103294104,
          "max_latency_ms": 0.1547857464844487,
          "speedup_vs_fp32": 1.0000006486017905,
          "test_size": 100000,
          "num_trials": 10,
          "arithmetic_intensity": 0.16666666666666666,
          "achieved_bandwidth_gbps": 7.8655721743422164
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.2919312233897884,
          "efficiency": 6.0654048046468936e-05,
          "mean_latency_ms": 0.15480700240004808,
          "std_latency_ms": 0.005796053874798564,
          "min_latency_ms": 0.14764901425223798,
          "max_latency_ms": 0.16060305627484664,
          "speedup_vs_fp32": 0.9855090254359544,
          "test_size": 100000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 3.8757936701693647
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.309471265814268,
          "efficiency": 6.14775242166323e-05,
          "mean_latency_ms": 0.15273340104613453,
          "std_latency_ms": 0.006861058401805744,
          "min_latency_ms": 0.14678399020340294,
          "max_latency_ms": 0.15959445944794026,
          "speedup_vs_fp32": 0.9988888941185142,
          "test_size": 100000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 3.9284137974428033
        },
        "int64": {
          "precision": "int64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.3103506291208689,
          "efficiency": 0.0,
          "mean_latency_ms": 0.152630903176032,
          "std_latency_ms": 0.008059148479721601,
          "min_latency_ms": 0.14630501391366124,
          "max_latency_ms": 0.16069005165575362,
          "speedup_vs_fp32": 0.9995596887085069,
          "test_size": 100000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 3.931051887362607
        },
        "int32": {
          "precision": "int32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.3124134726723957,
          "efficiency": 0.0002464626239760368,
          "mean_latency_ms": 0.15239099884638563,
          "std_latency_ms": 0.0029826657829942036,
          "min_latency_ms": 0.14636899868492037,
          "max_latency_ms": 0.15537366462937982,
          "speedup_vs_fp32": 1.0011332639122688,
          "test_size": 100000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 3.937240418017187
        },
        "int16": {
          "precision": "int16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.35020825010637,
          "efficiency": 6.33900586904399e-05,
          "mean_latency_ms": 0.14812529843766242,
          "std_latency_ms": 0.0031666114345509752,
          "min_latency_ms": 0.14256099530030042,
          "max_latency_ms": 0.1512919098722134,
          "speedup_vs_fp32": 1.0299638189767986,
          "test_size": 100000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 4.05062475031911
        },
        "int8": {
          "precision": "int8",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.3079914668514616,
          "efficiency": 3.070402504346154e-05,
          "mean_latency_ms": 0.15290619630832225,
          "std_latency_ms": 0.005383181213663242,
          "min_latency_ms": 0.14828900748398155,
          "max_latency_ms": 0.1582893775219855,
          "speedup_vs_fp32": 0.9977600761077149,
          "test_size": 100000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 3.923974400554385
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas1_axpy_best_precision=int8_blas_level=1_device=cuda_framework=pytorch_operation=axpy_size=1000000": {
      "operation_type": "blas1_axpy",
      "measured_gflops": 13.195623777074445,
      "efficiency": 0.00030975642669188837,
      "achieved_bandwidth_gbps": 39.586871331223335,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.3333333333333333,
      "batch_size": 1,
      "input_shape": [
        1000000
      ],
      "output_shape": [
        1000000
      ],
      "mean_latency_ms": 0.1515654003014788,
      "std_latency_ms": 0.0011580228988707162,
      "min_latency_ms": 0.1499840000178665,
      "max_latency_ms": 0.1527234232003495,
      "num_trials": 10,
      "extra_params": {
        "size": 1000000,
        "operation": "axpy",
        "blas_level": 1,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "int8"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 2.863875827566449,
          "efficiency": 0.017252264021484633,
          "mean_latency_ms": 0.6983543004025705,
          "std_latency_ms": 0.0024680253790985234,
          "min_latency_ms": 0.69411400181707,
          "max_latency_ms": 0.700822325781669,
          "speedup_vs_fp32": null,
          "test_size": 1000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 8.591627482699346
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 5.710557526051303,
          "efficiency": 0.0010724051692115122,
          "mean_latency_ms": 0.3502285006106831,
          "std_latency_ms": 0.0015778241208670417,
          "min_latency_ms": 0.3479369916021824,
          "max_latency_ms": 0.35180632473155016,
          "speedup_vs_fp32": 1.0,
          "test_size": 1000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.16666666666666666,
          "achieved_bandwidth_gbps": 34.26334515630782
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 5.7439902792087425,
          "efficiency": 0.0005393418102543421,
          "mean_latency_ms": 0.3481900042970665,
          "std_latency_ms": 0.0016822309055955177,
          "min_latency_ms": 0.3449930081842467,
          "max_latency_ms": 0.349872235202662,
          "speedup_vs_fp32": 1.0058545515048087,
          "test_size": 1000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.16666666666666666,
          "achieved_bandwidth_gbps": 34.46394167525246
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 8.917082798008545,
          "efficiency": 0.0004186423848830303,
          "mean_latency_ms": 0.22428859811043367,
          "std_latency_ms": 0.0038353287982320103,
          "min_latency_ms": 0.2196489949710667,
          "max_latency_ms": 0.22812392690866568,
          "speedup_vs_fp32": 1.5615082690839241,
          "test_size": 1000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 26.751248394025637
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 8.975983918550737,
          "efficiency": 0.0004214076957066074,
          "mean_latency_ms": 0.22281679848674685,
          "std_latency_ms": 0.0015348749078999792,
          "min_latency_ms": 0.21964900952298194,
          "max_latency_ms": 0.22435167339464682,
          "speedup_vs_fp32": 1.5718226946498146,
          "test_size": 1000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 26.92795175565221
        },
        "int64": {
          "precision": "int64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 3.071030938568566,
          "efficiency": 0.0,
          "mean_latency_ms": 0.6512471023597755,
          "std_latency_ms": 0.005152800487572038,
          "min_latency_ms": 0.6470740045187995,
          "max_latency_ms": 0.6563999028473475,
          "speedup_vs_fp32": 0.537781280471944,
          "test_size": 1000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 9.213092815705696
        },
        "int32": {
          "precision": "int32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 5.751919692578978,
          "efficiency": 0.0010801727122214044,
          "mean_latency_ms": 0.34771000064210966,
          "std_latency_ms": 0.0025257695015130353,
          "min_latency_ms": 0.34364900784567,
          "max_latency_ms": 0.35023577014362267,
          "speedup_vs_fp32": 1.0072431047824986,
          "test_size": 1000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 17.255759077736936
        },
        "int16": {
          "precision": "int16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 8.966840663802053,
          "efficiency": 0.00042097843492028416,
          "mean_latency_ms": 0.22304399899439886,
          "std_latency_ms": 0.0037595957325405162,
          "min_latency_ms": 0.21919999562669545,
          "max_latency_ms": 0.22680359472693937,
          "speedup_vs_fp32": 1.570221580449148,
          "test_size": 1000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 26.90052199140616
        },
        "int8": {
          "precision": "int8",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 13.195623777074445,
          "efficiency": 0.00030975642669188837,
          "mean_latency_ms": 0.1515654003014788,
          "std_latency_ms": 0.0011580228988707162,
          "min_latency_ms": 0.1499840000178665,
          "max_latency_ms": 0.1527234232003495,
          "speedup_vs_fp32": 2.310741765033731,
          "test_size": 1000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 39.586871331223335
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas1_axpy_best_precision=int8_blas_level=1_device=cuda_framework=pytorch_operation=axpy_size=10000000": {
      "operation_type": "blas1_axpy",
      "measured_gflops": 19.123848522487993,
      "efficiency": 0.00044891663198328623,
      "achieved_bandwidth_gbps": 57.371545567463976,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.3333333333333333,
      "batch_size": 1,
      "input_shape": [
        10000000
      ],
      "output_shape": [
        10000000
      ],
      "mean_latency_ms": 1.045814600365702,
      "std_latency_ms": 0.003732177971300241,
      "min_latency_ms": 1.041508003254421,
      "max_latency_ms": 1.0495467783370023,
      "num_trials": 10,
      "extra_params": {
        "size": 10000000,
        "operation": "axpy",
        "blas_level": 1,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "int8"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 3.2700330152722588,
          "efficiency": 0.019698994067905172,
          "mean_latency_ms": 6.116146199929062,
          "std_latency_ms": 0.006831791612968631,
          "min_latency_ms": 6.110101006925106,
          "max_latency_ms": 6.122977991542031,
          "speedup_vs_fp32": null,
          "test_size": 10000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 9.810099045816777
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 7.763186180649764,
          "efficiency": 0.0014578753390891575,
          "mean_latency_ms": 2.576261799549684,
          "std_latency_ms": 0.0027754438635187338,
          "min_latency_ms": 2.5719770055729896,
          "max_latency_ms": 2.5790372434132025,
          "speedup_vs_fp32": 1.0,
          "test_size": 10000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.16666666666666666,
          "achieved_bandwidth_gbps": 46.57911708389858
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 7.755758744488756,
          "efficiency": 0.0007282402576984748,
          "mean_latency_ms": 2.5787290011066943,
          "std_latency_ms": 0.006698788512516691,
          "min_latency_ms": 2.57271301234141,
          "max_latency_ms": 2.585427789619211,
          "speedup_vs_fp32": 0.9990432489974901,
          "test_size": 10000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.16666666666666666,
          "achieved_bandwidth_gbps": 46.53455246693254
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 14.211859315075754,
          "efficiency": 0.0006672234420223359,
          "mean_latency_ms": 1.407275399833452,
          "std_latency_ms": 0.0020300214428456047,
          "min_latency_ms": 1.4038130029803142,
          "max_latency_ms": 1.4093054212762977,
          "speedup_vs_fp32": 1.8306735127002003,
          "test_size": 10000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 42.63557794522726
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 14.214477376108876,
          "efficiency": 0.0006673463556858627,
          "mean_latency_ms": 1.4070162040297873,
          "std_latency_ms": 0.003866648219021396,
          "min_latency_ms": 1.4007410063641146,
          "max_latency_ms": 1.4108828522488088,
          "speedup_vs_fp32": 1.8310107532316262,
          "test_size": 10000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 42.64343212832662
        },
        "int64": {
          "precision": "int64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 3.3764210233446637,
          "efficiency": 0.0,
          "mean_latency_ms": 5.9234319007373415,
          "std_latency_ms": 0.007651966380341711,
          "min_latency_ms": 5.911221000133082,
          "max_latency_ms": 5.9310838671176835,
          "speedup_vs_fp32": 0.43492722508196546,
          "test_size": 10000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 10.129263070033991
        },
        "int32": {
          "precision": "int32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 7.759677810981473,
          "efficiency": 0.0014572164903251593,
          "mean_latency_ms": 2.577426600328181,
          "std_latency_ms": 0.005447234133767989,
          "min_latency_ms": 2.570825003203936,
          "max_latency_ms": 2.582873834461949,
          "speedup_vs_fp32": 0.9995480760622442,
          "test_size": 10000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 23.27903343294442
        },
        "int16": {
          "precision": "int16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 14.176015220832479,
          "efficiency": 0.0006655406206963605,
          "mean_latency_ms": 1.4108336996287107,
          "std_latency_ms": 0.0029481000607615537,
          "min_latency_ms": 1.406596988090314,
          "max_latency_ms": 1.4137817996894724,
          "speedup_vs_fp32": 1.82605632416328,
          "test_size": 10000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 42.52804566249743
        },
        "int8": {
          "precision": "int8",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 19.123848522487993,
          "efficiency": 0.00044891663198328623,
          "mean_latency_ms": 1.045814600365702,
          "std_latency_ms": 0.003732177971300241,
          "min_latency_ms": 1.041508003254421,
          "max_latency_ms": 1.0495467783370023,
          "speedup_vs_fp32": 2.4634020204430245,
          "test_size": 10000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 57.371545567463976
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas2_gemv_best_precision=fp64_blas_level=2_device=cuda_framework=pytorch_operation=gemv_size=32": {
      "operation_type": "blas2_gemv",
      "measured_gflops": 0.008192386677873257,
      "efficiency": 4.93517269751401e-05,
      "achieved_bandwidth_gbps": 0.008704410845240335,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.9411764705882353,
      "batch_size": 1,
      "input_shape": [
        32,
        32
      ],
      "output_shape": [
        32
      ],
      "mean_latency_ms": 0.24998820008477196,
      "std_latency_ms": 0.006498662670424552,
      "min_latency_ms": 0.24288099666591734,
      "max_latency_ms": 0.2564868627551965,
      "num_trials": 10,
      "extra_params": {
        "size": 32,
        "operation": "gemv",
        "blas_level": 2,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "fp64"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.008192386677873257,
          "efficiency": 4.93517269751401e-05,
          "mean_latency_ms": 0.24998820008477196,
          "std_latency_ms": 0.006498662670424552,
          "min_latency_ms": 0.24288099666591734,
          "max_latency_ms": 0.2564868627551965,
          "speedup_vs_fp32": null,
          "test_size": 32,
          "num_trials": 10,
          "arithmetic_intensity": 0.9411764705882353,
          "achieved_bandwidth_gbps": 0.008704410845240335
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.00815075722634963,
          "efficiency": 1.5306586340562685e-06,
          "mean_latency_ms": 0.2512649982236326,
          "std_latency_ms": 0.004565606872804538,
          "min_latency_ms": 0.2430729946354404,
          "max_latency_ms": 0.2558306050964371,
          "speedup_vs_fp32": 1.0,
          "test_size": 32,
          "num_trials": 10,
          "arithmetic_intensity": 0.47058823529411764,
          "achieved_bandwidth_gbps": 0.01732035910599296
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.008175648665724617,
          "efficiency": 7.676665413825931e-07,
          "mean_latency_ms": 0.2505000011296943,
          "std_latency_ms": 0.008759024273119927,
          "min_latency_ms": 0.24176099395845085,
          "max_latency_ms": 0.2592590254028142,
          "speedup_vs_fp32": 1.0030538806007518,
          "test_size": 32,
          "num_trials": 10,
          "arithmetic_intensity": 0.47058823529411764,
          "achieved_bandwidth_gbps": 0.017373253414664808
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.008153255786573175,
          "efficiency": 3.827819618109472e-07,
          "mean_latency_ms": 0.2511879982193932,
          "std_latency_ms": 0.009467471294057492,
          "min_latency_ms": 0.2423370024189353,
          "max_latency_ms": 0.2606554695134507,
          "speedup_vs_fp32": 1.0003065433252591,
          "test_size": 32,
          "num_trials": 10,
          "arithmetic_intensity": 0.9411764705882353,
          "achieved_bandwidth_gbps": 0.008662834273233999
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.008182550741314768,
          "efficiency": 3.8415731179881544e-07,
          "mean_latency_ms": 0.2502887014998123,
          "std_latency_ms": 0.005307846759332001,
          "min_latency_ms": 0.24464100715704262,
          "max_latency_ms": 0.2555965482591443,
          "speedup_vs_fp32": 1.003900682363886,
          "test_size": 32,
          "num_trials": 10,
          "arithmetic_intensity": 0.9411764705882353,
          "achieved_bandwidth_gbps": 0.00869396016264694
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Long'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Int'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Short'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Char'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas2_gemv_best_precision=fp64_blas_level=2_device=cuda_framework=pytorch_operation=gemv_size=64": {
      "operation_type": "blas2_gemv",
      "measured_gflops": 0.03359479449355116,
      "efficiency": 0.0002023782800816335,
      "achieved_bandwidth_gbps": 0.03464463182147464,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.9696969696969697,
      "batch_size": 1,
      "input_shape": [
        64,
        64
      ],
      "output_shape": [
        64
      ],
      "mean_latency_ms": 0.2438473020447418,
      "std_latency_ms": 0.007675193768758923,
      "min_latency_ms": 0.23228899226523936,
      "max_latency_ms": 0.2515224958135007,
      "num_trials": 10,
      "extra_params": {
        "size": 64,
        "operation": "gemv",
        "blas_level": 2,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "fp64"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.03359479449355116,
          "efficiency": 0.0002023782800816335,
          "mean_latency_ms": 0.2438473020447418,
          "std_latency_ms": 0.007675193768758923,
          "min_latency_ms": 0.23228899226523936,
          "max_latency_ms": 0.2515224958135007,
          "speedup_vs_fp32": null,
          "test_size": 64,
          "num_trials": 10,
          "arithmetic_intensity": 0.9696969696969697,
          "achieved_bandwidth_gbps": 0.03464463182147464
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.032647101019035715,
          "efficiency": 6.130910989490275e-06,
          "mean_latency_ms": 0.2509258018108085,
          "std_latency_ms": 0.009040465585295542,
          "min_latency_ms": 0.2397130010649562,
          "max_latency_ms": 0.259966267396104,
          "speedup_vs_fp32": 1.0,
          "test_size": 64,
          "num_trials": 10,
          "arithmetic_intensity": 0.48484848484848486,
          "achieved_bandwidth_gbps": 0.06733464585176116
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.03276748880802372,
          "efficiency": 3.07675951249049e-06,
          "mean_latency_ms": 0.25000390014611185,
          "std_latency_ms": 0.008945585051626206,
          "min_latency_ms": 0.2358089986955747,
          "max_latency_ms": 0.258949485197738,
          "speedup_vs_fp32": 1.003687549130865,
          "test_size": 64,
          "num_trials": 10,
          "arithmetic_intensity": 0.48484848484848486,
          "achieved_bandwidth_gbps": 0.06758294566654892
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.03293271598528613,
          "efficiency": 1.5461369007176588e-06,
          "mean_latency_ms": 0.24874960217857733,
          "std_latency_ms": 0.00941582696745048,
          "min_latency_ms": 0.23686399799771607,
          "max_latency_ms": 0.2581654291460278,
          "speedup_vs_fp32": 1.0087485552265079,
          "test_size": 64,
          "num_trials": 10,
          "arithmetic_intensity": 0.9696969696969697,
          "achieved_bandwidth_gbps": 0.03396186335982632
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.03232925328425282,
          "efficiency": 1.517805318509522e-06,
          "mean_latency_ms": 0.2533927996410057,
          "std_latency_ms": 0.007891217809459226,
          "min_latency_ms": 0.24560099700465798,
          "max_latency_ms": 0.2612840174504649,
          "speedup_vs_fp32": 0.9902641360224429,
          "test_size": 64,
          "num_trials": 10,
          "arithmetic_intensity": 0.9696969696969697,
          "achieved_bandwidth_gbps": 0.033339542449385716
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Long'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Int'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Short'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Char'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas2_gemv_best_precision=fp32_blas_level=2_device=cuda_framework=pytorch_operation=gemv_size=128": {
      "operation_type": "blas2_gemv",
      "measured_gflops": 0.13361119973606525,
      "efficiency": 2.5091305114754037e-05,
      "achieved_bandwidth_gbps": 0.2713977494638825,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.49230769230769234,
      "batch_size": 1,
      "input_shape": [
        128,
        128
      ],
      "output_shape": [
        128
      ],
      "mean_latency_ms": 0.24524890177417547,
      "std_latency_ms": 0.008465478175891192,
      "min_latency_ms": 0.23686399799771607,
      "max_latency_ms": 0.2537143799500667,
      "num_trials": 10,
      "extra_params": {
        "size": 128,
        "operation": "gemv",
        "blas_level": 2,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "fp32"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.1328208768108118,
          "efficiency": 0.0008001257639205531,
          "mean_latency_ms": 0.24670820421306416,
          "std_latency_ms": 0.0057612307111424245,
          "min_latency_ms": 0.23683300241827965,
          "max_latency_ms": 0.2524694349242066,
          "speedup_vs_fp32": null,
          "test_size": 128,
          "num_trials": 10,
          "arithmetic_intensity": 0.9846153846153847,
          "achieved_bandwidth_gbps": 0.13489620301098076
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.13361119973606525,
          "efficiency": 2.5091305114754037e-05,
          "mean_latency_ms": 0.24524890177417547,
          "std_latency_ms": 0.008465478175891192,
          "min_latency_ms": 0.23686399799771607,
          "max_latency_ms": 0.2537143799500667,
          "speedup_vs_fp32": 1.0,
          "test_size": 128,
          "num_trials": 10,
          "arithmetic_intensity": 0.49230769230769234,
          "achieved_bandwidth_gbps": 0.2713977494638825
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.1306568744260406,
          "efficiency": 1.2268251119816019e-05,
          "mean_latency_ms": 0.25079430488403887,
          "std_latency_ms": 0.011339869948769071,
          "min_latency_ms": 0.240353008848615,
          "max_latency_ms": 0.26213417483280793,
          "speedup_vs_fp32": 0.9778886402048586,
          "test_size": 128,
          "num_trials": 10,
          "arithmetic_intensity": 0.49230769230769234,
          "achieved_bandwidth_gbps": 0.265396776177895
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.13158697916903078,
          "efficiency": 6.1777924492502715e-06,
          "mean_latency_ms": 0.24902159930206835,
          "std_latency_ms": 0.010287812260290428,
          "min_latency_ms": 0.24048099294304848,
          "max_latency_ms": 0.25930941156235876,
          "speedup_vs_fp32": 0.9848499184871246,
          "test_size": 128,
          "num_trials": 10,
          "arithmetic_intensity": 0.9846153846153847,
          "achieved_bandwidth_gbps": 0.1336430257185469
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.13247560502155933,
          "efficiency": 6.219511972843161e-06,
          "mean_latency_ms": 0.24735120096011087,
          "std_latency_ms": 0.008938136919389083,
          "min_latency_ms": 0.23772899294272065,
          "max_latency_ms": 0.2562893378795,
          "speedup_vs_fp32": 0.9915007520570943,
          "test_size": 128,
          "num_trials": 10,
          "arithmetic_intensity": 0.9846153846153847,
          "achieved_bandwidth_gbps": 0.1345455363500212
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Long'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Int'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Short'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Char'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas2_gemv_best_precision=fp64_blas_level=2_device=cuda_framework=pytorch_operation=gemv_size=256": {
      "operation_type": "blas2_gemv",
      "measured_gflops": 0.5366713701923926,
      "efficiency": 0.003232960061399956,
      "achieved_bandwidth_gbps": 0.5408641152720207,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.9922480620155039,
      "batch_size": 1,
      "input_shape": [
        256,
        256
      ],
      "output_shape": [
        256
      ],
      "mean_latency_ms": 0.24423139984719455,
      "std_latency_ms": 0.01000583394250002,
      "min_latency_ms": 0.23244900512509048,
      "max_latency_ms": 0.2542372337896946,
      "num_trials": 10,
      "extra_params": {
        "size": 256,
        "operation": "gemv",
        "blas_level": 2,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "fp64"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.5366713701923926,
          "efficiency": 0.003232960061399956,
          "mean_latency_ms": 0.24423139984719455,
          "std_latency_ms": 0.01000583394250002,
          "min_latency_ms": 0.23244900512509048,
          "max_latency_ms": 0.2542372337896946,
          "speedup_vs_fp32": null,
          "test_size": 256,
          "num_trials": 10,
          "arithmetic_intensity": 0.9922480620155039,
          "achieved_bandwidth_gbps": 0.5408641152720207
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.523642868414911,
          "efficiency": 9.833668890420865e-05,
          "mean_latency_ms": 0.2503080017049797,
          "std_latency_ms": 0.0081248633958149,
          "min_latency_ms": 0.24521700106561184,
          "max_latency_ms": 0.2584328651007946,
          "speedup_vs_fp32": 1.0,
          "test_size": 256,
          "num_trials": 10,
          "arithmetic_intensity": 0.49612403100775193,
          "achieved_bandwidth_gbps": 1.055467656648805
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.5336581828727035,
          "efficiency": 5.0108749565512065e-05,
          "mean_latency_ms": 0.24561040045227855,
          "std_latency_ms": 0.00803034865664298,
          "min_latency_ms": 0.23699300072621554,
          "max_latency_ms": 0.25364074910892154,
          "speedup_vs_fp32": 1.0191262309904252,
          "test_size": 256,
          "num_trials": 10,
          "arithmetic_intensity": 0.49612403100775193,
          "achieved_bandwidth_gbps": 1.075654774852793
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.49559390640308354,
          "efficiency": 2.326731954944054e-05,
          "mean_latency_ms": 0.26447459968039766,
          "std_latency_ms": 0.04626285410121027,
          "min_latency_ms": 0.2406410058028996,
          "max_latency_ms": 0.31073745378160794,
          "speedup_vs_fp32": 0.9464349393380781,
          "test_size": 256,
          "num_trials": 10,
          "arithmetic_intensity": 0.9922480620155039,
          "achieved_bandwidth_gbps": 0.49946573379685766
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.5251399890817954,
          "efficiency": 2.4654459581304946e-05,
          "mean_latency_ms": 0.24959439906524494,
          "std_latency_ms": 0.007604711791703546,
          "min_latency_ms": 0.24140799359884113,
          "max_latency_ms": 0.25719911085694847,
          "speedup_vs_fp32": 1.002859049090874,
          "test_size": 256,
          "num_trials": 10,
          "arithmetic_intensity": 0.9922480620155039,
          "achieved_bandwidth_gbps": 0.5292426452464969
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Long'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Int'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Short'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Char'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas2_gemv_best_precision=fp64_blas_level=2_device=cuda_framework=pytorch_operation=gemv_size=512": {
      "operation_type": "blas2_gemv",
      "measured_gflops": 2.1364681108331567,
      "efficiency": 0.012870289824296124,
      "achieved_bandwidth_gbps": 2.144813689391099,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.9961089494163424,
      "batch_size": 1,
      "input_shape": [
        512,
        512
      ],
      "output_shape": [
        512
      ],
      "mean_latency_ms": 0.24539940350223333,
      "std_latency_ms": 0.00443991982360699,
      "min_latency_ms": 0.2391050074947998,
      "max_latency_ms": 0.24983932332584033,
      "num_trials": 10,
      "extra_params": {
        "size": 512,
        "operation": "gemv",
        "blas_level": 2,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "fp64"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 2.1364681108331567,
          "efficiency": 0.012870289824296124,
          "mean_latency_ms": 0.24539940350223333,
          "std_latency_ms": 0.00443991982360699,
          "min_latency_ms": 0.2391050074947998,
          "max_latency_ms": 0.24983932332584033,
          "speedup_vs_fp32": null,
          "test_size": 512,
          "num_trials": 10,
          "arithmetic_intensity": 0.9961089494163424,
          "achieved_bandwidth_gbps": 2.144813689391099
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 2.1231805233059826,
          "efficiency": 0.00039871934709971503,
          "mean_latency_ms": 0.2469351966283284,
          "std_latency_ms": 0.004875771976122078,
          "min_latency_ms": 0.23715299903415143,
          "max_latency_ms": 0.2518109686044505,
          "speedup_vs_fp32": 1.0,
          "test_size": 512,
          "num_trials": 10,
          "arithmetic_intensity": 0.4980544747081712,
          "achieved_bandwidth_gbps": 4.2629483944502935
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 2.1277576845748483,
          "efficiency": 0.00019978945395068997,
          "mean_latency_ms": 0.24640399788040668,
          "std_latency_ms": 0.0037486316539281925,
          "min_latency_ms": 0.24044900783337653,
          "max_latency_ms": 0.25015262953433487,
          "speedup_vs_fp32": 1.0021558040960825,
          "test_size": 512,
          "num_trials": 10,
          "arithmetic_intensity": 0.4980544747081712,
          "achieved_bandwidth_gbps": 4.272138476060437
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 2.129278557069225,
          "efficiency": 9.996612943986972e-05,
          "mean_latency_ms": 0.2462279997416772,
          "std_latency_ms": 0.004770711522139354,
          "min_latency_ms": 0.23952100309543312,
          "max_latency_ms": 0.25099871126381657,
          "speedup_vs_fp32": 1.0028721221282435,
          "test_size": 512,
          "num_trials": 10,
          "arithmetic_intensity": 0.9961089494163424,
          "achieved_bandwidth_gbps": 2.137596051432777
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 2.1231512583202092,
          "efficiency": 9.96784628319347e-05,
          "mean_latency_ms": 0.24693860032130033,
          "std_latency_ms": 0.0047291928379028765,
          "min_latency_ms": 0.2388809953117743,
          "max_latency_ms": 0.2516677931592032,
          "speedup_vs_fp32": 0.9999862164401697,
          "test_size": 512,
          "num_trials": 10,
          "arithmetic_intensity": 0.9961089494163424,
          "achieved_bandwidth_gbps": 2.1314448179230228
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Long'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Int'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Short'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Char'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas2_gemv_best_precision=fp32_blas_level=2_device=cuda_framework=pytorch_operation=gemv_size=1024": {
      "operation_type": "blas2_gemv",
      "measured_gflops": 8.489744649023455,
      "efficiency": 0.0015943182439480668,
      "achieved_bandwidth_gbps": 17.012652363082157,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.49902534113060426,
      "batch_size": 1,
      "input_shape": [
        1024,
        1024
      ],
      "output_shape": [
        1024
      ],
      "mean_latency_ms": 0.247021799441427,
      "std_latency_ms": 0.003241934254013357,
      "min_latency_ms": 0.23907300783321261,
      "max_latency_ms": 0.25026373369544036,
      "num_trials": 10,
      "extra_params": {
        "size": 1024,
        "operation": "gemv",
        "blas_level": 2,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "fp32"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 8.156182786015172,
          "efficiency": 0.049133631241055256,
          "mean_latency_ms": 0.25712420319905505,
          "std_latency_ms": 0.006049335448010219,
          "min_latency_ms": 0.24912100343499333,
          "max_latency_ms": 0.2631735386470653,
          "speedup_vs_fp32": null,
          "test_size": 1024,
          "num_trials": 10,
          "arithmetic_intensity": 0.9980506822612085,
          "achieved_bandwidth_gbps": 8.172112830519108
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 8.489744649023455,
          "efficiency": 0.0015943182439480668,
          "mean_latency_ms": 0.247021799441427,
          "std_latency_ms": 0.003241934254013357,
          "min_latency_ms": 0.23907300783321261,
          "max_latency_ms": 0.25026373369544036,
          "speedup_vs_fp32": 1.0,
          "test_size": 1024,
          "num_trials": 10,
          "arithmetic_intensity": 0.49902534113060426,
          "achieved_bandwidth_gbps": 17.012652363082157
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 8.436962073070363,
          "efficiency": 0.0007922030115559026,
          "mean_latency_ms": 0.24856719537638128,
          "std_latency_ms": 0.004413343219422175,
          "min_latency_ms": 0.24163299531210214,
          "max_latency_ms": 0.25298053859580344,
          "speedup_vs_fp32": 0.9937827840370719,
          "test_size": 1024,
          "num_trials": 10,
          "arithmetic_intensity": 0.49902534113060426,
          "achieved_bandwidth_gbps": 16.906881029238658
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 8.419504230387474,
          "efficiency": 0.00039528188875058564,
          "mean_latency_ms": 0.24908259947551414,
          "std_latency_ms": 0.00366013710465313,
          "min_latency_ms": 0.2432970068184659,
          "max_latency_ms": 0.25274273658016727,
          "speedup_vs_fp32": 0.9917264391875367,
          "test_size": 1024,
          "num_trials": 10,
          "arithmetic_intensity": 0.9980506822612085,
          "achieved_bandwidth_gbps": 8.43594857458745
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 8.419189878633073,
          "efficiency": 0.00039526713045225694,
          "mean_latency_ms": 0.2490918996045366,
          "std_latency_ms": 0.004641234577649547,
          "min_latency_ms": 0.24112098617479205,
          "max_latency_ms": 0.2537331341821861,
          "speedup_vs_fp32": 0.9916894119543986,
          "test_size": 1024,
          "num_trials": 10,
          "arithmetic_intensity": 0.9980506822612085,
          "achieved_bandwidth_gbps": 8.435633608864778
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Long'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Int'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Short'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Char'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas2_gemv_best_precision=tf32_blas_level=2_device=cuda_framework=pytorch_operation=gemv_size=2048": {
      "operation_type": "blas2_gemv",
      "measured_gflops": 30.813169158183374,
      "efficiency": 0.0028932553200172184,
      "achieved_bandwidth_gbps": 61.68652028737882,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.4995121951219512,
      "batch_size": 1,
      "input_shape": [
        2048,
        2048
      ],
      "output_shape": [
        2048
      ],
      "mean_latency_ms": 0.27224100049352273,
      "std_latency_ms": 0.00209882683583188,
      "min_latency_ms": 0.26844900276046246,
      "max_latency_ms": 0.27433982732935464,
      "num_trials": 10,
      "extra_params": {
        "size": 2048,
        "operation": "gemv",
        "blas_level": 2,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "tf32"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 9.378733015152676,
          "efficiency": 0.05649839165754624,
          "mean_latency_ms": 0.8944287023041397,
          "std_latency_ms": 0.08831864922647309,
          "min_latency_ms": 0.859906998812221,
          "max_latency_ms": 0.9827473515306129,
          "speedup_vs_fp32": null,
          "test_size": 2048,
          "num_trials": 10,
          "arithmetic_intensity": 0.9990243902439024,
          "achieved_bandwidth_gbps": 9.387891934112787
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 30.43786255980377,
          "efficiency": 0.00571603052766268,
          "mean_latency_ms": 0.27559780137380585,
          "std_latency_ms": 0.006104430101450234,
          "min_latency_ms": 0.2696650044526905,
          "max_latency_ms": 0.2817022314752561,
          "speedup_vs_fp32": 1.0,
          "test_size": 2048,
          "num_trials": 10,
          "arithmetic_intensity": 0.4995121951219512,
          "achieved_bandwidth_gbps": 60.935174069919654
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 30.813169158183374,
          "efficiency": 0.0028932553200172184,
          "mean_latency_ms": 0.27224100049352273,
          "std_latency_ms": 0.00209882683583188,
          "min_latency_ms": 0.26844900276046246,
          "max_latency_ms": 0.27433982732935464,
          "speedup_vs_fp32": 1.0123302547162176,
          "test_size": 2048,
          "num_trials": 10,
          "arithmetic_intensity": 0.4995121951219512,
          "achieved_bandwidth_gbps": 61.68652028737882
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 29.9072542373539,
          "efficiency": 0.0014040964430682582,
          "mean_latency_ms": 0.28048740059603006,
          "std_latency_ms": 0.010927349472110869,
          "min_latency_ms": 0.27059299463871866,
          "max_latency_ms": 0.29141475006814094,
          "speedup_vs_fp32": 0.9825674906900135,
          "test_size": 2048,
          "num_trials": 10,
          "arithmetic_intensity": 0.9990243902439024,
          "achieved_bandwidth_gbps": 29.936460540320066
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 27.8466764701414,
          "efficiency": 0.0013073557028235399,
          "mean_latency_ms": 0.30124269978841767,
          "std_latency_ms": 0.08008341936707274,
          "min_latency_ms": 0.25993700546678156,
          "max_latency_ms": 0.3813261191554904,
          "speedup_vs_fp32": 0.9148696435378387,
          "test_size": 2048,
          "num_trials": 10,
          "arithmetic_intensity": 0.9990243902439024,
          "achieved_bandwidth_gbps": 27.873870490131775
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Long'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Int'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Short'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Char'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas3_gemm_best_precision=fp64_blas_level=3_device=cuda_framework=pytorch_operation=gemm_size=32": {
      "operation_type": "blas3_gemm",
      "measured_gflops": 0.26516046689385964,
      "efficiency": 0.0015973522102039738,
      "achieved_bandwidth_gbps": 0.09943517508519736,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 2.6666666666666665,
      "batch_size": 1,
      "input_shape": [
        32,
        32
      ],
      "output_shape": [
        32,
        32
      ],
      "mean_latency_ms": 0.24715599865885451,
      "std_latency_ms": 0.006233384749512569,
      "min_latency_ms": 0.23513699125032872,
      "max_latency_ms": 0.2533893834083671,
      "num_trials": 10,
      "extra_params": {
        "size": 32,
        "operation": "gemm",
        "blas_level": 3,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "fp64"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.26516046689385964,
          "efficiency": 0.0015973522102039738,
          "mean_latency_ms": 0.24715599865885451,
          "std_latency_ms": 0.006233384749512569,
          "min_latency_ms": 0.23513699125032872,
          "max_latency_ms": 0.2533893834083671,
          "speedup_vs_fp32": null,
          "test_size": 32,
          "num_trials": 10,
          "arithmetic_intensity": 2.6666666666666665,
          "achieved_bandwidth_gbps": 0.09943517508519736
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.2518220138549925,
          "efficiency": 4.72905190338014e-05,
          "mean_latency_ms": 0.26024730323115364,
          "std_latency_ms": 0.04937619190624977,
          "min_latency_ms": 0.23465699632652104,
          "max_latency_ms": 0.3096234951374034,
          "speedup_vs_fp32": 1.0,
          "test_size": 32,
          "num_trials": 10,
          "arithmetic_intensity": 5.333333333333333,
          "achieved_bandwidth_gbps": 0.04721662759781109
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.2593480196275777,
          "efficiency": 2.435192672559415e-05,
          "mean_latency_ms": 0.2526952011976391,
          "std_latency_ms": 0.009834066459133898,
          "min_latency_ms": 0.24355200002901256,
          "max_latency_ms": 0.262529267656773,
          "speedup_vs_fp32": 1.029886210730246,
          "test_size": 32,
          "num_trials": 10,
          "arithmetic_intensity": 5.333333333333333,
          "achieved_bandwidth_gbps": 0.04862775368017082
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.2583762557187177,
          "efficiency": 1.2130340644071253e-05,
          "mean_latency_ms": 0.25364559842273593,
          "std_latency_ms": 0.00883572359476613,
          "min_latency_ms": 0.24467200273647904,
          "max_latency_ms": 0.2624813220175021,
          "speedup_vs_fp32": 1.0260272792016483,
          "test_size": 32,
          "num_trials": 10,
          "arithmetic_intensity": 10.666666666666666,
          "achieved_bandwidth_gbps": 0.024222773973629784
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.24110480807336143,
          "efficiency": 1.131947455743481e-05,
          "mean_latency_ms": 0.2718154006288387,
          "std_latency_ms": 0.026108210651577136,
          "min_latency_ms": 0.25497699971310794,
          "max_latency_ms": 0.29792361128041583,
          "speedup_vs_fp32": 0.9574413466973448,
          "test_size": 32,
          "num_trials": 10,
          "arithmetic_intensity": 10.666666666666666,
          "achieved_bandwidth_gbps": 0.022603575756877634
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'Lo",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'In",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'Sh",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'Ch",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas3_gemm_best_precision=fp64_blas_level=3_device=cuda_framework=pytorch_operation=gemm_size=64": {
      "operation_type": "blas3_gemm",
      "measured_gflops": 2.0470460536289865,
      "efficiency": 0.012331602732704738,
      "achieved_bandwidth_gbps": 0.383821135055435,
      "memory_bound": false,
      "compute_bound": true,
      "arithmetic_intensity": 5.333333333333333,
      "batch_size": 1,
      "input_shape": [
        64,
        64
      ],
      "output_shape": [
        64,
        64
      ],
      "mean_latency_ms": 0.25611929886508733,
      "std_latency_ms": 0.012434433772894854,
      "min_latency_ms": 0.24313699395861477,
      "max_latency_ms": 0.2685537326379822,
      "num_trials": 10,
      "extra_params": {
        "size": 64,
        "operation": "gemm",
        "blas_level": 3,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "fp64"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 2.0470460536289865,
          "efficiency": 0.012331602732704738,
          "mean_latency_ms": 0.25611929886508733,
          "std_latency_ms": 0.012434433772894854,
          "min_latency_ms": 0.24313699395861477,
          "max_latency_ms": 0.2685537326379822,
          "speedup_vs_fp32": null,
          "test_size": 64,
          "num_trials": 10,
          "arithmetic_intensity": 5.333333333333333,
          "achieved_bandwidth_gbps": 0.383821135055435
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.906528179922874,
          "efficiency": 0.0003580334610183801,
          "mean_latency_ms": 0.27499619754962623,
          "std_latency_ms": 0.04788945851154972,
          "min_latency_ms": 0.24083300377242267,
          "max_latency_ms": 0.322885656061176,
          "speedup_vs_fp32": 1.0,
          "test_size": 64,
          "num_trials": 10,
          "arithmetic_intensity": 10.666666666666666,
          "achieved_bandwidth_gbps": 0.1787370168677694
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 2.027363639091247,
          "efficiency": 0.00019036278301326262,
          "mean_latency_ms": 0.25860580208245665,
          "std_latency_ms": 0.010800298759253958,
          "min_latency_ms": 0.2505290030967444,
          "max_latency_ms": 0.2694061008417106,
          "speedup_vs_fp32": 1.0633798442849458,
          "test_size": 64,
          "num_trials": 10,
          "arithmetic_intensity": 10.666666666666666,
          "achieved_bandwidth_gbps": 0.1900653411648044
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.7502718947968576,
          "efficiency": 8.217238942708251e-05,
          "mean_latency_ms": 0.2995466027641669,
          "std_latency_ms": 0.06339046384563671,
          "min_latency_ms": 0.2479050017427653,
          "max_latency_ms": 0.3629370666098036,
          "speedup_vs_fp32": 0.918041450018149,
          "test_size": 64,
          "num_trials": 10,
          "arithmetic_intensity": 21.333333333333332,
          "achieved_bandwidth_gbps": 0.0820439950686027
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.9950000196551976,
          "efficiency": 9.366197275376515e-05,
          "mean_latency_ms": 0.26280099991708994,
          "std_latency_ms": 0.027771239863400975,
          "min_latency_ms": 0.2463690034346655,
          "max_latency_ms": 0.2905722397804909,
          "speedup_vs_fp32": 1.0464046850521258,
          "test_size": 64,
          "num_trials": 10,
          "arithmetic_intensity": 21.333333333333332,
          "achieved_bandwidth_gbps": 0.0935156259213374
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'Lo",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'In",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'Sh",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'Ch",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas3_gemm_best_precision=fp32_blas_level=3_device=cuda_framework=pytorch_operation=gemm_size=128": {
      "operation_type": "blas3_gemm",
      "measured_gflops": 14.397133767410542,
      "efficiency": 0.0027036870924714634,
      "achieved_bandwidth_gbps": 0.6748656453473691,
      "memory_bound": false,
      "compute_bound": true,
      "arithmetic_intensity": 21.333333333333332,
      "batch_size": 1,
      "input_shape": [
        128,
        128
      ],
      "output_shape": [
        128,
        128
      ],
      "mean_latency_ms": 0.29132909839972854,
      "std_latency_ms": 0.04687356432192832,
      "min_latency_ms": 0.26182500005234033,
      "max_latency_ms": 0.33820266272165683,
      "num_trials": 10,
      "extra_params": {
        "size": 128,
        "operation": "gemm",
        "blas_level": 3,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "fp32"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 10.996206695213926,
          "efficiency": 0.06624220900731281,
          "mean_latency_ms": 0.38143189885886386,
          "std_latency_ms": 0.002981857094533272,
          "min_latency_ms": 0.3766730078496039,
          "max_latency_ms": 0.3844137559533971,
          "speedup_vs_fp32": null,
          "test_size": 128,
          "num_trials": 10,
          "arithmetic_intensity": 10.666666666666666,
          "achieved_bandwidth_gbps": 1.0308943776763058
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 14.397133767410542,
          "efficiency": 0.0027036870924714634,
          "mean_latency_ms": 0.29132909839972854,
          "std_latency_ms": 0.04687356432192832,
          "min_latency_ms": 0.26182500005234033,
          "max_latency_ms": 0.33820266272165683,
          "speedup_vs_fp32": 1.0,
          "test_size": 128,
          "num_trials": 10,
          "arithmetic_intensity": 21.333333333333332,
          "achieved_bandwidth_gbps": 0.6748656453473691
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 13.971875646780672,
          "efficiency": 0.0013119132062704858,
          "mean_latency_ms": 0.3001962017151527,
          "std_latency_ms": 0.06568125050684236,
          "min_latency_ms": 0.26041700039058924,
          "max_latency_ms": 0.3658774522219951,
          "speedup_vs_fp32": 0.9704623067688315,
          "test_size": 128,
          "num_trials": 10,
          "arithmetic_intensity": 21.333333333333332,
          "achieved_bandwidth_gbps": 0.654931670942844
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 11.463013438191743,
          "efficiency": 0.0005381696449855278,
          "mean_latency_ms": 0.3658988993265666,
          "std_latency_ms": 0.06625870736937715,
          "min_latency_ms": 0.28780898719560355,
          "max_latency_ms": 0.4321576066959438,
          "speedup_vs_fp32": 0.7962010788660937,
          "test_size": 128,
          "num_trials": 10,
          "arithmetic_intensity": 42.666666666666664,
          "achieved_bandwidth_gbps": 0.26866437745761895
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 10.973381327351682,
          "efficiency": 0.0005151822219413935,
          "mean_latency_ms": 0.38222530274651945,
          "std_latency_ms": 0.06639786258461867,
          "min_latency_ms": 0.27884899463970214,
          "max_latency_ms": 0.4486231653311381,
          "speedup_vs_fp32": 0.762192079661794,
          "test_size": 128,
          "num_trials": 10,
          "arithmetic_intensity": 42.666666666666664,
          "achieved_bandwidth_gbps": 0.25718862485980504
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'Lo",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'In",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'Sh",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'Ch",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas3_gemm_best_precision=fp32_blas_level=3_device=cuda_framework=pytorch_operation=gemm_size=256": {
      "operation_type": "blas3_gemm",
      "measured_gflops": 122.79103847338673,
      "efficiency": 0.023059349948053847,
      "achieved_bandwidth_gbps": 2.8779149642200013,
      "memory_bound": false,
      "compute_bound": true,
      "arithmetic_intensity": 42.666666666666664,
      "batch_size": 1,
      "input_shape": [
        256,
        256
      ],
      "output_shape": [
        256,
        256
      ],
      "mean_latency_ms": 0.2732645021751523,
      "std_latency_ms": 0.012284012296876026,
      "min_latency_ms": 0.260736997006461,
      "max_latency_ms": 0.28554851447202834,
      "num_trials": 10,
      "extra_params": {
        "size": 256,
        "operation": "gemm",
        "blas_level": 3,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "fp32"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 13.878484296186306,
          "efficiency": 0.08360532708545967,
          "mean_latency_ms": 2.417730299930554,
          "std_latency_ms": 0.15064935724072248,
          "min_latency_ms": 2.1930639923084527,
          "max_latency_ms": 2.5683796571712763,
          "speedup_vs_fp32": null,
          "test_size": 256,
          "num_trials": 10,
          "arithmetic_intensity": 21.333333333333332,
          "achieved_bandwidth_gbps": 0.6505539513837332
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 122.79103847338673,
          "efficiency": 0.023059349948053847,
          "mean_latency_ms": 0.2732645021751523,
          "std_latency_ms": 0.012284012296876026,
          "min_latency_ms": 0.260736997006461,
          "max_latency_ms": 0.28554851447202834,
          "speedup_vs_fp32": 1.0,
          "test_size": 256,
          "num_trials": 10,
          "arithmetic_intensity": 42.666666666666664,
          "achieved_bandwidth_gbps": 2.8779149642200013
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 121.08080075616348,
          "efficiency": 0.0113690892728792,
          "mean_latency_ms": 0.27712429873645306,
          "std_latency_ms": 0.012768835040020583,
          "min_latency_ms": 0.2653130068210885,
          "max_latency_ms": 0.28989313377647363,
          "speedup_vs_fp32": 0.9860719663382119,
          "test_size": 256,
          "num_trials": 10,
          "arithmetic_intensity": 42.666666666666664,
          "achieved_bandwidth_gbps": 2.8378312677225814
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 113.75517415752127,
          "efficiency": 0.005340618505047947,
          "mean_latency_ms": 0.29497060022549704,
          "std_latency_ms": 0.06738693281280583,
          "min_latency_ms": 0.25776099937502295,
          "max_latency_ms": 0.36235753303830287,
          "speedup_vs_fp32": 0.9264126728773951,
          "test_size": 256,
          "num_trials": 10,
          "arithmetic_intensity": 85.33333333333333,
          "achieved_bandwidth_gbps": 1.3330684471584524
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 101.03795387270486,
          "efficiency": 0.00474356590951666,
          "mean_latency_ms": 0.3320973031804897,
          "std_latency_ms": 0.07969889366280443,
          "min_latency_ms": 0.2654730051290244,
          "max_latency_ms": 0.4117961968432941,
          "speedup_vs_fp32": 0.8228446890658347,
          "test_size": 256,
          "num_trials": 10,
          "arithmetic_intensity": 85.33333333333333,
          "achieved_bandwidth_gbps": 1.1840385219457603
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'Lo",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'In",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'Sh",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'Ch",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas3_gemm_best_precision=bf16_blas_level=3_device=cuda_framework=pytorch_operation=gemm_size=512": {
      "operation_type": "blas3_gemm",
      "measured_gflops": 1080.403162933339,
      "efficiency": 0.05072315318935864,
      "achieved_bandwidth_gbps": 6.330487282812533,
      "memory_bound": false,
      "compute_bound": true,
      "arithmetic_intensity": 170.66666666666666,
      "batch_size": 1,
      "input_shape": [
        512,
        512
      ],
      "output_shape": [
        512,
        512
      ],
      "mean_latency_ms": 0.24845859879860654,
      "std_latency_ms": 0.006131712432426291,
      "min_latency_ms": 0.23929700546432287,
      "max_latency_ms": 0.2545903112310328,
      "num_trials": 10,
      "extra_params": {
        "size": 512,
        "operation": "gemm",
        "blas_level": 3,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "bf16"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 16.27747740099676,
          "efficiency": 0.0980570927770889,
          "mean_latency_ms": 16.491219701129012,
          "std_latency_ms": 0.14463174718175542,
          "min_latency_ms": 16.316473003826104,
          "max_latency_ms": 16.635851448310767,
          "speedup_vs_fp32": null,
          "test_size": 512,
          "num_trials": 10,
          "arithmetic_intensity": 42.666666666666664,
          "achieved_bandwidth_gbps": 0.3815033765858616
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 393.8244294616962,
          "efficiency": 0.0739576393355298,
          "mean_latency_ms": 0.6816119974246249,
          "std_latency_ms": 0.14444317554756075,
          "min_latency_ms": 0.5661460018018261,
          "max_latency_ms": 0.8260551729721857,
          "speedup_vs_fp32": 1.0,
          "test_size": 512,
          "num_trials": 10,
          "arithmetic_intensity": 85.33333333333333,
          "achieved_bandwidth_gbps": 4.615130032754252
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 761.3393267453772,
          "efficiency": 0.07148726072726547,
          "mean_latency_ms": 0.3525831998558715,
          "std_latency_ms": 0.12076778180208766,
          "min_latency_ms": 0.2633599942782894,
          "max_latency_ms": 0.4733509816579592,
          "speedup_vs_fp32": 1.9331947685064212,
          "test_size": 512,
          "num_trials": 10,
          "arithmetic_intensity": 85.33333333333333,
          "achieved_bandwidth_gbps": 8.92194523529739
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1055.0625717470978,
          "efficiency": 0.049533454072633695,
          "mean_latency_ms": 0.25442610058235005,
          "std_latency_ms": 0.005060916356843243,
          "min_latency_ms": 0.24643300275783986,
          "max_latency_ms": 0.2594870169391933,
          "speedup_vs_fp32": 2.679017584534365,
          "test_size": 512,
          "num_trials": 10,
          "arithmetic_intensity": 170.66666666666666,
          "achieved_bandwidth_gbps": 6.1820072563306505
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1080.403162933339,
          "efficiency": 0.05072315318935864,
          "mean_latency_ms": 0.24845859879860654,
          "std_latency_ms": 0.006131712432426291,
          "min_latency_ms": 0.23929700546432287,
          "max_latency_ms": 0.2545903112310328,
          "speedup_vs_fp32": 2.7433624785798623,
          "test_size": 512,
          "num_trials": 10,
          "arithmetic_intensity": 170.66666666666666,
          "achieved_bandwidth_gbps": 6.330487282812533
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'Lo",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'In",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'Sh",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'Ch",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas3_gemm_best_precision=fp16_blas_level=3_device=cuda_framework=pytorch_operation=gemm_size=1024": {
      "operation_type": "blas3_gemm",
      "measured_gflops": 2718.6434439353884,
      "efficiency": 0.12763584243828113,
      "achieved_bandwidth_gbps": 7.964775714654457,
      "memory_bound": false,
      "compute_bound": true,
      "arithmetic_intensity": 341.3333333333333,
      "batch_size": 1,
      "input_shape": [
        1024,
        1024
      ],
      "output_shape": [
        1024,
        1024
      ],
      "mean_latency_ms": 0.7899100019130856,
      "std_latency_ms": 0.1300762160694639,
      "min_latency_ms": 0.6006740004522726,
      "max_latency_ms": 0.9199862179825495,
      "num_trials": 10,
      "extra_params": {
        "size": 1024,
        "operation": "gemm",
        "blas_level": 3,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "fp16"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 16.622062963295505,
          "efficiency": 0.10013290941744281,
          "mean_latency_ms": 129.19477279938292,
          "std_latency_ms": 0.18267968210119997,
          "min_latency_ms": 129.0044550114544,
          "max_latency_ms": 129.3774524814841,
          "speedup_vs_fp32": null,
          "test_size": 1024,
          "num_trials": 10,
          "arithmetic_intensity": 85.33333333333333,
          "achieved_bandwidth_gbps": 0.1947898003511192
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 620.679638558197,
          "efficiency": 0.11655955653675061,
          "mean_latency_ms": 3.4598906015162356,
          "std_latency_ms": 0.11413484152348553,
          "min_latency_ms": 3.41041199862957,
          "max_latency_ms": 3.574025443039721,
          "speedup_vs_fp32": 1.0,
          "test_size": 1024,
          "num_trials": 10,
          "arithmetic_intensity": 170.66666666666666,
          "achieved_bandwidth_gbps": 3.6367947571769355
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 2121.78354170071,
          "efficiency": 0.19922850156814179,
          "mean_latency_ms": 1.0121125014848076,
          "std_latency_ms": 0.1192437165553786,
          "min_latency_ms": 0.9520040039205924,
          "max_latency_ms": 1.1313562180401862,
          "speedup_vs_fp32": 3.4184842064893424,
          "test_size": 1024,
          "num_trials": 10,
          "arithmetic_intensity": 170.66666666666666,
          "achieved_bandwidth_gbps": 12.432325439652598
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 2718.6434439353884,
          "efficiency": 0.12763584243828113,
          "mean_latency_ms": 0.7899100019130856,
          "std_latency_ms": 0.1300762160694639,
          "min_latency_ms": 0.6006740004522726,
          "max_latency_ms": 0.9199862179825495,
          "speedup_vs_fp32": 4.380107345313664,
          "test_size": 1024,
          "num_trials": 10,
          "arithmetic_intensity": 341.3333333333333,
          "achieved_bandwidth_gbps": 7.964775714654457
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 2609.3320190223967,
          "efficiency": 0.12250385065832849,
          "mean_latency_ms": 0.8230013016145676,
          "std_latency_ms": 0.11243967826844717,
          "min_latency_ms": 0.6092500116210431,
          "max_latency_ms": 0.9354409798830148,
          "speedup_vs_fp32": 4.2039916519313,
          "test_size": 1024,
          "num_trials": 10,
          "arithmetic_intensity": 341.3333333333333,
          "achieved_bandwidth_gbps": 7.644527399479677
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'Lo",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'In",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'Sh",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'Ch",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas3_gemm_best_precision=fp16_blas_level=3_device=cuda_framework=pytorch_operation=gemm_size=2048": {
      "operation_type": "blas3_gemm",
      "measured_gflops": 5627.315754605452,
      "efficiency": 0.2641932279157489,
      "achieved_bandwidth_gbps": 8.24313831241033,
      "memory_bound": false,
      "compute_bound": true,
      "arithmetic_intensity": 682.6666666666666,
      "batch_size": 1,
      "input_shape": [
        2048,
        2048
      ],
      "output_shape": [
        2048,
        2048
      ],
      "mean_latency_ms": 3.052942101203371,
      "std_latency_ms": 0.0047797674193233814,
      "min_latency_ms": 3.045354998903349,
      "max_latency_ms": 3.057721868622694,
      "num_trials": 10,
      "extra_params": {
        "size": 2048,
        "operation": "gemm",
        "blas_level": 3,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "fp16"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 16.745125355596223,
          "efficiency": 0.10087424913009772,
          "mean_latency_ms": 1025.9624111000448,
          "std_latency_ms": 0.6681716802282085,
          "min_latency_ms": 1025.7129379897378,
          "max_latency_ms": 1026.630582780273,
          "speedup_vs_fp32": null,
          "test_size": 2048,
          "num_trials": 10,
          "arithmetic_intensity": 170.66666666666666,
          "achieved_bandwidth_gbps": 0.09811596888044663
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 752.9071282410351,
          "efficiency": 0.14139100999831647,
          "mean_latency_ms": 22.818045598978642,
          "std_latency_ms": 0.013094684675792658,
          "min_latency_ms": 22.789135997300036,
          "max_latency_ms": 22.831140283654435,
          "speedup_vs_fp32": 1.0,
          "test_size": 2048,
          "num_trials": 10,
          "arithmetic_intensity": 341.3333333333333,
          "achieved_bandwidth_gbps": 2.2057826022686577
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 3267.58828026538,
          "efficiency": 0.30681580096388544,
          "mean_latency_ms": 5.2576603018678725,
          "std_latency_ms": 0.13755933937642134,
          "min_latency_ms": 5.166866001673043,
          "max_latency_ms": 5.395219641244294,
          "speedup_vs_fp32": 4.339961939129492,
          "test_size": 2048,
          "num_trials": 10,
          "arithmetic_intensity": 341.3333333333333,
          "achieved_bandwidth_gbps": 9.57301253983998
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 5627.315754605452,
          "efficiency": 0.2641932279157489,
          "mean_latency_ms": 3.052942101203371,
          "std_latency_ms": 0.0047797674193233814,
          "min_latency_ms": 3.045354998903349,
          "max_latency_ms": 3.057721868622694,
          "speedup_vs_fp32": 7.474116718422046,
          "test_size": 2048,
          "num_trials": 10,
          "arithmetic_intensity": 682.6666666666666,
          "achieved_bandwidth_gbps": 8.24313831241033
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 5563.945530878081,
          "efficiency": 0.2612181000412244,
          "mean_latency_ms": 3.0877134020556696,
          "std_latency_ms": 0.0550218897891023,
          "min_latency_ms": 3.0478830012725666,
          "max_latency_ms": 3.142735291844772,
          "speedup_vs_fp32": 7.389949333959345,
          "test_size": 2048,
          "num_trials": 10,
          "arithmetic_intensity": 682.6666666666666,
          "achieved_bandwidth_gbps": 8.15031083624719
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'Lo",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'In",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'Sh",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'Ch",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    }
  },
  "fusion_profiles": {},
  "precision_matrix": {
    "hardware_name": "Jetson Orin AGX (GPU)",
    "supported_precisions": [
      "fp64",
      "fp32",
      "tf32",
      "fp16",
      "bf16",
      "int64",
      "int32",
      "int16",
      "int8"
    ],
    "unsupported_precisions": [
      "fp8",
      "fp4",
      "int4"
    ],
    "peak_gflops_by_precision": {
      "fp64": 16.745125355596223,
      "fp32": 752.9071282410351,
      "tf32": 3267.58828026538,
      "fp16": 5627.315754605452,
      "bf16": 5563.945530878081,
      "int64": 3.3764210233446637,
      "int32": 7.759677810981473,
      "int16": 14.176015220832479,
      "int8": 19.123848522487993
    },
    "speedup_vs_fp32": {
      "fp32": 1.0,
      "tf32": 4.339961939129492,
      "fp16": 7.474116718422046,
      "bf16": 7.389949333959345,
      "int64": 0.43492722508196546,
      "int32": 0.9995480760622442,
      "int16": 1.82605632416328,
      "int8": 2.4634020204430245
    },
    "theoretical_peaks": {
      "fp64": 166.0,
      "fp32": 5325.0,
      "fp16": 21300.0,
      "fp8": 0.0,
      "fp4": 0.0,
      "bf16": 21300.0,
      "tf32": 10650.0,
      "int64": 0.0,
      "int32": 5325.0,
      "int16": 21300.0,
      "int8": 42600.0,
      "int4": 0.0
    }
  }
}