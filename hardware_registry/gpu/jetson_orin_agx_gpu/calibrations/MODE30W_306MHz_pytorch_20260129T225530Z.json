{
  "metadata": {
    "hardware_name": "Jetson Orin AGX (GPU)",
    "calibration_date": "2026-01-29T22:50:19.975732",
    "calibration_tool_version": "1.0.0",
    "cpu_model": "aarch64",
    "cpu_count": 8,
    "total_memory_gb": 61.32390213012695,
    "python_version": "3.8.10",
    "pytorch_version": "2.1.0a0+41361538.nv23.06",
    "numpy_version": "1.24.4",
    "num_warmup_runs": 3,
    "num_measurement_runs": 10,
    "device_type": "cuda",
    "platform_architecture": "aarch64",
    "framework": "pytorch",
    "gpu_clock": {
      "sm_clock_mhz": 306,
      "query_method": "sysfs_under_load",
      "max_sm_clock_mhz": 612,
      "nvpmodel_mode": 30,
      "power_mode_name": "MODE_30W",
      "clock_policy": "dvfs"
    },
    "cpu_clock": {
      "current_freq_mhz": 1216.0,
      "query_method": "sysfs",
      "min_freq_mhz": 1728.0,
      "max_freq_mhz": 1728.0,
      "base_freq_mhz": 2201.6,
      "per_core_freq_mhz": [
        1728.0,
        1728.0,
        1728.0,
        1728.0,
        1728.0,
        1728.0,
        1728.0,
        1728.0,
        192.0,
        192.0,
        192.0,
        192.0
      ],
      "governor": "schedutil",
      "driver": "tegra194",
      "nvpmodel_mode": 30,
      "power_mode_name": "MODE_30W",
      "clock_policy": "dvfs"
    },
    "preflight": {
      "timestamp": "2026-01-29T22:50:16.256260",
      "passed": true,
      "forced": false,
      "checks": [
        {
          "name": "CPU Governor",
          "status": "passed",
          "message": "schedutil (Jetson default)",
          "current_value": "schedutil",
          "expected_value": "schedutil or performance"
        },
        {
          "name": "CPU Frequency",
          "status": "passed",
          "message": "1216 MHz idle (DVFS will boost under load)",
          "current_value": "1216 MHz (idle)",
          "expected_value": "Up to 1728 MHz under load"
        },
        {
          "name": "Turbo Boost",
          "status": "skipped",
          "message": "Could not determine (not Intel pstate)"
        },
        {
          "name": "System Load",
          "status": "passed",
          "message": "0.0% (idle)",
          "current_value": "0.0%",
          "expected_value": "< 5%"
        },
        {
          "name": "Thermal State",
          "status": "passed",
          "message": "41\u00b0C (cool)",
          "current_value": "41\u00b0C",
          "expected_value": "< 80\u00b0C"
        },
        {
          "name": "GPU Power Mode",
          "status": "warning",
          "message": "MODE_30W (unknown mode)",
          "current_value": "MODE_30W",
          "expected_value": "Known mode (MAXN, 7W, 15W, 25W, etc.)"
        }
      ]
    }
  },
  "theoretical_peak_gflops": 5325.0,
  "theoretical_bandwidth_gbps": 204.8,
  "best_measured_gflops": 5048.283519477215,
  "avg_measured_gflops": 182.4845607882996,
  "worst_measured_gflops": 0.008329395039891553,
  "measured_bandwidth_gbps": 127.68490021062378,
  "bandwidth_efficiency": 0.6234614268096864,
  "best_efficiency": 0.6234614268096864,
  "avg_efficiency": 0.2420572611486424,
  "worst_efficiency": 0.0,
  "operation_profiles": {
    "stream_copy_device=cuda_flops_per_element=0_framework=pytorch_kernel=copy_num_arrays=2_num_memory_ops=2_size_mb=8": {
      "operation_type": "stream_copy",
      "measured_gflops": 0.0,
      "efficiency": 0.2141229130973487,
      "achieved_bandwidth_gbps": 43.85237260233702,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.0,
      "batch_size": 1,
      "input_shape": [
        2097152
      ],
      "output_shape": [
        2097152
      ],
      "mean_latency_ms": 0.38258399727055803,
      "std_latency_ms": 0.12865334992489608,
      "min_latency_ms": 0.33715300378389657,
      "max_latency_ms": 0.7481949869543314,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 8,
        "kernel": "copy",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 2,
        "num_memory_ops": 2,
        "flops_per_element": 0
      },
      "precision_results": {}
    },
    "stream_copy_device=cuda_flops_per_element=0_framework=pytorch_kernel=copy_num_arrays=2_num_memory_ops=2_size_mb=16": {
      "operation_type": "stream_copy",
      "measured_gflops": 0.0,
      "efficiency": 0.27254515134005136,
      "achieved_bandwidth_gbps": 55.81724699444253,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.0,
      "batch_size": 1,
      "input_shape": [
        4194304
      ],
      "output_shape": [
        4194304
      ],
      "mean_latency_ms": 0.6011481003952213,
      "std_latency_ms": 0.0018395112594517713,
      "min_latency_ms": 0.5981779977446422,
      "max_latency_ms": 0.6036190025042742,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 16,
        "kernel": "copy",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 2,
        "num_memory_ops": 2,
        "flops_per_element": 0
      },
      "precision_results": {}
    },
    "stream_copy_device=cuda_flops_per_element=0_framework=pytorch_kernel=copy_num_arrays=2_num_memory_ops=2_size_mb=32": {
      "operation_type": "stream_copy",
      "measured_gflops": 0.0,
      "efficiency": 0.28889062610962774,
      "achieved_bandwidth_gbps": 59.16480022725176,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.0,
      "batch_size": 1,
      "input_shape": [
        8388608
      ],
      "output_shape": [
        8388608
      ],
      "mean_latency_ms": 1.1342701021931134,
      "std_latency_ms": 0.005692218238495997,
      "min_latency_ms": 1.1301170015940443,
      "max_latency_ms": 1.1496049992274493,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 32,
        "kernel": "copy",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 2,
        "num_memory_ops": 2,
        "flops_per_element": 0
      },
      "precision_results": {}
    },
    "stream_copy_device=cuda_flops_per_element=0_framework=pytorch_kernel=copy_num_arrays=2_num_memory_ops=2_size_mb=64": {
      "operation_type": "stream_copy",
      "measured_gflops": 0.0,
      "efficiency": 0.3217760058271968,
      "achieved_bandwidth_gbps": 65.8997259934099,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.0,
      "batch_size": 1,
      "input_shape": [
        16777216
      ],
      "output_shape": [
        16777216
      ],
      "mean_latency_ms": 2.036696298455354,
      "std_latency_ms": 0.11790719642548811,
      "min_latency_ms": 1.9547919946489856,
      "max_latency_ms": 2.2376409906428307,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 64,
        "kernel": "copy",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 2,
        "num_memory_ops": 2,
        "flops_per_element": 0
      },
      "precision_results": {}
    },
    "stream_copy_device=cuda_flops_per_element=0_framework=pytorch_kernel=copy_num_arrays=2_num_memory_ops=2_size_mb=128": {
      "operation_type": "stream_copy",
      "measured_gflops": 0.0,
      "efficiency": 0.35707262985269106,
      "achieved_bandwidth_gbps": 73.12847459383113,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.0,
      "batch_size": 1,
      "input_shape": [
        33554432
      ],
      "output_shape": [
        33554432
      ],
      "mean_latency_ms": 3.6707378007122315,
      "std_latency_ms": 0.25654892597349266,
      "min_latency_ms": 3.3328779973089695,
      "max_latency_ms": 3.883088007569313,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 128,
        "kernel": "copy",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 2,
        "num_memory_ops": 2,
        "flops_per_element": 0
      },
      "precision_results": {}
    },
    "stream_copy_device=cuda_flops_per_element=0_framework=pytorch_kernel=copy_num_arrays=2_num_memory_ops=2_size_mb=256": {
      "operation_type": "stream_copy",
      "measured_gflops": 0.0,
      "efficiency": 0.34148235832623014,
      "achieved_bandwidth_gbps": 69.93558698521194,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.0,
      "batch_size": 1,
      "input_shape": [
        67108864
      ],
      "output_shape": [
        67108864
      ],
      "mean_latency_ms": 7.676648400956765,
      "std_latency_ms": 0.01026438144258997,
      "min_latency_ms": 7.66316699446179,
      "max_latency_ms": 7.693182997172698,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 256,
        "kernel": "copy",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 2,
        "num_memory_ops": 2,
        "flops_per_element": 0
      },
      "precision_results": {}
    },
    "stream_copy_device=cuda_flops_per_element=0_framework=pytorch_kernel=copy_num_arrays=2_num_memory_ops=2_size_mb=512": {
      "operation_type": "stream_copy",
      "measured_gflops": 0.0,
      "efficiency": 0.34244842433713885,
      "achieved_bandwidth_gbps": 70.13343730424604,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.0,
      "batch_size": 1,
      "input_shape": [
        134217728
      ],
      "output_shape": [
        134217728
      ],
      "mean_latency_ms": 15.309984299528878,
      "std_latency_ms": 0.016956856869457037,
      "min_latency_ms": 15.291420990251936,
      "max_latency_ms": 15.338429002440535,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 512,
        "kernel": "copy",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 2,
        "num_memory_ops": 2,
        "flops_per_element": 0
      },
      "precision_results": {}
    },
    "stream_scale_device=cuda_flops_per_element=1_framework=pytorch_kernel=scale_num_arrays=2_num_memory_ops=2_size_mb=8": {
      "operation_type": "stream_scale",
      "measured_gflops": 10.514148222970526,
      "efficiency": 0.4107089149597862,
      "achieved_bandwidth_gbps": 84.11318578376421,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.5,
      "batch_size": 1,
      "input_shape": [
        2097152
      ],
      "output_shape": [
        2097152
      ],
      "mean_latency_ms": 0.19945999956689775,
      "std_latency_ms": 0.0017246199964818082,
      "min_latency_ms": 0.19715300004463643,
      "max_latency_ms": 0.20259300072211772,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 8,
        "kernel": "scale",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 2,
        "num_memory_ops": 2,
        "flops_per_element": 1
      },
      "precision_results": {}
    },
    "stream_scale_device=cuda_flops_per_element=1_framework=pytorch_kernel=scale_num_arrays=2_num_memory_ops=2_size_mb=16": {
      "operation_type": "stream_scale",
      "measured_gflops": 12.871471159884418,
      "efficiency": 0.502791842182985,
      "achieved_bandwidth_gbps": 102.97176927907535,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.5,
      "batch_size": 1,
      "input_shape": [
        4194304
      ],
      "output_shape": [
        4194304
      ],
      "mean_latency_ms": 0.32586049783276394,
      "std_latency_ms": 0.0017034380761489975,
      "min_latency_ms": 0.3231369919376448,
      "max_latency_ms": 0.3284169943071902,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 16,
        "kernel": "scale",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 2,
        "num_memory_ops": 2,
        "flops_per_element": 1
      },
      "precision_results": {}
    },
    "stream_scale_device=cuda_flops_per_element=1_framework=pytorch_kernel=scale_num_arrays=2_num_memory_ops=2_size_mb=32": {
      "operation_type": "stream_scale",
      "measured_gflops": 14.489280348260241,
      "efficiency": 0.5659875136039156,
      "achieved_bandwidth_gbps": 115.91424278608193,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.5,
      "batch_size": 1,
      "input_shape": [
        8388608
      ],
      "output_shape": [
        8388608
      ],
      "mean_latency_ms": 0.5789527014712803,
      "std_latency_ms": 0.0015777090197098347,
      "min_latency_ms": 0.576738006202504,
      "max_latency_ms": 0.580802996410057,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 32,
        "kernel": "scale",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 2,
        "num_memory_ops": 2,
        "flops_per_element": 1
      },
      "precision_results": {}
    },
    "stream_scale_device=cuda_flops_per_element=1_framework=pytorch_kernel=scale_num_arrays=2_num_memory_ops=2_size_mb=64": {
      "operation_type": "stream_scale",
      "measured_gflops": 15.374861074329765,
      "efficiency": 0.6005805107160064,
      "achieved_bandwidth_gbps": 122.99888859463812,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.5,
      "batch_size": 1,
      "input_shape": [
        16777216
      ],
      "output_shape": [
        16777216
      ],
      "mean_latency_ms": 1.0912109006312676,
      "std_latency_ms": 0.005488241216930771,
      "min_latency_ms": 1.083301001926884,
      "max_latency_ms": 1.1009650042979047,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 64,
        "kernel": "scale",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 2,
        "num_memory_ops": 2,
        "flops_per_element": 1
      },
      "precision_results": {}
    },
    "stream_scale_device=cuda_flops_per_element=1_framework=pytorch_kernel=scale_num_arrays=2_num_memory_ops=2_size_mb=128": {
      "operation_type": "stream_scale",
      "measured_gflops": 15.878237809995174,
      "efficiency": 0.6202436644529364,
      "achieved_bandwidth_gbps": 127.02590247996139,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.5,
      "batch_size": 1,
      "input_shape": [
        33554432
      ],
      "output_shape": [
        33554432
      ],
      "mean_latency_ms": 2.113233999989461,
      "std_latency_ms": 0.003909586957009189,
      "min_latency_ms": 2.1090320078656077,
      "max_latency_ms": 2.121800003806129,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 128,
        "kernel": "scale",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 2,
        "num_memory_ops": 2,
        "flops_per_element": 1
      },
      "precision_results": {}
    },
    "stream_scale_device=cuda_flops_per_element=1_framework=pytorch_kernel=scale_num_arrays=2_num_memory_ops=2_size_mb=256": {
      "operation_type": "stream_scale",
      "measured_gflops": 14.36584683549694,
      "efficiency": 0.5611658920115992,
      "achieved_bandwidth_gbps": 114.92677468397552,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.5,
      "batch_size": 1,
      "input_shape": [
        67108864
      ],
      "output_shape": [
        67108864
      ],
      "mean_latency_ms": 4.671417200006545,
      "std_latency_ms": 0.005892548578666085,
      "min_latency_ms": 4.663315005018376,
      "max_latency_ms": 4.679954989114776,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 256,
        "kernel": "scale",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 2,
        "num_memory_ops": 2,
        "flops_per_element": 1
      },
      "precision_results": {}
    },
    "stream_scale_device=cuda_flops_per_element=1_framework=pytorch_kernel=scale_num_arrays=2_num_memory_ops=2_size_mb=512": {
      "operation_type": "stream_scale",
      "measured_gflops": 14.463498310874984,
      "efficiency": 0.564980402768554,
      "achieved_bandwidth_gbps": 115.70798648699987,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.5,
      "batch_size": 1,
      "input_shape": [
        134217728
      ],
      "output_shape": [
        134217728
      ],
      "mean_latency_ms": 9.279755500028841,
      "std_latency_ms": 0.011743324094592857,
      "min_latency_ms": 9.265636996133253,
      "max_latency_ms": 9.300261008320376,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 512,
        "kernel": "scale",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 2,
        "num_memory_ops": 2,
        "flops_per_element": 1
      },
      "precision_results": {}
    },
    "stream_add_device=cuda_flops_per_element=1_framework=pytorch_kernel=add_num_arrays=3_num_memory_ops=3_size_mb=8": {
      "operation_type": "stream_add",
      "measured_gflops": 8.211470175898667,
      "efficiency": 0.4811408306190625,
      "achieved_bandwidth_gbps": 98.537642110784,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.3333333333333333,
      "batch_size": 1,
      "input_shape": [
        2097152
      ],
      "output_shape": [
        2097152
      ],
      "mean_latency_ms": 0.25539299967931584,
      "std_latency_ms": 0.004150199782791845,
      "min_latency_ms": 0.2514889929443598,
      "max_latency_ms": 0.2644810010679066,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 8,
        "kernel": "add",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 3,
        "num_memory_ops": 3,
        "flops_per_element": 1
      },
      "precision_results": {}
    },
    "stream_add_device=cuda_flops_per_element=1_framework=pytorch_kernel=add_num_arrays=3_num_memory_ops=3_size_mb=16": {
      "operation_type": "stream_add",
      "measured_gflops": 9.440400871451452,
      "efficiency": 0.5531484885616086,
      "achieved_bandwidth_gbps": 113.28481045741744,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.3333333333333333,
      "batch_size": 1,
      "input_shape": [
        4194304
      ],
      "output_shape": [
        4194304
      ],
      "mean_latency_ms": 0.44429299741750583,
      "std_latency_ms": 0.001210633609514452,
      "min_latency_ms": 0.44246499601285905,
      "max_latency_ms": 0.4455699963727966,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 16,
        "kernel": "add",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 3,
        "num_memory_ops": 3,
        "flops_per_element": 1
      },
      "precision_results": {}
    },
    "stream_add_device=cuda_flops_per_element=1_framework=pytorch_kernel=add_num_arrays=3_num_memory_ops=3_size_mb=32": {
      "operation_type": "stream_add",
      "measured_gflops": 10.169684944810426,
      "efficiency": 0.5958799772349858,
      "achieved_bandwidth_gbps": 122.0362193377251,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.3333333333333333,
      "batch_size": 1,
      "input_shape": [
        8388608
      ],
      "output_shape": [
        8388608
      ],
      "mean_latency_ms": 0.824864098103717,
      "std_latency_ms": 0.0042710700587469865,
      "min_latency_ms": 0.819459994090721,
      "max_latency_ms": 0.8317469910252839,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 32,
        "kernel": "add",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 3,
        "num_memory_ops": 3,
        "flops_per_element": 1
      },
      "precision_results": {}
    },
    "stream_add_device=cuda_flops_per_element=1_framework=pytorch_kernel=add_num_arrays=3_num_memory_ops=3_size_mb=64": {
      "operation_type": "stream_add",
      "measured_gflops": 10.640408350885314,
      "efficiency": 0.6234614268096864,
      "achieved_bandwidth_gbps": 127.68490021062378,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.3333333333333333,
      "batch_size": 1,
      "input_shape": [
        16777216
      ],
      "output_shape": [
        16777216
      ],
      "mean_latency_ms": 1.5767455013701692,
      "std_latency_ms": 0.0032726877984618438,
      "min_latency_ms": 1.5721340023446828,
      "max_latency_ms": 1.582758006406948,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 64,
        "kernel": "add",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 3,
        "num_memory_ops": 3,
        "flops_per_element": 1
      },
      "precision_results": {}
    },
    "stream_add_device=cuda_flops_per_element=1_framework=pytorch_kernel=add_num_arrays=3_num_memory_ops=3_size_mb=128": {
      "operation_type": "stream_add",
      "measured_gflops": 10.436105003858312,
      "efficiency": 0.611490527569823,
      "achieved_bandwidth_gbps": 125.23326004629976,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.3333333333333333,
      "batch_size": 1,
      "input_shape": [
        33554432
      ],
      "output_shape": [
        33554432
      ],
      "mean_latency_ms": 3.215225602616556,
      "std_latency_ms": 0.006334406151088963,
      "min_latency_ms": 3.206028006388806,
      "max_latency_ms": 3.2246530026895925,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 128,
        "kernel": "add",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 3,
        "num_memory_ops": 3,
        "flops_per_element": 1
      },
      "precision_results": {}
    },
    "stream_add_device=cuda_flops_per_element=1_framework=pytorch_kernel=add_num_arrays=3_num_memory_ops=3_size_mb=256": {
      "operation_type": "stream_add",
      "measured_gflops": 10.537965403328046,
      "efficiency": 0.6174589103512527,
      "achieved_bandwidth_gbps": 126.45558483993655,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.3333333333333333,
      "batch_size": 1,
      "input_shape": [
        67108864
      ],
      "output_shape": [
        67108864
      ],
      "mean_latency_ms": 6.368294204003178,
      "std_latency_ms": 0.007661113280375219,
      "min_latency_ms": 6.356024998240173,
      "max_latency_ms": 6.379609010764398,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 256,
        "kernel": "add",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 3,
        "num_memory_ops": 3,
        "flops_per_element": 1
      },
      "precision_results": {}
    },
    "stream_add_device=cuda_flops_per_element=1_framework=pytorch_kernel=add_num_arrays=3_num_memory_ops=3_size_mb=512": {
      "operation_type": "stream_add",
      "measured_gflops": 10.598718826691945,
      "efficiency": 0.6210186812514811,
      "achieved_bandwidth_gbps": 127.18462592030333,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.3333333333333333,
      "batch_size": 1,
      "input_shape": [
        134217728
      ],
      "output_shape": [
        134217728
      ],
      "mean_latency_ms": 12.66358040011255,
      "std_latency_ms": 0.010875076010508083,
      "min_latency_ms": 12.65240200154949,
      "max_latency_ms": 12.683155000559054,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 512,
        "kernel": "add",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 3,
        "num_memory_ops": 3,
        "flops_per_element": 1
      },
      "precision_results": {}
    },
    "stream_triad_device=cuda_flops_per_element=2_framework=pytorch_kernel=triad_num_arrays=3_num_memory_ops=3_size_mb=8": {
      "operation_type": "stream_triad",
      "measured_gflops": 10.578469629616372,
      "efficiency": 0.3099161024301671,
      "achieved_bandwidth_gbps": 63.47081777769822,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.6666666666666666,
      "batch_size": 1,
      "input_shape": [
        2097152
      ],
      "output_shape": [
        2097152
      ],
      "mean_latency_ms": 0.3964944029576145,
      "std_latency_ms": 0.0030290045080925733,
      "min_latency_ms": 0.393217007513158,
      "max_latency_ms": 0.40368099871557206,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 8,
        "kernel": "triad",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 3,
        "num_memory_ops": 3,
        "flops_per_element": 2
      },
      "precision_results": {}
    },
    "stream_triad_device=cuda_flops_per_element=2_framework=pytorch_kernel=triad_num_arrays=3_num_memory_ops=3_size_mb=16": {
      "operation_type": "stream_triad",
      "measured_gflops": 11.741022002825417,
      "efficiency": 0.3439752539890259,
      "achieved_bandwidth_gbps": 70.4461320169525,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.6666666666666666,
      "batch_size": 1,
      "input_shape": [
        4194304
      ],
      "output_shape": [
        4194304
      ],
      "mean_latency_ms": 0.7144700008211657,
      "std_latency_ms": 0.003939676057680913,
      "min_latency_ms": 0.7105309923645109,
      "max_latency_ms": 0.7246739987749606,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 16,
        "kernel": "triad",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 3,
        "num_memory_ops": 3,
        "flops_per_element": 2
      },
      "precision_results": {}
    },
    "stream_triad_device=cuda_flops_per_element=2_framework=pytorch_kernel=triad_num_arrays=3_num_memory_ops=3_size_mb=32": {
      "operation_type": "stream_triad",
      "measured_gflops": 12.49766632040911,
      "efficiency": 0.36614256798073563,
      "achieved_bandwidth_gbps": 74.98599792245466,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.6666666666666666,
      "batch_size": 1,
      "input_shape": [
        8388608
      ],
      "output_shape": [
        8388608
      ],
      "mean_latency_ms": 1.342427903728094,
      "std_latency_ms": 0.003045075612785002,
      "min_latency_ms": 1.3395580026553944,
      "max_latency_ms": 1.3501490029739216,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 32,
        "kernel": "triad",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 3,
        "num_memory_ops": 3,
        "flops_per_element": 2
      },
      "precision_results": {}
    },
    "stream_triad_device=cuda_flops_per_element=2_framework=pytorch_kernel=triad_num_arrays=3_num_memory_ops=3_size_mb=64": {
      "operation_type": "stream_triad",
      "measured_gflops": 12.87199248132961,
      "efficiency": 0.37710915472645334,
      "achieved_bandwidth_gbps": 77.23195488797765,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.6666666666666666,
      "batch_size": 1,
      "input_shape": [
        16777216
      ],
      "output_shape": [
        16777216
      ],
      "mean_latency_ms": 2.6067784026963636,
      "std_latency_ms": 0.002689822202867921,
      "min_latency_ms": 2.603147004265338,
      "max_latency_ms": 2.6112430059583858,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 64,
        "kernel": "triad",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 3,
        "num_memory_ops": 3,
        "flops_per_element": 2
      },
      "precision_results": {}
    },
    "stream_triad_device=cuda_flops_per_element=2_framework=pytorch_kernel=triad_num_arrays=3_num_memory_ops=3_size_mb=128": {
      "operation_type": "stream_triad",
      "measured_gflops": 12.737110560531232,
      "efficiency": 0.3731575359530634,
      "achieved_bandwidth_gbps": 76.42266336318738,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.6666666666666666,
      "batch_size": 1,
      "input_shape": [
        33554432
      ],
      "output_shape": [
        33554432
      ],
      "mean_latency_ms": 5.268766701919958,
      "std_latency_ms": 0.004023941342564635,
      "min_latency_ms": 5.261333004455082,
      "max_latency_ms": 5.2746449946425855,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 128,
        "kernel": "triad",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 3,
        "num_memory_ops": 3,
        "flops_per_element": 2
      },
      "precision_results": {}
    },
    "stream_triad_device=cuda_flops_per_element=2_framework=pytorch_kernel=triad_num_arrays=3_num_memory_ops=3_size_mb=256": {
      "operation_type": "stream_triad",
      "measured_gflops": 12.34861834581049,
      "efficiency": 0.3617759280999167,
      "achieved_bandwidth_gbps": 74.09171007486295,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.6666666666666666,
      "batch_size": 1,
      "input_shape": [
        67108864
      ],
      "output_shape": [
        67108864
      ],
      "mean_latency_ms": 10.86904819967458,
      "std_latency_ms": 0.00913567412588801,
      "min_latency_ms": 10.853771003894508,
      "max_latency_ms": 10.884938994422555,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 256,
        "kernel": "triad",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 3,
        "num_memory_ops": 3,
        "flops_per_element": 2
      },
      "precision_results": {}
    },
    "stream_triad_device=cuda_flops_per_element=2_framework=pytorch_kernel=triad_num_arrays=3_num_memory_ops=3_size_mb=512": {
      "operation_type": "stream_triad",
      "measured_gflops": 12.394011655696366,
      "efficiency": 0.36310581022547944,
      "achieved_bandwidth_gbps": 74.36406993417819,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.6666666666666666,
      "batch_size": 1,
      "input_shape": [
        134217728
      ],
      "output_shape": [
        134217728
      ],
      "mean_latency_ms": 21.658480196492746,
      "std_latency_ms": 0.013335503150204549,
      "min_latency_ms": 21.635190991219133,
      "max_latency_ms": 21.67602299596183,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 512,
        "kernel": "triad",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 3,
        "num_memory_ops": 3,
        "flops_per_element": 2
      },
      "precision_results": {}
    },
    "blas1_dot_best_precision=fp32_blas_level=1_device=cuda_framework=pytorch_operation=dot_size=1000": {
      "operation_type": "blas1_dot",
      "measured_gflops": 0.027081923120447715,
      "efficiency": 5.085807158769524e-06,
      "achieved_bandwidth_gbps": 0.10832769248179086,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.25,
      "batch_size": 1,
      "input_shape": [
        1000
      ],
      "output_shape": [
        1000
      ],
      "mean_latency_ms": 0.07384999917121604,
      "std_latency_ms": 0.003741673351270759,
      "min_latency_ms": 0.06723198748659343,
      "max_latency_ms": 0.0775916725224868,
      "num_trials": 10,
      "extra_params": {
        "size": 1000,
        "operation": "dot",
        "blas_level": 1,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "fp32"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.026431392431510076,
          "efficiency": 0.00015922525561150647,
          "mean_latency_ms": 0.07566759886685759,
          "std_latency_ms": 0.00251721066354682,
          "min_latency_ms": 0.06956800643820316,
          "max_latency_ms": 0.07818480953040441,
          "speedup_vs_fp32": null,
          "test_size": 1000,
          "num_trials": 10,
          "arithmetic_intensity": 0.5,
          "achieved_bandwidth_gbps": 0.05286278486302015
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.027081923120447715,
          "efficiency": 5.085807158769524e-06,
          "mean_latency_ms": 0.07384999917121604,
          "std_latency_ms": 0.003741673351270759,
          "min_latency_ms": 0.06723198748659343,
          "max_latency_ms": 0.0775916725224868,
          "speedup_vs_fp32": 1.0,
          "test_size": 1000,
          "num_trials": 10,
          "arithmetic_intensity": 0.25,
          "achieved_bandwidth_gbps": 0.10832769248179086
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.027039816112111113,
          "efficiency": 2.5389498696817945e-06,
          "mean_latency_ms": 0.07396500004688278,
          "std_latency_ms": 0.002411824062079809,
          "min_latency_ms": 0.06927999493200332,
          "max_latency_ms": 0.07637682410896258,
          "speedup_vs_fp32": 0.9984451987346198,
          "test_size": 1000,
          "num_trials": 10,
          "arithmetic_intensity": 0.25,
          "achieved_bandwidth_gbps": 0.10815926444844445
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.02634449140272489,
          "efficiency": 1.2368305822875534e-06,
          "mean_latency_ms": 0.07591719913762063,
          "std_latency_ms": 0.002617569639976496,
          "min_latency_ms": 0.06937699799891561,
          "max_latency_ms": 0.07853476877759713,
          "speedup_vs_fp32": 0.9727703341286704,
          "test_size": 1000,
          "num_trials": 10,
          "arithmetic_intensity": 0.5,
          "achieved_bandwidth_gbps": 0.05268898280544978
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.02677795634318192,
          "efficiency": 1.257181048975677e-06,
          "mean_latency_ms": 0.07468829862773418,
          "std_latency_ms": 0.003917500861305477,
          "min_latency_ms": 0.06704099359922111,
          "max_latency_ms": 0.07860579948903966,
          "speedup_vs_fp32": 0.9887760268754219,
          "test_size": 1000,
          "num_trials": 10,
          "arithmetic_intensity": 0.5,
          "achieved_bandwidth_gbps": 0.05355591268636384
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Long'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Int'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Short'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Char'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas1_dot_best_precision=tf32_blas_level=1_device=cuda_framework=pytorch_operation=dot_size=10000": {
      "operation_type": "blas1_dot",
      "measured_gflops": 0.28769940347971557,
      "efficiency": 2.701402849574794e-05,
      "achieved_bandwidth_gbps": 1.1507976139188623,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.25,
      "batch_size": 1,
      "input_shape": [
        10000
      ],
      "output_shape": [
        10000
      ],
      "mean_latency_ms": 0.06951700197532773,
      "std_latency_ms": 0.0028594024239461304,
      "min_latency_ms": 0.06409599154721946,
      "max_latency_ms": 0.07237640439927386,
      "num_trials": 10,
      "extra_params": {
        "size": 10000,
        "operation": "dot",
        "blas_level": 1,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "tf32"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.2826251948707743,
          "efficiency": 0.0017025614148841826,
          "mean_latency_ms": 0.07076509937178344,
          "std_latency_ms": 0.0018224906594117166,
          "min_latency_ms": 0.06848000339232385,
          "max_latency_ms": 0.07258759003119515,
          "speedup_vs_fp32": null,
          "test_size": 10000,
          "num_trials": 10,
          "arithmetic_intensity": 0.5,
          "achieved_bandwidth_gbps": 0.5652503897415486
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.253816451324249,
          "efficiency": 4.766506128154911e-05,
          "mean_latency_ms": 0.07879709883127362,
          "std_latency_ms": 0.007489620568036573,
          "min_latency_ms": 0.06864000170025975,
          "max_latency_ms": 0.0862867193993102,
          "speedup_vs_fp32": 1.0,
          "test_size": 10000,
          "num_trials": 10,
          "arithmetic_intensity": 0.25,
          "achieved_bandwidth_gbps": 1.015265805296996
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.28769940347971557,
          "efficiency": 2.701402849574794e-05,
          "mean_latency_ms": 0.06951700197532773,
          "std_latency_ms": 0.0028594024239461304,
          "min_latency_ms": 0.06409599154721946,
          "max_latency_ms": 0.07237640439927386,
          "speedup_vs_fp32": 1.1334939164844806,
          "test_size": 10000,
          "num_trials": 10,
          "arithmetic_intensity": 0.25,
          "achieved_bandwidth_gbps": 1.1507976139188623
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.26727605735720966,
          "efficiency": 1.2548171706911252e-05,
          "mean_latency_ms": 0.07482899964088574,
          "std_latency_ms": 0.005062180721369352,
          "min_latency_ms": 0.06716798816341907,
          "max_latency_ms": 0.0798911803622551,
          "speedup_vs_fp32": 1.0530288953404603,
          "test_size": 10000,
          "num_trials": 10,
          "arithmetic_intensity": 0.5,
          "achieved_bandwidth_gbps": 0.5345521147144193
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.27087826476080495,
          "efficiency": 1.2717289425389905e-05,
          "mean_latency_ms": 0.07383390475297347,
          "std_latency_ms": 0.0031370417989161382,
          "min_latency_ms": 0.06864000170025975,
          "max_latency_ms": 0.0769709465518896,
          "speedup_vs_fp32": 1.0672210699800526,
          "test_size": 10000,
          "num_trials": 10,
          "arithmetic_intensity": 0.5,
          "achieved_bandwidth_gbps": 0.5417565295216099
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Long'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Int'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Short'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Char'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas1_dot_best_precision=bf16_blas_level=1_device=cuda_framework=pytorch_operation=dot_size=100000": {
      "operation_type": "blas1_dot",
      "measured_gflops": 2.7927851526575336,
      "efficiency": 0.00013111667383368703,
      "achieved_bandwidth_gbps": 5.585570305315067,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.5,
      "batch_size": 1,
      "input_shape": [
        100000
      ],
      "output_shape": [
        100000
      ],
      "mean_latency_ms": 0.07161309913499281,
      "std_latency_ms": 0.002709008746172774,
      "min_latency_ms": 0.06566400406882167,
      "max_latency_ms": 0.07432210788116558,
      "num_trials": 10,
      "extra_params": {
        "size": 100000,
        "operation": "dot",
        "blas_level": 1,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "bf16"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 2.681011882762734,
          "efficiency": 0.01615067399254659,
          "mean_latency_ms": 0.07459869957529008,
          "std_latency_ms": 0.0020659131822425313,
          "min_latency_ms": 0.07075199391692877,
          "max_latency_ms": 0.07666461275753261,
          "speedup_vs_fp32": null,
          "test_size": 100000,
          "num_trials": 10,
          "arithmetic_intensity": 0.5,
          "achieved_bandwidth_gbps": 5.362023765525468
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 2.5766753475515127,
          "efficiency": 0.0004838826943758709,
          "mean_latency_ms": 0.07761940214550123,
          "std_latency_ms": 0.007151485658172443,
          "min_latency_ms": 0.06992000271566212,
          "max_latency_ms": 0.08477088780367367,
          "speedup_vs_fp32": 1.0,
          "test_size": 100000,
          "num_trials": 10,
          "arithmetic_intensity": 0.25,
          "achieved_bandwidth_gbps": 10.306701390206051
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 2.781842378849579,
          "efficiency": 0.00026120585716897456,
          "mean_latency_ms": 0.0718947994755581,
          "std_latency_ms": 0.003599897165137067,
          "min_latency_ms": 0.06470399966929108,
          "max_latency_ms": 0.07549469664069516,
          "speedup_vs_fp32": 1.0796247115466162,
          "test_size": 100000,
          "num_trials": 10,
          "arithmetic_intensity": 0.25,
          "achieved_bandwidth_gbps": 11.127369515398316
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 2.672642695189333,
          "efficiency": 0.00012547618287273864,
          "mean_latency_ms": 0.07483230001525953,
          "std_latency_ms": 0.006057736029528969,
          "min_latency_ms": 0.06803200813010335,
          "max_latency_ms": 0.0808900360447885,
          "speedup_vs_fp32": 1.0372446407456855,
          "test_size": 100000,
          "num_trials": 10,
          "arithmetic_intensity": 0.5,
          "achieved_bandwidth_gbps": 5.345285390378666
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 2.7927851526575336,
          "efficiency": 0.00013111667383368703,
          "mean_latency_ms": 0.07161309913499281,
          "std_latency_ms": 0.002709008746172774,
          "min_latency_ms": 0.06566400406882167,
          "max_latency_ms": 0.07432210788116558,
          "speedup_vs_fp32": 1.0838715693505507,
          "test_size": 100000,
          "num_trials": 10,
          "arithmetic_intensity": 0.5,
          "achieved_bandwidth_gbps": 5.585570305315067
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Long'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Int'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Short'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Char'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas1_dot_best_precision=fp16_blas_level=1_device=cuda_framework=pytorch_operation=dot_size=1000000": {
      "operation_type": "blas1_dot",
      "measured_gflops": 18.20399379009149,
      "efficiency": 0.0008546475957789433,
      "achieved_bandwidth_gbps": 36.40798758018298,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.5,
      "batch_size": 1,
      "input_shape": [
        1000000
      ],
      "output_shape": [
        1000000
      ],
      "mean_latency_ms": 0.10986600100295618,
      "std_latency_ms": 0.00838347819405603,
      "min_latency_ms": 0.09878400305751711,
      "max_latency_ms": 0.11824947919701222,
      "num_trials": 10,
      "extra_params": {
        "size": 1000000,
        "operation": "dot",
        "blas_level": 1,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "fp16"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 9.154918606864966,
          "efficiency": 0.05515011208954799,
          "mean_latency_ms": 0.21846180025022477,
          "std_latency_ms": 0.0016636222364179068,
          "min_latency_ms": 0.21523299801629037,
          "max_latency_ms": 0.22012542248664269,
          "speedup_vs_fp32": null,
          "test_size": 1000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.5,
          "achieved_bandwidth_gbps": 18.30983721372993
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 12.401970065058231,
          "efficiency": 0.0023290084629217335,
          "mean_latency_ms": 0.16126470145536587,
          "std_latency_ms": 0.00416365113724679,
          "min_latency_ms": 0.15660900680813938,
          "max_latency_ms": 0.16542835259261265,
          "speedup_vs_fp32": 1.0,
          "test_size": 1000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.25,
          "achieved_bandwidth_gbps": 49.607880260232925
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 12.506198411038268,
          "efficiency": 0.0011742909306139218,
          "mean_latency_ms": 0.1599206996615976,
          "std_latency_ms": 0.0021791005433352845,
          "min_latency_ms": 0.1568329898873344,
          "max_latency_ms": 0.1620998002049329,
          "speedup_vs_fp32": 1.0084041765488285,
          "test_size": 1000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.25,
          "achieved_bandwidth_gbps": 50.02479364415307
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 18.20399379009149,
          "efficiency": 0.0008546475957789433,
          "mean_latency_ms": 0.10986600100295618,
          "std_latency_ms": 0.00838347819405603,
          "min_latency_ms": 0.09878400305751711,
          "max_latency_ms": 0.11824947919701222,
          "speedup_vs_fp32": 1.4678308119272192,
          "test_size": 1000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.5,
          "achieved_bandwidth_gbps": 36.40798758018298
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 14.68300508191393,
          "efficiency": 0.0006893429615922032,
          "mean_latency_ms": 0.13621189864352345,
          "std_latency_ms": 0.0014514882486919916,
          "min_latency_ms": 0.13443299394566566,
          "max_latency_ms": 0.13766338689221544,
          "speedup_vs_fp32": 1.1839252155012348,
          "test_size": 1000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.5,
          "achieved_bandwidth_gbps": 29.36601016382786
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Long'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Int'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Short'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Char'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas1_dot_best_precision=fp16_blas_level=1_device=cuda_framework=pytorch_operation=dot_size=10000000": {
      "operation_type": "blas1_dot",
      "measured_gflops": 23.56719971046144,
      "efficiency": 0.001106441300960631,
      "achieved_bandwidth_gbps": 47.13439942092288,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.5,
      "batch_size": 1,
      "input_shape": [
        10000000
      ],
      "output_shape": [
        10000000
      ],
      "mean_latency_ms": 0.8486370992613956,
      "std_latency_ms": 0.0025856165658426516,
      "min_latency_ms": 0.8448349981335923,
      "max_latency_ms": 0.8512227158272383,
      "num_trials": 10,
      "extra_params": {
        "size": 10000000,
        "operation": "dot",
        "blas_level": 1,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "fp16"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 14.160749712148167,
          "efficiency": 0.08530572115751908,
          "mean_latency_ms": 1.4123546003247611,
          "std_latency_ms": 0.08186498569456314,
          "min_latency_ms": 1.3819580053677782,
          "max_latency_ms": 1.4942195860193244,
          "speedup_vs_fp32": null,
          "test_size": 10000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.5,
          "achieved_bandwidth_gbps": 28.321499424296334
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 22.49293209739273,
          "efficiency": 0.004224024807022109,
          "mean_latency_ms": 0.8891682024113834,
          "std_latency_ms": 0.004667000301628212,
          "min_latency_ms": 0.8815070032142103,
          "max_latency_ms": 0.8938352027130116,
          "speedup_vs_fp32": 1.0,
          "test_size": 10000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.25,
          "achieved_bandwidth_gbps": 89.97172838957091
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 22.507747983097836,
          "efficiency": 0.00211340356648806,
          "mean_latency_ms": 0.8885829010978341,
          "std_latency_ms": 0.0021669113218213635,
          "min_latency_ms": 0.8832360035739839,
          "max_latency_ms": 0.8907498124196555,
          "speedup_vs_fp32": 1.000658690722977,
          "test_size": 10000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.25,
          "achieved_bandwidth_gbps": 90.03099193239134
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 23.56719971046144,
          "efficiency": 0.001106441300960631,
          "mean_latency_ms": 0.8486370992613956,
          "std_latency_ms": 0.0025856165658426516,
          "min_latency_ms": 0.8448349981335923,
          "max_latency_ms": 0.8512227158272383,
          "speedup_vs_fp32": 1.0477602301210538,
          "test_size": 10000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.5,
          "achieved_bandwidth_gbps": 47.13439942092288
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 23.549972276567573,
          "efficiency": 0.001105632501247304,
          "mean_latency_ms": 0.8492578999721445,
          "std_latency_ms": 0.002318621676696142,
          "min_latency_ms": 0.8463069971185178,
          "max_latency_ms": 0.8515765216488407,
          "speedup_vs_fp32": 1.0469943257996752,
          "test_size": 10000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.5,
          "achieved_bandwidth_gbps": 47.099944553135145
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Long'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Int'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Short'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Char'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas1_axpy_best_precision=int32_blas_level=1_device=cuda_framework=pytorch_operation=axpy_size=1000": {
      "operation_type": "blas1_axpy",
      "measured_gflops": 0.013878037123304956,
      "efficiency": 2.6062041546112594e-06,
      "achieved_bandwidth_gbps": 0.041634111369914864,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.3333333333333333,
      "batch_size": 1,
      "input_shape": [
        1000
      ],
      "output_shape": [
        1000
      ],
      "mean_latency_ms": 0.14411259908229113,
      "std_latency_ms": 0.0032981179254606228,
      "min_latency_ms": 0.13852799020241946,
      "max_latency_ms": 0.14741071700775174,
      "num_trials": 10,
      "extra_params": {
        "size": 1000,
        "operation": "axpy",
        "blas_level": 1,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "int32"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.013604368535370186,
          "efficiency": 8.195402732150714e-05,
          "mean_latency_ms": 0.1470116010750644,
          "std_latency_ms": 0.0030081705143866202,
          "min_latency_ms": 0.14319999900180846,
          "max_latency_ms": 0.150019771589451,
          "speedup_vs_fp32": null,
          "test_size": 1000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 0.04081310560611056
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.013383530277122887,
          "efficiency": 2.513339019178007e-06,
          "mean_latency_ms": 0.1494374024332501,
          "std_latency_ms": 0.003093301208379169,
          "min_latency_ms": 0.1447690010536462,
          "max_latency_ms": 0.15253070364162927,
          "speedup_vs_fp32": 1.0,
          "test_size": 1000,
          "num_trials": 10,
          "arithmetic_intensity": 0.16666666666666666,
          "achieved_bandwidth_gbps": 0.08030118166273732
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.013477315925027192,
          "efficiency": 1.2654756737114735e-06,
          "mean_latency_ms": 0.14839750074315816,
          "std_latency_ms": 0.0036787032380232692,
          "min_latency_ms": 0.14464098785538226,
          "max_latency_ms": 0.15207620398118143,
          "speedup_vs_fp32": 1.0070075418041695,
          "test_size": 1000,
          "num_trials": 10,
          "arithmetic_intensity": 0.16666666666666666,
          "achieved_bandwidth_gbps": 0.08086389555016316
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.013570380660369924,
          "efficiency": 6.371070732568039e-07,
          "mean_latency_ms": 0.14737980091013014,
          "std_latency_ms": 0.0021287182379332035,
          "min_latency_ms": 0.14483300037682056,
          "max_latency_ms": 0.14950851914806335,
          "speedup_vs_fp32": 1.0139612179580473,
          "test_size": 1000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 0.040711141981109776
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.01381455874924059,
          "efficiency": 6.485708332976803e-07,
          "mean_latency_ms": 0.14477480144705623,
          "std_latency_ms": 0.0038274259603715845,
          "min_latency_ms": 0.13836899597663432,
          "max_latency_ms": 0.14860222740742782,
          "speedup_vs_fp32": 1.0322058876240212,
          "test_size": 1000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 0.04144367624772178
        },
        "int64": {
          "precision": "int64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.01348663111535897,
          "efficiency": 0.0,
          "mean_latency_ms": 0.14829500287305564,
          "std_latency_ms": 0.005601205181991932,
          "min_latency_ms": 0.14188801287673414,
          "max_latency_ms": 0.15389620805504756,
          "speedup_vs_fp32": 1.0077035607273455,
          "test_size": 1000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 0.040459893346076914
        },
        "int32": {
          "precision": "int32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.013878037123304956,
          "efficiency": 2.6062041546112594e-06,
          "mean_latency_ms": 0.14411259908229113,
          "std_latency_ms": 0.0032981179254606228,
          "min_latency_ms": 0.13852799020241946,
          "max_latency_ms": 0.14741071700775174,
          "speedup_vs_fp32": 1.0369489092894535,
          "test_size": 1000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 0.041634111369914864
        },
        "int16": {
          "precision": "int16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.013575972245854905,
          "efficiency": 6.373695890072726e-07,
          "mean_latency_ms": 0.14731909905094653,
          "std_latency_ms": 0.0048898748388948214,
          "min_latency_ms": 0.13971200678497553,
          "max_latency_ms": 0.15220897388984136,
          "speedup_vs_fp32": 1.0143790139632267,
          "test_size": 1000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 0.04072791673756472
        },
        "int8": {
          "precision": "int8",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.01333214226575042,
          "efficiency": 3.1296108605047934e-07,
          "mean_latency_ms": 0.15001340070739388,
          "std_latency_ms": 0.008627728944795299,
          "min_latency_ms": 0.1384650095133111,
          "max_latency_ms": 0.15864112965218918,
          "speedup_vs_fp32": 0.9961603545321441,
          "test_size": 1000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 0.03999642679725126
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas1_axpy_best_precision=int64_blas_level=1_device=cuda_framework=pytorch_operation=axpy_size=10000": {
      "operation_type": "blas1_axpy",
      "measured_gflops": 0.1382646826003105,
      "efficiency": 0.0,
      "achieved_bandwidth_gbps": 0.41479404780093143,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.3333333333333333,
      "batch_size": 1,
      "input_shape": [
        10000
      ],
      "output_shape": [
        10000
      ],
      "mean_latency_ms": 0.14465009880950674,
      "std_latency_ms": 0.0032735849824255363,
      "min_latency_ms": 0.14003200340084732,
      "max_latency_ms": 0.14792368379193227,
      "num_trials": 10,
      "extra_params": {
        "size": 10000,
        "operation": "axpy",
        "blas_level": 1,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "int64"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.13368063471861918,
          "efficiency": 0.0008053050284254167,
          "mean_latency_ms": 0.14961030101403594,
          "std_latency_ms": 0.006429866684187326,
          "min_latency_ms": 0.1411520061083138,
          "max_latency_ms": 0.15604016769822326,
          "speedup_vs_fp32": null,
          "test_size": 10000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 0.40104190415585755
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.13320492180814458,
          "efficiency": 2.5015008790261894e-05,
          "mean_latency_ms": 0.15014460223028436,
          "std_latency_ms": 0.003391693955086286,
          "min_latency_ms": 0.14339201152324677,
          "max_latency_ms": 0.15353629618537065,
          "speedup_vs_fp32": 1.0,
          "test_size": 10000,
          "num_trials": 10,
          "arithmetic_intensity": 0.16666666666666666,
          "achieved_bandwidth_gbps": 0.7992295308488675
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.1351491059519632,
          "efficiency": 1.2690056896897952e-05,
          "mean_latency_ms": 0.147984700743109,
          "std_latency_ms": 0.0026702948646239615,
          "min_latency_ms": 0.1432330027455464,
          "max_latency_ms": 0.15065499560773296,
          "speedup_vs_fp32": 1.0145954377468036,
          "test_size": 10000,
          "num_trials": 10,
          "arithmetic_intensity": 0.16666666666666666,
          "achieved_bandwidth_gbps": 0.8108946357117791
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.1341886546651133,
          "efficiency": 6.299936838737713e-06,
          "mean_latency_ms": 0.14904389681760222,
          "std_latency_ms": 0.004175582574981892,
          "min_latency_ms": 0.14400100917555392,
          "max_latency_ms": 0.1532194793925841,
          "speedup_vs_fp32": 1.0073851089255215,
          "test_size": 10000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 0.4025659639953399
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.1360494249150781,
          "efficiency": 6.3872969443698635e-06,
          "mean_latency_ms": 0.14700539904879406,
          "std_latency_ms": 0.0028822961563500556,
          "min_latency_ms": 0.14256099530030042,
          "max_latency_ms": 0.1498876952051441,
          "speedup_vs_fp32": 1.021354339376667,
          "test_size": 10000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 0.4081482747452343
        },
        "int64": {
          "precision": "int64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.1382646826003105,
          "efficiency": 0.0,
          "mean_latency_ms": 0.14465009880950674,
          "std_latency_ms": 0.0032735849824255363,
          "min_latency_ms": 0.14003200340084732,
          "max_latency_ms": 0.14792368379193227,
          "speedup_vs_fp32": 1.037984788576007,
          "test_size": 10000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 0.41479404780093143
        },
        "int32": {
          "precision": "int32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.13392411507193702,
          "efficiency": 2.515006855811024e-05,
          "mean_latency_ms": 0.1493383024353534,
          "std_latency_ms": 0.007676325868807562,
          "min_latency_ms": 0.14128100883681327,
          "max_latency_ms": 0.15701462830416096,
          "speedup_vs_fp32": 1.0053991493259409,
          "test_size": 10000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 0.401772345215811
        },
        "int16": {
          "precision": "int16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.13461060957111837,
          "efficiency": 6.319746928221519e-06,
          "mean_latency_ms": 0.14857669884804636,
          "std_latency_ms": 0.007245694866624827,
          "min_latency_ms": 0.14147299225442111,
          "max_latency_ms": 0.1558223937146712,
          "speedup_vs_fp32": 1.0105528215015838,
          "test_size": 10000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 0.40383182871335505
        },
        "int8": {
          "precision": "int8",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.13618282353513544,
          "efficiency": 3.196779895190973e-06,
          "mean_latency_ms": 0.14686139911646023,
          "std_latency_ms": 0.003116616540513954,
          "min_latency_ms": 0.14259199087973684,
          "max_latency_ms": 0.1499780156569742,
          "speedup_vs_fp32": 1.022355793513996,
          "test_size": 10000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 0.40854847060540633
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas1_axpy_best_precision=int16_blas_level=1_device=cuda_framework=pytorch_operation=axpy_size=100000": {
      "operation_type": "blas1_axpy",
      "measured_gflops": 1.371962313872789,
      "efficiency": 6.441137623815911e-05,
      "achieved_bandwidth_gbps": 4.115886941618367,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.3333333333333333,
      "batch_size": 1,
      "input_shape": [
        100000
      ],
      "output_shape": [
        100000
      ],
      "mean_latency_ms": 0.1457765989471227,
      "std_latency_ms": 0.004116279034631624,
      "min_latency_ms": 0.1399689936079085,
      "max_latency_ms": 0.14989287798175432,
      "num_trials": 10,
      "extra_params": {
        "size": 100000,
        "operation": "axpy",
        "blas_level": 1,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "int16"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.371931212338547,
          "efficiency": 0.008264645857461126,
          "mean_latency_ms": 0.14577990368707106,
          "std_latency_ms": 0.004044267520726703,
          "min_latency_ms": 0.13980900985188782,
          "max_latency_ms": 0.14982417120779776,
          "speedup_vs_fp32": null,
          "test_size": 100000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 4.115793637015641
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.3267905009263083,
          "efficiency": 0.00024916253538522225,
          "mean_latency_ms": 0.15073969843797386,
          "std_latency_ms": 0.004474261747353698,
          "min_latency_ms": 0.14556899259332567,
          "max_latency_ms": 0.15521396018532754,
          "speedup_vs_fp32": 1.0,
          "test_size": 100000,
          "num_trials": 10,
          "arithmetic_intensity": 0.16666666666666666,
          "achieved_bandwidth_gbps": 7.960743005557851
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.3717204684668665,
          "efficiency": 0.0001288000439874992,
          "mean_latency_ms": 0.14580230053979903,
          "std_latency_ms": 0.003320818141930671,
          "min_latency_ms": 0.140416988870129,
          "max_latency_ms": 0.1491231186817297,
          "speedup_vs_fp32": 1.0338636487894584,
          "test_size": 100000,
          "num_trials": 10,
          "arithmetic_intensity": 0.16666666666666666,
          "achieved_bandwidth_gbps": 8.2303228108012
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.3314807952244347,
          "efficiency": 6.251083545654623e-05,
          "mean_latency_ms": 0.15020870050648227,
          "std_latency_ms": 0.005580011646199843,
          "min_latency_ms": 0.14457599900197238,
          "max_latency_ms": 0.1557887121526821,
          "speedup_vs_fp32": 1.0035350677404247,
          "test_size": 100000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 3.9944423856733047
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.3427522900651527,
          "efficiency": 6.304001361808228e-05,
          "mean_latency_ms": 0.14894780033500865,
          "std_latency_ms": 0.0050066686380361046,
          "min_latency_ms": 0.14086399460211396,
          "max_latency_ms": 0.15395446897304477,
          "speedup_vs_fp32": 1.0120303764065997,
          "test_size": 100000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 4.028256870195459
        },
        "int64": {
          "precision": "int64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.3247384310557215,
          "efficiency": 0.0,
          "mean_latency_ms": 0.15097319992491975,
          "std_latency_ms": 0.007977856961618247,
          "min_latency_ms": 0.14179199934005737,
          "max_latency_ms": 0.158951056886538,
          "speedup_vs_fp32": 0.9984533580326704,
          "test_size": 100000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 3.974215293167165
        },
        "int32": {
          "precision": "int32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.3505583518613158,
          "efficiency": 0.0002536259815702002,
          "mean_latency_ms": 0.14808690029894933,
          "std_latency_ms": 0.003902939453683963,
          "min_latency_ms": 0.14211300003807992,
          "max_latency_ms": 0.1519898397526333,
          "speedup_vs_fp32": 1.0179137934123086,
          "test_size": 100000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 4.051675055583948
        },
        "int16": {
          "precision": "int16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.371962313872789,
          "efficiency": 6.441137623815911e-05,
          "mean_latency_ms": 0.1457765989471227,
          "std_latency_ms": 0.004116279034631624,
          "min_latency_ms": 0.1399689936079085,
          "max_latency_ms": 0.14989287798175432,
          "speedup_vs_fp32": 1.0340459273072453,
          "test_size": 100000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 4.115886941618367
        },
        "int8": {
          "precision": "int8",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.3300357035822932,
          "efficiency": 3.122149538925571e-05,
          "mean_latency_ms": 0.15037190314615145,
          "std_latency_ms": 0.007568074304891442,
          "min_latency_ms": 0.14240099699236453,
          "max_latency_ms": 0.1579399774510429,
          "speedup_vs_fp32": 1.0024459043486664,
          "test_size": 100000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 3.9901071107468797
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas1_axpy_best_precision=int8_blas_level=1_device=cuda_framework=pytorch_operation=axpy_size=1000000": {
      "operation_type": "blas1_axpy",
      "measured_gflops": 13.620359503722803,
      "efficiency": 0.0003197267489136808,
      "achieved_bandwidth_gbps": 40.86107851116841,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.3333333333333333,
      "batch_size": 1,
      "input_shape": [
        1000000
      ],
      "output_shape": [
        1000000
      ],
      "mean_latency_ms": 0.14683900226373225,
      "std_latency_ms": 0.004439510915056802,
      "min_latency_ms": 0.1389130047755316,
      "max_latency_ms": 0.15127851317878904,
      "num_trials": 10,
      "extra_params": {
        "size": 1000000,
        "operation": "axpy",
        "blas_level": 1,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "int8"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 2.8781831991963545,
          "efficiency": 0.017338453007206954,
          "mean_latency_ms": 0.6948827998712659,
          "std_latency_ms": 0.0025989420173149645,
          "min_latency_ms": 0.6912980024935678,
          "max_latency_ms": 0.6974817418885808,
          "speedup_vs_fp32": null,
          "test_size": 1000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 8.634549597589064
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 5.742410431064357,
          "efficiency": 0.001078386935411147,
          "mean_latency_ms": 0.3482857980998233,
          "std_latency_ms": 0.0018925106502437217,
          "min_latency_ms": 0.3454089892329648,
          "max_latency_ms": 0.350178308750067,
          "speedup_vs_fp32": 1.0,
          "test_size": 1000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.16666666666666666,
          "achieved_bandwidth_gbps": 34.454462586386136
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 5.69588306866429,
          "efficiency": 0.0005348247012830319,
          "mean_latency_ms": 0.3511308037559502,
          "std_latency_ms": 0.0049780076875594464,
          "min_latency_ms": 0.3452810051385313,
          "max_latency_ms": 0.35610881144350964,
          "speedup_vs_fp32": 0.9918975902265064,
          "test_size": 1000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.16666666666666666,
          "achieved_bandwidth_gbps": 34.175298411985736
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 9.09523341564966,
          "efficiency": 0.000427006263645524,
          "mean_latency_ms": 0.21989540109643713,
          "std_latency_ms": 0.0013522771981765807,
          "min_latency_ms": 0.21760100207757205,
          "max_latency_ms": 0.2212476782946137,
          "speedup_vs_fp32": 1.583870314536862,
          "test_size": 1000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 27.28570024694898
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 9.140057759433445,
          "efficiency": 0.00042911069293114764,
          "mean_latency_ms": 0.21881699794903398,
          "std_latency_ms": 0.0019262091811241516,
          "min_latency_ms": 0.2161290030926466,
          "max_latency_ms": 0.22074320713015813,
          "speedup_vs_fp32": 1.59167615571138,
          "test_size": 1000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 27.420173278300332
        },
        "int64": {
          "precision": "int64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 3.0845495143730988,
          "efficiency": 0.0,
          "mean_latency_ms": 0.6483928984380327,
          "std_latency_ms": 0.0023367447723277104,
          "min_latency_ms": 0.6446740007959306,
          "max_latency_ms": 0.6507296432103604,
          "speedup_vs_fp32": 0.5371523946959286,
          "test_size": 1000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 9.253648543119297
        },
        "int32": {
          "precision": "int32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 5.748317426864222,
          "efficiency": 0.001079496230397037,
          "mean_latency_ms": 0.3479278981103562,
          "std_latency_ms": 0.000815450462556655,
          "min_latency_ms": 0.3463059983914718,
          "max_latency_ms": 0.34874334857291284,
          "speedup_vs_fp32": 1.0010286613732642,
          "test_size": 1000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 17.244952280592667
        },
        "int16": {
          "precision": "int16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 8.968762625070049,
          "efficiency": 0.0004210686678436643,
          "mean_latency_ms": 0.22299620177363977,
          "std_latency_ms": 0.004020729661549712,
          "min_latency_ms": 0.21868900512345135,
          "max_latency_ms": 0.22701693143518947,
          "speedup_vs_fp32": 1.561846324420194,
          "test_size": 1000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 26.906287875210147
        },
        "int8": {
          "precision": "int8",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 13.620359503722803,
          "efficiency": 0.0003197267489136808,
          "mean_latency_ms": 0.14683900226373225,
          "std_latency_ms": 0.004439510915056802,
          "min_latency_ms": 0.1389130047755316,
          "max_latency_ms": 0.15127851317878904,
          "speedup_vs_fp32": 2.371888890080305,
          "test_size": 1000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 40.86107851116841
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas1_axpy_best_precision=int8_blas_level=1_device=cuda_framework=pytorch_operation=axpy_size=10000000": {
      "operation_type": "blas1_axpy",
      "measured_gflops": 19.113832992090963,
      "efficiency": 0.0004486815256359381,
      "achieved_bandwidth_gbps": 57.34149897627288,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.3333333333333333,
      "batch_size": 1,
      "input_shape": [
        10000000
      ],
      "output_shape": [
        10000000
      ],
      "mean_latency_ms": 1.0463626007549465,
      "std_latency_ms": 0.003992624617327847,
      "min_latency_ms": 1.0398120066383854,
      "max_latency_ms": 1.0503552253722743,
      "num_trials": 10,
      "extra_params": {
        "size": 10000000,
        "operation": "axpy",
        "blas_level": 1,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "int8"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 3.2495086292374187,
          "efficiency": 0.01957535318817722,
          "mean_latency_ms": 6.154776700714137,
          "std_latency_ms": 0.007715065599421959,
          "min_latency_ms": 6.144440994830802,
          "max_latency_ms": 6.162491766313559,
          "speedup_vs_fp32": null,
          "test_size": 10000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 9.748525887712255
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 7.752733991491835,
          "efficiency": 0.0014559124866651335,
          "mean_latency_ms": 2.5797351001529023,
          "std_latency_ms": 0.0034448812842478057,
          "min_latency_ms": 2.575753998826258,
          "max_latency_ms": 2.58317998143715,
          "speedup_vs_fp32": 1.0,
          "test_size": 10000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.16666666666666666,
          "achieved_bandwidth_gbps": 46.51640394895101
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 7.764735045607545,
          "efficiency": 0.0007290831028739479,
          "mean_latency_ms": 2.575747901573777,
          "std_latency_ms": 0.0030170565812697734,
          "min_latency_ms": 2.5721380079630762,
          "max_latency_ms": 2.578764958155047,
          "speedup_vs_fp32": 1.0015479770270566,
          "test_size": 10000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.16666666666666666,
          "achieved_bandwidth_gbps": 46.588410273645266
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 14.238304819937012,
          "efficiency": 0.000668465015020517,
          "mean_latency_ms": 1.4046615979168564,
          "std_latency_ms": 0.0047771891871692404,
          "min_latency_ms": 1.4004219992784783,
          "max_latency_ms": 1.4094387871040257,
          "speedup_vs_fp32": 1.836552735533388,
          "test_size": 10000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 42.714914459811034
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 14.275411545414661,
          "efficiency": 0.0006702071148082001,
          "mean_latency_ms": 1.4010103972395882,
          "std_latency_ms": 0.002511823096483333,
          "min_latency_ms": 1.3966449914732948,
          "max_latency_ms": 1.4035222203360715,
          "speedup_vs_fp32": 1.8413390116417094,
          "test_size": 10000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 42.82623463624399
        },
        "int64": {
          "precision": "int64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 3.357632859448031,
          "efficiency": 0.0,
          "mean_latency_ms": 5.9565773975919,
          "std_latency_ms": 0.010659265290648989,
          "min_latency_ms": 5.936278990702704,
          "max_latency_ms": 5.9672366628825495,
          "speedup_vs_fp32": 0.4330901670472421,
          "test_size": 10000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 10.072898578344091
        },
        "int32": {
          "precision": "int32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 7.758960739903924,
          "efficiency": 0.0014570818290899387,
          "mean_latency_ms": 2.5776648020837456,
          "std_latency_ms": 0.0031837521459417294,
          "min_latency_ms": 2.570601995103061,
          "max_latency_ms": 2.5808485542296875,
          "speedup_vs_fp32": 1.0008031680719243,
          "test_size": 10000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 23.27688221971177
        },
        "int16": {
          "precision": "int16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 14.202745931279644,
          "efficiency": 0.0006667955836281523,
          "mean_latency_ms": 1.4081783971050754,
          "std_latency_ms": 0.0030024307027118244,
          "min_latency_ms": 1.404901995556429,
          "max_latency_ms": 1.4111808278077873,
          "speedup_vs_fp32": 1.8319661098737958,
          "test_size": 10000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 42.60823779383894
        },
        "int8": {
          "precision": "int8",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 19.113832992090963,
          "efficiency": 0.0004486815256359381,
          "mean_latency_ms": 1.0463626007549465,
          "std_latency_ms": 0.003992624617327847,
          "min_latency_ms": 1.0398120066383854,
          "max_latency_ms": 1.0503552253722743,
          "speedup_vs_fp32": 2.4654312934078813,
          "test_size": 10000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 57.34149897627288
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas2_gemv_best_precision=fp32_blas_level=2_device=cuda_framework=pytorch_operation=gemv_size=32": {
      "operation_type": "blas2_gemv",
      "measured_gflops": 0.008329395039891553,
      "efficiency": 1.5642056412941885e-06,
      "achieved_bandwidth_gbps": 0.01769996445976955,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.47058823529411764,
      "batch_size": 1,
      "input_shape": [
        32,
        32
      ],
      "output_shape": [
        32
      ],
      "mean_latency_ms": 0.2458761999150738,
      "std_latency_ms": 0.005537596124861991,
      "min_latency_ms": 0.2379850047873333,
      "max_latency_ms": 0.2514137960399358,
      "num_trials": 10,
      "extra_params": {
        "size": 32,
        "operation": "gemv",
        "blas_level": 2,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "fp32"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.00829721527865475,
          "efficiency": 4.998322457020934e-05,
          "mean_latency_ms": 0.24682980147190392,
          "std_latency_ms": 0.008906407241568808,
          "min_latency_ms": 0.24067299091257155,
          "max_latency_ms": 0.25573620871347275,
          "speedup_vs_fp32": null,
          "test_size": 32,
          "num_trials": 10,
          "arithmetic_intensity": 0.9411764705882353,
          "achieved_bandwidth_gbps": 0.008815791233570673
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.008329395039891553,
          "efficiency": 1.5642056412941885e-06,
          "mean_latency_ms": 0.2458761999150738,
          "std_latency_ms": 0.005537596124861991,
          "min_latency_ms": 0.2379850047873333,
          "max_latency_ms": 0.2514137960399358,
          "speedup_vs_fp32": 1.0,
          "test_size": 32,
          "num_trials": 10,
          "arithmetic_intensity": 0.47058823529411764,
          "achieved_bandwidth_gbps": 0.01769996445976955
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.00827779098713678,
          "efficiency": 7.772573696842047e-07,
          "mean_latency_ms": 0.24740900116739795,
          "std_latency_ms": 0.006414249622381129,
          "min_latency_ms": 0.2408969885436818,
          "max_latency_ms": 0.2538232507897791,
          "speedup_vs_fp32": 0.9938045857463083,
          "test_size": 32,
          "num_trials": 10,
          "arithmetic_intensity": 0.47058823529411764,
          "achieved_bandwidth_gbps": 0.017590305847665657
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.008311546681555352,
          "efficiency": 3.902134592279508e-07,
          "mean_latency_ms": 0.24640419869683683,
          "std_latency_ms": 0.005682592506912659,
          "min_latency_ms": 0.23686500207986683,
          "max_latency_ms": 0.2520867912037495,
          "speedup_vs_fp32": 0.9978571843152207,
          "test_size": 32,
          "num_trials": 10,
          "arithmetic_intensity": 0.9411764705882353,
          "achieved_bandwidth_gbps": 0.00883101834915256
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.00831025485181212,
          "efficiency": 3.90152809944231e-07,
          "mean_latency_ms": 0.24644250224810094,
          "std_latency_ms": 0.005460535102755633,
          "min_latency_ms": 0.23664000036660582,
          "max_latency_ms": 0.25190303735085656,
          "speedup_vs_fp32": 0.9977020914498873,
          "test_size": 32,
          "num_trials": 10,
          "arithmetic_intensity": 0.9411764705882353,
          "achieved_bandwidth_gbps": 0.008829645780050377
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Long'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Int'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Short'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Char'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas2_gemv_best_precision=tf32_blas_level=2_device=cuda_framework=pytorch_operation=gemv_size=64": {
      "operation_type": "blas2_gemv",
      "measured_gflops": 0.033895935058556904,
      "efficiency": 3.1827169069067515e-06,
      "achieved_bandwidth_gbps": 0.06991036605827362,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.48484848484848486,
      "batch_size": 1,
      "input_shape": [
        64,
        64
      ],
      "output_shape": [
        64
      ],
      "mean_latency_ms": 0.24168089730665088,
      "std_latency_ms": 0.0032473355404904285,
      "min_latency_ms": 0.2355839969823137,
      "max_latency_ms": 0.2449282328471413,
      "num_trials": 10,
      "extra_params": {
        "size": 64,
        "operation": "gemv",
        "blas_level": 2,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "tf32"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.033591254564710675,
          "efficiency": 0.00020235695520910046,
          "mean_latency_ms": 0.24387299927184358,
          "std_latency_ms": 0.003536059589581624,
          "min_latency_ms": 0.23756899463478476,
          "max_latency_ms": 0.2474090588614252,
          "speedup_vs_fp32": null,
          "test_size": 64,
          "num_trials": 10,
          "arithmetic_intensity": 0.9696969696969697,
          "achieved_bandwidth_gbps": 0.034640981269857894
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.03318972167509869,
          "efficiency": 6.232811582178158e-06,
          "mean_latency_ms": 0.24682340153958648,
          "std_latency_ms": 0.006969370592181229,
          "min_latency_ms": 0.23897700884845108,
          "max_latency_ms": 0.2537927721317677,
          "speedup_vs_fp32": 1.0,
          "test_size": 64,
          "num_trials": 10,
          "arithmetic_intensity": 0.48484848484848486,
          "achieved_bandwidth_gbps": 0.06845380095489104
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.033895935058556904,
          "efficiency": 3.1827169069067515e-06,
          "mean_latency_ms": 0.24168089730665088,
          "std_latency_ms": 0.0032473355404904285,
          "min_latency_ms": 0.2355839969823137,
          "max_latency_ms": 0.2449282328471413,
          "speedup_vs_fp32": 1.0212780748923262,
          "test_size": 64,
          "num_trials": 10,
          "arithmetic_intensity": 0.48484848484848486,
          "achieved_bandwidth_gbps": 0.06991036605827362
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.033818022524763965,
          "efficiency": 1.5877005880170875e-06,
          "mean_latency_ms": 0.24223770014941692,
          "std_latency_ms": 0.004626594300603283,
          "min_latency_ms": 0.23363300715573132,
          "max_latency_ms": 0.2468642944500202,
          "speedup_vs_fp32": 1.0189305850713617,
          "test_size": 64,
          "num_trials": 10,
          "arithmetic_intensity": 0.9696969696969697,
          "achieved_bandwidth_gbps": 0.03487483572866283
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.03375424502140506,
          "efficiency": 1.5847063390331015e-06,
          "mean_latency_ms": 0.24269540008390322,
          "std_latency_ms": 0.0031411389277151854,
          "min_latency_ms": 0.23664100444875658,
          "max_latency_ms": 0.24583653901161842,
          "speedup_vs_fp32": 1.0170089810283018,
          "test_size": 64,
          "num_trials": 10,
          "arithmetic_intensity": 0.9696969696969697,
          "achieved_bandwidth_gbps": 0.03480906517832397
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Long'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Int'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Short'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Char'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas2_gemv_best_precision=tf32_blas_level=2_device=cuda_framework=pytorch_operation=gemv_size=128": {
      "operation_type": "blas2_gemv",
      "measured_gflops": 0.1355245231720351,
      "efficiency": 1.2725307340097192e-05,
      "achieved_bandwidth_gbps": 0.2752841876931963,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.49230769230769234,
      "batch_size": 1,
      "input_shape": [
        128,
        128
      ],
      "output_shape": [
        128
      ],
      "mean_latency_ms": 0.2417864991002716,
      "std_latency_ms": 0.005917741359628685,
      "min_latency_ms": 0.23129599867388606,
      "max_latency_ms": 0.2477042404599003,
      "num_trials": 10,
      "extra_params": {
        "size": 128,
        "operation": "gemv",
        "blas_level": 2,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "tf32"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.13453807879244614,
          "efficiency": 0.0008104703541713623,
          "mean_latency_ms": 0.2435592978144996,
          "std_latency_ms": 0.0038984746065314903,
          "min_latency_ms": 0.2370570000493899,
          "max_latency_ms": 0.24745777242103106,
          "speedup_vs_fp32": null,
          "test_size": 128,
          "num_trials": 10,
          "arithmetic_intensity": 0.9846153846153847,
          "achieved_bandwidth_gbps": 0.1366402362735781
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.13415905446046889,
          "efficiency": 2.519418863107397e-05,
          "mean_latency_ms": 0.24424739822279662,
          "std_latency_ms": 0.004050781161234496,
          "min_latency_ms": 0.2362569939577952,
          "max_latency_ms": 0.24829817938403112,
          "speedup_vs_fp32": 1.0,
          "test_size": 128,
          "num_trials": 10,
          "arithmetic_intensity": 0.49230769230769234,
          "achieved_bandwidth_gbps": 0.2725105793728274
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.1355245231720351,
          "efficiency": 1.2725307340097192e-05,
          "mean_latency_ms": 0.2417864991002716,
          "std_latency_ms": 0.005917741359628685,
          "min_latency_ms": 0.23129599867388606,
          "max_latency_ms": 0.2477042404599003,
          "speedup_vs_fp32": 1.0101779840135094,
          "test_size": 128,
          "num_trials": 10,
          "arithmetic_intensity": 0.49230769230769234,
          "achieved_bandwidth_gbps": 0.2752841876931963
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.13222745496956878,
          "efficiency": 6.207861735660506e-06,
          "mean_latency_ms": 0.2478154026903212,
          "std_latency_ms": 0.004407126687560625,
          "min_latency_ms": 0.24118500004988164,
          "max_latency_ms": 0.2522225293778818,
          "speedup_vs_fp32": 0.9856021682720695,
          "test_size": 128,
          "num_trials": 10,
          "arithmetic_intensity": 0.9846153846153847,
          "achieved_bandwidth_gbps": 0.13429350895346828
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.13250978362719665,
          "efficiency": 6.221116602215805e-06,
          "mean_latency_ms": 0.24728740099817514,
          "std_latency_ms": 0.004341219571797975,
          "min_latency_ms": 0.2400009980192408,
          "max_latency_ms": 0.2516286205699731,
          "speedup_vs_fp32": 0.9877066006472325,
          "test_size": 128,
          "num_trials": 10,
          "arithmetic_intensity": 0.9846153846153847,
          "achieved_bandwidth_gbps": 0.1345802489963716
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Long'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Int'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Short'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Char'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas2_gemv_best_precision=fp32_blas_level=2_device=cuda_framework=pytorch_operation=gemv_size=256": {
      "operation_type": "blas2_gemv",
      "measured_gflops": 0.5440202716507271,
      "efficiency": 0.0001021634312959112,
      "achieved_bandwidth_gbps": 1.0965408600459967,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.49612403100775193,
      "batch_size": 1,
      "input_shape": [
        256,
        256
      ],
      "output_shape": [
        256
      ],
      "mean_latency_ms": 0.24093219835776836,
      "std_latency_ms": 0.004822950600358389,
      "min_latency_ms": 0.23555300140287727,
      "max_latency_ms": 0.24575514895812675,
      "num_trials": 10,
      "extra_params": {
        "size": 256,
        "operation": "gemv",
        "blas_level": 2,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "fp32"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.5355346558018258,
          "efficiency": 0.003226112384348348,
          "mean_latency_ms": 0.24474980018567294,
          "std_latency_ms": 0.010219404852245298,
          "min_latency_ms": 0.23881699598859996,
          "max_latency_ms": 0.25496920503791826,
          "speedup_vs_fp32": null,
          "test_size": 256,
          "num_trials": 10,
          "arithmetic_intensity": 0.9922480620155039,
          "achieved_bandwidth_gbps": 0.5397185203002776
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.5440202716507271,
          "efficiency": 0.0001021634312959112,
          "mean_latency_ms": 0.24093219835776836,
          "std_latency_ms": 0.004822950600358389,
          "min_latency_ms": 0.23555300140287727,
          "max_latency_ms": 0.24575514895812675,
          "speedup_vs_fp32": 1.0,
          "test_size": 256,
          "num_trials": 10,
          "arithmetic_intensity": 0.49612403100775193,
          "achieved_bandwidth_gbps": 1.0965408600459967
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.534277491049789,
          "efficiency": 5.016690056805531e-05,
          "mean_latency_ms": 0.2453257009619847,
          "std_latency_ms": 0.00836944530541105,
          "min_latency_ms": 0.23593699734192342,
          "max_latency_ms": 0.25369514626739575,
          "speedup_vs_fp32": 0.982091144193257,
          "test_size": 256,
          "num_trials": 10,
          "arithmetic_intensity": 0.49612403100775193,
          "achieved_bandwidth_gbps": 1.0769030678972311
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.5255910499910987,
          "efficiency": 2.467563614981684e-05,
          "mean_latency_ms": 0.24938019778346643,
          "std_latency_ms": 0.007360395029539764,
          "min_latency_ms": 0.24118500004988164,
          "max_latency_ms": 0.2567405928130062,
          "speedup_vs_fp32": 0.9661240166589595,
          "test_size": 256,
          "num_trials": 10,
          "arithmetic_intensity": 0.9922480620155039,
          "achieved_bandwidth_gbps": 0.5296972300691543
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.5234816275142895,
          "efficiency": 2.4576602230717816e-05,
          "mean_latency_ms": 0.2503851006622426,
          "std_latency_ms": 0.01072302656213522,
          "min_latency_ms": 0.23993699869606644,
          "max_latency_ms": 0.2611081272243778,
          "speedup_vs_fp32": 0.9622465463021866,
          "test_size": 256,
          "num_trials": 10,
          "arithmetic_intensity": 0.9922480620155039,
          "achieved_bandwidth_gbps": 0.527571327729245
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Long'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Int'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Short'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Char'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas2_gemv_best_precision=fp64_blas_level=2_device=cuda_framework=pytorch_operation=gemv_size=512": {
      "operation_type": "blas2_gemv",
      "measured_gflops": 2.1508271623763466,
      "efficiency": 0.012956790134797268,
      "achieved_bandwidth_gbps": 2.1592288309793792,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.9961089494163424,
      "batch_size": 1,
      "input_shape": [
        512,
        512
      ],
      "output_shape": [
        512
      ],
      "mean_latency_ms": 0.24376110231969506,
      "std_latency_ms": 0.013219700137143145,
      "min_latency_ms": 0.23388898989651352,
      "max_latency_ms": 0.2569808024568382,
      "num_trials": 10,
      "extra_params": {
        "size": 512,
        "operation": "gemv",
        "blas_level": 2,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "fp64"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 2.1508271623763466,
          "efficiency": 0.012956790134797268,
          "mean_latency_ms": 0.24376110231969506,
          "std_latency_ms": 0.013219700137143145,
          "min_latency_ms": 0.23388898989651352,
          "max_latency_ms": 0.2569808024568382,
          "speedup_vs_fp32": null,
          "test_size": 512,
          "num_trials": 10,
          "arithmetic_intensity": 0.9961089494163424,
          "achieved_bandwidth_gbps": 2.1592288309793792
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 2.1238393302966134,
          "efficiency": 0.0003988430667223687,
          "mean_latency_ms": 0.24685859825694934,
          "std_latency_ms": 0.008944036262231714,
          "min_latency_ms": 0.24006499734241515,
          "max_latency_ms": 0.25580263451918106,
          "speedup_vs_fp32": 1.0,
          "test_size": 512,
          "num_trials": 10,
          "arithmetic_intensity": 0.4980544747081712,
          "achieved_bandwidth_gbps": 4.264271155361169
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 2.107312634143231,
          "efficiency": 0.0001978697309054677,
          "mean_latency_ms": 0.24879459815565497,
          "std_latency_ms": 0.008407522162638443,
          "min_latency_ms": 0.24102500174194574,
          "max_latency_ms": 0.2572021203182934,
          "speedup_vs_fp32": 0.9922184809756422,
          "test_size": 512,
          "num_trials": 10,
          "arithmetic_intensity": 0.4980544747081712,
          "achieved_bandwidth_gbps": 4.231088648240706
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 2.127093807600838,
          "efficiency": 9.986355904229288e-05,
          "mean_latency_ms": 0.24648090184200555,
          "std_latency_ms": 0.006984214161998428,
          "min_latency_ms": 0.23862400848884135,
          "max_latency_ms": 0.25346511600400395,
          "speedup_vs_fp32": 1.001532355700264,
          "test_size": 512,
          "num_trials": 10,
          "arithmetic_intensity": 0.9961089494163424,
          "achieved_bandwidth_gbps": 2.1354027677867786
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 2.1077192479542326,
          "efficiency": 9.895395530301562e-05,
          "mean_latency_ms": 0.24874660157365724,
          "std_latency_ms": 0.007227467816326701,
          "min_latency_ms": 0.2358410129090771,
          "max_latency_ms": 0.25597406938998396,
          "speedup_vs_fp32": 0.9924099332221475,
          "test_size": 512,
          "num_trials": 10,
          "arithmetic_intensity": 0.9961089494163424,
          "achieved_bandwidth_gbps": 2.115952526266554
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Long'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Int'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Short'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Char'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas2_gemv_best_precision=fp32_blas_level=2_device=cuda_framework=pytorch_operation=gemv_size=1024": {
      "operation_type": "blas2_gemv",
      "measured_gflops": 8.644969468799209,
      "efficiency": 0.0016234684448449218,
      "achieved_bandwidth_gbps": 17.323708349585914,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.49902534113060426,
      "batch_size": 1,
      "input_shape": [
        1024,
        1024
      ],
      "output_shape": [
        1024
      ],
      "mean_latency_ms": 0.24258639750769362,
      "std_latency_ms": 0.003583092303451257,
      "min_latency_ms": 0.23702399630565196,
      "max_latency_ms": 0.24616948981114486,
      "num_trials": 10,
      "extra_params": {
        "size": 1024,
        "operation": "gemv",
        "blas_level": 2,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "fp32"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 8.186029940322456,
          "efficiency": 0.049313433375436484,
          "mean_latency_ms": 0.2561867004260421,
          "std_latency_ms": 0.00509855849489749,
          "min_latency_ms": 0.24857699463609606,
          "max_latency_ms": 0.26128525892093957,
          "speedup_vs_fp32": null,
          "test_size": 1024,
          "num_trials": 10,
          "arithmetic_intensity": 0.9980506822612085,
          "achieved_bandwidth_gbps": 8.202018280049648
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 8.644969468799209,
          "efficiency": 0.0016234684448449218,
          "mean_latency_ms": 0.24258639750769362,
          "std_latency_ms": 0.003583092303451257,
          "min_latency_ms": 0.23702399630565196,
          "max_latency_ms": 0.24616948981114486,
          "speedup_vs_fp32": 1.0,
          "test_size": 1024,
          "num_trials": 10,
          "arithmetic_intensity": 0.49902534113060426,
          "achieved_bandwidth_gbps": 17.323708349585914
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 8.51212914216183,
          "efficiency": 0.0007992609523156648,
          "mean_latency_ms": 0.2463722019456327,
          "std_latency_ms": 0.009099566324788602,
          "min_latency_ms": 0.23817700275685638,
          "max_latency_ms": 0.2554717682704213,
          "speedup_vs_fp32": 0.9846338003717866,
          "test_size": 1024,
          "num_trials": 10,
          "arithmetic_intensity": 0.49902534113060426,
          "achieved_bandwidth_gbps": 17.05750878878523
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 8.457860973092135,
          "efficiency": 0.00039708267479305796,
          "mean_latency_ms": 0.24795299977995455,
          "std_latency_ms": 0.006051380140043548,
          "min_latency_ms": 0.24150499666575342,
          "max_latency_ms": 0.2540043799199981,
          "speedup_vs_fp32": 0.9783563728729903,
          "test_size": 1024,
          "num_trials": 10,
          "arithmetic_intensity": 0.9980506822612085,
          "achieved_bandwidth_gbps": 8.474380232805204
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 8.496018161797618,
          "efficiency": 0.00039887409210317455,
          "mean_latency_ms": 0.2468393970048055,
          "std_latency_ms": 0.00832930995177065,
          "min_latency_ms": 0.23769699328113347,
          "max_latency_ms": 0.2551687069565762,
          "speedup_vs_fp32": 0.9827701754715069,
          "test_size": 1024,
          "num_trials": 10,
          "arithmetic_intensity": 0.9980506822612085,
          "achieved_bandwidth_gbps": 8.512611947269878
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Long'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Int'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Short'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Char'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas2_gemv_best_precision=tf32_blas_level=2_device=cuda_framework=pytorch_operation=gemv_size=2048": {
      "operation_type": "blas2_gemv",
      "measured_gflops": 31.069517024078568,
      "efficiency": 0.0029173255421670015,
      "achieved_bandwidth_gbps": 62.199716698594784,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.4995121951219512,
      "batch_size": 1,
      "input_shape": [
        2048,
        2048
      ],
      "output_shape": [
        2048
      ],
      "mean_latency_ms": 0.26999479887308553,
      "std_latency_ms": 0.0026363319090303597,
      "min_latency_ms": 0.26595300005283207,
      "max_latency_ms": 0.27263113078211587,
      "num_trials": 10,
      "extra_params": {
        "size": 2048,
        "operation": "gemv",
        "blas_level": 2,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "tf32"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 9.70777525050411,
          "efficiency": 0.05848057379821753,
          "mean_latency_ms": 0.8641123000415973,
          "std_latency_ms": 0.002539273352534734,
          "min_latency_ms": 0.8601950103184208,
          "max_latency_ms": 0.8666515733941321,
          "speedup_vs_fp32": null,
          "test_size": 2048,
          "num_trials": 10,
          "arithmetic_intensity": 0.9990243902439024,
          "achieved_bandwidth_gbps": 9.71725549977218
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 30.595236394010183,
          "efficiency": 0.005745584299344636,
          "mean_latency_ms": 0.27418019890319556,
          "std_latency_ms": 0.0066812589261596896,
          "min_latency_ms": 0.2677769953152165,
          "max_latency_ms": 0.28086145782935523,
          "speedup_vs_fp32": 1.0,
          "test_size": 2048,
          "num_trials": 10,
          "arithmetic_intensity": 0.4995121951219512,
          "achieved_bandwidth_gbps": 61.25022910910242
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 31.069517024078568,
          "efficiency": 0.0029173255421670015,
          "mean_latency_ms": 0.26999479887308553,
          "std_latency_ms": 0.0026363319090303597,
          "min_latency_ms": 0.26595300005283207,
          "max_latency_ms": 0.27263113078211587,
          "speedup_vs_fp32": 1.0155017802105049,
          "test_size": 2048,
          "num_trials": 10,
          "arithmetic_intensity": 0.4995121951219512,
          "achieved_bandwidth_gbps": 62.199716698594784
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 30.0605324920461,
          "efficiency": 0.0014112926052603802,
          "mean_latency_ms": 0.27905719907721505,
          "std_latency_ms": 0.007968114297375747,
          "min_latency_ms": 0.2702409983612597,
          "max_latency_ms": 0.2870253133745908,
          "speedup_vs_fp32": 0.9825232956177202,
          "test_size": 2048,
          "num_trials": 10,
          "arithmetic_intensity": 0.9990243902439024,
          "achieved_bandwidth_gbps": 30.089888480807865
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 30.3199046249909,
          "efficiency": 0.0014234697007037983,
          "mean_latency_ms": 0.2766699995845556,
          "std_latency_ms": 0.004875186025263868,
          "min_latency_ms": 0.2687699889065698,
          "max_latency_ms": 0.2815451856098195,
          "speedup_vs_fp32": 0.9910008288390547,
          "test_size": 2048,
          "num_trials": 10,
          "arithmetic_intensity": 0.9990243902439024,
          "achieved_bandwidth_gbps": 30.349513906851247
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Long'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Int'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Short'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Char'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas3_gemm_best_precision=fp64_blas_level=3_device=cuda_framework=pytorch_operation=gemm_size=32": {
      "operation_type": "blas3_gemm",
      "measured_gflops": 0.26800560144431773,
      "efficiency": 0.0016144915749657695,
      "achieved_bandwidth_gbps": 0.10050210054161915,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 2.6666666666666665,
      "batch_size": 1,
      "input_shape": [
        32,
        32
      ],
      "output_shape": [
        32,
        32
      ],
      "mean_latency_ms": 0.24453220248688012,
      "std_latency_ms": 0.004758508893165304,
      "min_latency_ms": 0.23833700106479228,
      "max_latency_ms": 0.24929071138004544,
      "num_trials": 10,
      "extra_params": {
        "size": 32,
        "operation": "gemm",
        "blas_level": 3,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "fp64"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.26800560144431773,
          "efficiency": 0.0016144915749657695,
          "mean_latency_ms": 0.24453220248688012,
          "std_latency_ms": 0.004758508893165304,
          "min_latency_ms": 0.23833700106479228,
          "max_latency_ms": 0.24929071138004544,
          "speedup_vs_fp32": null,
          "test_size": 32,
          "num_trials": 10,
          "arithmetic_intensity": 2.6666666666666665,
          "achieved_bandwidth_gbps": 0.10050210054161915
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.2633226319401232,
          "efficiency": 4.945025951927196e-05,
          "mean_latency_ms": 0.2488810001523234,
          "std_latency_ms": 0.005821696980684948,
          "min_latency_ms": 0.24006501189433038,
          "max_latency_ms": 0.25470269713300836,
          "speedup_vs_fp32": 1.0,
          "test_size": 32,
          "num_trials": 10,
          "arithmetic_intensity": 5.333333333333333,
          "achieved_bandwidth_gbps": 0.049372993488773095
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.2518282095634335,
          "efficiency": 2.3645841273561832e-05,
          "mean_latency_ms": 0.26024090038845316,
          "std_latency_ms": 0.024301546876795747,
          "min_latency_ms": 0.2441929973429069,
          "max_latency_ms": 0.2845424472652489,
          "speedup_vs_fp32": 0.9563485208544346,
          "test_size": 32,
          "num_trials": 10,
          "arithmetic_intensity": 5.333333333333333,
          "achieved_bandwidth_gbps": 0.047217789293143776
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.25168266002565304,
          "efficiency": 1.181608732514803e-05,
          "mean_latency_ms": 0.26039139920612797,
          "std_latency_ms": 0.0104635787057309,
          "min_latency_ms": 0.2534730010665953,
          "max_latency_ms": 0.27085497791185886,
          "speedup_vs_fp32": 0.955795778628261,
          "test_size": 32,
          "num_trials": 10,
          "arithmetic_intensity": 10.666666666666666,
          "achieved_bandwidth_gbps": 0.02359524937740497
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.24883557650703633,
          "efficiency": 1.1682421432255227e-05,
          "mean_latency_ms": 0.2633707001223229,
          "std_latency_ms": 0.008867370043600655,
          "min_latency_ms": 0.2536329993745312,
          "max_latency_ms": 0.27223807016592355,
          "speedup_vs_fp32": 0.9449836296776001,
          "test_size": 32,
          "num_trials": 10,
          "arithmetic_intensity": 10.666666666666666,
          "achieved_bandwidth_gbps": 0.023328335297534655
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'Lo",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'In",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'Sh",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'Ch",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas3_gemm_best_precision=fp16_blas_level=3_device=cuda_framework=pytorch_operation=gemm_size=64": {
      "operation_type": "blas3_gemm",
      "measured_gflops": 2.0896543026803314,
      "efficiency": 9.810583580658832e-05,
      "achieved_bandwidth_gbps": 0.09795254543814053,
      "memory_bound": false,
      "compute_bound": true,
      "arithmetic_intensity": 21.333333333333332,
      "batch_size": 1,
      "input_shape": [
        64,
        64
      ],
      "output_shape": [
        64,
        64
      ],
      "mean_latency_ms": 0.25089700211538,
      "std_latency_ms": 0.008558167781923368,
      "min_latency_ms": 0.23859301290940493,
      "max_latency_ms": 0.2594551698973034,
      "num_trials": 10,
      "extra_params": {
        "size": 64,
        "operation": "gemm",
        "blas_level": 3,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "fp16"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 2.0109644826175157,
          "efficiency": 0.012114243871189853,
          "mean_latency_ms": 0.2607146991067566,
          "std_latency_ms": 0.00735418419569624,
          "min_latency_ms": 0.25308899057563394,
          "max_latency_ms": 0.2680688833024528,
          "speedup_vs_fp32": null,
          "test_size": 64,
          "num_trials": 10,
          "arithmetic_intensity": 5.333333333333333,
          "achieved_bandwidth_gbps": 0.37705584049078417
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.9915307654772323,
          "efficiency": 0.0003739963878830483,
          "mean_latency_ms": 0.2632588002597913,
          "std_latency_ms": 0.025846106692134198,
          "min_latency_ms": 0.2445130085106939,
          "max_latency_ms": 0.28910490695192553,
          "speedup_vs_fp32": 1.0,
          "test_size": 64,
          "num_trials": 10,
          "arithmetic_intensity": 10.666666666666666,
          "achieved_bandwidth_gbps": 0.18670600926349054
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.6534901718739479,
          "efficiency": 0.00015525729313370403,
          "mean_latency_ms": 0.3170795986079611,
          "std_latency_ms": 0.20461186904927078,
          "min_latency_ms": 0.24803300038911402,
          "max_latency_ms": 0.5216914676572318,
          "speedup_vs_fp32": 0.8302609231736978,
          "test_size": 64,
          "num_trials": 10,
          "arithmetic_intensity": 10.666666666666666,
          "achieved_bandwidth_gbps": 0.1550147036131826
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 2.0896543026803314,
          "efficiency": 9.810583580658832e-05,
          "mean_latency_ms": 0.25089700211538,
          "std_latency_ms": 0.008558167781923368,
          "min_latency_ms": 0.23859301290940493,
          "max_latency_ms": 0.2594551698973034,
          "speedup_vs_fp32": 1.0492704099299142,
          "test_size": 64,
          "num_trials": 10,
          "arithmetic_intensity": 21.333333333333332,
          "achieved_bandwidth_gbps": 0.09795254543814053
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 2.0760707529039264,
          "efficiency": 9.746811046497307e-05,
          "mean_latency_ms": 0.2525385993067175,
          "std_latency_ms": 0.005772723421067937,
          "min_latency_ms": 0.24611299159005284,
          "max_latency_ms": 0.25831132272778545,
          "speedup_vs_fp32": 1.0424497521666132,
          "test_size": 64,
          "num_trials": 10,
          "arithmetic_intensity": 21.333333333333332,
          "achieved_bandwidth_gbps": 0.09731581654237155
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'Lo",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'In",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'Sh",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'Ch",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas3_gemm_best_precision=fp32_blas_level=3_device=cuda_framework=pytorch_operation=gemm_size=128": {
      "operation_type": "blas3_gemm",
      "measured_gflops": 15.854383088552776,
      "efficiency": 0.0029773489368174226,
      "achieved_bandwidth_gbps": 0.7431742072759113,
      "memory_bound": false,
      "compute_bound": true,
      "arithmetic_intensity": 21.333333333333332,
      "batch_size": 1,
      "input_shape": [
        128,
        128
      ],
      "output_shape": [
        128,
        128
      ],
      "mean_latency_ms": 0.2645517000928521,
      "std_latency_ms": 0.00671538033193275,
      "min_latency_ms": 0.25312100478913635,
      "max_latency_ms": 0.27126708042478487,
      "num_trials": 10,
      "extra_params": {
        "size": 128,
        "operation": "gemm",
        "blas_level": 3,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "fp32"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 6.439742329667882,
          "efficiency": 0.03879362849197519,
          "mean_latency_ms": 0.6513155007269233,
          "std_latency_ms": 0.004818730330938337,
          "min_latency_ms": 0.6460830045398325,
          "max_latency_ms": 0.6561342310578617,
          "speedup_vs_fp32": null,
          "test_size": 128,
          "num_trials": 10,
          "arithmetic_intensity": 10.666666666666666,
          "achieved_bandwidth_gbps": 0.6037258434063638
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 15.854383088552776,
          "efficiency": 0.0029773489368174226,
          "mean_latency_ms": 0.2645517000928521,
          "std_latency_ms": 0.00671538033193275,
          "min_latency_ms": 0.25312100478913635,
          "max_latency_ms": 0.27126708042478487,
          "speedup_vs_fp32": 1.0,
          "test_size": 128,
          "num_trials": 10,
          "arithmetic_intensity": 21.333333333333332,
          "achieved_bandwidth_gbps": 0.7431742072759113
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 8.389208645543723,
          "efficiency": 0.000787719121647298,
          "mean_latency_ms": 0.499964201299008,
          "std_latency_ms": 0.2268515262764144,
          "min_latency_ms": 0.267329000052996,
          "max_latency_ms": 0.7268157275754223,
          "speedup_vs_fp32": 0.5291412853270161,
          "test_size": 128,
          "num_trials": 10,
          "arithmetic_intensity": 21.333333333333332,
          "achieved_bandwidth_gbps": 0.39324415525986206
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 5.957625263857298,
          "efficiency": 0.0002797007166130187,
          "mean_latency_ms": 0.7040227967081591,
          "std_latency_ms": 0.012031240894521936,
          "min_latency_ms": 0.681154997437261,
          "max_latency_ms": 0.716054037602681,
          "speedup_vs_fp32": 0.375771496789354,
          "test_size": 128,
          "num_trials": 10,
          "arithmetic_intensity": 42.666666666666664,
          "achieved_bandwidth_gbps": 0.13963184212165544
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 5.9545389517984795,
          "efficiency": 0.00027955581933326195,
          "mean_latency_ms": 0.7043877005344257,
          "std_latency_ms": 0.004313385924181538,
          "min_latency_ms": 0.698020012350753,
          "max_latency_ms": 0.7087010864586072,
          "speedup_vs_fp32": 0.3755768306177609,
          "test_size": 128,
          "num_trials": 10,
          "arithmetic_intensity": 42.666666666666664,
          "achieved_bandwidth_gbps": 0.13955950668277683
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'Lo",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'In",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'Sh",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'Ch",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas3_gemm_best_precision=fp16_blas_level=3_device=cuda_framework=pytorch_operation=gemm_size=256": {
      "operation_type": "blas3_gemm",
      "measured_gflops": 125.65099297655188,
      "efficiency": 0.005899107651481309,
      "achieved_bandwidth_gbps": 1.4724725739439672,
      "memory_bound": false,
      "compute_bound": true,
      "arithmetic_intensity": 85.33333333333333,
      "batch_size": 1,
      "input_shape": [
        256,
        256
      ],
      "output_shape": [
        256,
        256
      ],
      "mean_latency_ms": 0.2670447021955624,
      "std_latency_ms": 0.004275749669757801,
      "min_latency_ms": 0.26166500174440444,
      "max_latency_ms": 0.2713204518653202,
      "num_trials": 10,
      "extra_params": {
        "size": 256,
        "operation": "gemm",
        "blas_level": 3,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "fp16"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 8.06500355989988,
          "efficiency": 0.04858435879457759,
          "mean_latency_ms": 4.160498101555277,
          "std_latency_ms": 0.7957025245577586,
          "min_latency_ms": 2.6790539996000007,
          "max_latency_ms": 4.956200626113035,
          "speedup_vs_fp32": null,
          "test_size": 256,
          "num_trials": 10,
          "arithmetic_intensity": 21.333333333333332,
          "achieved_bandwidth_gbps": 0.3780470418703069
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 113.9144007794456,
          "efficiency": 0.021392375733229222,
          "mean_latency_ms": 0.2945582979009487,
          "std_latency_ms": 0.023973293711242922,
          "min_latency_ms": 0.2794899919535965,
          "max_latency_ms": 0.3185315916121916,
          "speedup_vs_fp32": 1.0,
          "test_size": 256,
          "num_trials": 10,
          "arithmetic_intensity": 42.666666666666664,
          "achieved_bandwidth_gbps": 2.6698687682682563
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 54.27074057515999,
          "efficiency": 0.005095844185461032,
          "mean_latency_ms": 0.6182784985867329,
          "std_latency_ms": 0.22948322511119482,
          "min_latency_ms": 0.27760100783780217,
          "max_latency_ms": 0.8477617236979277,
          "speedup_vs_fp32": 0.47641685514578463,
          "test_size": 256,
          "num_trials": 10,
          "arithmetic_intensity": 42.666666666666664,
          "achieved_bandwidth_gbps": 1.2719704822303122
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 125.65099297655188,
          "efficiency": 0.005899107651481309,
          "mean_latency_ms": 0.2670447021955624,
          "std_latency_ms": 0.004275749669757801,
          "min_latency_ms": 0.26166500174440444,
          "max_latency_ms": 0.2713204518653202,
          "speedup_vs_fp32": 1.103029925249135,
          "test_size": 256,
          "num_trials": 10,
          "arithmetic_intensity": 85.33333333333333,
          "achieved_bandwidth_gbps": 1.4724725739439672
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 92.01457844851477,
          "efficiency": 0.004319933260493651,
          "mean_latency_ms": 0.36466430174186826,
          "std_latency_ms": 0.17297294511122743,
          "min_latency_ms": 0.2613460092106834,
          "max_latency_ms": 0.5376372468530957,
          "speedup_vs_fp32": 0.8077519419749923,
          "test_size": 256,
          "num_trials": 10,
          "arithmetic_intensity": 85.33333333333333,
          "achieved_bandwidth_gbps": 1.0782958411935324
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'Lo",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'In",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'Sh",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'Ch",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas3_gemm_best_precision=bf16_blas_level=3_device=cuda_framework=pytorch_operation=gemm_size=512": {
      "operation_type": "blas3_gemm",
      "measured_gflops": 1047.3923641482,
      "efficiency": 0.04917335042949295,
      "achieved_bandwidth_gbps": 6.137064633680859,
      "memory_bound": false,
      "compute_bound": true,
      "arithmetic_intensity": 170.66666666666666,
      "batch_size": 1,
      "input_shape": [
        512,
        512
      ],
      "output_shape": [
        512,
        512
      ],
      "mean_latency_ms": 0.2562893001595512,
      "std_latency_ms": 0.004090229638790279,
      "min_latency_ms": 0.24956899869721383,
      "max_latency_ms": 0.2603795297983415,
      "num_trials": 10,
      "extra_params": {
        "size": 512,
        "operation": "gemm",
        "blas_level": 3,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "bf16"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 15.321228719339636,
          "efficiency": 0.09229655855023877,
          "mean_latency_ms": 17.520491399045568,
          "std_latency_ms": 2.5983458432410966,
          "min_latency_ms": 16.38929899490904,
          "max_latency_ms": 20.118837242286666,
          "speedup_vs_fp32": null,
          "test_size": 512,
          "num_trials": 10,
          "arithmetic_intensity": 42.666666666666664,
          "achieved_bandwidth_gbps": 0.3590912981095227
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 218.23626886406942,
          "efficiency": 0.04098333687588158,
          "mean_latency_ms": 1.2300222020712681,
          "std_latency_ms": 0.2685674520113502,
          "min_latency_ms": 1.016677008010447,
          "max_latency_ms": 1.4985896540826182,
          "speedup_vs_fp32": 1.0,
          "test_size": 512,
          "num_trials": 10,
          "arithmetic_intensity": 85.33333333333333,
          "achieved_bandwidth_gbps": 2.557456275750814
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 516.2639238275484,
          "efficiency": 0.048475485805403604,
          "mean_latency_ms": 0.5199578037718311,
          "std_latency_ms": 0.22595940280584298,
          "min_latency_ms": 0.4074580065207556,
          "max_latency_ms": 0.745917206577674,
          "speedup_vs_fp32": 2.3656192736190356,
          "test_size": 512,
          "num_trials": 10,
          "arithmetic_intensity": 85.33333333333333,
          "achieved_bandwidth_gbps": 6.049967857354083
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 518.6803774321793,
          "efficiency": 0.02435119142874081,
          "mean_latency_ms": 0.5175353988306597,
          "std_latency_ms": 0.4638802009762235,
          "min_latency_ms": 0.25180898956023157,
          "max_latency_ms": 0.9814155998068832,
          "speedup_vs_fp32": 2.3766919226210033,
          "test_size": 512,
          "num_trials": 10,
          "arithmetic_intensity": 170.66666666666666,
          "achieved_bandwidth_gbps": 3.0391428365166755
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1047.3923641482,
          "efficiency": 0.04917335042949295,
          "mean_latency_ms": 0.2562893001595512,
          "std_latency_ms": 0.004090229638790279,
          "min_latency_ms": 0.24956899869721383,
          "max_latency_ms": 0.2603795297983415,
          "speedup_vs_fp32": 4.799350582741948,
          "test_size": 512,
          "num_trials": 10,
          "arithmetic_intensity": 170.66666666666666,
          "achieved_bandwidth_gbps": 6.137064633680859
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'Lo",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'In",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'Sh",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'Ch",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas3_gemm_best_precision=tf32_blas_level=3_device=cuda_framework=pytorch_operation=gemm_size=1024": {
      "operation_type": "blas3_gemm",
      "measured_gflops": 1597.3811862544876,
      "efficiency": 0.1499888437797641,
      "achieved_bandwidth_gbps": 9.35965538820989,
      "memory_bound": false,
      "compute_bound": true,
      "arithmetic_intensity": 170.66666666666666,
      "batch_size": 1,
      "input_shape": [
        1024,
        1024
      ],
      "output_shape": [
        1024,
        1024
      ],
      "mean_latency_ms": 1.3443777017528191,
      "std_latency_ms": 0.18392716476855306,
      "min_latency_ms": 1.166213012766093,
      "max_latency_ms": 1.528304866521372,
      "num_trials": 10,
      "extra_params": {
        "size": 1024,
        "operation": "gemm",
        "blas_level": 3,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "tf32"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 16.62759649607946,
          "efficiency": 0.10016624395228589,
          "mean_latency_ms": 129.15177779941587,
          "std_latency_ms": 0.16488198187253297,
          "min_latency_ms": 128.99043300421908,
          "max_latency_ms": 129.3166597812884,
          "speedup_vs_fp32": null,
          "test_size": 1024,
          "num_trials": 10,
          "arithmetic_intensity": 85.33333333333333,
          "achieved_bandwidth_gbps": 0.19485464643843114
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 531.6251667930237,
          "efficiency": 0.09983571207380727,
          "mean_latency_ms": 4.0394695024588145,
          "std_latency_ms": 0.8577722368164021,
          "min_latency_ms": 3.165903006447479,
          "max_latency_ms": 4.897241739275216,
          "speedup_vs_fp32": 1.0,
          "test_size": 1024,
          "num_trials": 10,
          "arithmetic_intensity": 170.66666666666666,
          "achieved_bandwidth_gbps": 3.1149912116778737
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1597.3811862544876,
          "efficiency": 0.1499888437797641,
          "mean_latency_ms": 1.3443777017528191,
          "std_latency_ms": 0.18392716476855306,
          "min_latency_ms": 1.166213012766093,
          "max_latency_ms": 1.528304866521372,
          "speedup_vs_fp32": 3.0047132566927406,
          "test_size": 1024,
          "num_trials": 10,
          "arithmetic_intensity": 170.66666666666666,
          "achieved_bandwidth_gbps": 9.35965538820989
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1473.5524954920322,
          "efficiency": 0.06918086833295926,
          "mean_latency_ms": 1.4573513020877726,
          "std_latency_ms": 0.21833433561598564,
          "min_latency_ms": 1.0394300043117255,
          "max_latency_ms": 1.6756856377037583,
          "speedup_vs_fp32": 2.771788447076522,
          "test_size": 1024,
          "num_trials": 10,
          "arithmetic_intensity": 341.3333333333333,
          "achieved_bandwidth_gbps": 4.317048326636813
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1371.3502724211546,
          "efficiency": 0.06438264189770679,
          "mean_latency_ms": 1.5659628988942131,
          "std_latency_ms": 0.009272234350230335,
          "min_latency_ms": 1.551687004393898,
          "max_latency_ms": 1.5752351332444434,
          "speedup_vs_fp32": 2.5795435545192293,
          "test_size": 1024,
          "num_trials": 10,
          "arithmetic_intensity": 341.3333333333333,
          "achieved_bandwidth_gbps": 4.017627751233851
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'Lo",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'In",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'Sh",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'Ch",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas3_gemm_best_precision=bf16_blas_level=3_device=cuda_framework=pytorch_operation=gemm_size=2048": {
      "operation_type": "blas3_gemm",
      "measured_gflops": 5048.283519477215,
      "efficiency": 0.23700861593789743,
      "achieved_bandwidth_gbps": 7.394946561734202,
      "memory_bound": false,
      "compute_bound": true,
      "arithmetic_intensity": 682.6666666666666,
      "batch_size": 1,
      "input_shape": [
        2048,
        2048
      ],
      "output_shape": [
        2048,
        2048
      ],
      "mean_latency_ms": 3.403111001534853,
      "std_latency_ms": 0.341630203396224,
      "min_latency_ms": 3.081390997976996,
      "max_latency_ms": 3.7447412049310773,
      "num_trials": 10,
      "extra_params": {
        "size": 2048,
        "operation": "gemm",
        "blas_level": 3,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "bf16"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 16.748432908667507,
          "efficiency": 0.10089417414859944,
          "mean_latency_ms": 1025.759799599473,
          "std_latency_ms": 0.016558155945663067,
          "min_latency_ms": 1025.7355570065556,
          "max_latency_ms": 1025.7763577554185,
          "speedup_vs_fp32": null,
          "test_size": 2048,
          "num_trials": 10,
          "arithmetic_intensity": 170.66666666666666,
          "achieved_bandwidth_gbps": 0.09813534907422368
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 756.1033167794874,
          "efficiency": 0.1419912331980258,
          "mean_latency_ms": 22.721589500724804,
          "std_latency_ms": 0.15285847817057002,
          "min_latency_ms": 22.53729398944415,
          "max_latency_ms": 22.874447978895375,
          "speedup_vs_fp32": 1.0,
          "test_size": 2048,
          "num_trials": 10,
          "arithmetic_intensity": 341.3333333333333,
          "achieved_bandwidth_gbps": 2.2151464358774047
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 2567.8840847709735,
          "efficiency": 0.24111587650431676,
          "mean_latency_ms": 6.690282199997455,
          "std_latency_ms": 0.3400397599812488,
          "min_latency_ms": 6.389054993633181,
          "max_latency_ms": 7.0303219599787035,
          "speedup_vs_fp32": 3.396207935852608,
          "test_size": 2048,
          "num_trials": 10,
          "arithmetic_intensity": 341.3333333333333,
          "achieved_bandwidth_gbps": 7.523097904602462
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 4887.458769892833,
          "efficiency": 0.2294581582109311,
          "mean_latency_ms": 3.5150924013578333,
          "std_latency_ms": 0.2701898881381431,
          "min_latency_ms": 3.0771669989917427,
          "max_latency_ms": 3.7852822894959766,
          "speedup_vs_fp32": 6.46400916571859,
          "test_size": 2048,
          "num_trials": 10,
          "arithmetic_intensity": 682.6666666666666,
          "achieved_bandwidth_gbps": 7.1593634324602045
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 5048.283519477215,
          "efficiency": 0.23700861593789743,
          "mean_latency_ms": 3.403111001534853,
          "std_latency_ms": 0.341630203396224,
          "min_latency_ms": 3.081390997976996,
          "max_latency_ms": 3.7447412049310773,
          "speedup_vs_fp32": 6.676711247584057,
          "test_size": 2048,
          "num_trials": 10,
          "arithmetic_intensity": 682.6666666666666,
          "achieved_bandwidth_gbps": 7.394946561734202
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'Lo",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'In",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'Sh",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'Ch",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    }
  },
  "fusion_profiles": {},
  "precision_matrix": {
    "hardware_name": "Jetson Orin AGX (GPU)",
    "supported_precisions": [
      "fp64",
      "fp32",
      "tf32",
      "fp16",
      "bf16",
      "int64",
      "int32",
      "int16",
      "int8"
    ],
    "unsupported_precisions": [
      "fp8",
      "fp4",
      "int4"
    ],
    "peak_gflops_by_precision": {
      "fp64": 16.748432908667507,
      "fp32": 756.1033167794874,
      "tf32": 2567.8840847709735,
      "fp16": 4887.458769892833,
      "bf16": 5048.283519477215,
      "int64": 3.357632859448031,
      "int32": 7.758960739903924,
      "int16": 14.202745931279644,
      "int8": 19.113832992090963
    },
    "speedup_vs_fp32": {
      "fp32": 1.0,
      "tf32": 3.396207935852608,
      "fp16": 6.46400916571859,
      "bf16": 6.676711247584057,
      "int64": 0.4330901670472421,
      "int32": 1.0008031680719243,
      "int16": 1.8319661098737958,
      "int8": 2.4654312934078813
    },
    "theoretical_peaks": {
      "fp64": 166.0,
      "fp32": 5325.0,
      "fp16": 21300.0,
      "fp8": 0.0,
      "fp4": 0.0,
      "bf16": 21300.0,
      "tf32": 10650.0,
      "int64": 0.0,
      "int32": 5325.0,
      "int16": 21300.0,
      "int8": 42600.0,
      "int4": 0.0
    }
  }
}