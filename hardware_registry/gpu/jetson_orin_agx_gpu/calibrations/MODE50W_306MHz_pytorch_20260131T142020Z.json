{
  "metadata": {
    "hardware_name": "Jetson Orin AGX (GPU)",
    "calibration_date": "2026-01-31T14:12:43.160258",
    "calibration_tool_version": "1.0.0",
    "cpu_model": "aarch64",
    "cpu_count": 12,
    "total_memory_gb": 61.32390213012695,
    "python_version": "3.8.10",
    "pytorch_version": "2.1.0a0+41361538.nv23.06",
    "numpy_version": "1.24.4",
    "num_warmup_runs": 3,
    "num_measurement_runs": 10,
    "device_type": "cuda",
    "platform_architecture": "aarch64",
    "framework": "pytorch",
    "gpu_clock": {
      "sm_clock_mhz": 306,
      "query_method": "sysfs_under_load",
      "max_sm_clock_mhz": 816,
      "nvpmodel_mode": 50,
      "power_mode_name": "MODE_50W",
      "clock_policy": "dvfs"
    },
    "cpu_clock": {
      "current_freq_mhz": 985.6000000000003,
      "query_method": "sysfs",
      "min_freq_mhz": 729.6,
      "max_freq_mhz": 1497.6,
      "base_freq_mhz": 2201.6,
      "per_core_freq_mhz": [
        1497.6,
        1497.6,
        1497.6,
        1497.6,
        729.6,
        729.6,
        729.6,
        729.6,
        729.6,
        729.6,
        729.6,
        729.6
      ],
      "governor": "schedutil",
      "driver": "tegra194",
      "nvpmodel_mode": 50,
      "power_mode_name": "MODE_50W",
      "clock_policy": "dvfs"
    },
    "preflight": {
      "timestamp": "2026-01-31T14:12:35.664938",
      "passed": true,
      "forced": false,
      "checks": [
        {
          "name": "CPU Governor",
          "status": "passed",
          "message": "schedutil (Jetson default)",
          "current_value": "schedutil",
          "expected_value": "schedutil or performance"
        },
        {
          "name": "CPU Frequency",
          "status": "passed",
          "message": "1498 MHz (100% of max)",
          "current_value": "1498 MHz",
          "expected_value": ">= 1348 MHz (90%)"
        },
        {
          "name": "Turbo Boost",
          "status": "skipped",
          "message": "Could not determine (not Intel pstate)"
        },
        {
          "name": "System Load",
          "status": "warning",
          "message": "6.0% (some background activity)",
          "current_value": "6.0%",
          "expected_value": "< 5%"
        },
        {
          "name": "Thermal State",
          "status": "passed",
          "message": "43\u00b0C (cool)",
          "current_value": "43\u00b0C",
          "expected_value": "< 80\u00b0C"
        },
        {
          "name": "GPU Power Mode",
          "status": "warning",
          "message": "MODE_50W (unknown mode)",
          "current_value": "MODE_50W",
          "expected_value": "Known mode (MAXN, 7W, 15W, 25W, etc.)"
        }
      ]
    }
  },
  "theoretical_peak_gflops": 5325.0,
  "theoretical_bandwidth_gbps": 204.8,
  "best_measured_gflops": 4019.166278210346,
  "avg_measured_gflops": 161.61141803147746,
  "worst_measured_gflops": 0.0050297264691996245,
  "measured_bandwidth_gbps": 168.7288490578358,
  "bandwidth_efficiency": 0.8238713332902138,
  "best_efficiency": 0.8238713332902138,
  "avg_efficiency": 0.23732234616661646,
  "worst_efficiency": 0.0,
  "operation_profiles": {
    "stream_copy_device=cuda_flops_per_element=0_framework=pytorch_kernel=copy_num_arrays=2_num_memory_ops=2_size_mb=8": {
      "operation_type": "stream_copy",
      "measured_gflops": 0.0,
      "efficiency": 0.10042522579996119,
      "achieved_bandwidth_gbps": 20.56708624383205,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.0,
      "batch_size": 1,
      "input_shape": [
        2097152
      ],
      "output_shape": [
        2097152
      ],
      "mean_latency_ms": 0.8157313000538124,
      "std_latency_ms": 0.30563044821780405,
      "min_latency_ms": 0.5637780000142811,
      "max_latency_ms": 1.1873329999616544,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 8,
        "kernel": "copy",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 2,
        "num_memory_ops": 2,
        "flops_per_element": 0
      },
      "precision_results": {}
    },
    "stream_copy_device=cuda_flops_per_element=0_framework=pytorch_kernel=copy_num_arrays=2_num_memory_ops=2_size_mb=16": {
      "operation_type": "stream_copy",
      "measured_gflops": 0.0,
      "efficiency": 0.12907886739313948,
      "achieved_bandwidth_gbps": 26.435352042114967,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.0,
      "batch_size": 1,
      "input_shape": [
        4194304
      ],
      "output_shape": [
        4194304
      ],
      "mean_latency_ms": 1.2693014999968,
      "std_latency_ms": 0.3055901400422142,
      "min_latency_ms": 1.0087409996231145,
      "max_latency_ms": 1.6405830001531285,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 16,
        "kernel": "copy",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 2,
        "num_memory_ops": 2,
        "flops_per_element": 0
      },
      "precision_results": {}
    },
    "stream_copy_device=cuda_flops_per_element=0_framework=pytorch_kernel=copy_num_arrays=2_num_memory_ops=2_size_mb=32": {
      "operation_type": "stream_copy",
      "measured_gflops": 0.0,
      "efficiency": 0.1531455692399717,
      "achieved_bandwidth_gbps": 31.3642125803462,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.0,
      "batch_size": 1,
      "input_shape": [
        8388608
      ],
      "output_shape": [
        8388608
      ],
      "mean_latency_ms": 2.1396635999735736,
      "std_latency_ms": 0.30370960834242255,
      "min_latency_ms": 1.9345679997968546,
      "max_latency_ms": 2.6414189997012727,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 32,
        "kernel": "copy",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 2,
        "num_memory_ops": 2,
        "flops_per_element": 0
      },
      "precision_results": {}
    },
    "stream_copy_device=cuda_flops_per_element=0_framework=pytorch_kernel=copy_num_arrays=2_num_memory_ops=2_size_mb=64": {
      "operation_type": "stream_copy",
      "measured_gflops": 0.0,
      "efficiency": 0.1577231606659872,
      "achieved_bandwidth_gbps": 32.30170330439418,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.0,
      "batch_size": 1,
      "input_shape": [
        16777216
      ],
      "output_shape": [
        16777216
      ],
      "mean_latency_ms": 4.155128500042338,
      "std_latency_ms": 0.4047185769858064,
      "min_latency_ms": 3.7216480000097363,
      "max_latency_ms": 4.746932000216475,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 64,
        "kernel": "copy",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 2,
        "num_memory_ops": 2,
        "flops_per_element": 0
      },
      "precision_results": {}
    },
    "stream_copy_device=cuda_flops_per_element=0_framework=pytorch_kernel=copy_num_arrays=2_num_memory_ops=2_size_mb=128": {
      "operation_type": "stream_copy",
      "measured_gflops": 0.0,
      "efficiency": 0.47320668253638426,
      "achieved_bandwidth_gbps": 96.9127285834515,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.0,
      "batch_size": 1,
      "input_shape": [
        33554432
      ],
      "output_shape": [
        33554432
      ],
      "mean_latency_ms": 2.7698678999513504,
      "std_latency_ms": 0.11600416607788053,
      "min_latency_ms": 2.7206519998799195,
      "max_latency_ms": 3.0987329996605695,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 128,
        "kernel": "copy",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 2,
        "num_memory_ops": 2,
        "flops_per_element": 0
      },
      "precision_results": {}
    },
    "stream_copy_device=cuda_flops_per_element=0_framework=pytorch_kernel=copy_num_arrays=2_num_memory_ops=2_size_mb=256": {
      "operation_type": "stream_copy",
      "measured_gflops": 0.0,
      "efficiency": 0.46957811161711704,
      "achieved_bandwidth_gbps": 96.16959725918558,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.0,
      "batch_size": 1,
      "input_shape": [
        67108864
      ],
      "output_shape": [
        67108864
      ],
      "mean_latency_ms": 5.582543000082296,
      "std_latency_ms": 0.1816518168351174,
      "min_latency_ms": 5.208918999869638,
      "max_latency_ms": 5.87826600030894,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 256,
        "kernel": "copy",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 2,
        "num_memory_ops": 2,
        "flops_per_element": 0
      },
      "precision_results": {}
    },
    "stream_copy_device=cuda_flops_per_element=0_framework=pytorch_kernel=copy_num_arrays=2_num_memory_ops=2_size_mb=512": {
      "operation_type": "stream_copy",
      "measured_gflops": 0.0,
      "efficiency": 0.49676296989006513,
      "achieved_bandwidth_gbps": 101.73705623348535,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.0,
      "batch_size": 1,
      "input_shape": [
        134217728
      ],
      "output_shape": [
        134217728
      ],
      "mean_latency_ms": 10.55408779998288,
      "std_latency_ms": 0.5762101235767018,
      "min_latency_ms": 9.63034599999446,
      "max_latency_ms": 11.184752999724878,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 512,
        "kernel": "copy",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 2,
        "num_memory_ops": 2,
        "flops_per_element": 0
      },
      "precision_results": {}
    },
    "stream_scale_device=cuda_flops_per_element=1_framework=pytorch_kernel=scale_num_arrays=2_num_memory_ops=2_size_mb=8": {
      "operation_type": "stream_scale",
      "measured_gflops": 7.32176785146953,
      "efficiency": 0.2860065566980285,
      "achieved_bandwidth_gbps": 58.57414281175624,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.5,
      "batch_size": 1,
      "input_shape": [
        2097152
      ],
      "output_shape": [
        2097152
      ],
      "mean_latency_ms": 0.28642699994634313,
      "std_latency_ms": 0.12387443173962749,
      "min_latency_ms": 0.20745699976032483,
      "max_latency_ms": 0.4891869998573384,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 8,
        "kernel": "scale",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 2,
        "num_memory_ops": 2,
        "flops_per_element": 1
      },
      "precision_results": {}
    },
    "stream_scale_device=cuda_flops_per_element=1_framework=pytorch_kernel=scale_num_arrays=2_num_memory_ops=2_size_mb=16": {
      "operation_type": "stream_scale",
      "measured_gflops": 9.020932034529054,
      "efficiency": 0.35238015759879115,
      "achieved_bandwidth_gbps": 72.16745627623243,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.5,
      "batch_size": 1,
      "input_shape": [
        4194304
      ],
      "output_shape": [
        4194304
      ],
      "mean_latency_ms": 0.4649524000342353,
      "std_latency_ms": 0.13090632737964647,
      "min_latency_ms": 0.3402900001674425,
      "max_latency_ms": 0.6301789999270113,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 16,
        "kernel": "scale",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 2,
        "num_memory_ops": 2,
        "flops_per_element": 1
      },
      "precision_results": {}
    },
    "stream_scale_device=cuda_flops_per_element=1_framework=pytorch_kernel=scale_num_arrays=2_num_memory_ops=2_size_mb=32": {
      "operation_type": "stream_scale",
      "measured_gflops": 11.817763794844923,
      "efficiency": 0.4616313982361298,
      "achieved_bandwidth_gbps": 94.54211035875939,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.5,
      "batch_size": 1,
      "input_shape": [
        8388608
      ],
      "output_shape": [
        8388608
      ],
      "mean_latency_ms": 0.7098303998645861,
      "std_latency_ms": 0.12879615681674306,
      "min_latency_ms": 0.6085139998504019,
      "max_latency_ms": 0.8919399997466826,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 32,
        "kernel": "scale",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 2,
        "num_memory_ops": 2,
        "flops_per_element": 1
      },
      "precision_results": {}
    },
    "stream_scale_device=cuda_flops_per_element=1_framework=pytorch_kernel=scale_num_arrays=2_num_memory_ops=2_size_mb=64": {
      "operation_type": "stream_scale",
      "measured_gflops": 12.662682467463128,
      "efficiency": 0.49463603388527844,
      "achieved_bandwidth_gbps": 101.30145973970502,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.5,
      "batch_size": 1,
      "input_shape": [
        16777216
      ],
      "output_shape": [
        16777216
      ],
      "mean_latency_ms": 1.3249338000150601,
      "std_latency_ms": 0.12221449817647577,
      "min_latency_ms": 1.143717000104516,
      "max_latency_ms": 1.4656380003543745,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 64,
        "kernel": "scale",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 2,
        "num_memory_ops": 2,
        "flops_per_element": 1
      },
      "precision_results": {}
    },
    "stream_scale_device=cuda_flops_per_element=1_framework=pytorch_kernel=scale_num_arrays=2_num_memory_ops=2_size_mb=128": {
      "operation_type": "stream_scale",
      "measured_gflops": 13.529135691297423,
      "efficiency": 0.5284818629413055,
      "achieved_bandwidth_gbps": 108.23308553037938,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.5,
      "batch_size": 1,
      "input_shape": [
        33554432
      ],
      "output_shape": [
        33554432
      ],
      "mean_latency_ms": 2.480160800041631,
      "std_latency_ms": 0.12148941700971244,
      "min_latency_ms": 2.388618000168208,
      "max_latency_ms": 2.810316000250168,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 128,
        "kernel": "scale",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 2,
        "num_memory_ops": 2,
        "flops_per_element": 1
      },
      "precision_results": {}
    },
    "stream_scale_device=cuda_flops_per_element=1_framework=pytorch_kernel=scale_num_arrays=2_num_memory_ops=2_size_mb=256": {
      "operation_type": "stream_scale",
      "measured_gflops": 14.706461639020883,
      "efficiency": 0.5744711577742532,
      "achieved_bandwidth_gbps": 117.65169311216707,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.5,
      "batch_size": 1,
      "input_shape": [
        67108864
      ],
      "output_shape": [
        67108864
      ],
      "mean_latency_ms": 4.56322300001375,
      "std_latency_ms": 0.03037979390997505,
      "min_latency_ms": 4.525107000063144,
      "max_latency_ms": 4.605107999850588,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 256,
        "kernel": "scale",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 2,
        "num_memory_ops": 2,
        "flops_per_element": 1
      },
      "precision_results": {}
    },
    "stream_scale_device=cuda_flops_per_element=1_framework=pytorch_kernel=scale_num_arrays=2_num_memory_ops=2_size_mb=512": {
      "operation_type": "stream_scale",
      "measured_gflops": 15.096269761199848,
      "efficiency": 0.589698037546869,
      "achieved_bandwidth_gbps": 120.77015808959878,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.5,
      "batch_size": 1,
      "input_shape": [
        134217728
      ],
      "output_shape": [
        134217728
      ],
      "mean_latency_ms": 8.890787600057592,
      "std_latency_ms": 0.18618456418813906,
      "min_latency_ms": 8.604484999978013,
      "max_latency_ms": 9.145095999883779,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 512,
        "kernel": "scale",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 2,
        "num_memory_ops": 2,
        "flops_per_element": 1
      },
      "precision_results": {}
    },
    "stream_add_device=cuda_flops_per_element=1_framework=pytorch_kernel=add_num_arrays=3_num_memory_ops=3_size_mb=8": {
      "operation_type": "stream_add",
      "measured_gflops": 5.973758954789897,
      "efficiency": 0.3500249387572205,
      "achieved_bandwidth_gbps": 71.68510745747876,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.3333333333333333,
      "batch_size": 1,
      "input_shape": [
        2097152
      ],
      "output_shape": [
        2097152
      ],
      "mean_latency_ms": 0.35106069994981226,
      "std_latency_ms": 0.11202193699925017,
      "min_latency_ms": 0.26310499970350065,
      "max_latency_ms": 0.5306590001055156,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 8,
        "kernel": "add",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 3,
        "num_memory_ops": 3,
        "flops_per_element": 1
      },
      "precision_results": {}
    },
    "stream_add_device=cuda_flops_per_element=1_framework=pytorch_kernel=add_num_arrays=3_num_memory_ops=3_size_mb=16": {
      "operation_type": "stream_add",
      "measured_gflops": 6.843458982111304,
      "efficiency": 0.4009839247330843,
      "achieved_bandwidth_gbps": 82.12150778533567,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.3333333333333333,
      "batch_size": 1,
      "input_shape": [
        4194304
      ],
      "output_shape": [
        4194304
      ],
      "mean_latency_ms": 0.6128924000222469,
      "std_latency_ms": 0.1251590527146611,
      "min_latency_ms": 0.45958600003359606,
      "max_latency_ms": 0.7451550000041607,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 16,
        "kernel": "add",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 3,
        "num_memory_ops": 3,
        "flops_per_element": 1
      },
      "precision_results": {}
    },
    "stream_add_device=cuda_flops_per_element=1_framework=pytorch_kernel=add_num_arrays=3_num_memory_ops=3_size_mb=32": {
      "operation_type": "stream_add",
      "measured_gflops": 8.363337340352487,
      "efficiency": 0.4900392972862786,
      "achieved_bandwidth_gbps": 100.36004808422986,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.3333333333333333,
      "batch_size": 1,
      "input_shape": [
        8388608
      ],
      "output_shape": [
        8388608
      ],
      "mean_latency_ms": 1.0030215999449865,
      "std_latency_ms": 0.11897667776619752,
      "min_latency_ms": 0.8431709998149017,
      "max_latency_ms": 1.1193010000170034,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 32,
        "kernel": "add",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 3,
        "num_memory_ops": 3,
        "flops_per_element": 1
      },
      "precision_results": {}
    },
    "stream_add_device=cuda_flops_per_element=1_framework=pytorch_kernel=add_num_arrays=3_num_memory_ops=3_size_mb=64": {
      "operation_type": "stream_add",
      "measured_gflops": 9.678417280243597,
      "efficiency": 0.5670947625142733,
      "achieved_bandwidth_gbps": 116.14100736292316,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.3333333333333333,
      "batch_size": 1,
      "input_shape": [
        16777216
      ],
      "output_shape": [
        16777216
      ],
      "mean_latency_ms": 1.733466900031999,
      "std_latency_ms": 0.11815552552322008,
      "min_latency_ms": 1.61735099982252,
      "max_latency_ms": 1.893768000172713,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 64,
        "kernel": "add",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 3,
        "num_memory_ops": 3,
        "flops_per_element": 1
      },
      "precision_results": {}
    },
    "stream_add_device=cuda_flops_per_element=1_framework=pytorch_kernel=add_num_arrays=3_num_memory_ops=3_size_mb=128": {
      "operation_type": "stream_add",
      "measured_gflops": 10.998047686473969,
      "efficiency": 0.6444168566293341,
      "achieved_bandwidth_gbps": 131.97657223768763,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.3333333333333333,
      "batch_size": 1,
      "input_shape": [
        33554432
      ],
      "output_shape": [
        33554432
      ],
      "mean_latency_ms": 3.050944400001754,
      "std_latency_ms": 0.5592159934328743,
      "min_latency_ms": 2.5886190001074283,
      "max_latency_ms": 3.974864999690908,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 128,
        "kernel": "add",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 3,
        "num_memory_ops": 3,
        "flops_per_element": 1
      },
      "precision_results": {}
    },
    "stream_add_device=cuda_flops_per_element=1_framework=pytorch_kernel=add_num_arrays=3_num_memory_ops=3_size_mb=256": {
      "operation_type": "stream_add",
      "measured_gflops": 13.540550508905861,
      "efficiency": 0.7933916313812028,
      "achieved_bandwidth_gbps": 162.48660610687034,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.3333333333333333,
      "batch_size": 1,
      "input_shape": [
        67108864
      ],
      "output_shape": [
        67108864
      ],
      "mean_latency_ms": 4.95614000005844,
      "std_latency_ms": 0.05949869033600312,
      "min_latency_ms": 4.903285000182223,
      "max_latency_ms": 5.110838999826228,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 256,
        "kernel": "add",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 3,
        "num_memory_ops": 3,
        "flops_per_element": 1
      },
      "precision_results": {}
    },
    "stream_add_device=cuda_flops_per_element=1_framework=pytorch_kernel=add_num_arrays=3_num_memory_ops=3_size_mb=512": {
      "operation_type": "stream_add",
      "measured_gflops": 14.060737421486314,
      "efficiency": 0.8238713332902138,
      "achieved_bandwidth_gbps": 168.7288490578358,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.3333333333333333,
      "batch_size": 1,
      "input_shape": [
        134217728
      ],
      "output_shape": [
        134217728
      ],
      "mean_latency_ms": 9.545568200064736,
      "std_latency_ms": 0.1273797570223532,
      "min_latency_ms": 9.345897000002878,
      "max_latency_ms": 9.760554999957094,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 512,
        "kernel": "add",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 3,
        "num_memory_ops": 3,
        "flops_per_element": 1
      },
      "precision_results": {}
    },
    "stream_triad_device=cuda_flops_per_element=2_framework=pytorch_kernel=triad_num_arrays=3_num_memory_ops=3_size_mb=8": {
      "operation_type": "stream_triad",
      "measured_gflops": 9.168015866929194,
      "efficiency": 0.2685942148514412,
      "achieved_bandwidth_gbps": 55.00809520157516,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.6666666666666666,
      "batch_size": 1,
      "input_shape": [
        2097152
      ],
      "output_shape": [
        2097152
      ],
      "mean_latency_ms": 0.45749310002065613,
      "std_latency_ms": 0.11533367217529739,
      "min_latency_ms": 0.3239369998482289,
      "max_latency_ms": 0.5715869997402478,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 8,
        "kernel": "triad",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 3,
        "num_memory_ops": 3,
        "flops_per_element": 2
      },
      "precision_results": {}
    },
    "stream_triad_device=cuda_flops_per_element=2_framework=pytorch_kernel=triad_num_arrays=3_num_memory_ops=3_size_mb=16": {
      "operation_type": "stream_triad",
      "measured_gflops": 10.714224772109505,
      "efficiency": 0.31389330387039566,
      "achieved_bandwidth_gbps": 64.28534863265703,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.6666666666666666,
      "batch_size": 1,
      "input_shape": [
        4194304
      ],
      "output_shape": [
        4194304
      ],
      "mean_latency_ms": 0.7829411999864533,
      "std_latency_ms": 0.14961223284851496,
      "min_latency_ms": 0.5546900001718313,
      "max_latency_ms": 1.0305969999535591,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 16,
        "kernel": "triad",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 3,
        "num_memory_ops": 3,
        "flops_per_element": 2
      },
      "precision_results": {}
    },
    "stream_triad_device=cuda_flops_per_element=2_framework=pytorch_kernel=triad_num_arrays=3_num_memory_ops=3_size_mb=32": {
      "operation_type": "stream_triad",
      "measured_gflops": 14.136835424065875,
      "efficiency": 0.4141651003144299,
      "achieved_bandwidth_gbps": 84.82101254439524,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.6666666666666666,
      "batch_size": 1,
      "input_shape": [
        8388608
      ],
      "output_shape": [
        8388608
      ],
      "mean_latency_ms": 1.1867730999711057,
      "std_latency_ms": 0.11245644406821925,
      "min_latency_ms": 1.0257640001327673,
      "max_latency_ms": 1.2874300000476069,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 32,
        "kernel": "triad",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 3,
        "num_memory_ops": 3,
        "flops_per_element": 2
      },
      "precision_results": {}
    },
    "stream_triad_device=cuda_flops_per_element=2_framework=pytorch_kernel=triad_num_arrays=3_num_memory_ops=3_size_mb=64": {
      "operation_type": "stream_triad",
      "measured_gflops": 15.262114596202569,
      "efficiency": 0.4471322635606221,
      "achieved_bandwidth_gbps": 91.5726875772154,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.6666666666666666,
      "batch_size": 1,
      "input_shape": [
        16777216
      ],
      "output_shape": [
        16777216
      ],
      "mean_latency_ms": 2.1985441000651917,
      "std_latency_ms": 0.03497191262932762,
      "min_latency_ms": 2.161992999845097,
      "max_latency_ms": 2.2407139999813808,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 64,
        "kernel": "triad",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 3,
        "num_memory_ops": 3,
        "flops_per_element": 2
      },
      "precision_results": {}
    },
    "stream_triad_device=cuda_flops_per_element=2_framework=pytorch_kernel=triad_num_arrays=3_num_memory_ops=3_size_mb=128": {
      "operation_type": "stream_triad",
      "measured_gflops": 15.358721004974706,
      "efficiency": 0.44996252944261833,
      "achieved_bandwidth_gbps": 92.15232602984824,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.6666666666666666,
      "batch_size": 1,
      "input_shape": [
        33554432
      ],
      "output_shape": [
        33554432
      ],
      "mean_latency_ms": 4.369430499991722,
      "std_latency_ms": 0.17784446085529526,
      "min_latency_ms": 4.139761999795155,
      "max_latency_ms": 4.5499400002881885,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 128,
        "kernel": "triad",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 3,
        "num_memory_ops": 3,
        "flops_per_element": 2
      },
      "precision_results": {}
    },
    "stream_triad_device=cuda_flops_per_element=2_framework=pytorch_kernel=triad_num_arrays=3_num_memory_ops=3_size_mb=256": {
      "operation_type": "stream_triad",
      "measured_gflops": 16.568532025696136,
      "efficiency": 0.48540621169031645,
      "achieved_bandwidth_gbps": 99.41119215417682,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.6666666666666666,
      "batch_size": 1,
      "input_shape": [
        67108864
      ],
      "output_shape": [
        67108864
      ],
      "mean_latency_ms": 8.100761599871475,
      "std_latency_ms": 0.14606250642611682,
      "min_latency_ms": 7.992898999873432,
      "max_latency_ms": 8.328099999744154,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 256,
        "kernel": "triad",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 3,
        "num_memory_ops": 3,
        "flops_per_element": 2
      },
      "precision_results": {}
    },
    "stream_triad_device=cuda_flops_per_element=2_framework=pytorch_kernel=triad_num_arrays=3_num_memory_ops=3_size_mb=512": {
      "operation_type": "stream_triad",
      "measured_gflops": 16.939152604988415,
      "efficiency": 0.4962642364742701,
      "achieved_bandwidth_gbps": 101.63491562993052,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.6666666666666666,
      "batch_size": 1,
      "input_shape": [
        134217728
      ],
      "output_shape": [
        134217728
      ],
      "mean_latency_ms": 15.847041600000011,
      "std_latency_ms": 0.183094530779984,
      "min_latency_ms": 15.573540000332287,
      "max_latency_ms": 16.05491800000891,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 512,
        "kernel": "triad",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 3,
        "num_memory_ops": 3,
        "flops_per_element": 2
      },
      "precision_results": {}
    },
    "blas1_dot_best_precision=bf16_blas_level=1_device=cuda_framework=pytorch_operation=dot_size=1000": {
      "operation_type": "blas1_dot",
      "measured_gflops": 0.02313173640816435,
      "efficiency": 1.0859970144678098e-06,
      "achieved_bandwidth_gbps": 0.0462634728163287,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.5,
      "batch_size": 1,
      "input_shape": [
        1000
      ],
      "output_shape": [
        1000
      ],
      "mean_latency_ms": 0.08646129995213414,
      "std_latency_ms": 0.0011258796051981407,
      "min_latency_ms": 0.08531200001016259,
      "max_latency_ms": 0.08758717955733228,
      "num_trials": 10,
      "extra_params": {
        "size": 1000,
        "operation": "dot",
        "blas_level": 1,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "bf16"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.008587959166820681,
          "efficiency": 5.17346937760282e-05,
          "mean_latency_ms": 0.2328841999769793,
          "std_latency_ms": 0.09920632039449638,
          "min_latency_ms": 0.11424099966461654,
          "max_latency_ms": 0.3320905203714757,
          "speedup_vs_fp32": null,
          "test_size": 1000,
          "num_trials": 10,
          "arithmetic_intensity": 0.5,
          "achieved_bandwidth_gbps": 0.017175918333641363
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.02294243626777673,
          "efficiency": 4.30843873573272e-06,
          "mean_latency_ms": 0.0871747000473988,
          "std_latency_ms": 0.0027642943346832547,
          "min_latency_ms": 0.08051199984038249,
          "max_latency_ms": 0.08993899438208205,
          "speedup_vs_fp32": 1.0,
          "test_size": 1000,
          "num_trials": 10,
          "arithmetic_intensity": 0.25,
          "achieved_bandwidth_gbps": 0.09176974507110693
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.00956399195592582,
          "efficiency": 8.98027413701955e-07,
          "mean_latency_ms": 0.20911769993290363,
          "std_latency_ms": 0.18162799753523826,
          "min_latency_ms": 0.08700799980942975,
          "max_latency_ms": 0.3907456974681419,
          "speedup_vs_fp32": 0.4168690650067841,
          "test_size": 1000,
          "num_trials": 10,
          "arithmetic_intensity": 0.25,
          "achieved_bandwidth_gbps": 0.03825596782370328
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.012684632755066491,
          "efficiency": 5.955226645571123e-07,
          "mean_latency_ms": 0.15767110003253038,
          "std_latency_ms": 0.10607351479544537,
          "min_latency_ms": 0.08182399960787734,
          "max_latency_ms": 0.26374461482797573,
          "speedup_vs_fp32": 0.5528895278171656,
          "test_size": 1000,
          "num_trials": 10,
          "arithmetic_intensity": 0.5,
          "achieved_bandwidth_gbps": 0.025369265510132983
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.02313173640816435,
          "efficiency": 1.0859970144678098e-06,
          "mean_latency_ms": 0.08646129995213414,
          "std_latency_ms": 0.0011258796051981407,
          "min_latency_ms": 0.08531200001016259,
          "max_latency_ms": 0.08758717955733228,
          "speedup_vs_fp32": 1.0082510914786105,
          "test_size": 1000,
          "num_trials": 10,
          "arithmetic_intensity": 0.5,
          "achieved_bandwidth_gbps": 0.0462634728163287
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Long'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Int'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Short'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Char'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas1_dot_best_precision=fp16_blas_level=1_device=cuda_framework=pytorch_operation=dot_size=10000": {
      "operation_type": "blas1_dot",
      "measured_gflops": 0.2353420165680237,
      "efficiency": 1.1048920965634915e-05,
      "achieved_bandwidth_gbps": 0.4706840331360474,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.5,
      "batch_size": 1,
      "input_shape": [
        10000
      ],
      "output_shape": [
        10000
      ],
      "mean_latency_ms": 0.08498270003656216,
      "std_latency_ms": 0.0039313979278124845,
      "min_latency_ms": 0.0797130001046753,
      "max_latency_ms": 0.08891409796437465,
      "num_trials": 10,
      "extra_params": {
        "size": 10000,
        "operation": "dot",
        "blas_level": 1,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "fp16"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.22780158894392769,
          "efficiency": 0.0013722987285778776,
          "mean_latency_ms": 0.08779570016486105,
          "std_latency_ms": 0.0012285159036633502,
          "min_latency_ms": 0.0855369999044342,
          "max_latency_ms": 0.0890242160685244,
          "speedup_vs_fp32": null,
          "test_size": 10000,
          "num_trials": 10,
          "arithmetic_intensity": 0.5,
          "achieved_bandwidth_gbps": 0.45560317788785537
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.2343706969883322,
          "efficiency": 4.401327642973375e-05,
          "mean_latency_ms": 0.08533490004083433,
          "std_latency_ms": 0.0021316462076103665,
          "min_latency_ms": 0.08169600005203392,
          "max_latency_ms": 0.08746654624844469,
          "speedup_vs_fp32": 1.0,
          "test_size": 10000,
          "num_trials": 10,
          "arithmetic_intensity": 0.25,
          "achieved_bandwidth_gbps": 0.9374827879533288
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.2330771431075562,
          "efficiency": 2.1885177756578047e-05,
          "mean_latency_ms": 0.08580849985264649,
          "std_latency_ms": 0.0036578837943400454,
          "min_latency_ms": 0.08137599979818333,
          "max_latency_ms": 0.08946638364698653,
          "speedup_vs_fp32": 0.9944807354443272,
          "test_size": 10000,
          "num_trials": 10,
          "arithmetic_intensity": 0.25,
          "achieved_bandwidth_gbps": 0.9323085724302248
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.2353420165680237,
          "efficiency": 1.1048920965634915e-05,
          "mean_latency_ms": 0.08498270003656216,
          "std_latency_ms": 0.0039313979278124845,
          "min_latency_ms": 0.0797130001046753,
          "max_latency_ms": 0.08891409796437465,
          "speedup_vs_fp32": 1.0041443729620338,
          "test_size": 10000,
          "num_trials": 10,
          "arithmetic_intensity": 0.5,
          "achieved_bandwidth_gbps": 0.4706840331360474
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.23388885810280616,
          "efficiency": 1.0980697563512026e-05,
          "mean_latency_ms": 0.08551070009161776,
          "std_latency_ms": 0.0024413286206386342,
          "min_latency_ms": 0.08160100014720229,
          "max_latency_ms": 0.0879520287122564,
          "speedup_vs_fp32": 0.9979441163433923,
          "test_size": 10000,
          "num_trials": 10,
          "arithmetic_intensity": 0.5,
          "achieved_bandwidth_gbps": 0.4677777162056123
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Long'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Int'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Short'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Char'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas1_dot_best_precision=fp32_blas_level=1_device=cuda_framework=pytorch_operation=dot_size=100000": {
      "operation_type": "blas1_dot",
      "measured_gflops": 2.4270813744915123,
      "efficiency": 0.00045578992948197414,
      "achieved_bandwidth_gbps": 9.70832549796605,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.25,
      "batch_size": 1,
      "input_shape": [
        100000
      ],
      "output_shape": [
        100000
      ],
      "mean_latency_ms": 0.08240349998231977,
      "std_latency_ms": 0.003790915026824601,
      "min_latency_ms": 0.07360000017797574,
      "max_latency_ms": 0.08619441500914438,
      "num_trials": 10,
      "extra_params": {
        "size": 100000,
        "operation": "dot",
        "blas_level": 1,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "fp32"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 2.302020483944681,
          "efficiency": 0.013867593276775187,
          "mean_latency_ms": 0.08688019997862284,
          "std_latency_ms": 0.0029504374402962753,
          "min_latency_ms": 0.08239999988290947,
          "max_latency_ms": 0.08983063741891911,
          "speedup_vs_fp32": null,
          "test_size": 100000,
          "num_trials": 10,
          "arithmetic_intensity": 0.5,
          "achieved_bandwidth_gbps": 4.604040967889362
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 2.4270813744915123,
          "efficiency": 0.00045578992948197414,
          "mean_latency_ms": 0.08240349998231977,
          "std_latency_ms": 0.003790915026824601,
          "min_latency_ms": 0.07360000017797574,
          "max_latency_ms": 0.08619441500914438,
          "speedup_vs_fp32": 1.0,
          "test_size": 100000,
          "num_trials": 10,
          "arithmetic_intensity": 0.25,
          "achieved_bandwidth_gbps": 9.70832549796605
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 2.2976146167618174,
          "efficiency": 0.0002157384616677763,
          "mean_latency_ms": 0.08704679999027576,
          "std_latency_ms": 0.008838015195462224,
          "min_latency_ms": 0.07532799963883008,
          "max_latency_ms": 0.09588481518573798,
          "speedup_vs_fp32": 0.9466574301585504,
          "test_size": 100000,
          "num_trials": 10,
          "arithmetic_intensity": 0.25,
          "achieved_bandwidth_gbps": 9.19045846704727
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 2.3367843730146642,
          "efficiency": 0.00010970818652651006,
          "mean_latency_ms": 0.08558770005038241,
          "std_latency_ms": 0.002765386564269643,
          "min_latency_ms": 0.08044900005188538,
          "max_latency_ms": 0.08835308661465205,
          "speedup_vs_fp32": 0.9627960552019951,
          "test_size": 100000,
          "num_trials": 10,
          "arithmetic_intensity": 0.5,
          "achieved_bandwidth_gbps": 4.6735687460293285
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 2.2838428387875824,
          "efficiency": 0.00010722266848767992,
          "mean_latency_ms": 0.08757170003264036,
          "std_latency_ms": 0.0075122638186867876,
          "min_latency_ms": 0.079872000242176,
          "max_latency_ms": 0.09508396385132716,
          "speedup_vs_fp32": 0.9409832166282686,
          "test_size": 100000,
          "num_trials": 10,
          "arithmetic_intensity": 0.5,
          "achieved_bandwidth_gbps": 4.567685677575165
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Long'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Int'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Short'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Char'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas1_dot_best_precision=fp16_blas_level=1_device=cuda_framework=pytorch_operation=dot_size=1000000": {
      "operation_type": "blas1_dot",
      "measured_gflops": 23.66788280862949,
      "efficiency": 0.0011111682069779103,
      "achieved_bandwidth_gbps": 47.33576561725898,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.5,
      "batch_size": 1,
      "input_shape": [
        1000000
      ],
      "output_shape": [
        1000000
      ],
      "mean_latency_ms": 0.08450269997410942,
      "std_latency_ms": 0.0025299830905124963,
      "min_latency_ms": 0.08083300008365768,
      "max_latency_ms": 0.08703268306462192,
      "num_trials": 10,
      "extra_params": {
        "size": 1000000,
        "operation": "dot",
        "blas_level": 1,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "fp16"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 10.616043703475356,
          "efficiency": 0.06395207050286358,
          "mean_latency_ms": 0.18839410008695268,
          "std_latency_ms": 0.003039106404340044,
          "min_latency_ms": 0.1848650003921648,
          "max_latency_ms": 0.19143320649129272,
          "speedup_vs_fp32": null,
          "test_size": 1000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.5,
          "achieved_bandwidth_gbps": 21.23208740695071
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 16.647064738616095,
          "efficiency": 0.003126209340585182,
          "mean_latency_ms": 0.12014130006718915,
          "std_latency_ms": 0.00920228601149094,
          "min_latency_ms": 0.10908900003414601,
          "max_latency_ms": 0.1293435860786801,
          "speedup_vs_fp32": 1.0,
          "test_size": 1000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.25,
          "achieved_bandwidth_gbps": 66.58825895446438
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 15.080522448785354,
          "efficiency": 0.001416011497538531,
          "mean_latency_ms": 0.1326214000073378,
          "std_latency_ms": 0.0019770344419432627,
          "min_latency_ms": 0.12953599980392028,
          "max_latency_ms": 0.13459843444928107,
          "speedup_vs_fp32": 0.9058967863447517,
          "test_size": 1000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.25,
          "achieved_bandwidth_gbps": 60.322089795141416
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 23.66788280862949,
          "efficiency": 0.0011111682069779103,
          "mean_latency_ms": 0.08450269997410942,
          "std_latency_ms": 0.0025299830905124963,
          "min_latency_ms": 0.08083300008365768,
          "max_latency_ms": 0.08703268306462192,
          "speedup_vs_fp32": 1.4217451052333114,
          "test_size": 1000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.5,
          "achieved_bandwidth_gbps": 47.33576561725898
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 23.198734252381893,
          "efficiency": 0.0010891424531634692,
          "mean_latency_ms": 0.08621160009170126,
          "std_latency_ms": 0.002164883354068304,
          "min_latency_ms": 0.08323200017912313,
          "max_latency_ms": 0.08837648344576957,
          "speedup_vs_fp32": 1.393563046497196,
          "test_size": 1000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.5,
          "achieved_bandwidth_gbps": 46.397468504763786
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Long'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Int'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Short'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Char'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas1_dot_best_precision=fp16_blas_level=1_device=cuda_framework=pytorch_operation=dot_size=10000000": {
      "operation_type": "blas1_dot",
      "measured_gflops": 47.47990887424067,
      "efficiency": 0.002229103703015994,
      "achieved_bandwidth_gbps": 94.95981774848134,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.5,
      "batch_size": 1,
      "input_shape": [
        10000000
      ],
      "output_shape": [
        10000000
      ],
      "mean_latency_ms": 0.4212308000205667,
      "std_latency_ms": 0.003417504031860966,
      "min_latency_ms": 0.41705800003910554,
      "max_latency_ms": 0.42464830405242765,
      "num_trials": 10,
      "extra_params": {
        "size": 10000000,
        "operation": "dot",
        "blas_level": 1,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "fp16"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 19.00993773035532,
          "efficiency": 0.11451769717081517,
          "mean_latency_ms": 1.0520812999857299,
          "std_latency_ms": 0.004138043185653815,
          "min_latency_ms": 1.047876000029646,
          "max_latency_ms": 1.0562193431713838,
          "speedup_vs_fp32": null,
          "test_size": 10000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.5,
          "achieved_bandwidth_gbps": 38.01987546071064
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 33.59224556567176,
          "efficiency": 0.006308402923130847,
          "mean_latency_ms": 0.595375500006412,
          "std_latency_ms": 0.022018936903313906,
          "min_latency_ms": 0.5671060002896411,
          "max_latency_ms": 0.617394436909726,
          "speedup_vs_fp32": 1.0,
          "test_size": 10000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.25,
          "achieved_bandwidth_gbps": 134.36898226268704
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 33.49377970244979,
          "efficiency": 0.0031449558406056143,
          "mean_latency_ms": 0.5971258000045054,
          "std_latency_ms": 0.024669414298893688,
          "min_latency_ms": 0.5671389999406529,
          "max_latency_ms": 0.6217952143033991,
          "speedup_vs_fp32": 0.997068791872533,
          "test_size": 10000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.25,
          "achieved_bandwidth_gbps": 133.97511880979917
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 47.47990887424067,
          "efficiency": 0.002229103703015994,
          "mean_latency_ms": 0.4212308000205667,
          "std_latency_ms": 0.003417504031860966,
          "min_latency_ms": 0.41705800003910554,
          "max_latency_ms": 0.42464830405242765,
          "speedup_vs_fp32": 1.4134187243129959,
          "test_size": 10000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.5,
          "achieved_bandwidth_gbps": 94.95981774848134
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 46.94184446002688,
          "efficiency": 0.00220384246291206,
          "mean_latency_ms": 0.4260590999365377,
          "std_latency_ms": 0.006884297340986993,
          "min_latency_ms": 0.417792999996891,
          "max_latency_ms": 0.4329433972775247,
          "speedup_vs_fp32": 1.3974012058305862,
          "test_size": 10000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.5,
          "achieved_bandwidth_gbps": 93.88368892005376
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Long'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Int'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Short'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Char'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas1_axpy_best_precision=int64_blas_level=1_device=cuda_framework=pytorch_operation=axpy_size=1000": {
      "operation_type": "blas1_axpy",
      "measured_gflops": 0.011688087032923448,
      "efficiency": 0.0,
      "achieved_bandwidth_gbps": 0.03506426109877035,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.3333333333333333,
      "batch_size": 1,
      "input_shape": [
        1000
      ],
      "output_shape": [
        1000
      ],
      "mean_latency_ms": 0.1711144000182685,
      "std_latency_ms": 0.005348360257200555,
      "min_latency_ms": 0.1613770000403747,
      "max_latency_ms": 0.17646276027546906,
      "num_trials": 10,
      "extra_params": {
        "size": 1000,
        "operation": "axpy",
        "blas_level": 1,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "int64"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.011619631370379874,
          "efficiency": 6.99977793396378e-05,
          "mean_latency_ms": 0.17212249995282036,
          "std_latency_ms": 0.0061240917671079795,
          "min_latency_ms": 0.16364900011467398,
          "max_latency_ms": 0.17824659171992835,
          "speedup_vs_fp32": null,
          "test_size": 1000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 0.03485889411113963
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.01128886686265397,
          "efficiency": 2.1199749976814967e-06,
          "mean_latency_ms": 0.17716570000629872,
          "std_latency_ms": 0.009762567888950576,
          "min_latency_ms": 0.16700900005162111,
          "max_latency_ms": 0.1869282678952493,
          "speedup_vs_fp32": 1.0,
          "test_size": 1000,
          "num_trials": 10,
          "arithmetic_intensity": 0.16666666666666666,
          "achieved_bandwidth_gbps": 0.06773320117592382
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.010599828383951026,
          "efficiency": 9.952890501362466e-07,
          "mean_latency_ms": 0.18868230008592946,
          "std_latency_ms": 0.0445536041576038,
          "min_latency_ms": 0.1650250001148379,
          "max_latency_ms": 0.23323590424353324,
          "speedup_vs_fp32": 0.9389630077946588,
          "test_size": 1000,
          "num_trials": 10,
          "arithmetic_intensity": 0.16666666666666666,
          "achieved_bandwidth_gbps": 0.06359897030370615
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.011634129886978557,
          "efficiency": 5.462032810788055e-07,
          "mean_latency_ms": 0.17190799994750705,
          "std_latency_ms": 0.002721038539437387,
          "min_latency_ms": 0.16870400031621102,
          "max_latency_ms": 0.17462903848694444,
          "speedup_vs_fp32": 1.0305843826953784,
          "test_size": 1000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 0.03490238966093567
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.011534723840315635,
          "efficiency": 5.415363305312505e-07,
          "mean_latency_ms": 0.17338950005978404,
          "std_latency_ms": 0.0043948994449199965,
          "min_latency_ms": 0.16771199989307206,
          "max_latency_ms": 0.17778439950470404,
          "speedup_vs_fp32": 1.0217787117744308,
          "test_size": 1000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 0.03460417152094691
        },
        "int64": {
          "precision": "int64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.011688087032923448,
          "efficiency": 0.0,
          "mean_latency_ms": 0.1711144000182685,
          "std_latency_ms": 0.005348360257200555,
          "min_latency_ms": 0.1613770000403747,
          "max_latency_ms": 0.17646276027546906,
          "speedup_vs_fp32": 1.0353640604612129,
          "test_size": 1000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 0.03506426109877035
        },
        "int32": {
          "precision": "int32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.011510499876617541,
          "efficiency": 2.1615962209610406e-06,
          "mean_latency_ms": 0.17375440002069809,
          "std_latency_ms": 0.0064267215415057906,
          "min_latency_ms": 0.16598499996689497,
          "max_latency_ms": 0.18018112156220387,
          "speedup_vs_fp32": 1.0196328840316808,
          "test_size": 1000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 0.03453149962985262
        },
        "int16": {
          "precision": "int16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.01152961699655995,
          "efficiency": 5.412965726084484e-07,
          "mean_latency_ms": 0.1734662999297143,
          "std_latency_ms": 0.007955042098293992,
          "min_latency_ms": 0.16691299970261753,
          "max_latency_ms": 0.18142134202800828,
          "speedup_vs_fp32": 1.0213263330000315,
          "test_size": 1000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 0.03458885098967985
        },
        "int8": {
          "precision": "int8",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.011391746798596206,
          "efficiency": 2.674118966806621e-07,
          "mean_latency_ms": 0.17556569991938886,
          "std_latency_ms": 0.0050947969497500195,
          "min_latency_ms": 0.16691199971319293,
          "max_latency_ms": 0.18066049686913888,
          "speedup_vs_fp32": 1.0091133979339046,
          "test_size": 1000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 0.03417524039578861
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas1_axpy_best_precision=int64_blas_level=1_device=cuda_framework=pytorch_operation=axpy_size=10000": {
      "operation_type": "blas1_axpy",
      "measured_gflops": 0.11574670218681164,
      "efficiency": 0.0,
      "achieved_bandwidth_gbps": 0.3472401065604349,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.3333333333333333,
      "batch_size": 1,
      "input_shape": [
        10000
      ],
      "output_shape": [
        10000
      ],
      "mean_latency_ms": 0.17279110006711562,
      "std_latency_ms": 0.004194993587161165,
      "min_latency_ms": 0.16588900007263874,
      "max_latency_ms": 0.17698609365427678,
      "num_trials": 10,
      "extra_params": {
        "size": 10000,
        "operation": "axpy",
        "blas_level": 1,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "int64"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.11331855658073374,
          "efficiency": 0.0006826419071128539,
          "mean_latency_ms": 0.17649360001996683,
          "std_latency_ms": 0.006110304729349415,
          "min_latency_ms": 0.16716799973437446,
          "max_latency_ms": 0.18260390474931626,
          "speedup_vs_fp32": null,
          "test_size": 10000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 0.3399556697422012
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.10620717200430559,
          "efficiency": 1.994500882709964e-05,
          "mean_latency_ms": 0.18831119991773448,
          "std_latency_ms": 0.045011246409228926,
          "min_latency_ms": 0.16800000003058813,
          "max_latency_ms": 0.23332244632696342,
          "speedup_vs_fp32": 1.0,
          "test_size": 10000,
          "num_trials": 10,
          "arithmetic_intensity": 0.16666666666666666,
          "achieved_bandwidth_gbps": 0.6372430320258334
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.10989349125033267,
          "efficiency": 1.0318637676087574e-05,
          "mean_latency_ms": 0.1819943999635143,
          "std_latency_ms": 0.008397356242533604,
          "min_latency_ms": 0.1743369998621347,
          "max_latency_ms": 0.1903917562060479,
          "speedup_vs_fp32": 1.0347087600249598,
          "test_size": 10000,
          "num_trials": 10,
          "arithmetic_intensity": 0.16666666666666666,
          "achieved_bandwidth_gbps": 0.6593609475019959
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.11186232876285378,
          "efficiency": 5.251752524077642e-06,
          "mean_latency_ms": 0.17879120005090954,
          "std_latency_ms": 0.007259739305138728,
          "min_latency_ms": 0.1723210002637643,
          "max_latency_ms": 0.18605093935604827,
          "speedup_vs_fp32": 1.0532464677462547,
          "test_size": 10000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 0.33558698628856126
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.11353476293691778,
          "efficiency": 5.330270560418675e-06,
          "mean_latency_ms": 0.17615749998185493,
          "std_latency_ms": 0.003584536913773721,
          "min_latency_ms": 0.1716169999781414,
          "max_latency_ms": 0.17974203689562865,
          "speedup_vs_fp32": 1.0689933720513256,
          "test_size": 10000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 0.34060428881075333
        },
        "int64": {
          "precision": "int64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.11574670218681164,
          "efficiency": 0.0,
          "mean_latency_ms": 0.17279110006711562,
          "std_latency_ms": 0.004194993587161165,
          "min_latency_ms": 0.16588900007263874,
          "max_latency_ms": 0.17698609365427678,
          "speedup_vs_fp32": 1.089820018765958,
          "test_size": 10000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 0.3472401065604349
        },
        "int32": {
          "precision": "int32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.11312575512936085,
          "efficiency": 2.1244273263729738e-05,
          "mean_latency_ms": 0.17679439997664304,
          "std_latency_ms": 0.0037236399765839556,
          "min_latency_ms": 0.1722239999253361,
          "max_latency_ms": 0.180518039953227,
          "speedup_vs_fp32": 1.0651423345004873,
          "test_size": 10000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 0.33937726538808255
        },
        "int16": {
          "precision": "int16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.11386350840015487,
          "efficiency": 5.3457046197255805e-06,
          "mean_latency_ms": 0.17564889999448496,
          "std_latency_ms": 0.008119273553695086,
          "min_latency_ms": 0.1654719999351073,
          "max_latency_ms": 0.18376817354818004,
          "speedup_vs_fp32": 1.07208869468381,
          "test_size": 10000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 0.3415905252004646
        },
        "int8": {
          "precision": "int8",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.108602572683386,
          "efficiency": 2.5493561662766665e-06,
          "mean_latency_ms": 0.18415770000501652,
          "std_latency_ms": 0.04709391784228968,
          "min_latency_ms": 0.1626890002626169,
          "max_latency_ms": 0.2312516178473062,
          "speedup_vs_fp32": 1.0225540388080694,
          "test_size": 10000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 0.32580771805015796
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas1_axpy_best_precision=int8_blas_level=1_device=cuda_framework=pytorch_operation=axpy_size=100000": {
      "operation_type": "blas1_axpy",
      "measured_gflops": 1.1646066716206873,
      "efficiency": 2.733818477982834e-05,
      "achieved_bandwidth_gbps": 3.493820014862062,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.3333333333333333,
      "batch_size": 1,
      "input_shape": [
        100000
      ],
      "output_shape": [
        100000
      ],
      "mean_latency_ms": 0.17173179999190324,
      "std_latency_ms": 0.009286085431299015,
      "min_latency_ms": 0.15894499983915011,
      "max_latency_ms": 0.18101788542320227,
      "num_trials": 10,
      "extra_params": {
        "size": 100000,
        "operation": "axpy",
        "blas_level": 1,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "int8"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.1392175060371381,
          "efficiency": 0.006862756060464687,
          "mean_latency_ms": 0.17555909994371177,
          "std_latency_ms": 0.007129156222988388,
          "min_latency_ms": 0.1693449999038421,
          "max_latency_ms": 0.18268825616670015,
          "speedup_vs_fp32": null,
          "test_size": 100000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 3.4176525181114146
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.1434491228465489,
          "efficiency": 0.00021473222964254438,
          "mean_latency_ms": 0.17490939999333932,
          "std_latency_ms": 0.004501812022770382,
          "min_latency_ms": 0.16880100019989186,
          "max_latency_ms": 0.1794112120161097,
          "speedup_vs_fp32": 1.0,
          "test_size": 100000,
          "num_trials": 10,
          "arithmetic_intensity": 0.16666666666666666,
          "achieved_bandwidth_gbps": 6.860694737079293
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.1620947922265357,
          "efficiency": 0.00010911688189920522,
          "mean_latency_ms": 0.17210299997714174,
          "std_latency_ms": 0.004932020353917914,
          "min_latency_ms": 0.16348799999832409,
          "max_latency_ms": 0.17703502033105964,
          "speedup_vs_fp32": 1.0163065142186383,
          "test_size": 100000,
          "num_trials": 10,
          "arithmetic_intensity": 0.16666666666666666,
          "achieved_bandwidth_gbps": 6.972568753359214
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.1533440056623883,
          "efficiency": 5.414760589964264e-05,
          "mean_latency_ms": 0.173408799992103,
          "std_latency_ms": 0.006549919139641196,
          "min_latency_ms": 0.16521699990335037,
          "max_latency_ms": 0.17995871913174422,
          "speedup_vs_fp32": 1.0086535400816143,
          "test_size": 100000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 3.460032016987165
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.135759619199518,
          "efficiency": 5.332204784974263e-05,
          "mean_latency_ms": 0.17609359993002727,
          "std_latency_ms": 0.008833928253261408,
          "min_latency_ms": 0.16739200009396882,
          "max_latency_ms": 0.18492752818328867,
          "speedup_vs_fp32": 0.9932751676542563,
          "test_size": 100000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 3.4072788575985538
        },
        "int64": {
          "precision": "int64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.1384911921566865,
          "efficiency": 0.0,
          "mean_latency_ms": 0.17567109994161,
          "std_latency_ms": 0.01021159348336572,
          "min_latency_ms": 0.16412900004070252,
          "max_latency_ms": 0.18588269342497574,
          "speedup_vs_fp32": 0.995664056589138,
          "test_size": 100000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 3.4154735764700592
        },
        "int32": {
          "precision": "int32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.147520667093476,
          "efficiency": 0.00021549683889079363,
          "mean_latency_ms": 0.17428879996259639,
          "std_latency_ms": 0.002305627582815036,
          "min_latency_ms": 0.17094399981942843,
          "max_latency_ms": 0.1765944275454114,
          "speedup_vs_fp32": 1.0035607568063818,
          "test_size": 100000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 3.442562001280428
        },
        "int16": {
          "precision": "int16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.1626555055428138,
          "efficiency": 5.458476551844196e-05,
          "mean_latency_ms": 0.1720199999454053,
          "std_latency_ms": 0.0024236415959907978,
          "min_latency_ms": 0.16870499985088827,
          "max_latency_ms": 0.17444364154139608,
          "speedup_vs_fp32": 1.0167968843672308,
          "test_size": 100000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 3.4879665166284415
        },
        "int8": {
          "precision": "int8",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.1646066716206873,
          "efficiency": 2.733818477982834e-05,
          "mean_latency_ms": 0.17173179999190324,
          "std_latency_ms": 0.009286085431299015,
          "min_latency_ms": 0.15894499983915011,
          "max_latency_ms": 0.18101788542320227,
          "speedup_vs_fp32": 1.0185032708070718,
          "test_size": 100000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 3.493820014862062
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas1_axpy_best_precision=int8_blas_level=1_device=cuda_framework=pytorch_operation=axpy_size=1000000": {
      "operation_type": "blas1_axpy",
      "measured_gflops": 11.249245591643826,
      "efficiency": 0.0002640667979259114,
      "achieved_bandwidth_gbps": 33.747736774931475,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.3333333333333333,
      "batch_size": 1,
      "input_shape": [
        1000000
      ],
      "output_shape": [
        1000000
      ],
      "mean_latency_ms": 0.17778970009203476,
      "std_latency_ms": 0.005175993291604775,
      "min_latency_ms": 0.16956800027401187,
      "max_latency_ms": 0.18296569338363955,
      "num_trials": 10,
      "extra_params": {
        "size": 1000000,
        "operation": "axpy",
        "blas_level": 1,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "int8"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 4.0803635765822275,
          "efficiency": 0.024580503473386913,
          "mean_latency_ms": 0.4901524000160862,
          "std_latency_ms": 0.0018569070725435774,
          "min_latency_ms": 0.4868500000156928,
          "max_latency_ms": 0.4920093070886298,
          "speedup_vs_fp32": null,
          "test_size": 1000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 12.24109072974668
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 7.506574821846922,
          "efficiency": 0.0014096854125534126,
          "mean_latency_ms": 0.26643309997780307,
          "std_latency_ms": 0.0021286232132210546,
          "min_latency_ms": 0.26323300016883877,
          "max_latency_ms": 0.2685617231910241,
          "speedup_vs_fp32": 1.0,
          "test_size": 1000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.16666666666666666,
          "achieved_bandwidth_gbps": 45.03944893108153
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 7.5630722365742065,
          "efficiency": 0.0007101476278473433,
          "mean_latency_ms": 0.2644428001531196,
          "std_latency_ms": 0.0014825419973281948,
          "min_latency_ms": 0.2611220002108894,
          "max_latency_ms": 0.2659253421504478,
          "speedup_vs_fp32": 1.007526390673261,
          "test_size": 1000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.16666666666666666,
          "achieved_bandwidth_gbps": 45.37843341944524
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 11.236504258573854,
          "efficiency": 0.0005275354112006504,
          "mean_latency_ms": 0.17799129996092233,
          "std_latency_ms": 0.006843160681192973,
          "min_latency_ms": 0.17113700005211285,
          "max_latency_ms": 0.1848344606421153,
          "speedup_vs_fp32": 1.4968883312628087,
          "test_size": 1000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 33.709512775721564
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 10.955446387282722,
          "efficiency": 0.0005143402059757146,
          "mean_latency_ms": 0.1825576000555884,
          "std_latency_ms": 0.009004431989921973,
          "min_latency_ms": 0.17187299999932293,
          "max_latency_ms": 0.1915620320455104,
          "speedup_vs_fp32": 1.4594467713021793,
          "test_size": 1000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 32.86633916184817
        },
        "int64": {
          "precision": "int64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 4.125556357054023,
          "efficiency": 0.0,
          "mean_latency_ms": 0.48478310000064084,
          "std_latency_ms": 0.011936823659566932,
          "min_latency_ms": 0.47440200023629586,
          "max_latency_ms": 0.4967199236602078,
          "speedup_vs_fp32": 0.5495923846715177,
          "test_size": 1000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 12.37666907116207
        },
        "int32": {
          "precision": "int32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 7.4760458166210215,
          "efficiency": 0.0014039522660321167,
          "mean_latency_ms": 0.2675210999314004,
          "std_latency_ms": 0.0036930243061704593,
          "min_latency_ms": 0.26246500010529417,
          "max_latency_ms": 0.27121412423757085,
          "speedup_vs_fp32": 0.9959330312492124,
          "test_size": 1000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 22.428137449863065
        },
        "int16": {
          "precision": "int16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 10.76264651405276,
          "efficiency": 0.0005052885687348714,
          "mean_latency_ms": 0.18582789998617955,
          "std_latency_ms": 0.0060987849110959984,
          "min_latency_ms": 0.17622499990466167,
          "max_latency_ms": 0.19192668489727555,
          "speedup_vs_fp32": 1.4337626373521861,
          "test_size": 1000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 32.28793954215828
        },
        "int8": {
          "precision": "int8",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 11.249245591643826,
          "efficiency": 0.0002640667979259114,
          "mean_latency_ms": 0.17778970009203476,
          "std_latency_ms": 0.005175993291604775,
          "min_latency_ms": 0.16956800027401187,
          "max_latency_ms": 0.18296569338363955,
          "speedup_vs_fp32": 1.49858568769665,
          "test_size": 1000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 33.747736774931475
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas1_axpy_best_precision=int8_blas_level=1_device=cuda_framework=pytorch_operation=axpy_size=10000000": {
      "operation_type": "blas1_axpy",
      "measured_gflops": 28.43805005661,
      "efficiency": 0.0006675598604838028,
      "achieved_bandwidth_gbps": 85.31415016983,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.3333333333333333,
      "batch_size": 1,
      "input_shape": [
        10000000
      ],
      "output_shape": [
        10000000
      ],
      "mean_latency_ms": 0.7032830999378348,
      "std_latency_ms": 0.1191572747776515,
      "min_latency_ms": 0.5597790000138048,
      "max_latency_ms": 0.8224403747154863,
      "num_trials": 10,
      "extra_params": {
        "size": 10000000,
        "operation": "axpy",
        "blas_level": 1,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "int8"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 4.807878381806469,
          "efficiency": 0.02896312278196668,
          "mean_latency_ms": 4.159839000021748,
          "std_latency_ms": 0.06299760907226516,
          "min_latency_ms": 4.122801999983494,
          "max_latency_ms": 4.222836609094013,
          "speedup_vs_fp32": null,
          "test_size": 10000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 14.423635145419407
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 10.153031568466657,
          "efficiency": 0.0019066725950172127,
          "mean_latency_ms": 1.9698549999702664,
          "std_latency_ms": 0.029325459727373427,
          "min_latency_ms": 1.9300559997645905,
          "max_latency_ms": 1.9991804596976397,
          "speedup_vs_fp32": 1.0,
          "test_size": 10000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.16666666666666666,
          "achieved_bandwidth_gbps": 60.91818941079994
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 10.139459649125053,
          "efficiency": 0.0009520619388849815,
          "mean_latency_ms": 1.97249169996212,
          "std_latency_ms": 0.03900521885389267,
          "min_latency_ms": 1.9305040000290319,
          "max_latency_ms": 2.011496918816013,
          "speedup_vs_fp32": 0.9986632643412874,
          "test_size": 10000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.16666666666666666,
          "achieved_bandwidth_gbps": 60.83675789475032
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 18.058543994019146,
          "efficiency": 0.000847818966855359,
          "mean_latency_ms": 1.1075089999849297,
          "std_latency_ms": 0.10052659923867945,
          "min_latency_ms": 0.9186600000248291,
          "max_latency_ms": 1.2080355992236091,
          "speedup_vs_fp32": 1.778635658940082,
          "test_size": 10000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 54.17563198205743
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 18.178830239506265,
          "efficiency": 0.0008534662084275241,
          "mean_latency_ms": 1.100180800222006,
          "std_latency_ms": 0.09834356927485023,
          "min_latency_ms": 0.9194600002047082,
          "max_latency_ms": 1.1985243694968561,
          "speedup_vs_fp32": 1.7904829820451045,
          "test_size": 10000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 54.53649071851879
        },
        "int64": {
          "precision": "int64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 4.597396875755548,
          "efficiency": 0.0,
          "mean_latency_ms": 4.350287899978866,
          "std_latency_ms": 0.135470278556747,
          "min_latency_ms": 4.250547000083316,
          "max_latency_ms": 4.4857581785356135,
          "speedup_vs_fp32": 0.45281026112773737,
          "test_size": 10000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 13.792190627266642
        },
        "int32": {
          "precision": "int32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 10.153015590398637,
          "efficiency": 0.0019066695944410586,
          "mean_latency_ms": 1.9698580999829574,
          "std_latency_ms": 0.03365557948098782,
          "min_latency_ms": 1.9330000000081782,
          "max_latency_ms": 2.003513679463945,
          "speedup_vs_fp32": 0.999998426276141,
          "test_size": 10000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 30.459046771195908
        },
        "int16": {
          "precision": "int16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 18.378702537925065,
          "efficiency": 0.0008628498844096275,
          "mean_latency_ms": 1.0882161000608903,
          "std_latency_ms": 0.15459520215347797,
          "min_latency_ms": 0.9267570003430592,
          "max_latency_ms": 1.2428113022143683,
          "speedup_vs_fp32": 1.8101689543648956,
          "test_size": 10000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 55.136107613775195
        },
        "int8": {
          "precision": "int8",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 28.43805005661,
          "efficiency": 0.0006675598604838028,
          "mean_latency_ms": 0.7032830999378348,
          "std_latency_ms": 0.1191572747776515,
          "min_latency_ms": 0.5597790000138048,
          "max_latency_ms": 0.8224403747154863,
          "speedup_vs_fp32": 2.800941754670896,
          "test_size": 10000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 85.31415016983
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas2_gemv_best_precision=tf32_blas_level=2_device=cuda_framework=pytorch_operation=gemv_size=32": {
      "operation_type": "blas2_gemv",
      "measured_gflops": 0.0050297264691996245,
      "efficiency": 4.722747858403403e-07,
      "achieved_bandwidth_gbps": 0.010688168747049203,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.47058823529411764,
      "batch_size": 1,
      "input_shape": [
        32,
        32
      ],
      "output_shape": [
        32
      ],
      "mean_latency_ms": 0.4071792000104324,
      "std_latency_ms": 0.02764871781823473,
      "min_latency_ms": 0.37190600005487795,
      "max_latency_ms": 0.43482791782866714,
      "num_trials": 10,
      "extra_params": {
        "size": 32,
        "operation": "gemv",
        "blas_level": 2,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "tf32"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.004922940832579239,
          "efficiency": 2.9656270075778546e-05,
          "mean_latency_ms": 0.41601149996495224,
          "std_latency_ms": 0.1674435067080875,
          "min_latency_ms": 0.27747300009650644,
          "max_latency_ms": 0.5834550066730397,
          "speedup_vs_fp32": null,
          "test_size": 32,
          "num_trials": 10,
          "arithmetic_intensity": 0.9411764705882353,
          "achieved_bandwidth_gbps": 0.0052306246346154415
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.003881263654205393,
          "efficiency": 7.288758036066465e-07,
          "mean_latency_ms": 0.5276632000459358,
          "std_latency_ms": 0.039163741213678716,
          "min_latency_ms": 0.4915219997201348,
          "max_latency_ms": 0.5668269412596145,
          "speedup_vs_fp32": 1.0,
          "test_size": 32,
          "num_trials": 10,
          "arithmetic_intensity": 0.47058823529411764,
          "achieved_bandwidth_gbps": 0.008247685265186459
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.0050297264691996245,
          "efficiency": 4.722747858403403e-07,
          "mean_latency_ms": 0.4071792000104324,
          "std_latency_ms": 0.02764871781823473,
          "min_latency_ms": 0.37190600005487795,
          "max_latency_ms": 0.43482791782866714,
          "speedup_vs_fp32": 1.2958992012175878,
          "test_size": 32,
          "num_trials": 10,
          "arithmetic_intensity": 0.47058823529411764,
          "achieved_bandwidth_gbps": 0.010688168747049203
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.004114520278065867,
          "efficiency": 1.9316996610637875e-07,
          "mean_latency_ms": 0.49774940007409896,
          "std_latency_ms": 0.03286103254478471,
          "min_latency_ms": 0.4593940002450836,
          "max_latency_ms": 0.5306104326188836,
          "speedup_vs_fp32": 1.0600981135635397,
          "test_size": 32,
          "num_trials": 10,
          "arithmetic_intensity": 0.9411764705882353,
          "achieved_bandwidth_gbps": 0.004371677795444983
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.004863127191133717,
          "efficiency": 2.2831583056965804e-07,
          "mean_latency_ms": 0.42112819992325967,
          "std_latency_ms": 0.07938737981834995,
          "min_latency_ms": 0.37772999985463684,
          "max_latency_ms": 0.5005155797416097,
          "speedup_vs_fp32": 1.2529752226093849,
          "test_size": 32,
          "num_trials": 10,
          "arithmetic_intensity": 0.9411764705882353,
          "achieved_bandwidth_gbps": 0.005167072640579574
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Long'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Int'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Short'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Char'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas2_gemv_best_precision=tf32_blas_level=2_device=cuda_framework=pytorch_operation=gemv_size=64": {
      "operation_type": "blas2_gemv",
      "measured_gflops": 0.02854200259978395,
      "efficiency": 2.680000244111169e-06,
      "achieved_bandwidth_gbps": 0.05886788036205439,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.48484848484848486,
      "batch_size": 1,
      "input_shape": [
        64,
        64
      ],
      "output_shape": [
        64
      ],
      "mean_latency_ms": 0.287015599951701,
      "std_latency_ms": 0.010499994535425518,
      "min_latency_ms": 0.27497700011736015,
      "max_latency_ms": 0.2975155944871265,
      "num_trials": 10,
      "extra_params": {
        "size": 64,
        "operation": "gemv",
        "blas_level": 2,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "tf32"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.028357029967596783,
          "efficiency": 0.00017082548173251075,
          "mean_latency_ms": 0.28888779993394564,
          "std_latency_ms": 0.012791753690348276,
          "min_latency_ms": 0.27836999970531906,
          "max_latency_ms": 0.30167955362429394,
          "speedup_vs_fp32": null,
          "test_size": 64,
          "num_trials": 10,
          "arithmetic_intensity": 0.9696969696969697,
          "achieved_bandwidth_gbps": 0.029243187154084183
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.028440849834586345,
          "efficiency": 5.341004663772084e-06,
          "mean_latency_ms": 0.2880364000247937,
          "std_latency_ms": 0.007368510216295334,
          "min_latency_ms": 0.27990499984298367,
          "max_latency_ms": 0.295404910241089,
          "speedup_vs_fp32": 1.0,
          "test_size": 64,
          "num_trials": 10,
          "arithmetic_intensity": 0.48484848484848486,
          "achieved_bandwidth_gbps": 0.05865925278383433
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.02854200259978395,
          "efficiency": 2.680000244111169e-06,
          "mean_latency_ms": 0.287015599951701,
          "std_latency_ms": 0.010499994535425518,
          "min_latency_ms": 0.27497700011736015,
          "max_latency_ms": 0.2975155944871265,
          "speedup_vs_fp32": 1.003556601359872,
          "test_size": 64,
          "num_trials": 10,
          "arithmetic_intensity": 0.48484848484848486,
          "achieved_bandwidth_gbps": 0.05886788036205439
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.028116294102434616,
          "efficiency": 1.3200138076260383e-06,
          "mean_latency_ms": 0.2913612999691395,
          "std_latency_ms": 0.01293529530735191,
          "min_latency_ms": 0.2811539998219814,
          "max_latency_ms": 0.30429659527649144,
          "speedup_vs_fp32": 0.9885883954228033,
          "test_size": 64,
          "num_trials": 10,
          "arithmetic_intensity": 0.9696969696969697,
          "achieved_bandwidth_gbps": 0.0289949282931357
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.028047897802298636,
          "efficiency": 1.3168027137229407e-06,
          "mean_latency_ms": 0.29207180009507283,
          "std_latency_ms": 0.011418001764862028,
          "min_latency_ms": 0.2793610001390334,
          "max_latency_ms": 0.30348980185993485,
          "speedup_vs_fp32": 0.9861835340865993,
          "test_size": 64,
          "num_trials": 10,
          "arithmetic_intensity": 0.9696969696969697,
          "achieved_bandwidth_gbps": 0.02892439460862047
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Long'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Int'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Short'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Char'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas2_gemv_best_precision=fp64_blas_level=2_device=cuda_framework=pytorch_operation=gemv_size=128": {
      "operation_type": "blas2_gemv",
      "measured_gflops": 0.11551515785130238,
      "efficiency": 0.0006958744448873638,
      "achieved_bandwidth_gbps": 0.11732008219272899,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.9846153846153847,
      "batch_size": 1,
      "input_shape": [
        128,
        128
      ],
      "output_shape": [
        128
      ],
      "mean_latency_ms": 0.2836683999703382,
      "std_latency_ms": 0.006816276658082246,
      "min_latency_ms": 0.27558500005397946,
      "max_latency_ms": 0.2904846766284205,
      "num_trials": 10,
      "extra_params": {
        "size": 128,
        "operation": "gemv",
        "blas_level": 2,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "fp64"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.11551515785130238,
          "efficiency": 0.0006958744448873638,
          "mean_latency_ms": 0.2836683999703382,
          "std_latency_ms": 0.006816276658082246,
          "min_latency_ms": 0.27558500005397946,
          "max_latency_ms": 0.2904846766284205,
          "speedup_vs_fp32": null,
          "test_size": 128,
          "num_trials": 10,
          "arithmetic_intensity": 0.9846153846153847,
          "achieved_bandwidth_gbps": 0.11732008219272899
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.11392037601099532,
          "efficiency": 2.1393497842440436e-05,
          "mean_latency_ms": 0.2876395000384946,
          "std_latency_ms": 0.005180485096364712,
          "min_latency_ms": 0.2812170000652259,
          "max_latency_ms": 0.2928199851348593,
          "speedup_vs_fp32": 1.0,
          "test_size": 128,
          "num_trials": 10,
          "arithmetic_intensity": 0.49230769230769234,
          "achieved_bandwidth_gbps": 0.2314007637723342
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.1147257390058692,
          "efficiency": 1.0772369859706028e-05,
          "mean_latency_ms": 0.28562030006469286,
          "std_latency_ms": 0.0036673568170827796,
          "min_latency_ms": 0.28060900012860657,
          "max_latency_ms": 0.28928765688177566,
          "speedup_vs_fp32": 1.0070695254270943,
          "test_size": 128,
          "num_trials": 10,
          "arithmetic_intensity": 0.49230769230769234,
          "achieved_bandwidth_gbps": 0.23303665735567183
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.11131107791517529,
          "efficiency": 5.2258722025903896e-06,
          "mean_latency_ms": 0.2943821999906504,
          "std_latency_ms": 0.012478942303551744,
          "min_latency_ms": 0.28598500011867145,
          "max_latency_ms": 0.30686114229420214,
          "speedup_vs_fp32": 0.9770954223714273,
          "test_size": 128,
          "num_trials": 10,
          "arithmetic_intensity": 0.9846153846153847,
          "achieved_bandwidth_gbps": 0.1130503135075999
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.1097895208936153,
          "efficiency": 5.154437600639215e-06,
          "mean_latency_ms": 0.2984620001370786,
          "std_latency_ms": 0.023987174308360906,
          "min_latency_ms": 0.2800330003083218,
          "max_latency_ms": 0.32244917444543947,
          "speedup_vs_fp32": 0.9637391021516526,
          "test_size": 128,
          "num_trials": 10,
          "arithmetic_intensity": 0.9846153846153847,
          "achieved_bandwidth_gbps": 0.11150498215757802
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Long'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Int'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Short'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Char'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas2_gemv_best_precision=fp64_blas_level=2_device=cuda_framework=pytorch_operation=gemv_size=256": {
      "operation_type": "blas2_gemv",
      "measured_gflops": 0.4611395500510856,
      "efficiency": 0.0027779490966932867,
      "achieved_bandwidth_gbps": 0.4647422027858597,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.9922480620155039,
      "batch_size": 1,
      "input_shape": [
        256,
        256
      ],
      "output_shape": [
        256
      ],
      "mean_latency_ms": 0.28423499998098123,
      "std_latency_ms": 0.007329589061778372,
      "min_latency_ms": 0.2741130001595593,
      "max_latency_ms": 0.2915645890427596,
      "num_trials": 10,
      "extra_params": {
        "size": 256,
        "operation": "gemv",
        "blas_level": 2,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "fp64"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.4611395500510856,
          "efficiency": 0.0027779490966932867,
          "mean_latency_ms": 0.28423499998098123,
          "std_latency_ms": 0.007329589061778372,
          "min_latency_ms": 0.2741130001595593,
          "max_latency_ms": 0.2915645890427596,
          "speedup_vs_fp32": null,
          "test_size": 256,
          "num_trials": 10,
          "arithmetic_intensity": 0.9922480620155039,
          "achieved_bandwidth_gbps": 0.4647422027858597
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.44482378886534024,
          "efficiency": 8.353498382447703e-05,
          "mean_latency_ms": 0.2946604999124247,
          "std_latency_ms": 0.010799457088035197,
          "min_latency_ms": 0.282688999959646,
          "max_latency_ms": 0.3054599570004599,
          "speedup_vs_fp32": 1.0,
          "test_size": 256,
          "num_trials": 10,
          "arithmetic_intensity": 0.49612403100775193,
          "achieved_bandwidth_gbps": 0.8965979494317015
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.45377829483938936,
          "efficiency": 4.2608290595247826e-05,
          "mean_latency_ms": 0.2888459000587318,
          "std_latency_ms": 0.013832422526092713,
          "min_latency_ms": 0.2763850002338586,
          "max_latency_ms": 0.3026783225848245,
          "speedup_vs_fp32": 1.020130456594712,
          "test_size": 256,
          "num_trials": 10,
          "arithmetic_intensity": 0.49612403100775193,
          "achieved_bandwidth_gbps": 0.9146468755356443
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.4546644978761131,
          "efficiency": 2.134575107399592e-05,
          "mean_latency_ms": 0.28828290005549206,
          "std_latency_ms": 0.0077102686905072175,
          "min_latency_ms": 0.2781130001494603,
          "max_latency_ms": 0.2959931687459993,
          "speedup_vs_fp32": 1.0221227129868091,
          "test_size": 256,
          "num_trials": 10,
          "arithmetic_intensity": 0.9922480620155039,
          "achieved_bandwidth_gbps": 0.45821656426577023
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.4594895036122428,
          "efficiency": 2.157227716489403e-05,
          "mean_latency_ms": 0.2852557000096567,
          "std_latency_ms": 0.005075408637840181,
          "min_latency_ms": 0.28051400022377493,
          "max_latency_ms": 0.2903311086474969,
          "speedup_vs_fp32": 1.0329697177039743,
          "test_size": 256,
          "num_trials": 10,
          "arithmetic_intensity": 0.9922480620155039,
          "achieved_bandwidth_gbps": 0.4630792653592134
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Long'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Int'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Short'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Char'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas2_gemv_best_precision=fp64_blas_level=2_device=cuda_framework=pytorch_operation=gemv_size=512": {
      "operation_type": "blas2_gemv",
      "measured_gflops": 1.8366393950639843,
      "efficiency": 0.011064092741349302,
      "achieved_bandwidth_gbps": 1.843813767700953,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.9961089494163424,
      "batch_size": 1,
      "input_shape": [
        512,
        512
      ],
      "output_shape": [
        512
      ],
      "mean_latency_ms": 0.2854604999811272,
      "std_latency_ms": 0.006090200063546572,
      "min_latency_ms": 0.2776659998744435,
      "max_latency_ms": 0.29155070004467376,
      "num_trials": 10,
      "extra_params": {
        "size": 512,
        "operation": "gemv",
        "blas_level": 2,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "fp64"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.8366393950639843,
          "efficiency": 0.011064092741349302,
          "mean_latency_ms": 0.2854604999811272,
          "std_latency_ms": 0.006090200063546572,
          "min_latency_ms": 0.2776659998744435,
          "max_latency_ms": 0.29155070004467376,
          "speedup_vs_fp32": null,
          "test_size": 512,
          "num_trials": 10,
          "arithmetic_intensity": 0.9961089494163424,
          "achieved_bandwidth_gbps": 1.843813767700953
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.7717526220250228,
          "efficiency": 0.000332723497093901,
          "mean_latency_ms": 0.29591490001621423,
          "std_latency_ms": 0.014121709829374721,
          "min_latency_ms": 0.28089700026612263,
          "max_latency_ms": 0.31003660984558895,
          "speedup_vs_fp32": 1.0,
          "test_size": 512,
          "num_trials": 10,
          "arithmetic_intensity": 0.4980544747081712,
          "achieved_bandwidth_gbps": 3.557347061409616
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.828215630263824,
          "efficiency": 0.00017166343946139193,
          "mean_latency_ms": 0.2867758000320464,
          "std_latency_ms": 0.009117684985511678,
          "min_latency_ms": 0.27324900020175846,
          "max_latency_ms": 0.2958934850175581,
          "speedup_vs_fp32": 1.031868449092101,
          "test_size": 512,
          "num_trials": 10,
          "arithmetic_intensity": 0.4980544747081712,
          "achieved_bandwidth_gbps": 3.670714195139084
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.798238076813444,
          "efficiency": 8.442432285509127e-05,
          "mean_latency_ms": 0.2915565000876086,
          "std_latency_ms": 0.015596041320883571,
          "min_latency_ms": 0.2726419997998164,
          "max_latency_ms": 0.30715254140849213,
          "speedup_vs_fp32": 1.0149487318145745,
          "test_size": 512,
          "num_trials": 10,
          "arithmetic_intensity": 0.9961089494163424,
          "achieved_bandwidth_gbps": 1.8052624443009966
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.8237189066235966,
          "efficiency": 8.56206059447698e-05,
          "mean_latency_ms": 0.2874828999665624,
          "std_latency_ms": 0.009537721800325638,
          "min_latency_ms": 0.27715299984265584,
          "max_latency_ms": 0.29702062176688804,
          "speedup_vs_fp32": 1.0293304403518697,
          "test_size": 512,
          "num_trials": 10,
          "arithmetic_intensity": 0.9961089494163424,
          "achieved_bandwidth_gbps": 1.8308428086025952
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Long'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Int'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Short'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Char'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas2_gemv_best_precision=fp64_blas_level=2_device=cuda_framework=pytorch_operation=gemv_size=1024": {
      "operation_type": "blas2_gemv",
      "measured_gflops": 7.365131629734486,
      "efficiency": 0.044368262829725814,
      "achieved_bandwidth_gbps": 7.37951665244881,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.9980506822612085,
      "batch_size": 1,
      "input_shape": [
        1024,
        1024
      ],
      "output_shape": [
        1024
      ],
      "mean_latency_ms": 0.28474060009102686,
      "std_latency_ms": 0.004812018299100203,
      "min_latency_ms": 0.2778260000013688,
      "max_latency_ms": 0.2895526183901271,
      "num_trials": 10,
      "extra_params": {
        "size": 1024,
        "operation": "gemv",
        "blas_level": 2,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "fp64"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 7.365131629734486,
          "efficiency": 0.044368262829725814,
          "mean_latency_ms": 0.28474060009102686,
          "std_latency_ms": 0.004812018299100203,
          "min_latency_ms": 0.2778260000013688,
          "max_latency_ms": 0.2895526183901271,
          "speedup_vs_fp32": null,
          "test_size": 1024,
          "num_trials": 10,
          "arithmetic_intensity": 0.9980506822612085,
          "achieved_bandwidth_gbps": 7.37951665244881
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 7.120895004904483,
          "efficiency": 0.0013372572779163348,
          "mean_latency_ms": 0.2945067998552986,
          "std_latency_ms": 0.01506788507092571,
          "min_latency_ms": 0.2803539996421023,
          "max_latency_ms": 0.3095746849262243,
          "speedup_vs_fp32": 1.0,
          "test_size": 1024,
          "num_trials": 10,
          "arithmetic_intensity": 0.49902534113060426,
          "achieved_bandwidth_gbps": 14.269606005921874
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 7.326929984094244,
          "efficiency": 0.0006879746463938258,
          "mean_latency_ms": 0.28622519998862117,
          "std_latency_ms": 0.007167342273317291,
          "min_latency_ms": 0.2776649998850189,
          "max_latency_ms": 0.29339254226193845,
          "speedup_vs_fp32": 1.0289338600060605,
          "test_size": 1024,
          "num_trials": 10,
          "arithmetic_intensity": 0.49902534113060426,
          "achieved_bandwidth_gbps": 14.682480788438856
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 7.187356382166703,
          "efficiency": 0.00033743457193270905,
          "mean_latency_ms": 0.2917834998697799,
          "std_latency_ms": 0.01192608924287283,
          "min_latency_ms": 0.2797130000544712,
          "max_latency_ms": 0.3037095891126527,
          "speedup_vs_fp32": 1.0093332898766862,
          "test_size": 1024,
          "num_trials": 10,
          "arithmetic_intensity": 0.9980506822612085,
          "achieved_bandwidth_gbps": 7.2013941876006236
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 7.134536311028086,
          "efficiency": 0.0003349547563862951,
          "mean_latency_ms": 0.2939436998531164,
          "std_latency_ms": 0.01341981164552048,
          "min_latency_ms": 0.2749129998846911,
          "max_latency_ms": 0.3073635114986369,
          "speedup_vs_fp32": 1.0019156729756873,
          "test_size": 1024,
          "num_trials": 10,
          "arithmetic_intensity": 0.9980506822612085,
          "achieved_bandwidth_gbps": 7.1484709522605625
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Long'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Int'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Short'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Char'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas2_gemv_best_precision=fp16_blas_level=2_device=cuda_framework=pytorch_operation=gemv_size=2048": {
      "operation_type": "blas2_gemv",
      "measured_gflops": 19.582476215813244,
      "efficiency": 0.0009193650805546125,
      "achieved_bandwidth_gbps": 19.601599727742748,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.9990243902439024,
      "batch_size": 1,
      "input_shape": [
        2048,
        2048
      ],
      "output_shape": [
        2048
      ],
      "mean_latency_ms": 0.4283731999748852,
      "std_latency_ms": 0.004779100084381179,
      "min_latency_ms": 0.42109000014534104,
      "max_latency_ms": 0.4331523000592664,
      "num_trials": 10,
      "extra_params": {
        "size": 2048,
        "operation": "gemv",
        "blas_level": 2,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "fp16"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 17.175512704998123,
          "efficiency": 0.10346694400601279,
          "mean_latency_ms": 0.4884050999862666,
          "std_latency_ms": 0.10763300857538978,
          "min_latency_ms": 0.4191060002085578,
          "max_latency_ms": 0.5960381085616564,
          "speedup_vs_fp32": null,
          "test_size": 2048,
          "num_trials": 10,
          "arithmetic_intensity": 0.9990243902439024,
          "achieved_bandwidth_gbps": 17.192285666624095
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 17.909359759453725,
          "efficiency": 0.003363260048723704,
          "mean_latency_ms": 0.46839239998917037,
          "std_latency_ms": 0.004926055598189564,
          "min_latency_ms": 0.459745999705774,
          "max_latency_ms": 0.4733184555873599,
          "speedup_vs_fp32": 1.0,
          "test_size": 2048,
          "num_trials": 10,
          "arithmetic_intensity": 0.4995121951219512,
          "achieved_bandwidth_gbps": 35.85369873718763
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 18.494109233299945,
          "efficiency": 0.0017365360782441264,
          "mean_latency_ms": 0.45358269999269396,
          "std_latency_ms": 0.047003843185073814,
          "min_latency_ms": 0.32044900035543833,
          "max_latency_ms": 0.5005865431777677,
          "speedup_vs_fp32": 1.0326504957016986,
          "test_size": 2048,
          "num_trials": 10,
          "arithmetic_intensity": 0.4995121951219512,
          "achieved_bandwidth_gbps": 37.02433977369618
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 19.582476215813244,
          "efficiency": 0.0009193650805546125,
          "mean_latency_ms": 0.4283731999748852,
          "std_latency_ms": 0.004779100084381179,
          "min_latency_ms": 0.42109000014534104,
          "max_latency_ms": 0.4331523000592664,
          "speedup_vs_fp32": 1.093421343857719,
          "test_size": 2048,
          "num_trials": 10,
          "arithmetic_intensity": 0.9990243902439024,
          "achieved_bandwidth_gbps": 19.601599727742748
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 19.533593573708753,
          "efficiency": 0.0009170701208313968,
          "mean_latency_ms": 0.4294452000522142,
          "std_latency_ms": 0.007492822054984286,
          "min_latency_ms": 0.41283400014435756,
          "max_latency_ms": 0.4369380221071985,
          "speedup_vs_fp32": 1.0906918972018333,
          "test_size": 2048,
          "num_trials": 10,
          "arithmetic_intensity": 0.9990243902439024,
          "achieved_bandwidth_gbps": 19.552669348683075
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Long'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Int'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Short'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Char'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas3_gemm_best_precision=fp32_blas_level=3_device=cuda_framework=pytorch_operation=gemm_size=32": {
      "operation_type": "blas3_gemm",
      "measured_gflops": 0.19730921728149953,
      "efficiency": 3.70533741373708e-05,
      "achieved_bandwidth_gbps": 0.03699547824028116,
      "memory_bound": false,
      "compute_bound": true,
      "arithmetic_intensity": 5.333333333333333,
      "batch_size": 1,
      "input_shape": [
        32,
        32
      ],
      "output_shape": [
        32,
        32
      ],
      "mean_latency_ms": 0.33214869990843,
      "std_latency_ms": 0.11353163773067157,
      "min_latency_ms": 0.2857619997485017,
      "max_latency_ms": 0.44568033763910153,
      "num_trials": 10,
      "extra_params": {
        "size": 32,
        "operation": "gemm",
        "blas_level": 3,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "fp32"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.18562073734022747,
          "efficiency": 0.0011181972128929366,
          "mean_latency_ms": 0.35306399995533866,
          "std_latency_ms": 0.15840160648508989,
          "min_latency_ms": 0.29219299995020265,
          "max_latency_ms": 0.5114656064404286,
          "speedup_vs_fp32": null,
          "test_size": 32,
          "num_trials": 10,
          "arithmetic_intensity": 2.6666666666666665,
          "achieved_bandwidth_gbps": 0.06960777650258529
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.19730921728149953,
          "efficiency": 3.70533741373708e-05,
          "mean_latency_ms": 0.33214869990843,
          "std_latency_ms": 0.11353163773067157,
          "min_latency_ms": 0.2857619997485017,
          "max_latency_ms": 0.44568033763910153,
          "speedup_vs_fp32": 1.0,
          "test_size": 32,
          "num_trials": 10,
          "arithmetic_intensity": 5.333333333333333,
          "achieved_bandwidth_gbps": 0.03699547824028116
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.16794387660924975,
          "efficiency": 1.5769378085375563e-05,
          "mean_latency_ms": 0.3902255999037152,
          "std_latency_ms": 0.1942426356817971,
          "min_latency_ms": 0.28694499997072853,
          "max_latency_ms": 0.5844682355855123,
          "speedup_vs_fp32": 0.8511709636435562,
          "test_size": 32,
          "num_trials": 10,
          "arithmetic_intensity": 5.333333333333333,
          "achieved_bandwidth_gbps": 0.031489476864234325
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.16666183486078187,
          "efficiency": 7.824499289238585e-06,
          "mean_latency_ms": 0.39322739999079204,
          "std_latency_ms": 0.19475468241294389,
          "min_latency_ms": 0.2941450002253987,
          "max_latency_ms": 0.587982082403736,
          "speedup_vs_fp32": 0.844673336385531,
          "test_size": 32,
          "num_trials": 10,
          "arithmetic_intensity": 10.666666666666666,
          "achieved_bandwidth_gbps": 0.0156245470181983
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.14853866114603523,
          "efficiency": 6.973646063194142e-06,
          "mean_latency_ms": 0.4412050000610179,
          "std_latency_ms": 0.22011091537009903,
          "min_latency_ms": 0.28425800019249436,
          "max_latency_ms": 0.661315915431117,
          "speedup_vs_fp32": 0.7528217038848026,
          "test_size": 32,
          "num_trials": 10,
          "arithmetic_intensity": 10.666666666666666,
          "achieved_bandwidth_gbps": 0.013925499482440803
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'Lo",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'In",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'Sh",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'Ch",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas3_gemm_best_precision=fp64_blas_level=3_device=cuda_framework=pytorch_operation=gemm_size=64": {
      "operation_type": "blas3_gemm",
      "measured_gflops": 1.258714027296182,
      "efficiency": 0.0075826146222661575,
      "achieved_bandwidth_gbps": 0.23600888011803414,
      "memory_bound": false,
      "compute_bound": true,
      "arithmetic_intensity": 5.333333333333333,
      "batch_size": 1,
      "input_shape": [
        64,
        64
      ],
      "output_shape": [
        64,
        64
      ],
      "mean_latency_ms": 0.416526699973474,
      "std_latency_ms": 0.24923768475087005,
      "min_latency_ms": 0.28041699988534674,
      "max_latency_ms": 0.6657643847243441,
      "num_trials": 10,
      "extra_params": {
        "size": 64,
        "operation": "gemm",
        "blas_level": 3,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "fp64"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.258714027296182,
          "efficiency": 0.0075826146222661575,
          "mean_latency_ms": 0.416526699973474,
          "std_latency_ms": 0.24923768475087005,
          "min_latency_ms": 0.28041699988534674,
          "max_latency_ms": 0.6657643847243441,
          "speedup_vs_fp32": null,
          "test_size": 64,
          "num_trials": 10,
          "arithmetic_intensity": 5.333333333333333,
          "achieved_bandwidth_gbps": 0.23600888011803414
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.1722065107315505,
          "efficiency": 0.00022013267807165267,
          "mean_latency_ms": 0.44726589999299904,
          "std_latency_ms": 0.22664697262585773,
          "min_latency_ms": 0.30204999984562164,
          "max_latency_ms": 0.6739128726188568,
          "speedup_vs_fp32": 1.0,
          "test_size": 64,
          "num_trials": 10,
          "arithmetic_intensity": 10.666666666666666,
          "achieved_bandwidth_gbps": 0.10989436038108284
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.194686383654618,
          "efficiency": 0.00011217712522578572,
          "mean_latency_ms": 0.43884990000151447,
          "std_latency_ms": 0.2365556071310274,
          "min_latency_ms": 0.2852490001714614,
          "max_latency_ms": 0.6754055071325419,
          "speedup_vs_fp32": 1.0191773998158722,
          "test_size": 64,
          "num_trials": 10,
          "arithmetic_intensity": 10.666666666666666,
          "achieved_bandwidth_gbps": 0.11200184846762043
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.9873463109060161,
          "efficiency": 4.635428689699606e-05,
          "mean_latency_ms": 0.5310072000156651,
          "std_latency_ms": 0.309109004385457,
          "min_latency_ms": 0.2959060002467595,
          "max_latency_ms": 0.8401162044011221,
          "speedup_vs_fp32": 0.8422972418826041,
          "test_size": 64,
          "num_trials": 10,
          "arithmetic_intensity": 21.333333333333332,
          "achieved_bandwidth_gbps": 0.046281858323719505
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.1818544337153012,
          "efficiency": 5.548612364860569e-05,
          "mean_latency_ms": 0.4436146999523771,
          "std_latency_ms": 0.22029880005468316,
          "min_latency_ms": 0.30147300003591226,
          "max_latency_ms": 0.6639135000070603,
          "speedup_vs_fp32": 1.0082305659416015,
          "test_size": 64,
          "num_trials": 10,
          "arithmetic_intensity": 21.333333333333332,
          "achieved_bandwidth_gbps": 0.055399426580404754
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'Lo",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'In",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'Sh",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'Ch",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas3_gemm_best_precision=fp64_blas_level=3_device=cuda_framework=pytorch_operation=gemm_size=128": {
      "operation_type": "blas3_gemm",
      "measured_gflops": 7.615568404699565,
      "efficiency": 0.04587691810059979,
      "achieved_bandwidth_gbps": 0.7139595379405842,
      "memory_bound": false,
      "compute_bound": true,
      "arithmetic_intensity": 10.666666666666666,
      "batch_size": 1,
      "input_shape": [
        128,
        128
      ],
      "output_shape": [
        128,
        128
      ],
      "mean_latency_ms": 0.5507539000518591,
      "std_latency_ms": 0.24717959889458327,
      "min_latency_ms": 0.427521000347042,
      "max_latency_ms": 0.7979334989464424,
      "num_trials": 10,
      "extra_params": {
        "size": 128,
        "operation": "gemm",
        "blas_level": 3,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "fp64"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 7.615568404699565,
          "efficiency": 0.04587691810059979,
          "mean_latency_ms": 0.5507539000518591,
          "std_latency_ms": 0.24717959889458327,
          "min_latency_ms": 0.427521000347042,
          "max_latency_ms": 0.7979334989464424,
          "speedup_vs_fp32": null,
          "test_size": 128,
          "num_trials": 10,
          "arithmetic_intensity": 10.666666666666666,
          "achieved_bandwidth_gbps": 0.7139595379405842
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 5.29042905381725,
          "efficiency": 0.0009935078035337558,
          "mean_latency_ms": 0.7928097999865713,
          "std_latency_ms": 0.013233242603341881,
          "min_latency_ms": 0.7739229999970121,
          "max_latency_ms": 0.8060430425899132,
          "speedup_vs_fp32": 1.0,
          "test_size": 128,
          "num_trials": 10,
          "arithmetic_intensity": 21.333333333333332,
          "achieved_bandwidth_gbps": 0.2479888618976836
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 5.36443679660928,
          "efficiency": 0.0005037029855971155,
          "mean_latency_ms": 0.7818722000138223,
          "std_latency_ms": 0.015076740521201368,
          "min_latency_ms": 0.7559719997516368,
          "max_latency_ms": 0.7969489405350236,
          "speedup_vs_fp32": 1.0139889869118708,
          "test_size": 128,
          "num_trials": 10,
          "arithmetic_intensity": 21.333333333333332,
          "achieved_bandwidth_gbps": 0.25145797484106003
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 5.43170648598615,
          "efficiency": 0.0002550096941777535,
          "mean_latency_ms": 0.7721890000539133,
          "std_latency_ms": 0.005643414807922356,
          "min_latency_ms": 0.7651870000700001,
          "max_latency_ms": 0.7778324148618357,
          "speedup_vs_fp32": 1.0267043430186373,
          "test_size": 128,
          "num_trials": 10,
          "arithmetic_intensity": 42.666666666666664,
          "achieved_bandwidth_gbps": 0.1273056207653004
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 5.487190289598785,
          "efficiency": 0.0002576145675867974,
          "mean_latency_ms": 0.7643809998626239,
          "std_latency_ms": 0.014768731032621373,
          "min_latency_ms": 0.7362269998338888,
          "max_latency_ms": 0.7791497308952452,
          "speedup_vs_fp32": 1.037191924091594,
          "test_size": 128,
          "num_trials": 10,
          "arithmetic_intensity": 42.666666666666664,
          "achieved_bandwidth_gbps": 0.12860602241247154
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'Lo",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'In",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'Sh",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'Ch",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas3_gemm_best_precision=fp32_blas_level=3_device=cuda_framework=pytorch_operation=gemm_size=256": {
      "operation_type": "blas3_gemm",
      "measured_gflops": 45.7999512203382,
      "efficiency": 0.008600929806636282,
      "achieved_bandwidth_gbps": 1.0734363567266767,
      "memory_bound": false,
      "compute_bound": true,
      "arithmetic_intensity": 42.666666666666664,
      "batch_size": 1,
      "input_shape": [
        256,
        256
      ],
      "output_shape": [
        256,
        256
      ],
      "mean_latency_ms": 0.7326302999445033,
      "std_latency_ms": 0.21600444036392952,
      "min_latency_ms": 0.31920099991111783,
      "max_latency_ms": 0.9486347403084329,
      "num_trials": 10,
      "extra_params": {
        "size": 256,
        "operation": "gemm",
        "blas_level": 3,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "fp32"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 11.841828049435785,
          "efficiency": 0.07133631355081799,
          "mean_latency_ms": 2.833551699950476,
          "std_latency_ms": 0.010374867343547613,
          "min_latency_ms": 2.817901000071288,
          "max_latency_ms": 2.843926567294024,
          "speedup_vs_fp32": null,
          "test_size": 256,
          "num_trials": 10,
          "arithmetic_intensity": 21.333333333333332,
          "achieved_bandwidth_gbps": 0.5550856898173024
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 45.7999512203382,
          "efficiency": 0.008600929806636282,
          "mean_latency_ms": 0.7326302999445033,
          "std_latency_ms": 0.21600444036392952,
          "min_latency_ms": 0.31920099991111783,
          "max_latency_ms": 0.9486347403084329,
          "speedup_vs_fp32": 1.0,
          "test_size": 256,
          "num_trials": 10,
          "arithmetic_intensity": 42.666666666666664,
          "achieved_bandwidth_gbps": 1.0734363567266767
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 42.26543013547435,
          "efficiency": 0.003968584989246417,
          "mean_latency_ms": 0.7938977999856434,
          "std_latency_ms": 0.01061693570562204,
          "min_latency_ms": 0.7694749997426698,
          "max_latency_ms": 0.8045147356912654,
          "speedup_vs_fp32": 0.9228269683550603,
          "test_size": 256,
          "num_trials": 10,
          "arithmetic_intensity": 42.666666666666664,
          "achieved_bandwidth_gbps": 0.9905960188001801
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 42.626416049865085,
          "efficiency": 0.002001240190134511,
          "mean_latency_ms": 0.7871745999182167,
          "std_latency_ms": 0.010583061135886628,
          "min_latency_ms": 0.7739559996480239,
          "max_latency_ms": 0.7977576610541033,
          "speedup_vs_fp32": 0.9307087652734474,
          "test_size": 256,
          "num_trials": 10,
          "arithmetic_intensity": 85.33333333333333,
          "achieved_bandwidth_gbps": 0.4995283130843564
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 42.723507695173815,
          "efficiency": 0.0020057984833414936,
          "mean_latency_ms": 0.7853857000554854,
          "std_latency_ms": 0.015330186420326054,
          "min_latency_ms": 0.7547230002273864,
          "max_latency_ms": 0.8007158864758114,
          "speedup_vs_fp32": 0.9328286724506762,
          "test_size": 256,
          "num_trials": 10,
          "arithmetic_intensity": 85.33333333333333,
          "achieved_bandwidth_gbps": 0.5006661058028181
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'Lo",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'In",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'Sh",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'Ch",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas3_gemm_best_precision=bf16_blas_level=3_device=cuda_framework=pytorch_operation=gemm_size=512": {
      "operation_type": "blas3_gemm",
      "measured_gflops": 753.2913726473108,
      "efficiency": 0.03536579214306623,
      "achieved_bandwidth_gbps": 4.413816636605337,
      "memory_bound": false,
      "compute_bound": true,
      "arithmetic_intensity": 170.66666666666666,
      "batch_size": 1,
      "input_shape": [
        512,
        512
      ],
      "output_shape": [
        512,
        512
      ],
      "mean_latency_ms": 0.3563501000371616,
      "std_latency_ms": 0.17034604291683955,
      "min_latency_ms": 0.2909130002990423,
      "max_latency_ms": 0.5266961429540011,
      "num_trials": 10,
      "extra_params": {
        "size": 512,
        "operation": "gemm",
        "blas_level": 3,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "bf16"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 29.990652509152046,
          "efficiency": 0.180666581380434,
          "mean_latency_ms": 8.95063740003934,
          "std_latency_ms": 0.9947682646448834,
          "min_latency_ms": 8.449541000118188,
          "max_latency_ms": 9.945405664684223,
          "speedup_vs_fp32": null,
          "test_size": 512,
          "num_trials": 10,
          "arithmetic_intensity": 42.666666666666664,
          "achieved_bandwidth_gbps": 0.702905918183251
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 276.11975843683854,
          "efficiency": 0.05185347576278658,
          "mean_latency_ms": 0.972170399973038,
          "std_latency_ms": 0.2988856833359072,
          "min_latency_ms": 0.7357149997915258,
          "max_latency_ms": 1.2710560833089453,
          "speedup_vs_fp32": 1.0,
          "test_size": 512,
          "num_trials": 10,
          "arithmetic_intensity": 85.33333333333333,
          "achieved_bandwidth_gbps": 3.235778419181702
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 264.36682415842654,
          "efficiency": 0.024823175977317046,
          "mean_latency_ms": 1.0153900999284815,
          "std_latency_ms": 0.012525834230151179,
          "min_latency_ms": 0.9923570000864856,
          "max_latency_ms": 1.0279159341586326,
          "speedup_vs_fp32": 0.9574353738937503,
          "test_size": 512,
          "num_trials": 10,
          "arithmetic_intensity": 85.33333333333333,
          "achieved_bandwidth_gbps": 3.098048720606561
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 518.072046121808,
          "efficiency": 0.024322631273324315,
          "mean_latency_ms": 0.5181430999982695,
          "std_latency_ms": 0.2785402684975562,
          "min_latency_ms": 0.29628899983435986,
          "max_latency_ms": 0.7966833684958257,
          "speedup_vs_fp32": 1.8762585084627879,
          "test_size": 512,
          "num_trials": 10,
          "arithmetic_intensity": 170.66666666666666,
          "achieved_bandwidth_gbps": 3.0355783952449684
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 753.2913726473108,
          "efficiency": 0.03536579214306623,
          "mean_latency_ms": 0.3563501000371616,
          "std_latency_ms": 0.17034604291683955,
          "min_latency_ms": 0.2909130002990423,
          "max_latency_ms": 0.5266961429540011,
          "speedup_vs_fp32": 2.7281328106029896,
          "test_size": 512,
          "num_trials": 10,
          "arithmetic_intensity": 170.66666666666666,
          "achieved_bandwidth_gbps": 4.413816636605337
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'Lo",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'In",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'Sh",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'Ch",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas3_gemm_best_precision=bf16_blas_level=3_device=cuda_framework=pytorch_operation=gemm_size=1024": {
      "operation_type": "blas3_gemm",
      "measured_gflops": 2049.216542383044,
      "efficiency": 0.09620734940765464,
      "achieved_bandwidth_gbps": 6.003564089012824,
      "memory_bound": false,
      "compute_bound": true,
      "arithmetic_intensity": 341.3333333333333,
      "batch_size": 1,
      "input_shape": [
        1024,
        1024
      ],
      "output_shape": [
        1024,
        1024
      ],
      "mean_latency_ms": 1.0479535000740725,
      "std_latency_ms": 0.035730867358177744,
      "min_latency_ms": 0.9677160001047014,
      "max_latency_ms": 1.0836843674322503,
      "num_trials": 10,
      "extra_params": {
        "size": 1024,
        "operation": "gemm",
        "blas_level": 3,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "bf16"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 43.734857540540595,
          "efficiency": 0.26346299723217226,
          "mean_latency_ms": 49.10233549999248,
          "std_latency_ms": 0.16605034790223744,
          "min_latency_ms": 48.89656500017736,
          "max_latency_ms": 49.26838584789471,
          "speedup_vs_fp32": null,
          "test_size": 1024,
          "num_trials": 10,
          "arithmetic_intensity": 85.33333333333333,
          "achieved_bandwidth_gbps": 0.5125178618032101
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 460.8826638739299,
          "efficiency": 0.08655073499979904,
          "mean_latency_ms": 4.659501900005125,
          "std_latency_ms": 0.1861919725144679,
          "min_latency_ms": 4.531603000032192,
          "max_latency_ms": 4.845693872519593,
          "speedup_vs_fp32": 1.0,
          "test_size": 1024,
          "num_trials": 10,
          "arithmetic_intensity": 170.66666666666666,
          "achieved_bandwidth_gbps": 2.700484358636308
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 820.533573636359,
          "efficiency": 0.07704540597524498,
          "mean_latency_ms": 2.6171795000209386,
          "std_latency_ms": 0.13961064844032495,
          "min_latency_ms": 2.4078820001705026,
          "max_latency_ms": 2.7567901484612634,
          "speedup_vs_fp32": 1.7803524366471033,
          "test_size": 1024,
          "num_trials": 10,
          "arithmetic_intensity": 170.66666666666666,
          "achieved_bandwidth_gbps": 4.807813908025541
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1342.7085730596039,
          "efficiency": 0.06303796117650723,
          "mean_latency_ms": 1.5993668999271904,
          "std_latency_ms": 0.020943317261520388,
          "min_latency_ms": 1.5660869999010174,
          "max_latency_ms": 1.6203102171887107,
          "speedup_vs_fp32": 2.913341460434904,
          "test_size": 1024,
          "num_trials": 10,
          "arithmetic_intensity": 341.3333333333333,
          "achieved_bandwidth_gbps": 3.933716522635558
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 2049.216542383044,
          "efficiency": 0.09620734940765464,
          "mean_latency_ms": 1.0479535000740725,
          "std_latency_ms": 0.035730867358177744,
          "min_latency_ms": 0.9677160001047014,
          "max_latency_ms": 1.0836843674322503,
          "speedup_vs_fp32": 4.4462868816944425,
          "test_size": 1024,
          "num_trials": 10,
          "arithmetic_intensity": 341.3333333333333,
          "achieved_bandwidth_gbps": 6.003564089012824
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'Lo",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'In",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'Sh",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'Ch",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas3_gemm_best_precision=bf16_blas_level=3_device=cuda_framework=pytorch_operation=gemm_size=2048": {
      "operation_type": "blas3_gemm",
      "measured_gflops": 4019.166278210346,
      "efficiency": 0.18869325249813831,
      "achieved_bandwidth_gbps": 5.887450602847186,
      "memory_bound": false,
      "compute_bound": true,
      "arithmetic_intensity": 682.6666666666666,
      "batch_size": 1,
      "input_shape": [
        2048,
        2048
      ],
      "output_shape": [
        2048,
        2048
      ],
      "mean_latency_ms": 4.274485799987815,
      "std_latency_ms": 0.9896516655471503,
      "min_latency_ms": 2.177417999973841,
      "max_latency_ms": 5.264137465534965,
      "num_trials": 10,
      "extra_params": {
        "size": 2048,
        "operation": "gemm",
        "blas_level": 3,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "bf16"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 44.42488773017199,
          "efficiency": 0.2676198056034457,
          "mean_latency_ms": 386.71722229996703,
          "std_latency_ms": 0.2944460684937247,
          "min_latency_ms": 386.35153799987165,
          "max_latency_ms": 387.01166836846073,
          "speedup_vs_fp32": null,
          "test_size": 2048,
          "num_trials": 10,
          "arithmetic_intensity": 170.66666666666666,
          "achieved_bandwidth_gbps": 0.2603020765439765
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1397.3990857084486,
          "efficiency": 0.2624223635133237,
          "mean_latency_ms": 12.294175199986057,
          "std_latency_ms": 3.628437078702842,
          "min_latency_ms": 9.576393999850552,
          "max_latency_ms": 15.922612278688899,
          "speedup_vs_fp32": 1.0,
          "test_size": 2048,
          "num_trials": 10,
          "arithmetic_intensity": 341.3333333333333,
          "achieved_bandwidth_gbps": 4.093942633911471
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 2525.526487909452,
          "efficiency": 0.23713863736238985,
          "mean_latency_ms": 6.802490200061584,
          "std_latency_ms": 3.084975356956057,
          "min_latency_ms": 3.861456000322505,
          "max_latency_ms": 9.887465557017642,
          "speedup_vs_fp32": 1.80730509540091,
          "test_size": 2048,
          "num_trials": 10,
          "arithmetic_intensity": 341.3333333333333,
          "achieved_bandwidth_gbps": 7.399003382547223
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 3550.044212442294,
          "efficiency": 0.1666687423681828,
          "mean_latency_ms": 4.839339499994821,
          "std_latency_ms": 0.29793822240865975,
          "min_latency_ms": 4.303410999909829,
          "max_latency_ms": 5.137277722403481,
          "speedup_vs_fp32": 2.5404655325379037,
          "test_size": 2048,
          "num_trials": 10,
          "arithmetic_intensity": 682.6666666666666,
          "achieved_bandwidth_gbps": 5.200260076819766
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 4019.166278210346,
          "efficiency": 0.18869325249813831,
          "mean_latency_ms": 4.274485799987815,
          "std_latency_ms": 0.9896516655471503,
          "min_latency_ms": 2.177417999973841,
          "max_latency_ms": 5.264137465534965,
          "speedup_vs_fp32": 2.876176404661609,
          "test_size": 2048,
          "num_trials": 10,
          "arithmetic_intensity": 682.6666666666666,
          "achieved_bandwidth_gbps": 5.887450602847186
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'Lo",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'In",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'Sh",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'Ch",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    }
  },
  "fusion_profiles": {},
  "precision_matrix": {
    "hardware_name": "Jetson Orin AGX (GPU)",
    "supported_precisions": [
      "fp64",
      "fp32",
      "tf32",
      "fp16",
      "bf16",
      "int64",
      "int32",
      "int16",
      "int8"
    ],
    "unsupported_precisions": [
      "fp8",
      "fp4",
      "int4"
    ],
    "peak_gflops_by_precision": {
      "fp64": 44.42488773017199,
      "fp32": 1397.3990857084486,
      "tf32": 2525.526487909452,
      "fp16": 3550.044212442294,
      "bf16": 4019.166278210346,
      "int64": 4.597396875755548,
      "int32": 10.153015590398637,
      "int16": 18.378702537925065,
      "int8": 28.43805005661
    },
    "speedup_vs_fp32": {
      "fp32": 1.0,
      "tf32": 1.80730509540091,
      "fp16": 2.5404655325379037,
      "bf16": 2.876176404661609,
      "int64": 0.45281026112773737,
      "int32": 0.999998426276141,
      "int16": 1.8101689543648956,
      "int8": 2.800941754670896
    },
    "theoretical_peaks": {
      "fp64": 166.0,
      "fp32": 5325.0,
      "fp16": 21300.0,
      "fp8": 0.0,
      "fp4": 0.0,
      "bf16": 21300.0,
      "tf32": 10650.0,
      "int64": 0.0,
      "int32": 5325.0,
      "int16": 21300.0,
      "int8": 42600.0,
      "int4": 0.0
    }
  }
}