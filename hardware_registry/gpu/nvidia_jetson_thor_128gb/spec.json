{
  "id": "nvidia_jetson_thor_128gb",
  "vendor": "NVIDIA",
  "model": "NVIDIA Jetson Thor 128GB",
  "device_type": "gpu",
  "product_category": "embodied",
  "ops_per_clock": {
    "fp64": 256,
    "fp32": 16384,
    "fp16": 65536,
    "fp8": 131072,
    "fp4": 0,
    "bf16": 65536,
    "tf32": 32768,
    "int64": 0,
    "int32": 16384,
    "int16": 65536,
    "int8": 131072,
    "int4": 0
  },
  "ops_per_clock_notes": {
    "fp32": "64 SMs x 128 CUDA cores/SM x 2 (FMA) = 16,384 FP32 ops/clock",
    "fp16": "64 SMs x 4 Tensor Cores/SM x 256 ops/TC/clock = 65,536 FP16 ops/clock",
    "int8": "64 SMs x 4 Tensor Cores/SM x 512 ops/TC/clock = 131,072 INT8 ops/clock (Blackwell 5th gen TC)"
  },
  "theoretical_peaks": {
    "fp64": 333.0,
    "fp32": 21299.0,
    "fp16": 85197.0,
    "fp8": 170394.0,
    "fp4": 0.0,
    "bf16": 85197.0,
    "tf32": 42598.0,
    "int64": 0.0,
    "int32": 21299.0,
    "int16": 85197.0,
    "int8": 170394.0,
    "int4": 0.0
  },
  "theoretical_peaks_notes": "Legacy field - calculated at boost_clock_mhz (1300 MHz). Use ops_per_clock x clock_mhz for accurate peaks. Actual 1000 TOPS is datapath; 2000 TOPS marketing includes sparsity.",
  "peak_bandwidth_gbps": 450.0,
  "l2_cache_size_mb": 8.0,
  "l2_cache_bandwidth_gbps": 2000.0,
  "l2_cache_bandwidth_notes": "Estimated 8MB L2 for 64 SMs. Blackwell L2 bandwidth estimated ~2 TB/s. PROJECTED specs.",
  "architecture": "Blackwell",
  "compute_units": 64,
  "memory_gb": 128,
  "tdp_watts": 100,
  "base_clock_mhz": 500.0,
  "boost_clock_mhz": 1300.0,
  "platform": "aarch64",
  "power_profiles": {
    "30W": {
      "clock_mhz": 750,
      "power_limit_w": 30
    },
    "60W": {
      "clock_mhz": 1100,
      "power_limit_w": 60
    },
    "100W": {
      "clock_mhz": 1250,
      "power_limit_w": 100
    }
  },
  "notes": "Next-gen automotive AI platform (2025+). Blackwell-based GPU. 128GB LPDDR5X. 1000 TOPS INT8 actual datapath (2000 TOPS marketing includes sparsity). For autonomous vehicles and humanoid robots. PROJECTED specs."
}