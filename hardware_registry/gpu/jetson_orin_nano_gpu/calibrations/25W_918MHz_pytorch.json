{
  "metadata": {
    "hardware_name": "Jetson Orin Nano (GPU)",
    "calibration_date": "2025-11-27T15:15:08.480393",
    "calibration_tool_version": "1.0.0",
    "cpu_model": "aarch64",
    "cpu_count": 6,
    "total_memory_gb": 7.441219329833984,
    "python_version": "3.10.12",
    "pytorch_version": "2.5.0a0+872d972e41.nv24.08",
    "numpy_version": "1.26.4",
    "num_warmup_runs": 3,
    "num_measurement_runs": 10,
    "device_type": "cuda",
    "platform_architecture": "aarch64",
    "framework": "pytorch",
    "gpu_clock": {
      "sm_clock_mhz": 918,
      "query_method": "sysfs_under_load",
      "max_sm_clock_mhz": 918,
      "nvpmodel_mode": 25,
      "power_mode_name": "25W"
    },
    "cpu_clock": {
      "current_freq_mhz": 960.0000000000001,
      "query_method": "sysfs",
      "min_freq_mhz": 729.6,
      "max_freq_mhz": 1344.0,
      "base_freq_mhz": 1728.0,
      "per_core_freq_mhz": [
        1190.4,
        1190.4,
        1190.4,
        729.6,
        729.6,
        729.6
      ],
      "governor": "schedutil",
      "driver": "tegra194"
    },
    "preflight": {
      "timestamp": "2025-11-27T15:15:07.278011",
      "passed": true,
      "forced": false,
      "checks": [
        {
          "name": "CPU Governor",
          "status": "passed",
          "message": "schedutil (Jetson default)",
          "current_value": "schedutil",
          "expected_value": "schedutil or performance"
        },
        {
          "name": "CPU Frequency",
          "status": "passed",
          "message": "1139 MHz idle (DVFS will boost under load)",
          "current_value": "1139 MHz (idle)",
          "expected_value": "Up to 1344 MHz under load"
        },
        {
          "name": "Turbo Boost",
          "status": "skipped",
          "message": "Could not determine (not Intel pstate)"
        },
        {
          "name": "System Load",
          "status": "warning",
          "message": "5.0% (some background activity)",
          "current_value": "5.0%",
          "expected_value": "< 5%"
        },
        {
          "name": "Thermal State",
          "status": "passed",
          "message": "46\u00b0C (cool)",
          "current_value": "46\u00b0C",
          "expected_value": "< 80\u00b0C"
        },
        {
          "name": "GPU Power Mode",
          "status": "passed",
          "message": "25W (power-limited profile)"
        }
      ]
    }
  },
  "theoretical_peak_gflops": 1880.0,
  "theoretical_bandwidth_gbps": 68.0,
  "best_measured_gflops": 6314.757934627888,
  "avg_measured_gflops": 222.34089126563345,
  "worst_measured_gflops": 0.006636164505689259,
  "measured_bandwidth_gbps": 95.11411613583296,
  "bandwidth_efficiency": 1.3987370019975436,
  "best_efficiency": 1.3987370019975436,
  "avg_efficiency": 0.4598912923860767,
  "worst_efficiency": 0.0,
  "operation_profiles": {
    "stream_copy_device=cuda_flops_per_element=0_framework=pytorch_kernel=copy_num_arrays=2_num_memory_ops=2_size_mb=8": {
      "operation_type": "stream_copy",
      "measured_gflops": 0.0,
      "efficiency": 0.59022296584863,
      "achieved_bandwidth_gbps": 40.13516167770684,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.0,
      "batch_size": 1,
      "input_shape": [
        2097152
      ],
      "output_shape": [
        2097152
      ],
      "mean_latency_ms": 0.4180178999831696,
      "std_latency_ms": 0.01103811752993039,
      "min_latency_ms": 0.4076750001331675,
      "max_latency_ms": 0.4413409997141571,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 8,
        "kernel": "copy",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 2,
        "num_memory_ops": 2,
        "flops_per_element": 0
      },
      "precision_results": {}
    },
    "stream_copy_device=cuda_flops_per_element=0_framework=pytorch_kernel=copy_num_arrays=2_num_memory_ops=2_size_mb=16": {
      "operation_type": "stream_copy",
      "measured_gflops": 0.0,
      "efficiency": 0.7361489028549295,
      "achieved_bandwidth_gbps": 50.05812539413521,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.0,
      "batch_size": 1,
      "input_shape": [
        4194304
      ],
      "output_shape": [
        4194304
      ],
      "mean_latency_ms": 0.6703094000386045,
      "std_latency_ms": 0.009471585344344651,
      "min_latency_ms": 0.6576750001840992,
      "max_latency_ms": 0.6901890001245192,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 16,
        "kernel": "copy",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 2,
        "num_memory_ops": 2,
        "flops_per_element": 0
      },
      "precision_results": {}
    },
    "stream_copy_device=cuda_flops_per_element=0_framework=pytorch_kernel=copy_num_arrays=2_num_memory_ops=2_size_mb=32": {
      "operation_type": "stream_copy",
      "measured_gflops": 0.0,
      "efficiency": 0.5353869598283869,
      "achieved_bandwidth_gbps": 36.40631326833031,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.0,
      "batch_size": 1,
      "input_shape": [
        8388608
      ],
      "output_shape": [
        8388608
      ],
      "mean_latency_ms": 1.8433304000154749,
      "std_latency_ms": 0.8280368984045757,
      "min_latency_ms": 1.1899340001946257,
      "max_latency_ms": 3.303831999801332,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 32,
        "kernel": "copy",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 2,
        "num_memory_ops": 2,
        "flops_per_element": 0
      },
      "precision_results": {}
    },
    "stream_copy_device=cuda_flops_per_element=0_framework=pytorch_kernel=copy_num_arrays=2_num_memory_ops=2_size_mb=64": {
      "operation_type": "stream_copy",
      "measured_gflops": 0.0,
      "efficiency": 0.6227291922489353,
      "achieved_bandwidth_gbps": 42.3455850729276,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.0,
      "batch_size": 1,
      "input_shape": [
        16777216
      ],
      "output_shape": [
        16777216
      ],
      "mean_latency_ms": 3.1695801998921525,
      "std_latency_ms": 1.261307494171608,
      "min_latency_ms": 2.3401529997499892,
      "max_latency_ms": 6.252825000046869,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 64,
        "kernel": "copy",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 2,
        "num_memory_ops": 2,
        "flops_per_element": 0
      },
      "precision_results": {}
    },
    "stream_copy_device=cuda_flops_per_element=0_framework=pytorch_kernel=copy_num_arrays=2_num_memory_ops=2_size_mb=128": {
      "operation_type": "stream_copy",
      "measured_gflops": 0.0,
      "efficiency": 0.7723079901445928,
      "achieved_bandwidth_gbps": 52.516943329832316,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.0,
      "batch_size": 1,
      "input_shape": [
        33554432
      ],
      "output_shape": [
        33554432
      ],
      "mean_latency_ms": 5.111406700007137,
      "std_latency_ms": 1.3340159098771354,
      "min_latency_ms": 4.496070000186592,
      "max_latency_ms": 8.712089999789896,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 128,
        "kernel": "copy",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 2,
        "num_memory_ops": 2,
        "flops_per_element": 0
      },
      "precision_results": {}
    },
    "stream_copy_device=cuda_flops_per_element=0_framework=pytorch_kernel=copy_num_arrays=2_num_memory_ops=2_size_mb=256": {
      "operation_type": "stream_copy",
      "measured_gflops": 0.0,
      "efficiency": 0.8388681448095151,
      "achieved_bandwidth_gbps": 57.04303384704703,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.0,
      "batch_size": 1,
      "input_shape": [
        67108864
      ],
      "output_shape": [
        67108864
      ],
      "mean_latency_ms": 9.41168230006042,
      "std_latency_ms": 0.11307193527747737,
      "min_latency_ms": 9.324387000106071,
      "max_latency_ms": 9.5925650002755,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 256,
        "kernel": "copy",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 2,
        "num_memory_ops": 2,
        "flops_per_element": 0
      },
      "precision_results": {}
    },
    "stream_copy_device=cuda_flops_per_element=0_framework=pytorch_kernel=copy_num_arrays=2_num_memory_ops=2_size_mb=512": {
      "operation_type": "stream_copy",
      "measured_gflops": 0.0,
      "efficiency": 0.7856033769380533,
      "achieved_bandwidth_gbps": 53.421029631787626,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.0,
      "batch_size": 1,
      "input_shape": [
        134217728
      ],
      "output_shape": [
        134217728
      ],
      "mean_latency_ms": 20.099609299950316,
      "std_latency_ms": 3.452987152450765,
      "min_latency_ms": 18.64867599988429,
      "max_latency_ms": 29.867584999919927,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 512,
        "kernel": "copy",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 2,
        "num_memory_ops": 2,
        "flops_per_element": 0
      },
      "precision_results": {}
    },
    "stream_scale_device=cuda_flops_per_element=1_framework=pytorch_kernel=scale_num_arrays=2_num_memory_ops=2_size_mb=8": {
      "operation_type": "stream_scale",
      "measured_gflops": 2.786212423069418,
      "efficiency": 0.32778969683169623,
      "achieved_bandwidth_gbps": 22.289699384555345,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.5,
      "batch_size": 1,
      "input_shape": [
        2097152
      ],
      "output_shape": [
        2097152
      ],
      "mean_latency_ms": 0.7526892000896623,
      "std_latency_ms": 0.9873033225932923,
      "min_latency_ms": 0.2532640000936226,
      "max_latency_ms": 3.378589000021748,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 8,
        "kernel": "scale",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 2,
        "num_memory_ops": 2,
        "flops_per_element": 1
      },
      "precision_results": {}
    },
    "stream_scale_device=cuda_flops_per_element=1_framework=pytorch_kernel=scale_num_arrays=2_num_memory_ops=2_size_mb=16": {
      "operation_type": "stream_scale",
      "measured_gflops": 4.898742139481973,
      "efficiency": 0.576322604644938,
      "achieved_bandwidth_gbps": 39.189937115855784,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.5,
      "batch_size": 1,
      "input_shape": [
        4194304
      ],
      "output_shape": [
        4194304
      ],
      "mean_latency_ms": 0.8562002000871871,
      "std_latency_ms": 0.8301745144602335,
      "min_latency_ms": 0.4735350003102212,
      "max_latency_ms": 2.9208959999778017,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 16,
        "kernel": "scale",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 2,
        "num_memory_ops": 2,
        "flops_per_element": 1
      },
      "precision_results": {}
    },
    "stream_scale_device=cuda_flops_per_element=1_framework=pytorch_kernel=scale_num_arrays=2_num_memory_ops=2_size_mb=32": {
      "operation_type": "stream_scale",
      "measured_gflops": 10.260775814603939,
      "efficiency": 1.2071500958357575,
      "achieved_bandwidth_gbps": 82.08620651683151,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.5,
      "batch_size": 1,
      "input_shape": [
        8388608
      ],
      "output_shape": [
        8388608
      ],
      "mean_latency_ms": 0.8175413001481502,
      "std_latency_ms": 0.005687557141348885,
      "min_latency_ms": 0.8101329999590234,
      "max_latency_ms": 0.8277020001514757,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 32,
        "kernel": "scale",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 2,
        "num_memory_ops": 2,
        "flops_per_element": 1
      },
      "precision_results": {}
    },
    "stream_scale_device=cuda_flops_per_element=1_framework=pytorch_kernel=scale_num_arrays=2_num_memory_ops=2_size_mb=64": {
      "operation_type": "stream_scale",
      "measured_gflops": 8.225742010162234,
      "efficiency": 0.9677343541367334,
      "achieved_bandwidth_gbps": 65.80593608129787,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.5,
      "batch_size": 1,
      "input_shape": [
        16777216
      ],
      "output_shape": [
        16777216
      ],
      "mean_latency_ms": 2.0395990999077185,
      "std_latency_ms": 0.8257201890405353,
      "min_latency_ms": 1.503265999872383,
      "max_latency_ms": 3.3848620000753726,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 64,
        "kernel": "scale",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 2,
        "num_memory_ops": 2,
        "flops_per_element": 1
      },
      "precision_results": {}
    },
    "stream_scale_device=cuda_flops_per_element=1_framework=pytorch_kernel=scale_num_arrays=2_num_memory_ops=2_size_mb=128": {
      "operation_type": "stream_scale",
      "measured_gflops": 9.463174401378366,
      "efficiency": 1.1133146354562784,
      "achieved_bandwidth_gbps": 75.70539521102693,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.5,
      "batch_size": 1,
      "input_shape": [
        33554432
      ],
      "output_shape": [
        33554432
      ],
      "mean_latency_ms": 3.5457903000406077,
      "std_latency_ms": 1.5262353997305362,
      "min_latency_ms": 2.895517000069958,
      "max_latency_ms": 7.720440999946732,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 128,
        "kernel": "scale",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 2,
        "num_memory_ops": 2,
        "flops_per_element": 1
      },
      "precision_results": {}
    },
    "stream_scale_device=cuda_flops_per_element=1_framework=pytorch_kernel=scale_num_arrays=2_num_memory_ops=2_size_mb=256": {
      "operation_type": "stream_scale",
      "measured_gflops": 11.376731191910343,
      "efficiency": 1.338438963754158,
      "achieved_bandwidth_gbps": 91.01384953528274,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.5,
      "batch_size": 1,
      "input_shape": [
        67108864
      ],
      "output_shape": [
        67108864
      ],
      "mean_latency_ms": 5.898782600024788,
      "std_latency_ms": 0.5134077590435233,
      "min_latency_ms": 5.729110999709519,
      "max_latency_ms": 7.359777000147005,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 256,
        "kernel": "scale",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 2,
        "num_memory_ops": 2,
        "flops_per_element": 1
      },
      "precision_results": {}
    },
    "stream_scale_device=cuda_flops_per_element=1_framework=pytorch_kernel=scale_num_arrays=2_num_memory_ops=2_size_mb=512": {
      "operation_type": "stream_scale",
      "measured_gflops": 11.28239236028038,
      "efficiency": 1.3273402776800447,
      "achieved_bandwidth_gbps": 90.25913888224304,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.5,
      "batch_size": 1,
      "input_shape": [
        134217728
      ],
      "output_shape": [
        134217728
      ],
      "mean_latency_ms": 11.896211699968262,
      "std_latency_ms": 1.2773429469415247,
      "min_latency_ms": 11.319235999962984,
      "max_latency_ms": 15.325546999974904,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 512,
        "kernel": "scale",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 2,
        "num_memory_ops": 2,
        "flops_per_element": 1
      },
      "precision_results": {}
    },
    "stream_add_device=cuda_flops_per_element=1_framework=pytorch_kernel=add_num_arrays=3_num_memory_ops=3_size_mb=8": {
      "operation_type": "stream_add",
      "measured_gflops": 3.9270656146363807,
      "efficiency": 0.6930115790534789,
      "achieved_bandwidth_gbps": 47.124787375636565,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.3333333333333333,
      "batch_size": 1,
      "input_shape": [
        2097152
      ],
      "output_shape": [
        2097152
      ],
      "mean_latency_ms": 0.5340251999314205,
      "std_latency_ms": 0.41415005361967544,
      "min_latency_ms": 0.3347739998389443,
      "max_latency_ms": 1.6923029997997219,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 8,
        "kernel": "add",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 3,
        "num_memory_ops": 3,
        "flops_per_element": 1
      },
      "precision_results": {}
    },
    "stream_add_device=cuda_flops_per_element=1_framework=pytorch_kernel=add_num_arrays=3_num_memory_ops=3_size_mb=16": {
      "operation_type": "stream_add",
      "measured_gflops": 3.414817033421565,
      "efficiency": 0.6026147706038055,
      "achieved_bandwidth_gbps": 40.977804401058776,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.3333333333333333,
      "batch_size": 1,
      "input_shape": [
        4194304
      ],
      "output_shape": [
        4194304
      ],
      "mean_latency_ms": 1.2282661000426742,
      "std_latency_ms": 0.9889205094183231,
      "min_latency_ms": 0.5945670000073733,
      "max_latency_ms": 3.1033069999466534,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 16,
        "kernel": "add",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 3,
        "num_memory_ops": 3,
        "flops_per_element": 1
      },
      "precision_results": {}
    },
    "stream_add_device=cuda_flops_per_element=1_framework=pytorch_kernel=add_num_arrays=3_num_memory_ops=3_size_mb=32": {
      "operation_type": "stream_add",
      "measured_gflops": 7.24005507521175,
      "efficiency": 1.2776567779785442,
      "achieved_bandwidth_gbps": 86.880660902541,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.3333333333333333,
      "batch_size": 1,
      "input_shape": [
        8388608
      ],
      "output_shape": [
        8388608
      ],
      "mean_latency_ms": 1.1586386999624665,
      "std_latency_ms": 0.006539899840763563,
      "min_latency_ms": 1.14621900002021,
      "max_latency_ms": 1.166699999885168,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 32,
        "kernel": "add",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 3,
        "num_memory_ops": 3,
        "flops_per_element": 1
      },
      "precision_results": {}
    },
    "stream_add_device=cuda_flops_per_element=1_framework=pytorch_kernel=add_num_arrays=3_num_memory_ops=3_size_mb=64": {
      "operation_type": "stream_add",
      "measured_gflops": 6.309749383274579,
      "efficiency": 1.1134851852837493,
      "achieved_bandwidth_gbps": 75.71699259929495,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.3333333333333333,
      "batch_size": 1,
      "input_shape": [
        16777216
      ],
      "output_shape": [
        16777216
      ],
      "mean_latency_ms": 2.658935399949769,
      "std_latency_ms": 1.1803392844163376,
      "min_latency_ms": 2.181198000016593,
      "max_latency_ms": 5.9233949996269075,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 64,
        "kernel": "add",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 3,
        "num_memory_ops": 3,
        "flops_per_element": 1
      },
      "precision_results": {}
    },
    "stream_add_device=cuda_flops_per_element=1_framework=pytorch_kernel=add_num_arrays=3_num_memory_ops=3_size_mb=128": {
      "operation_type": "stream_add",
      "measured_gflops": 6.72384850066387,
      "efficiency": 1.1865615001171534,
      "achieved_bandwidth_gbps": 80.68618200796644,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.3333333333333333,
      "batch_size": 1,
      "input_shape": [
        33554432
      ],
      "output_shape": [
        33554432
      ],
      "mean_latency_ms": 4.990361099999063,
      "std_latency_ms": 1.7439066881317078,
      "min_latency_ms": 4.282231000161119,
      "max_latency_ms": 9.767005999947287,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 128,
        "kernel": "add",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 3,
        "num_memory_ops": 3,
        "flops_per_element": 1
      },
      "precision_results": {}
    },
    "stream_add_device=cuda_flops_per_element=1_framework=pytorch_kernel=add_num_arrays=3_num_memory_ops=3_size_mb=256": {
      "operation_type": "stream_add",
      "measured_gflops": 7.926176344652746,
      "efficiency": 1.3987370019975436,
      "achieved_bandwidth_gbps": 95.11411613583296,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.3333333333333333,
      "batch_size": 1,
      "input_shape": [
        67108864
      ],
      "output_shape": [
        67108864
      ],
      "mean_latency_ms": 8.466738699962661,
      "std_latency_ms": 0.0060066543576388935,
      "min_latency_ms": 8.45780100007687,
      "max_latency_ms": 8.476970000174333,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 256,
        "kernel": "add",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 3,
        "num_memory_ops": 3,
        "flops_per_element": 1
      },
      "precision_results": {}
    },
    "stream_add_device=cuda_flops_per_element=1_framework=pytorch_kernel=add_num_arrays=3_num_memory_ops=3_size_mb=512": {
      "operation_type": "stream_add",
      "measured_gflops": 7.588912624692046,
      "efficiency": 1.3392198749456552,
      "achieved_bandwidth_gbps": 91.06695149630455,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.3333333333333333,
      "batch_size": 1,
      "input_shape": [
        134217728
      ],
      "output_shape": [
        134217728
      ],
      "mean_latency_ms": 17.686028900016026,
      "std_latency_ms": 1.4180348768794628,
      "min_latency_ms": 16.812395000215474,
      "max_latency_ms": 20.641348000026483,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 512,
        "kernel": "add",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 3,
        "num_memory_ops": 3,
        "flops_per_element": 1
      },
      "precision_results": {}
    },
    "stream_triad_device=cuda_flops_per_element=2_framework=pytorch_kernel=triad_num_arrays=3_num_memory_ops=3_size_mb=8": {
      "operation_type": "stream_triad",
      "measured_gflops": 6.983945250317599,
      "efficiency": 0.6162304632633175,
      "achieved_bandwidth_gbps": 41.90367150190559,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.6666666666666666,
      "batch_size": 1,
      "input_shape": [
        2097152
      ],
      "output_shape": [
        2097152
      ],
      "mean_latency_ms": 0.6005636999816488,
      "std_latency_ms": 0.05518524076250275,
      "min_latency_ms": 0.5703729998458584,
      "max_latency_ms": 0.7500649999201414,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 8,
        "kernel": "triad",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 3,
        "num_memory_ops": 3,
        "flops_per_element": 2
      },
      "precision_results": {}
    },
    "stream_triad_device=cuda_flops_per_element=2_framework=pytorch_kernel=triad_num_arrays=3_num_memory_ops=3_size_mb=16": {
      "operation_type": "stream_triad",
      "measured_gflops": 5.2184280768387605,
      "efficiency": 0.46044953619165535,
      "achieved_bandwidth_gbps": 31.310568461032563,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.6666666666666666,
      "batch_size": 1,
      "input_shape": [
        4194304
      ],
      "output_shape": [
        4194304
      ],
      "mean_latency_ms": 1.6074970999852667,
      "std_latency_ms": 0.6469001430511438,
      "min_latency_ms": 1.0011209997173864,
      "max_latency_ms": 2.6160749998780375,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 16,
        "kernel": "triad",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 3,
        "num_memory_ops": 3,
        "flops_per_element": 2
      },
      "precision_results": {}
    },
    "stream_triad_device=cuda_flops_per_element=2_framework=pytorch_kernel=triad_num_arrays=3_num_memory_ops=3_size_mb=32": {
      "operation_type": "stream_triad",
      "measured_gflops": 7.993561780023894,
      "efficiency": 0.7053142747079906,
      "achieved_bandwidth_gbps": 47.96137068014336,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.6666666666666666,
      "batch_size": 1,
      "input_shape": [
        8388608
      ],
      "output_shape": [
        8388608
      ],
      "mean_latency_ms": 2.0988411000871565,
      "std_latency_ms": 0.41472085820867544,
      "min_latency_ms": 1.8639300001268566,
      "max_latency_ms": 2.903005000007397,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 32,
        "kernel": "triad",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 3,
        "num_memory_ops": 3,
        "flops_per_element": 2
      },
      "precision_results": {}
    },
    "stream_triad_device=cuda_flops_per_element=2_framework=pytorch_kernel=triad_num_arrays=3_num_memory_ops=3_size_mb=64": {
      "operation_type": "stream_triad",
      "measured_gflops": 7.9529388520816475,
      "efficiency": 0.7017298987130866,
      "achieved_bandwidth_gbps": 47.717633112489885,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.6666666666666666,
      "batch_size": 1,
      "input_shape": [
        16777216
      ],
      "output_shape": [
        16777216
      ],
      "mean_latency_ms": 4.219123599978047,
      "std_latency_ms": 1.2952643284083514,
      "min_latency_ms": 3.5956259998783935,
      "max_latency_ms": 7.42390899995371,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 64,
        "kernel": "triad",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 3,
        "num_memory_ops": 3,
        "flops_per_element": 2
      },
      "precision_results": {}
    },
    "stream_triad_device=cuda_flops_per_element=2_framework=pytorch_kernel=triad_num_arrays=3_num_memory_ops=3_size_mb=128": {
      "operation_type": "stream_triad",
      "measured_gflops": 9.182673617527472,
      "efficiency": 0.8102359074288946,
      "achieved_bandwidth_gbps": 55.096041705164836,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.6666666666666666,
      "batch_size": 1,
      "input_shape": [
        33554432
      ],
      "output_shape": [
        33554432
      ],
      "mean_latency_ms": 7.308205300023474,
      "std_latency_ms": 0.45656720431298775,
      "min_latency_ms": 7.085423000262381,
      "max_latency_ms": 8.415590000367956,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 128,
        "kernel": "triad",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 3,
        "num_memory_ops": 3,
        "flops_per_element": 2
      },
      "precision_results": {}
    },
    "stream_triad_device=cuda_flops_per_element=2_framework=pytorch_kernel=triad_num_arrays=3_num_memory_ops=3_size_mb=256": {
      "operation_type": "stream_triad",
      "measured_gflops": 9.190316468960622,
      "efficiency": 0.8109102766729962,
      "achieved_bandwidth_gbps": 55.14189881376374,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.6666666666666666,
      "batch_size": 1,
      "input_shape": [
        67108864
      ],
      "output_shape": [
        67108864
      ],
      "mean_latency_ms": 14.60425529994609,
      "std_latency_ms": 1.2170114149157218,
      "min_latency_ms": 14.075606000005791,
      "max_latency_ms": 17.844332000095164,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 256,
        "kernel": "triad",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 3,
        "num_memory_ops": 3,
        "flops_per_element": 2
      },
      "precision_results": {}
    },
    "stream_triad_device=cuda_flops_per_element=2_framework=pytorch_kernel=triad_num_arrays=3_num_memory_ops=3_size_mb=512": {
      "operation_type": "stream_triad",
      "measured_gflops": 8.91917448738412,
      "efficiency": 0.7869859841809519,
      "achieved_bandwidth_gbps": 53.51504692430473,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.6666666666666666,
      "batch_size": 1,
      "input_shape": [
        134217728
      ],
      "output_shape": [
        134217728
      ],
      "mean_latency_ms": 30.096446300012758,
      "std_latency_ms": 4.0982718447351,
      "min_latency_ms": 28.035621000071842,
      "max_latency_ms": 40.74940999998944,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 512,
        "kernel": "triad",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 3,
        "num_memory_ops": 3,
        "flops_per_element": 2
      },
      "precision_results": {}
    },
    "blas1_dot_best_precision=fp16_blas_level=1_device=cuda_framework=pytorch_operation=dot_size=1000": {
      "operation_type": "blas1_dot",
      "measured_gflops": 0.011375509554823512,
      "efficiency": 1.5127007386733394e-06,
      "achieved_bandwidth_gbps": 0.022751019109647025,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.5,
      "batch_size": 1,
      "input_shape": [
        1000
      ],
      "output_shape": [
        1000
      ],
      "mean_latency_ms": 0.17581629995220283,
      "std_latency_ms": 0.012081602439527417,
      "min_latency_ms": 0.1644590001887991,
      "max_latency_ms": 0.18789790239173024,
      "num_trials": 10,
      "extra_params": {
        "size": 1000,
        "operation": "dot",
        "blas_level": 1,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "fp16"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.010749209125169228,
          "efficiency": 0.00017915348541948714,
          "mean_latency_ms": 0.1860602000306244,
          "std_latency_ms": 0.0220152660697356,
          "min_latency_ms": 0.16858700018929085,
          "max_latency_ms": 0.20807546610036,
          "speedup_vs_fp32": null,
          "test_size": 1000,
          "num_trials": 10,
          "arithmetic_intensity": 0.5,
          "achieved_bandwidth_gbps": 0.021498418250338457
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.010511643748338474,
          "efficiency": 5.5912998661374865e-06,
          "mean_latency_ms": 0.19026519998988078,
          "std_latency_ms": 0.054678373457717,
          "min_latency_ms": 0.15476199996555806,
          "max_latency_ms": 0.2449435734475978,
          "speedup_vs_fp32": 1.0,
          "test_size": 1000,
          "num_trials": 10,
          "arithmetic_intensity": 0.25,
          "achieved_bandwidth_gbps": 0.042046574993353895
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.011375509554823512,
          "efficiency": 1.5127007386733394e-06,
          "mean_latency_ms": 0.17581629995220283,
          "std_latency_ms": 0.012081602439527417,
          "min_latency_ms": 0.1644590001887991,
          "max_latency_ms": 0.18789790239173024,
          "speedup_vs_fp32": 1.0821818002176478,
          "test_size": 1000,
          "num_trials": 10,
          "arithmetic_intensity": 0.5,
          "achieved_bandwidth_gbps": 0.022751019109647025
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.006692788622034895,
          "efficiency": 8.899984869727254e-07,
          "mean_latency_ms": 0.29882909993830253,
          "std_latency_ms": 0.37846653128290014,
          "min_latency_ms": 0.16708299972378882,
          "max_latency_ms": 0.6772956312212026,
          "speedup_vs_fp32": 0.636702382830734,
          "test_size": 1000,
          "num_trials": 10,
          "arithmetic_intensity": 0.5,
          "achieved_bandwidth_gbps": 0.01338557724406979
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.01113155607222078,
          "efficiency": 2.960520231973612e-06,
          "mean_latency_ms": 0.17966939994948916,
          "std_latency_ms": 0.012641049255313433,
          "min_latency_ms": 0.16538699992452166,
          "max_latency_ms": 0.19231044920480259,
          "speedup_vs_fp32": 1.0589738711398293,
          "test_size": 1000,
          "num_trials": 10,
          "arithmetic_intensity": 0.25,
          "achieved_bandwidth_gbps": 0.04452622428888312
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Long'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Int'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Short'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Char'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas1_dot_best_precision=fp16_blas_level=1_device=cuda_framework=pytorch_operation=dot_size=10000": {
      "operation_type": "blas1_dot",
      "measured_gflops": 0.11499632585928397,
      "efficiency": 1.5292064608947338e-05,
      "achieved_bandwidth_gbps": 0.22999265171856795,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.5,
      "batch_size": 1,
      "input_shape": [
        10000
      ],
      "output_shape": [
        10000
      ],
      "mean_latency_ms": 0.17391860001225723,
      "std_latency_ms": 0.01071471253289226,
      "min_latency_ms": 0.15764299996590125,
      "max_latency_ms": 0.18463331254514947,
      "num_trials": 10,
      "extra_params": {
        "size": 10000,
        "operation": "dot",
        "blas_level": 1,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "fp16"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.11191760182319103,
          "efficiency": 0.0018652933637198505,
          "mean_latency_ms": 0.1787028999387985,
          "std_latency_ms": 0.01083554603057123,
          "min_latency_ms": 0.16746700021030847,
          "max_latency_ms": 0.18953844596936975,
          "speedup_vs_fp32": null,
          "test_size": 10000,
          "num_trials": 10,
          "arithmetic_intensity": 0.5,
          "achieved_bandwidth_gbps": 0.22383520364638207
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.1142814042070891,
          "efficiency": 6.07879809612176e-05,
          "mean_latency_ms": 0.17500660005680402,
          "std_latency_ms": 0.010142500804302068,
          "min_latency_ms": 0.15553000002910267,
          "max_latency_ms": 0.1851491008611061,
          "speedup_vs_fp32": 1.0,
          "test_size": 10000,
          "num_trials": 10,
          "arithmetic_intensity": 0.25,
          "achieved_bandwidth_gbps": 0.4571256168283564
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.11499632585928397,
          "efficiency": 1.5292064608947338e-05,
          "mean_latency_ms": 0.17391860001225723,
          "std_latency_ms": 0.01071471253289226,
          "min_latency_ms": 0.15764299996590125,
          "max_latency_ms": 0.18463331254514947,
          "speedup_vs_fp32": 1.006255800382881,
          "test_size": 10000,
          "num_trials": 10,
          "arithmetic_intensity": 0.5,
          "achieved_bandwidth_gbps": 0.22999265171856795
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.11148843759973268,
          "efficiency": 1.482559010634743e-05,
          "mean_latency_ms": 0.17939079989446327,
          "std_latency_ms": 0.010744657193812618,
          "min_latency_ms": 0.16381899968109792,
          "max_latency_ms": 0.1901354570882759,
          "speedup_vs_fp32": 0.9755606204987183,
          "test_size": 10000,
          "num_trials": 10,
          "arithmetic_intensity": 0.5,
          "achieved_bandwidth_gbps": 0.22297687519946535
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.04603751642624741,
          "efficiency": 1.2244020326129631e-05,
          "mean_latency_ms": 0.4344283000591531,
          "std_latency_ms": 0.7542552157499093,
          "min_latency_ms": 0.16682600016793003,
          "max_latency_ms": 1.1886835158090623,
          "speedup_vs_fp32": 0.4028434612408413,
          "test_size": 10000,
          "num_trials": 10,
          "arithmetic_intensity": 0.25,
          "achieved_bandwidth_gbps": 0.18415006570498965
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Long'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Int'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Short'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Char'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas1_dot_best_precision=bf16_blas_level=1_device=cuda_framework=pytorch_operation=dot_size=100000": {
      "operation_type": "blas1_dot",
      "measured_gflops": 1.1562177339773294,
      "efficiency": 0.00015375235824166615,
      "achieved_bandwidth_gbps": 2.312435467954659,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.5,
      "batch_size": 1,
      "input_shape": [
        100000
      ],
      "output_shape": [
        100000
      ],
      "mean_latency_ms": 0.17297780004810193,
      "std_latency_ms": 0.019770813604809808,
      "min_latency_ms": 0.15652199999749428,
      "max_latency_ms": 0.19274861365291174,
      "num_trials": 10,
      "extra_params": {
        "size": 100000,
        "operation": "dot",
        "blas_level": 1,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "bf16"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.6634385955183031,
          "efficiency": 0.011057309925305051,
          "mean_latency_ms": 0.3014597000401409,
          "std_latency_ms": 0.3668575239799582,
          "min_latency_ms": 0.1696750000519387,
          "max_latency_ms": 0.6683172240200991,
          "speedup_vs_fp32": null,
          "test_size": 100000,
          "num_trials": 10,
          "arithmetic_intensity": 0.5,
          "achieved_bandwidth_gbps": 1.3268771910366062
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.0889865339936824,
          "efficiency": 0.0005792481563796183,
          "mean_latency_ms": 0.18365700011599984,
          "std_latency_ms": 0.02777029867711165,
          "min_latency_ms": 0.1609710002412612,
          "max_latency_ms": 0.21142729879311148,
          "speedup_vs_fp32": 1.0,
          "test_size": 100000,
          "num_trials": 10,
          "arithmetic_intensity": 0.25,
          "achieved_bandwidth_gbps": 4.35594613597473
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.123886579947814,
          "efficiency": 0.00014945300265263483,
          "mean_latency_ms": 0.1779538999471697,
          "std_latency_ms": 0.016986464896102532,
          "min_latency_ms": 0.15610599984938744,
          "max_latency_ms": 0.19494036484327223,
          "speedup_vs_fp32": 1.0320481887192317,
          "test_size": 100000,
          "num_trials": 10,
          "arithmetic_intensity": 0.5,
          "achieved_bandwidth_gbps": 2.247773159895628
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.1562177339773294,
          "efficiency": 0.00015375235824166615,
          "mean_latency_ms": 0.17297780004810193,
          "std_latency_ms": 0.019770813604809808,
          "min_latency_ms": 0.15652199999749428,
          "max_latency_ms": 0.19274861365291174,
          "speedup_vs_fp32": 1.0617374025159774,
          "test_size": 100000,
          "num_trials": 10,
          "arithmetic_intensity": 0.5,
          "achieved_bandwidth_gbps": 2.312435467954659
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.9796521357952415,
          "efficiency": 0.0002605457807966068,
          "mean_latency_ms": 0.20415409990164335,
          "std_latency_ms": 0.07681778639059814,
          "min_latency_ms": 0.15741900006105425,
          "max_latency_ms": 0.28097188629224146,
          "speedup_vs_fp32": 0.8995998620869308,
          "test_size": 100000,
          "num_trials": 10,
          "arithmetic_intensity": 0.25,
          "achieved_bandwidth_gbps": 3.918608543180966
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Long'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Int'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Short'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Char'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas1_dot_best_precision=fp16_blas_level=1_device=cuda_framework=pytorch_operation=dot_size=1000000": {
      "operation_type": "blas1_dot",
      "measured_gflops": 14.226906358325524,
      "efficiency": 0.001891875845522011,
      "achieved_bandwidth_gbps": 28.453812716651047,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.5,
      "batch_size": 1,
      "input_shape": [
        1000000
      ],
      "output_shape": [
        1000000
      ],
      "mean_latency_ms": 0.14057869993848726,
      "std_latency_ms": 0.012013312234630048,
      "min_latency_ms": 0.1250959999197221,
      "max_latency_ms": 0.1525920121731173,
      "num_trials": 10,
      "extra_params": {
        "size": 1000000,
        "operation": "dot",
        "blas_level": 1,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "fp16"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 2.2761632442454247,
          "efficiency": 0.03793605407075708,
          "mean_latency_ms": 0.8786716001395689,
          "std_latency_ms": 0.9253276025445967,
          "min_latency_ms": 0.30821200016362127,
          "max_latency_ms": 1.8039992026841656,
          "speedup_vs_fp32": null,
          "test_size": 1000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.5,
          "achieved_bandwidth_gbps": 4.552326488490849
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 11.162377426549556,
          "efficiency": 0.0059374348013561465,
          "mean_latency_ms": 0.17917330005730037,
          "std_latency_ms": 0.0034433802698080615,
          "min_latency_ms": 0.1746990001265658,
          "max_latency_ms": 0.18261668032710843,
          "speedup_vs_fp32": 1.0,
          "test_size": 1000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.25,
          "achieved_bandwidth_gbps": 44.649509706198224
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 14.226906358325524,
          "efficiency": 0.001891875845522011,
          "mean_latency_ms": 0.14057869993848726,
          "std_latency_ms": 0.012013312234630048,
          "min_latency_ms": 0.1250959999197221,
          "max_latency_ms": 0.1525920121731173,
          "speedup_vs_fp32": 1.274540880913687,
          "test_size": 1000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.5,
          "achieved_bandwidth_gbps": 28.453812716651047
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 7.272711403679463,
          "efficiency": 0.0009671158781488648,
          "mean_latency_ms": 0.27500060004967963,
          "std_latency_ms": 0.20341765329323427,
          "min_latency_ms": 0.14215400005923584,
          "max_latency_ms": 0.4784182533429139,
          "speedup_vs_fp32": 0.6515378512808053,
          "test_size": 1000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.5,
          "achieved_bandwidth_gbps": 14.545422807358927
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 11.001445035039525,
          "efficiency": 0.002925916232723278,
          "mean_latency_ms": 0.18179430007876363,
          "std_latency_ms": 0.0038377060982820615,
          "min_latency_ms": 0.17633100014791125,
          "max_latency_ms": 0.1856320061770457,
          "speedup_vs_fp32": 0.9855826061635172,
          "test_size": 1000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.25,
          "achieved_bandwidth_gbps": 44.0057801401581
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Long'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Int'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Short'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Char'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas1_dot_best_precision=fp16_blas_level=1_device=cuda_framework=pytorch_operation=dot_size=10000000": {
      "operation_type": "blas1_dot",
      "measured_gflops": 31.48472353554992,
      "efficiency": 0.00418679834249334,
      "achieved_bandwidth_gbps": 62.96944707109984,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.5,
      "batch_size": 1,
      "input_shape": [
        10000000
      ],
      "output_shape": [
        10000000
      ],
      "mean_latency_ms": 0.6352286999572243,
      "std_latency_ms": 0.007066858653394491,
      "min_latency_ms": 0.6225049996828602,
      "max_latency_ms": 0.6422955586106188,
      "num_trials": 10,
      "extra_params": {
        "size": 10000000,
        "operation": "dot",
        "blas_level": 1,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "fp16"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 9.887938509504115,
          "efficiency": 0.16479897515840192,
          "mean_latency_ms": 2.0226663000357803,
          "std_latency_ms": 0.37453285100231826,
          "min_latency_ms": 1.852376999977423,
          "max_latency_ms": 2.3971991510380986,
          "speedup_vs_fp32": null,
          "test_size": 10000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.5,
          "achieved_bandwidth_gbps": 19.77587701900823
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 20.10543086987303,
          "efficiency": 0.010694378122272887,
          "mean_latency_ms": 0.9947560999535199,
          "std_latency_ms": 0.00818785252369684,
          "min_latency_ms": 0.9861759999694186,
          "max_latency_ms": 1.0029439524772168,
          "speedup_vs_fp32": 1.0,
          "test_size": 10000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.25,
          "achieved_bandwidth_gbps": 80.42172347949212
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 31.48472353554992,
          "efficiency": 0.00418679834249334,
          "mean_latency_ms": 0.6352286999572243,
          "std_latency_ms": 0.007066858653394491,
          "min_latency_ms": 0.6225049996828602,
          "max_latency_ms": 0.6422955586106188,
          "speedup_vs_fp32": 1.565981039616922,
          "test_size": 10000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.5,
          "achieved_bandwidth_gbps": 62.96944707109984
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 31.31042422717983,
          "efficiency": 0.004163620242976041,
          "mean_latency_ms": 0.6387648999861995,
          "std_latency_ms": 0.010981400596805082,
          "min_latency_ms": 0.6164880001051642,
          "max_latency_ms": 0.6497463005830045,
          "speedup_vs_fp32": 1.5573117746059806,
          "test_size": 10000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.5,
          "achieved_bandwidth_gbps": 62.62084845435966
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 20.130880922832706,
          "efficiency": 0.005353957692242741,
          "mean_latency_ms": 0.9934984999745211,
          "std_latency_ms": 0.004613249712920403,
          "min_latency_ms": 0.985343999673205,
          "max_latency_ms": 0.9981117496874415,
          "speedup_vs_fp32": 1.0012658297712889,
          "test_size": 10000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.25,
          "achieved_bandwidth_gbps": 80.52352369133082
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Long'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Int'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Short'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Char'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas1_axpy_best_precision=int16_blas_level=1_device=cuda_framework=pytorch_operation=axpy_size=1000": {
      "operation_type": "blas1_axpy",
      "measured_gflops": 0.006769419683598765,
      "efficiency": 9.001887877126017e-07,
      "achieved_bandwidth_gbps": 0.020308259050796293,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.3333333333333333,
      "batch_size": 1,
      "input_shape": [
        1000
      ],
      "output_shape": [
        1000
      ],
      "mean_latency_ms": 0.2954463001969998,
      "std_latency_ms": 0.014773552672904948,
      "min_latency_ms": 0.27108900030725636,
      "max_latency_ms": 0.3102198528699047,
      "num_trials": 10,
      "extra_params": {
        "size": 1000,
        "operation": "axpy",
        "blas_level": 1,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "int16"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.006451329878441077,
          "efficiency": 0.00010752216464068462,
          "mean_latency_ms": 0.31001359993751976,
          "std_latency_ms": 0.01263786973947646,
          "min_latency_ms": 0.29400300036286353,
          "max_latency_ms": 0.3226514696769962,
          "speedup_vs_fp32": null,
          "test_size": 1000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 0.019353989635323234
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.0067524406690926755,
          "efficiency": 3.5917237601556784e-06,
          "mean_latency_ms": 0.2961892000257649,
          "std_latency_ms": 0.018396536828518665,
          "min_latency_ms": 0.27137799997944967,
          "max_latency_ms": 0.31458573685428354,
          "speedup_vs_fp32": 1.0,
          "test_size": 1000,
          "num_trials": 10,
          "arithmetic_intensity": 0.16666666666666666,
          "achieved_bandwidth_gbps": 0.04051464401455605
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.0065713298125809495,
          "efficiency": 8.738470495453391e-07,
          "mean_latency_ms": 0.3043524000531761,
          "std_latency_ms": 0.016618373647125154,
          "min_latency_ms": 0.27192100014872267,
          "max_latency_ms": 0.32097077370030125,
          "speedup_vs_fp32": 0.9731784601469053,
          "test_size": 1000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 0.019713989437742847
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.006746470668600515,
          "efficiency": 8.971370569947494e-07,
          "mean_latency_ms": 0.29645129998243647,
          "std_latency_ms": 0.012593008261511338,
          "min_latency_ms": 0.27742599968405557,
          "max_latency_ms": 0.3090443082439478,
          "speedup_vs_fp32": 0.9991158751650369,
          "test_size": 1000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 0.02023941200580155
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.005191814170713244,
          "efficiency": 1.3808016411471395e-06,
          "mean_latency_ms": 0.38522179997926287,
          "std_latency_ms": 0.27534339239390926,
          "min_latency_ms": 0.2846900001713948,
          "max_latency_ms": 0.6605651923731721,
          "speedup_vs_fp32": 0.7688796429529928,
          "test_size": 1000,
          "num_trials": 10,
          "arithmetic_intensity": 0.16666666666666666,
          "achieved_bandwidth_gbps": 0.031150885024279464
        },
        "int64": {
          "precision": "int64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.0067624568675926765,
          "efficiency": 0.0,
          "mean_latency_ms": 0.29575050002677017,
          "std_latency_ms": 0.014284032730416842,
          "min_latency_ms": 0.2727850001065235,
          "max_latency_ms": 0.310034532757187,
          "speedup_vs_fp32": 1.0014833449105074,
          "test_size": 1000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 0.020287370602778028
        },
        "int32": {
          "precision": "int32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.004404472388787893,
          "efficiency": 2.3428044621212194e-06,
          "mean_latency_ms": 0.4540839000583219,
          "std_latency_ms": 0.3361733311192136,
          "min_latency_ms": 0.2773300002445467,
          "max_latency_ms": 0.7902572311775355,
          "speedup_vs_fp32": 0.6522785766853278,
          "test_size": 1000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 0.01321341716636368
        },
        "int16": {
          "precision": "int16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.006769419683598765,
          "efficiency": 9.001887877126017e-07,
          "mean_latency_ms": 0.2954463001969998,
          "std_latency_ms": 0.014773552672904948,
          "min_latency_ms": 0.27108900030725636,
          "max_latency_ms": 0.3102198528699047,
          "speedup_vs_fp32": 1.0025145003618923,
          "test_size": 1000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 0.020308259050796293
        },
        "int8": {
          "precision": "int8",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.006593161703022342,
          "efficiency": 4.3837511323286846e-07,
          "mean_latency_ms": 0.3033446000699769,
          "std_latency_ms": 0.020051343934322837,
          "min_latency_ms": 0.2778100001705752,
          "max_latency_ms": 0.3233959440042997,
          "speedup_vs_fp32": 0.9764116452293484,
          "test_size": 1000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 0.019779485109067026
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas1_axpy_best_precision=int8_blas_level=1_device=cuda_framework=pytorch_operation=axpy_size=10000": {
      "operation_type": "blas1_axpy",
      "measured_gflops": 0.07910181474323924,
      "efficiency": 5.2594291717579285e-06,
      "achieved_bandwidth_gbps": 0.23730544422971772,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.3333333333333333,
      "batch_size": 1,
      "input_shape": [
        10000
      ],
      "output_shape": [
        10000
      ],
      "mean_latency_ms": 0.2528386999074428,
      "std_latency_ms": 0.011971865568081524,
      "min_latency_ms": 0.24139100014508585,
      "max_latency_ms": 0.2648105654755243,
      "num_trials": 10,
      "extra_params": {
        "size": 10000,
        "operation": "axpy",
        "blas_level": 1,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "int8"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.047115883643082376,
          "efficiency": 0.0007852647273847063,
          "mean_latency_ms": 0.4244852999363502,
          "std_latency_ms": 0.3484906458890431,
          "min_latency_ms": 0.2712169998630998,
          "max_latency_ms": 0.7729759458253933,
          "speedup_vs_fp32": null,
          "test_size": 10000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 0.14134765092924714
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.06653950969369976,
          "efficiency": 3.5393356220053066e-05,
          "mean_latency_ms": 0.30057329986448167,
          "std_latency_ms": 0.019277351415002156,
          "min_latency_ms": 0.26603299966154736,
          "max_latency_ms": 0.3198506512794838,
          "speedup_vs_fp32": 1.0,
          "test_size": 10000,
          "num_trials": 10,
          "arithmetic_intensity": 0.16666666666666666,
          "achieved_bandwidth_gbps": 0.39923705816219857
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.027818253336996713,
          "efficiency": 3.6992358160899883e-06,
          "mean_latency_ms": 0.7189523999841185,
          "std_latency_ms": 0.9970926788991048,
          "min_latency_ms": 0.28593900015039253,
          "max_latency_ms": 1.7160450788832233,
          "speedup_vs_fp32": 0.41807121009836146,
          "test_size": 10000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 0.08345476001099013
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.06696876273443599,
          "efficiency": 8.905420576387764e-06,
          "mean_latency_ms": 0.29864670009374095,
          "std_latency_ms": 0.01097757200289526,
          "min_latency_ms": 0.2866429999812681,
          "max_latency_ms": 0.30962427209663623,
          "speedup_vs_fp32": 1.0064511001465475,
          "test_size": 10000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 0.20090628820330797
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.019808097173361423,
          "efficiency": 5.268110950362081e-06,
          "mean_latency_ms": 1.0096881000208668,
          "std_latency_ms": 1.0383291032660693,
          "min_latency_ms": 0.29409900025711977,
          "max_latency_ms": 2.0480172032869364,
          "speedup_vs_fp32": 0.29768925657167766,
          "test_size": 10000,
          "num_trials": 10,
          "arithmetic_intensity": 0.16666666666666666,
          "achieved_bandwidth_gbps": 0.11884858304016854
        },
        "int64": {
          "precision": "int64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.06843992223882873,
          "efficiency": 0.0,
          "mean_latency_ms": 0.2922270999988541,
          "std_latency_ms": 0.016747661828338256,
          "min_latency_ms": 0.2702580000004673,
          "max_latency_ms": 0.30897476182719236,
          "speedup_vs_fp32": 1.0285606634896638,
          "test_size": 10000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 0.2053197667164862
        },
        "int32": {
          "precision": "int32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.06601725493934102,
          "efficiency": 3.511556113794735e-05,
          "mean_latency_ms": 0.30295109995677194,
          "std_latency_ms": 0.017340376719980254,
          "min_latency_ms": 0.28472299982240656,
          "max_latency_ms": 0.3202914766767522,
          "speedup_vs_fp32": 0.992151208255624,
          "test_size": 10000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 0.19805176481802308
        },
        "int16": {
          "precision": "int16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.07290532078317524,
          "efficiency": 9.694856487124368e-06,
          "mean_latency_ms": 0.2743283999734558,
          "std_latency_ms": 0.030372528045465943,
          "min_latency_ms": 0.24702400014575687,
          "max_latency_ms": 0.30470092801892174,
          "speedup_vs_fp32": 1.0956696422738779,
          "test_size": 10000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 0.21871596234952573
        },
        "int8": {
          "precision": "int8",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.07910181474323924,
          "efficiency": 5.2594291717579285e-06,
          "mean_latency_ms": 0.2528386999074428,
          "std_latency_ms": 0.011971865568081524,
          "min_latency_ms": 0.24139100014508585,
          "max_latency_ms": 0.2648105654755243,
          "speedup_vs_fp32": 1.1887946741322162,
          "test_size": 10000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 0.23730544422971772
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas1_axpy_best_precision=int64_blas_level=1_device=cuda_framework=pytorch_operation=axpy_size=100000": {
      "operation_type": "blas1_axpy",
      "measured_gflops": 0.9311073660811647,
      "efficiency": 0.0,
      "achieved_bandwidth_gbps": 2.7933220982434945,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.3333333333333333,
      "batch_size": 1,
      "input_shape": [
        100000
      ],
      "output_shape": [
        100000
      ],
      "mean_latency_ms": 0.21479799997905502,
      "std_latency_ms": 0.00874637723129938,
      "min_latency_ms": 0.20183700007692096,
      "max_latency_ms": 0.2235443772103544,
      "num_trials": 10,
      "extra_params": {
        "size": 100000,
        "operation": "axpy",
        "blas_level": 1,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "int64"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.801455764144523,
          "efficiency": 0.013357596069075384,
          "mean_latency_ms": 0.24954590003289923,
          "std_latency_ms": 0.013623815319390293,
          "min_latency_ms": 0.23371099996438716,
          "max_latency_ms": 0.2631697153522895,
          "speedup_vs_fp32": null,
          "test_size": 100000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 2.404367292433569
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.8553694319952945,
          "efficiency": 0.000454983740423029,
          "mean_latency_ms": 0.23381709997920552,
          "std_latency_ms": 0.007940721248148423,
          "min_latency_ms": 0.22369499993146746,
          "max_latency_ms": 0.24175782122735395,
          "speedup_vs_fp32": 1.0,
          "test_size": 100000,
          "num_trials": 10,
          "arithmetic_intensity": 0.16666666666666666,
          "achieved_bandwidth_gbps": 5.132216591971766
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.9276244234266945,
          "efficiency": 0.0001233543116258902,
          "mean_latency_ms": 0.21560449999924458,
          "std_latency_ms": 0.010957003409338419,
          "min_latency_ms": 0.19582100003390224,
          "max_latency_ms": 0.226561503408583,
          "speedup_vs_fp32": 1.0844722627775614,
          "test_size": 100000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 2.782873270280083
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.34280015962118743,
          "efficiency": 4.5585127609200453e-05,
          "mean_latency_ms": 0.5834303000938235,
          "std_latency_ms": 0.9208350285529022,
          "min_latency_ms": 0.22091100026955246,
          "max_latency_ms": 1.5042653286467256,
          "speedup_vs_fp32": 0.40076269597517394,
          "test_size": 100000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 1.0284004788635623
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.930233423549743,
          "efficiency": 0.00024740250626322955,
          "mean_latency_ms": 0.21499979998225172,
          "std_latency_ms": 0.015086112244731177,
          "min_latency_ms": 0.1988290000554116,
          "max_latency_ms": 0.23008591222698288,
          "speedup_vs_fp32": 1.0875224069906444,
          "test_size": 100000,
          "num_trials": 10,
          "arithmetic_intensity": 0.16666666666666666,
          "achieved_bandwidth_gbps": 5.581400541298458
        },
        "int64": {
          "precision": "int64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.9311073660811647,
          "efficiency": 0.0,
          "mean_latency_ms": 0.21479799997905502,
          "std_latency_ms": 0.00874637723129938,
          "min_latency_ms": 0.20183700007692096,
          "max_latency_ms": 0.2235443772103544,
          "speedup_vs_fp32": 1.088544120531872,
          "test_size": 100000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 2.7933220982434945
        },
        "int32": {
          "precision": "int32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.2590987044461608,
          "efficiency": 0.00013781845981178766,
          "mean_latency_ms": 0.7719065999481245,
          "std_latency_ms": 0.6659435553765721,
          "min_latency_ms": 0.26401700006317697,
          "max_latency_ms": 1.4378501553246967,
          "speedup_vs_fp32": 0.302908538409853,
          "test_size": 100000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 0.7772961133384824
        },
        "int16": {
          "precision": "int16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.7487327700121624,
          "efficiency": 9.956552792714926e-05,
          "mean_latency_ms": 0.2671179999197193,
          "std_latency_ms": 0.020413140888164916,
          "min_latency_ms": 0.24411200001850375,
          "max_latency_ms": 0.2875311408078842,
          "speedup_vs_fp32": 0.8753326247182064,
          "test_size": 100000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 2.2461983100364877
        },
        "int8": {
          "precision": "int8",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.5550507678673863,
          "efficiency": 3.690497126777834e-05,
          "mean_latency_ms": 0.3603273999033263,
          "std_latency_ms": 0.3166151250740947,
          "min_latency_ms": 0.23761599959470914,
          "max_latency_ms": 0.676942524977421,
          "speedup_vs_fp32": 0.6489018044199173,
          "test_size": 100000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 1.6651523036021585
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas1_axpy_best_precision=int8_blas_level=1_device=cuda_framework=pytorch_operation=axpy_size=1000000": {
      "operation_type": "blas1_axpy",
      "measured_gflops": 7.5053916835178,
      "efficiency": 0.0004990287023615558,
      "achieved_bandwidth_gbps": 22.5161750505534,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.3333333333333333,
      "batch_size": 1,
      "input_shape": [
        1000000
      ],
      "output_shape": [
        1000000
      ],
      "mean_latency_ms": 0.26647510007933306,
      "std_latency_ms": 0.022245080986833088,
      "min_latency_ms": 0.2475040000717854,
      "max_latency_ms": 0.28872018106616615,
      "num_trials": 10,
      "extra_params": {
        "size": 1000000,
        "operation": "axpy",
        "blas_level": 1,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "int8"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 2.3460578426550844,
          "efficiency": 0.03910096404425141,
          "mean_latency_ms": 0.8524939000380982,
          "std_latency_ms": 0.0050574148495036485,
          "min_latency_ms": 0.8434469996245753,
          "max_latency_ms": 0.8575513148876018,
          "speedup_vs_fp32": null,
          "test_size": 1000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 7.038173527965253
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 2.128724162789574,
          "efficiency": 0.001132300086590199,
          "mean_latency_ms": 0.9395299000971136,
          "std_latency_ms": 0.8589990967701931,
          "min_latency_ms": 0.4320919997553574,
          "max_latency_ms": 1.7985289968673066,
          "speedup_vs_fp32": 1.0,
          "test_size": 1000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.16666666666666666,
          "achieved_bandwidth_gbps": 12.772344976737443
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 4.819539569729111,
          "efficiency": 0.0006408962193788711,
          "mean_latency_ms": 0.4149774000325124,
          "std_latency_ms": 0.34100678842942794,
          "min_latency_ms": 0.2878909999708412,
          "max_latency_ms": 0.7559841884619403,
          "speedup_vs_fp32": 2.2640507652308384,
          "test_size": 1000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 14.458618709187334
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 6.138426427007071,
          "efficiency": 0.0008162801099743446,
          "mean_latency_ms": 0.3258163999817043,
          "std_latency_ms": 0.09960741972279946,
          "min_latency_ms": 0.26257700028509134,
          "max_latency_ms": 0.42542381970450377,
          "speedup_vs_fp32": 2.8836175838597176,
          "test_size": 1000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 18.415279281021213
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 4.4353529567381855,
          "efficiency": 0.0011796151480686664,
          "mean_latency_ms": 0.45092239997757133,
          "std_latency_ms": 0.020013197606508853,
          "min_latency_ms": 0.4381079997983761,
          "max_latency_ms": 0.4709355975840802,
          "speedup_vs_fp32": 2.083573360169832,
          "test_size": 1000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.16666666666666666,
          "achieved_bandwidth_gbps": 26.612117740429117
        },
        "int64": {
          "precision": "int64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 2.2976193679710626,
          "efficiency": 0.0,
          "mean_latency_ms": 0.8704661998763186,
          "std_latency_ms": 0.06319384965066806,
          "min_latency_ms": 0.8417499998358835,
          "max_latency_ms": 0.9336600495269867,
          "speedup_vs_fp32": 1.0793410476255227,
          "test_size": 1000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 6.892858103913189
        },
        "int32": {
          "precision": "int32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 4.331571394465765,
          "efficiency": 0.00230402733748179,
          "mean_latency_ms": 0.4617262000010669,
          "std_latency_ms": 0.06528455441792011,
          "min_latency_ms": 0.42354799961685785,
          "max_latency_ms": 0.527010754418987,
          "speedup_vs_fp32": 2.034820419752968,
          "test_size": 1000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 12.994714183397296
        },
        "int16": {
          "precision": "int16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 6.778523606163339,
          "efficiency": 0.0009013994157132099,
          "mean_latency_ms": 0.29504949989132,
          "std_latency_ms": 0.015375016023036685,
          "min_latency_ms": 0.26552100007393165,
          "max_latency_ms": 0.3104245159143567,
          "speedup_vs_fp32": 3.1843128032522836,
          "test_size": 1000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 20.335570818490016
        },
        "int8": {
          "precision": "int8",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 7.5053916835178,
          "efficiency": 0.0004990287023615558,
          "mean_latency_ms": 0.26647510007933306,
          "std_latency_ms": 0.022245080986833088,
          "min_latency_ms": 0.2475040000717854,
          "max_latency_ms": 0.28872018106616615,
          "speedup_vs_fp32": 3.525769949302593,
          "test_size": 1000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 22.5161750505534
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas1_axpy_best_precision=int8_blas_level=1_device=cuda_framework=pytorch_operation=axpy_size=10000000": {
      "operation_type": "blas1_axpy",
      "measured_gflops": 16.70947355280789,
      "efficiency": 0.00111100223090478,
      "achieved_bandwidth_gbps": 50.12842065842367,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.3333333333333333,
      "batch_size": 1,
      "input_shape": [
        10000000
      ],
      "output_shape": [
        10000000
      ],
      "mean_latency_ms": 1.1969258000135596,
      "std_latency_ms": 0.007288546070577071,
      "min_latency_ms": 1.1893249998138344,
      "max_latency_ms": 1.2042143460841368,
      "num_trials": 10,
      "extra_params": {
        "size": 10000000,
        "operation": "axpy",
        "blas_level": 1,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "int8"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 2.593241623339156,
          "efficiency": 0.04322069372231927,
          "mean_latency_ms": 7.712355000012394,
          "std_latency_ms": 0.7626817953175687,
          "min_latency_ms": 7.44166899994525,
          "max_latency_ms": 8.475036795329963,
          "speedup_vs_fp32": null,
          "test_size": 10000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 7.779724870017469
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 6.302057356993475,
          "efficiency": 0.0033521581686135507,
          "mean_latency_ms": 3.173566800023764,
          "std_latency_ms": 0.005955260761950611,
          "min_latency_ms": 3.161550000186253,
          "max_latency_ms": 3.179522060785714,
          "speedup_vs_fp32": 1.0,
          "test_size": 10000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.16666666666666666,
          "achieved_bandwidth_gbps": 37.81234414196084
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 11.88800053167247,
          "efficiency": 0.0015808511345309134,
          "mean_latency_ms": 1.6823686999941856,
          "std_latency_ms": 0.01042431096749623,
          "min_latency_ms": 1.6727489996810618,
          "max_latency_ms": 1.6927930109616818,
          "speedup_vs_fp32": 1.88636819029903,
          "test_size": 10000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 35.66400159501741
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 11.874763283779197,
          "efficiency": 0.0015790908622046805,
          "mean_latency_ms": 1.6842441000335384,
          "std_latency_ms": 0.010286043545271963,
          "min_latency_ms": 1.6694209998604492,
          "max_latency_ms": 1.6945301435788105,
          "speedup_vs_fp32": 1.8842677257771412,
          "test_size": 10000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 35.62428985133759
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 6.055666471749547,
          "efficiency": 0.0016105495935504115,
          "mean_latency_ms": 3.302691800035973,
          "std_latency_ms": 0.41870986534164584,
          "min_latency_ms": 3.1632139998691855,
          "max_latency_ms": 3.7214016653776185,
          "speedup_vs_fp32": 0.9609031033380703,
          "test_size": 10000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.16666666666666666,
          "achieved_bandwidth_gbps": 36.333998830497286
        },
        "int64": {
          "precision": "int64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 2.6613060865367024,
          "efficiency": 0.0,
          "mean_latency_ms": 7.515106999971977,
          "std_latency_ms": 0.4092733779394298,
          "min_latency_ms": 7.350813999892125,
          "max_latency_ms": 7.924380377911406,
          "speedup_vs_fp32": 0.4222916320467024,
          "test_size": 10000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 7.983918259610108
        },
        "int32": {
          "precision": "int32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 4.774913559047975,
          "efficiency": 0.002539847637791476,
          "mean_latency_ms": 4.188557500083334,
          "std_latency_ms": 1.1478846603743122,
          "min_latency_ms": 3.1715350000922626,
          "max_latency_ms": 5.336442160457646,
          "speedup_vs_fp32": 0.757675357198898,
          "test_size": 10000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 14.324740677143925
        },
        "int16": {
          "precision": "int16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 11.593866171410173,
          "efficiency": 0.001541737522793906,
          "mean_latency_ms": 1.7250501001399243,
          "std_latency_ms": 0.0700734677311871,
          "min_latency_ms": 1.6829260002850788,
          "max_latency_ms": 1.7951235678711115,
          "speedup_vs_fp32": 1.8396954382752972,
          "test_size": 10000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 34.781598514230524
        },
        "int8": {
          "precision": "int8",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 16.70947355280789,
          "efficiency": 0.00111100223090478,
          "mean_latency_ms": 1.1969258000135596,
          "std_latency_ms": 0.007288546070577071,
          "min_latency_ms": 1.1893249998138344,
          "max_latency_ms": 1.2042143460841368,
          "speedup_vs_fp32": 2.651431525653312,
          "test_size": 10000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 50.12842065842367
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas2_gemv_best_precision=bf16_blas_level=2_device=cuda_framework=pytorch_operation=gemv_size=32": {
      "operation_type": "blas2_gemv",
      "measured_gflops": 0.006636164505689259,
      "efficiency": 8.824686842671886e-07,
      "achieved_bandwidth_gbps": 0.007050924787294838,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.9411764705882353,
      "batch_size": 1,
      "input_shape": [
        32,
        32
      ],
      "output_shape": [
        32
      ],
      "mean_latency_ms": 0.3086119999352377,
      "std_latency_ms": 0.014335809767946368,
      "min_latency_ms": 0.2961790000881592,
      "max_latency_ms": 0.32294780970318404,
      "num_trials": 10,
      "extra_params": {
        "size": 32,
        "operation": "gemv",
        "blas_level": 2,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "bf16"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.005762122262357839,
          "efficiency": 9.603537103929732e-05,
          "mean_latency_ms": 0.3554245999566774,
          "std_latency_ms": 0.007599075301837701,
          "min_latency_ms": 0.33966999990298063,
          "max_latency_ms": 0.3630236752585151,
          "speedup_vs_fp32": null,
          "test_size": 32,
          "num_trials": 10,
          "arithmetic_intensity": 0.9411764705882353,
          "achieved_bandwidth_gbps": 0.006122254903755205
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.005721987407676178,
          "efficiency": 3.0436103232320093e-06,
          "mean_latency_ms": 0.3579175999675499,
          "std_latency_ms": 0.01571702728027965,
          "min_latency_ms": 0.32805399996505,
          "max_latency_ms": 0.37363462724782953,
          "speedup_vs_fp32": 1.0,
          "test_size": 32,
          "num_trials": 10,
          "arithmetic_intensity": 0.47058823529411764,
          "achieved_bandwidth_gbps": 0.012159223241311879
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.006585831584657632,
          "efficiency": 8.757754766831957e-07,
          "mean_latency_ms": 0.31097060009415145,
          "std_latency_ms": 0.009453670830981647,
          "min_latency_ms": 0.29992300005687866,
          "max_latency_ms": 0.3204242709251331,
          "speedup_vs_fp32": 1.1509692551616921,
          "test_size": 32,
          "num_trials": 10,
          "arithmetic_intensity": 0.9411764705882353,
          "achieved_bandwidth_gbps": 0.006997446058698733
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.006636164505689259,
          "efficiency": 8.824686842671886e-07,
          "mean_latency_ms": 0.3086119999352377,
          "std_latency_ms": 0.014335809767946368,
          "min_latency_ms": 0.2961790000881592,
          "max_latency_ms": 0.32294780970318404,
          "speedup_vs_fp32": 1.1597656605791706,
          "test_size": 32,
          "num_trials": 10,
          "arithmetic_intensity": 0.9411764705882353,
          "achieved_bandwidth_gbps": 0.007050924787294838
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.006432318379533519,
          "efficiency": 1.7107229732801913e-06,
          "mean_latency_ms": 0.31839220000620116,
          "std_latency_ms": 0.0442481516495039,
          "min_latency_ms": 0.29573099982371787,
          "max_latency_ms": 0.3626403516557051,
          "speedup_vs_fp32": 1.124140603823143,
          "test_size": 32,
          "num_trials": 10,
          "arithmetic_intensity": 0.47058823529411764,
          "achieved_bandwidth_gbps": 0.013668676556508727
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Long'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Int'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Short'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Char'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas2_gemv_best_precision=tf32_blas_level=2_device=cuda_framework=pytorch_operation=gemv_size=64": {
      "operation_type": "blas2_gemv",
      "measured_gflops": 0.02666327299802581,
      "efficiency": 7.091296010113247e-06,
      "achieved_bandwidth_gbps": 0.054993000558428234,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.48484848484848486,
      "batch_size": 1,
      "input_shape": [
        64,
        64
      ],
      "output_shape": [
        64
      ],
      "mean_latency_ms": 0.30723910003871424,
      "std_latency_ms": 0.006682243724500408,
      "min_latency_ms": 0.2980989997922734,
      "max_latency_ms": 0.3139213437632146,
      "num_trials": 10,
      "extra_params": {
        "size": 64,
        "operation": "gemv",
        "blas_level": 2,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "tf32"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.02595837155204751,
          "efficiency": 0.0004326395258674585,
          "mean_latency_ms": 0.3155821998916508,
          "std_latency_ms": 0.015253813222874483,
          "min_latency_ms": 0.2934270000878314,
          "max_latency_ms": 0.3308360131145253,
          "speedup_vs_fp32": null,
          "test_size": 64,
          "num_trials": 10,
          "arithmetic_intensity": 0.9696969696969697,
          "achieved_bandwidth_gbps": 0.026769570663048997
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.02647162799515377,
          "efficiency": 1.408065318891158e-05,
          "mean_latency_ms": 0.3094633998898644,
          "std_latency_ms": 0.01212231717665172,
          "min_latency_ms": 0.28993899968554615,
          "max_latency_ms": 0.3215857170665161,
          "speedup_vs_fp32": 1.0,
          "test_size": 64,
          "num_trials": 10,
          "arithmetic_intensity": 0.48484848484848486,
          "achieved_bandwidth_gbps": 0.05459773274000465
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.01825505963948105,
          "efficiency": 2.427534526526735e-06,
          "mean_latency_ms": 0.44875230000798183,
          "std_latency_ms": 0.4269898853723507,
          "min_latency_ms": 0.29566700004579616,
          "max_latency_ms": 0.8757421853803325,
          "speedup_vs_fp32": 0.6896084986848202,
          "test_size": 64,
          "num_trials": 10,
          "arithmetic_intensity": 0.9696969696969697,
          "achieved_bandwidth_gbps": 0.018825530253214828
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.026388131014778,
          "efficiency": 3.509059975369415e-06,
          "mean_latency_ms": 0.3104425999481464,
          "std_latency_ms": 0.010681189570077788,
          "min_latency_ms": 0.2946109998447355,
          "max_latency_ms": 0.3211237895182242,
          "speedup_vs_fp32": 0.9968457935269015,
          "test_size": 64,
          "num_trials": 10,
          "arithmetic_intensity": 0.9696969696969697,
          "achieved_bandwidth_gbps": 0.027212760108989813
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.02666327299802581,
          "efficiency": 7.091296010113247e-06,
          "mean_latency_ms": 0.30723910003871424,
          "std_latency_ms": 0.006682243724500408,
          "min_latency_ms": 0.2980989997922734,
          "max_latency_ms": 0.3139213437632146,
          "speedup_vs_fp32": 1.007239637959068,
          "test_size": 64,
          "num_trials": 10,
          "arithmetic_intensity": 0.48484848484848486,
          "achieved_bandwidth_gbps": 0.054993000558428234
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Long'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Int'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Short'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Char'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas2_gemv_best_precision=tf32_blas_level=2_device=cuda_framework=pytorch_operation=gemv_size=128": {
      "operation_type": "blas2_gemv",
      "measured_gflops": 0.10953859609180623,
      "efficiency": 2.9132605343565488e-05,
      "achieved_bandwidth_gbps": 0.22250027331148142,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.49230769230769234,
      "batch_size": 1,
      "input_shape": [
        128,
        128
      ],
      "output_shape": [
        128
      ],
      "mean_latency_ms": 0.2991456999552611,
      "std_latency_ms": 0.007909479259542853,
      "min_latency_ms": 0.2897790000133682,
      "max_latency_ms": 0.3070551792148039,
      "num_trials": 10,
      "extra_params": {
        "size": 128,
        "operation": "gemv",
        "blas_level": 2,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "tf32"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.10425956716002845,
          "efficiency": 0.0017376594526671409,
          "mean_latency_ms": 0.31429249988832453,
          "std_latency_ms": 0.014473793836504349,
          "min_latency_ms": 0.2938429997811909,
          "max_latency_ms": 0.32876629372482885,
          "speedup_vs_fp32": null,
          "test_size": 128,
          "num_trials": 10,
          "arithmetic_intensity": 0.9846153846153847,
          "achieved_bandwidth_gbps": 0.10588862289690389
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.04926854227763581,
          "efficiency": 2.6206671424274367e-05,
          "mean_latency_ms": 0.6650896999417455,
          "std_latency_ms": 0.8297750968408075,
          "min_latency_ms": 0.3054280000469589,
          "max_latency_ms": 1.494864796782553,
          "speedup_vs_fp32": 1.0,
          "test_size": 128,
          "num_trials": 10,
          "arithmetic_intensity": 0.49230769230769234,
          "achieved_bandwidth_gbps": 0.10007672650144772
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.10671178991134754,
          "efficiency": 1.4190397594594089e-05,
          "mean_latency_ms": 0.30707010000696755,
          "std_latency_ms": 0.008339438576485655,
          "min_latency_ms": 0.29838799991921405,
          "max_latency_ms": 0.3154095385834532,
          "speedup_vs_fp32": 2.1659213968623265,
          "test_size": 128,
          "num_trials": 10,
          "arithmetic_intensity": 0.9846153846153847,
          "achieved_bandwidth_gbps": 0.10837916162871235
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.1068333155042966,
          "efficiency": 1.4206557912805399e-05,
          "mean_latency_ms": 0.30672080001750146,
          "std_latency_ms": 0.008245796156409196,
          "min_latency_ms": 0.29605100007756846,
          "max_latency_ms": 0.31496659617391065,
          "speedup_vs_fp32": 2.168387992936232,
          "test_size": 128,
          "num_trials": 10,
          "arithmetic_intensity": 0.9846153846153847,
          "achieved_bandwidth_gbps": 0.10850258605905125
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.10953859609180623,
          "efficiency": 2.9132605343565488e-05,
          "mean_latency_ms": 0.2991456999552611,
          "std_latency_ms": 0.007909479259542853,
          "min_latency_ms": 0.2897790000133682,
          "max_latency_ms": 0.3070551792148039,
          "speedup_vs_fp32": 2.223296875205672,
          "test_size": 128,
          "num_trials": 10,
          "arithmetic_intensity": 0.49230769230769234,
          "achieved_bandwidth_gbps": 0.22250027331148142
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Long'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Int'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Short'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Char'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas2_gemv_best_precision=fp64_blas_level=2_device=cuda_framework=pytorch_operation=gemv_size=256": {
      "operation_type": "blas2_gemv",
      "measured_gflops": 0.4275701034362154,
      "efficiency": 0.00712616839060359,
      "achieved_bandwidth_gbps": 0.4309104948693108,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.9922480620155039,
      "batch_size": 1,
      "input_shape": [
        256,
        256
      ],
      "output_shape": [
        256
      ],
      "mean_latency_ms": 0.3065508999497979,
      "std_latency_ms": 0.015139136792842293,
      "min_latency_ms": 0.2911229998971976,
      "max_latency_ms": 0.3216900367426402,
      "num_trials": 10,
      "extra_params": {
        "size": 256,
        "operation": "gemv",
        "blas_level": 2,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "fp64"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.4275701034362154,
          "efficiency": 0.00712616839060359,
          "mean_latency_ms": 0.3065508999497979,
          "std_latency_ms": 0.015139136792842293,
          "min_latency_ms": 0.2911229998971976,
          "max_latency_ms": 0.3216900367426402,
          "speedup_vs_fp32": null,
          "test_size": 256,
          "num_trials": 10,
          "arithmetic_intensity": 0.9922480620155039,
          "achieved_bandwidth_gbps": 0.4309104948693108
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.4228461852839194,
          "efficiency": 0.00022491818366165924,
          "mean_latency_ms": 0.30997560002106184,
          "std_latency_ms": 0.014046151459402283,
          "min_latency_ms": 0.2908349997596815,
          "max_latency_ms": 0.32402175148046414,
          "speedup_vs_fp32": 1.0,
          "test_size": 256,
          "num_trials": 10,
          "arithmetic_intensity": 0.49612403100775193,
          "achieved_bandwidth_gbps": 0.8522993422129
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.4191338543554738,
          "efficiency": 5.573588488769598e-05,
          "mean_latency_ms": 0.31272110004465503,
          "std_latency_ms": 0.009203581444510063,
          "min_latency_ms": 0.29550699991887086,
          "max_latency_ms": 0.3219246814891651,
          "speedup_vs_fp32": 0.9912206115186946,
          "test_size": 256,
          "num_trials": 10,
          "arithmetic_intensity": 0.9922480620155039,
          "achieved_bandwidth_gbps": 0.42240833759262597
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.16571049869476462,
          "efficiency": 2.2035970571112315e-05,
          "mean_latency_ms": 0.7909697999366472,
          "std_latency_ms": 0.6305269773859306,
          "min_latency_ms": 0.29006700015088427,
          "max_latency_ms": 1.4214967773225777,
          "speedup_vs_fp32": 0.3918930912986683,
          "test_size": 256,
          "num_trials": 10,
          "arithmetic_intensity": 0.9922480620155039,
          "achieved_bandwidth_gbps": 0.16700511196581744
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.38585848884794716,
          "efficiency": 0.00010262193852339021,
          "mean_latency_ms": 0.3396893000626733,
          "std_latency_ms": 0.06828960286520178,
          "min_latency_ms": 0.3024520001417841,
          "max_latency_ms": 0.4079789029278751,
          "speedup_vs_fp32": 0.912526829558278,
          "test_size": 256,
          "num_trials": 10,
          "arithmetic_intensity": 0.49612403100775193,
          "achieved_bandwidth_gbps": 0.7777460165841436
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Long'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Int'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Short'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Char'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas2_gemv_best_precision=fp32_blas_level=2_device=cuda_framework=pytorch_operation=gemv_size=512": {
      "operation_type": "blas2_gemv",
      "measured_gflops": 1.6976435142421054,
      "efficiency": 0.0009030018692777156,
      "achieved_bandwidth_gbps": 3.4085498684392266,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.4980544747081712,
      "batch_size": 1,
      "input_shape": [
        512,
        512
      ],
      "output_shape": [
        512
      ],
      "mean_latency_ms": 0.3088328000558249,
      "std_latency_ms": 0.015355207275564912,
      "min_latency_ms": 0.29630700009875,
      "max_latency_ms": 0.3241880073313898,
      "num_trials": 10,
      "extra_params": {
        "size": 512,
        "operation": "gemv",
        "blas_level": 2,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "fp32"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.6841715729914024,
          "efficiency": 0.028069526216523373,
          "mean_latency_ms": 0.3113031999873783,
          "std_latency_ms": 0.007766578825482246,
          "min_latency_ms": 0.2986750000673055,
          "max_latency_ms": 0.3190697788128606,
          "speedup_vs_fp32": null,
          "test_size": 512,
          "num_trials": 10,
          "arithmetic_intensity": 0.9961089494163424,
          "achieved_bandwidth_gbps": 1.6907503681984
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.6976435142421054,
          "efficiency": 0.0009030018692777156,
          "mean_latency_ms": 0.3088328000558249,
          "std_latency_ms": 0.015355207275564912,
          "min_latency_ms": 0.29630700009875,
          "max_latency_ms": 0.3241880073313898,
          "speedup_vs_fp32": 1.0,
          "test_size": 512,
          "num_trials": 10,
          "arithmetic_intensity": 0.4980544747081712,
          "achieved_bandwidth_gbps": 3.4085498684392266
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.6489963475992113,
          "efficiency": 0.0002192814292020228,
          "mean_latency_ms": 0.3179436999744212,
          "std_latency_ms": 0.009258275247146121,
          "min_latency_ms": 0.30219600012060255,
          "max_latency_ms": 0.3272019752215673,
          "speedup_vs_fp32": 0.9713442980020384,
          "test_size": 512,
          "num_trials": 10,
          "arithmetic_intensity": 0.9961089494163424,
          "achieved_bandwidth_gbps": 1.6554377395820208
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.3361339796780408,
          "efficiency": 4.469866751037777e-05,
          "mean_latency_ms": 1.5597589999742922,
          "std_latency_ms": 1.0102786537233999,
          "min_latency_ms": 0.33272600012423936,
          "max_latency_ms": 2.570037653697692,
          "speedup_vs_fp32": 0.19800033214164175,
          "test_size": 512,
          "num_trials": 10,
          "arithmetic_intensity": 0.9961089494163424,
          "achieved_bandwidth_gbps": 0.33744700303615816
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.5984906830958225,
          "efficiency": 0.00042513050082335703,
          "mean_latency_ms": 0.3279893999660999,
          "std_latency_ms": 0.017289375799042384,
          "min_latency_ms": 0.3127559998574725,
          "max_latency_ms": 0.34527877576514227,
          "speedup_vs_fp32": 0.94159384445883,
          "test_size": 512,
          "num_trials": 10,
          "arithmetic_intensity": 0.4980544747081712,
          "achieved_bandwidth_gbps": 3.2094695746533315
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Long'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Int'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Short'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Char'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas2_gemv_best_precision=fp32_blas_level=2_device=cuda_framework=pytorch_operation=gemv_size=1024": {
      "operation_type": "blas2_gemv",
      "measured_gflops": 6.4057121265239845,
      "efficiency": 0.0034072936843212685,
      "achieved_bandwidth_gbps": 12.836446566042204,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.49902534113060426,
      "batch_size": 1,
      "input_shape": [
        1024,
        1024
      ],
      "output_shape": [
        1024
      ],
      "mean_latency_ms": 0.3273877999163233,
      "std_latency_ms": 0.016089141715303918,
      "min_latency_ms": 0.3029320000678126,
      "max_latency_ms": 0.3434769416316272,
      "num_trials": 10,
      "extra_params": {
        "size": 1024,
        "operation": "gemv",
        "blas_level": 2,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "fp32"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 6.186385805755334,
          "efficiency": 0.10310643009592223,
          "mean_latency_ms": 0.33899469995049003,
          "std_latency_ms": 0.007837885737062076,
          "min_latency_ms": 0.3299729996797396,
          "max_latency_ms": 0.3468325856875521,
          "speedup_vs_fp32": null,
          "test_size": 1024,
          "num_trials": 10,
          "arithmetic_intensity": 0.9980506822612085,
          "achieved_bandwidth_gbps": 6.1984685905322
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 6.4057121265239845,
          "efficiency": 0.0034072936843212685,
          "mean_latency_ms": 0.3273877999163233,
          "std_latency_ms": 0.016089141715303918,
          "min_latency_ms": 0.3029320000678126,
          "max_latency_ms": 0.3434769416316272,
          "speedup_vs_fp32": 1.0,
          "test_size": 1024,
          "num_trials": 10,
          "arithmetic_intensity": 0.49902534113060426,
          "achieved_bandwidth_gbps": 12.836446566042204
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 2.2867698093218376,
          "efficiency": 0.0003040917299630103,
          "mean_latency_ms": 0.9170804999484972,
          "std_latency_ms": 0.7644353463811306,
          "min_latency_ms": 0.3228049999961513,
          "max_latency_ms": 1.6815158463296278,
          "speedup_vs_fp32": 0.35698916282126736,
          "test_size": 1024,
          "num_trials": 10,
          "arithmetic_intensity": 0.9980506822612085,
          "achieved_bandwidth_gbps": 2.291236156605669
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 5.623932349208636,
          "efficiency": 0.0007478633443096591,
          "mean_latency_ms": 0.37289779993443517,
          "std_latency_ms": 0.0169573613684337,
          "min_latency_ms": 0.35608700000011595,
          "max_latency_ms": 0.38985516130286885,
          "speedup_vs_fp32": 0.8779558366230273,
          "test_size": 1024,
          "num_trials": 10,
          "arithmetic_intensity": 0.9980506822612085,
          "achieved_bandwidth_gbps": 5.634916592078184
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 6.043075331986809,
          "efficiency": 0.0016072008861667045,
          "mean_latency_ms": 0.3470338999250089,
          "std_latency_ms": 0.018107114021254395,
          "min_latency_ms": 0.3302290001556685,
          "max_latency_ms": 0.3651410139462633,
          "speedup_vs_fp32": 0.9433885277117569,
          "test_size": 1024,
          "num_trials": 10,
          "arithmetic_intensity": 0.49902534113060426,
          "achieved_bandwidth_gbps": 12.109756426989192
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Long'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Int'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Short'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Char'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas2_gemv_best_precision=bf16_blas_level=2_device=cuda_framework=pytorch_operation=gemv_size=2048": {
      "operation_type": "blas2_gemv",
      "measured_gflops": 19.33902134293457,
      "efficiency": 0.002571678370071086,
      "achieved_bandwidth_gbps": 19.357907105964777,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.9990243902439024,
      "batch_size": 1,
      "input_shape": [
        2048,
        2048
      ],
      "output_shape": [
        2048
      ],
      "mean_latency_ms": 0.43376590010666405,
      "std_latency_ms": 0.02436801590720343,
      "min_latency_ms": 0.40095399981510127,
      "max_latency_ms": 0.4581339160138675,
      "num_trials": 10,
      "extra_params": {
        "size": 2048,
        "operation": "gemv",
        "blas_level": 2,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "bf16"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 5.623508583882802,
          "efficiency": 0.09372514306471337,
          "mean_latency_ms": 1.4917036001406814,
          "std_latency_ms": 1.1301018209756608,
          "min_latency_ms": 1.0282910002388235,
          "max_latency_ms": 2.621805421116342,
          "speedup_vs_fp32": null,
          "test_size": 2048,
          "num_trials": 10,
          "arithmetic_intensity": 0.9990243902439024,
          "achieved_bandwidth_gbps": 5.62900029148425
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 4.750277150002222,
          "efficiency": 0.002526743164894799,
          "mean_latency_ms": 1.7659197000739368,
          "std_latency_ms": 1.049028712830857,
          "min_latency_ms": 0.46326199981194804,
          "max_latency_ms": 2.814948412904794,
          "speedup_vs_fp32": 1.0,
          "test_size": 2048,
          "num_trials": 10,
          "arithmetic_intensity": 0.4995121951219512,
          "achieved_bandwidth_gbps": 9.509832185063042
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 15.614695662986263,
          "efficiency": 0.002076422295609875,
          "mean_latency_ms": 0.537225199968816,
          "std_latency_ms": 0.3096924782858376,
          "min_latency_ms": 0.4182029997537029,
          "max_latency_ms": 0.8469176782546537,
          "speedup_vs_fp32": 3.287112555733503,
          "test_size": 2048,
          "num_trials": 10,
          "arithmetic_intensity": 0.9990243902439024,
          "achieved_bandwidth_gbps": 15.629944389219649
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 19.33902134293457,
          "efficiency": 0.002571678370071086,
          "mean_latency_ms": 0.43376590010666405,
          "std_latency_ms": 0.02436801590720343,
          "min_latency_ms": 0.40095399981510127,
          "max_latency_ms": 0.4581339160138675,
          "speedup_vs_fp32": 4.071135374264536,
          "test_size": 2048,
          "num_trials": 10,
          "arithmetic_intensity": 0.9990243902439024,
          "achieved_bandwidth_gbps": 19.357907105964777
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 17.93315104818981,
          "efficiency": 0.004769455066007928,
          "mean_latency_ms": 0.4677710000578372,
          "std_latency_ms": 0.004129978565719919,
          "min_latency_ms": 0.4598689997692418,
          "max_latency_ms": 0.4719009786235571,
          "speedup_vs_fp32": 3.7751799488544413,
          "test_size": 2048,
          "num_trials": 10,
          "arithmetic_intensity": 0.4995121951219512,
          "achieved_bandwidth_gbps": 35.90132778202062
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Long'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Int'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Short'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Char'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas3_gemm_best_precision=fp32_blas_level=3_device=cuda_framework=pytorch_operation=gemm_size=32": {
      "operation_type": "blas3_gemm",
      "measured_gflops": 0.17764280132069812,
      "efficiency": 9.449085176632879e-05,
      "achieved_bandwidth_gbps": 0.03330802524763089,
      "memory_bound": false,
      "compute_bound": true,
      "arithmetic_intensity": 5.333333333333333,
      "batch_size": 1,
      "input_shape": [
        32,
        32
      ],
      "output_shape": [
        32,
        32
      ],
      "mean_latency_ms": 0.36892009984512697,
      "std_latency_ms": 0.02074266644495009,
      "min_latency_ms": 0.3475109997452819,
      "max_latency_ms": 0.38966276629007707,
      "num_trials": 10,
      "extra_params": {
        "size": 32,
        "operation": "gemm",
        "blas_level": 3,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "fp32"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.16279784957868632,
          "efficiency": 0.0027132974929781053,
          "mean_latency_ms": 0.4025605999686377,
          "std_latency_ms": 0.026820963091322876,
          "min_latency_ms": 0.3764400003092305,
          "max_latency_ms": 0.42938156305996056,
          "speedup_vs_fp32": null,
          "test_size": 32,
          "num_trials": 10,
          "arithmetic_intensity": 10.666666666666666,
          "achieved_bandwidth_gbps": 0.015262298398001844
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.17764280132069812,
          "efficiency": 9.449085176632879e-05,
          "mean_latency_ms": 0.36892009984512697,
          "std_latency_ms": 0.02074266644495009,
          "min_latency_ms": 0.3475109997452819,
          "max_latency_ms": 0.38966276629007707,
          "speedup_vs_fp32": 1.0,
          "test_size": 32,
          "num_trials": 10,
          "arithmetic_intensity": 5.333333333333333,
          "achieved_bandwidth_gbps": 0.03330802524763089
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.17373494340429294,
          "efficiency": 2.310305098461342e-05,
          "mean_latency_ms": 0.3772182999910001,
          "std_latency_ms": 0.010943804318147404,
          "min_latency_ms": 0.3671919998851081,
          "max_latency_ms": 0.3881621043091475,
          "speedup_vs_fp32": 0.9780015970962407,
          "test_size": 32,
          "num_trials": 10,
          "arithmetic_intensity": 10.666666666666666,
          "achieved_bandwidth_gbps": 0.016287650944152462
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.056479320659561634,
          "efficiency": 7.510547960048089e-06,
          "mean_latency_ms": 1.160353900058908,
          "std_latency_ms": 0.9063307162015054,
          "min_latency_ms": 0.3635759999269794,
          "max_latency_ms": 2.0666846162604133,
          "speedup_vs_fp32": 0.3179375704484622,
          "test_size": 32,
          "num_trials": 10,
          "arithmetic_intensity": 10.666666666666666,
          "achieved_bandwidth_gbps": 0.005294936311833903
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.11864403713059106,
          "efficiency": 3.1554265194306134e-05,
          "mean_latency_ms": 0.552374999915628,
          "std_latency_ms": 0.3374139544068409,
          "min_latency_ms": 0.4217550003886572,
          "max_latency_ms": 0.8897889543224689,
          "speedup_vs_fp32": 0.6678797916297394,
          "test_size": 32,
          "num_trials": 10,
          "arithmetic_intensity": 5.333333333333333,
          "achieved_bandwidth_gbps": 0.022245756961985826
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmm_cuda\" not implemented for 'Long'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmm_cuda\" not implemented for 'Int'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmm_cuda\" not implemented for 'Short'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmm_cuda\" not implemented for 'Char'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas3_gemm_best_precision=tf32_blas_level=3_device=cuda_framework=pytorch_operation=gemm_size=64": {
      "operation_type": "blas3_gemm",
      "measured_gflops": 1.3354301314326484,
      "efficiency": 0.00035516758814698097,
      "achieved_bandwidth_gbps": 0.1251965748218108,
      "memory_bound": false,
      "compute_bound": true,
      "arithmetic_intensity": 10.666666666666666,
      "batch_size": 1,
      "input_shape": [
        64,
        64
      ],
      "output_shape": [
        64,
        64
      ],
      "mean_latency_ms": 0.39259860000129265,
      "std_latency_ms": 0.027752366596864544,
      "min_latency_ms": 0.3706170000441489,
      "max_latency_ms": 0.4203509665981572,
      "num_trials": 10,
      "extra_params": {
        "size": 64,
        "operation": "gemm",
        "blas_level": 3,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "tf32"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.2362889167819235,
          "efficiency": 0.020604815279698725,
          "mean_latency_ms": 0.4240820999712014,
          "std_latency_ms": 0.007872691317901977,
          "min_latency_ms": 0.4128909999963071,
          "max_latency_ms": 0.43195479128910336,
          "speedup_vs_fp32": null,
          "test_size": 64,
          "num_trials": 10,
          "arithmetic_intensity": 21.333333333333332,
          "achieved_bandwidth_gbps": 0.05795104297415267
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.4006870912909694,
          "efficiency": 0.00021313143153774968,
          "mean_latency_ms": 1.3084724000236747,
          "std_latency_ms": 0.9154697625922776,
          "min_latency_ms": 0.38079300020399387,
          "max_latency_ms": 2.2239421626159523,
          "speedup_vs_fp32": 1.0,
          "test_size": 64,
          "num_trials": 10,
          "arithmetic_intensity": 10.666666666666666,
          "achieved_bandwidth_gbps": 0.03756441480852838
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.8725978045705293,
          "efficiency": 0.00011603694209714486,
          "mean_latency_ms": 0.6008358000144653,
          "std_latency_ms": 0.44546539032014987,
          "min_latency_ms": 0.4455319999578933,
          "max_latency_ms": 1.0463011903346153,
          "speedup_vs_fp32": 2.1777537223850056,
          "test_size": 64,
          "num_trials": 10,
          "arithmetic_intensity": 21.333333333333332,
          "achieved_bandwidth_gbps": 0.040903022089243554
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.1516356434107617,
          "efficiency": 0.00015314303768760128,
          "mean_latency_ms": 0.45525509999606584,
          "std_latency_ms": 0.017777409469548387,
          "min_latency_ms": 0.4270350000297185,
          "max_latency_ms": 0.4730325094656142,
          "speedup_vs_fp32": 2.8741520963411107,
          "test_size": 64,
          "num_trials": 10,
          "arithmetic_intensity": 21.333333333333332,
          "achieved_bandwidth_gbps": 0.053982920784879464
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.3354301314326484,
          "efficiency": 0.00035516758814698097,
          "mean_latency_ms": 0.39259860000129265,
          "std_latency_ms": 0.027752366596864544,
          "min_latency_ms": 0.3706170000441489,
          "max_latency_ms": 0.4203509665981572,
          "speedup_vs_fp32": 3.332850397376268,
          "test_size": 64,
          "num_trials": 10,
          "arithmetic_intensity": 10.666666666666666,
          "achieved_bandwidth_gbps": 0.1251965748218108
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmm_cuda\" not implemented for 'Long'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmm_cuda\" not implemented for 'Int'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmm_cuda\" not implemented for 'Short'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmm_cuda\" not implemented for 'Char'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas3_gemm_best_precision=fp32_blas_level=3_device=cuda_framework=pytorch_operation=gemm_size=128": {
      "operation_type": "blas3_gemm",
      "measured_gflops": 12.661430593581569,
      "efficiency": 0.0067348035072242384,
      "achieved_bandwidth_gbps": 0.5935045590741361,
      "memory_bound": false,
      "compute_bound": true,
      "arithmetic_intensity": 21.333333333333332,
      "batch_size": 1,
      "input_shape": [
        128,
        128
      ],
      "output_shape": [
        128,
        128
      ],
      "mean_latency_ms": 0.3312662000553246,
      "std_latency_ms": 0.013543793602912033,
      "min_latency_ms": 0.31781300003785873,
      "max_latency_ms": 0.3448099936582366,
      "num_trials": 10,
      "extra_params": {
        "size": 128,
        "operation": "gemm",
        "blas_level": 3,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "fp32"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 9.654126956639045,
          "efficiency": 0.1609021159439841,
          "mean_latency_ms": 0.4344570999364805,
          "std_latency_ms": 0.00538441456796615,
          "min_latency_ms": 0.42492399961702176,
          "max_latency_ms": 0.43984151450444664,
          "speedup_vs_fp32": null,
          "test_size": 128,
          "num_trials": 10,
          "arithmetic_intensity": 42.666666666666664,
          "achieved_bandwidth_gbps": 0.22626860054622763
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 12.661430593581569,
          "efficiency": 0.0067348035072242384,
          "mean_latency_ms": 0.3312662000553246,
          "std_latency_ms": 0.013543793602912033,
          "min_latency_ms": 0.31781300003785873,
          "max_latency_ms": 0.3448099936582366,
          "speedup_vs_fp32": 1.0,
          "test_size": 128,
          "num_trials": 10,
          "arithmetic_intensity": 21.333333333333332,
          "achieved_bandwidth_gbps": 0.5935045590741361
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 10.597928477001775,
          "efficiency": 0.0014092989996012998,
          "mean_latency_ms": 0.3957663999244687,
          "std_latency_ms": 0.04827384947877673,
          "min_latency_ms": 0.3413340000406606,
          "max_latency_ms": 0.44404024940324544,
          "speedup_vs_fp32": 0.8370245683275442,
          "test_size": 128,
          "num_trials": 10,
          "arithmetic_intensity": 42.666666666666664,
          "achieved_bandwidth_gbps": 0.24838894867972908
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 3.0832955053996858,
          "efficiency": 0.00041001270018612844,
          "mean_latency_ms": 1.360331500063694,
          "std_latency_ms": 0.997579607667958,
          "min_latency_ms": 0.34792700034813606,
          "max_latency_ms": 2.3579111077316517,
          "speedup_vs_fp32": 0.2435187305739917,
          "test_size": 128,
          "num_trials": 10,
          "arithmetic_intensity": 42.666666666666664,
          "achieved_bandwidth_gbps": 0.07226473840780513
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 7.8106001577103585,
          "efficiency": 0.0020772872759867974,
          "mean_latency_ms": 0.5370014999243722,
          "std_latency_ms": 0.3684041994128239,
          "min_latency_ms": 0.3955779998250364,
          "max_latency_ms": 0.9054056993371961,
          "speedup_vs_fp32": 0.6168813310614181,
          "test_size": 128,
          "num_trials": 10,
          "arithmetic_intensity": 21.333333333333332,
          "achieved_bandwidth_gbps": 0.36612188239267307
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmm_cuda\" not implemented for 'Long'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmm_cuda\" not implemented for 'Int'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmm_cuda\" not implemented for 'Short'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmm_cuda\" not implemented for 'Char'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas3_gemm_best_precision=tf32_blas_level=3_device=cuda_framework=pytorch_operation=gemm_size=256": {
      "operation_type": "blas3_gemm",
      "measured_gflops": 77.87950625782014,
      "efficiency": 0.02071263464303727,
      "achieved_bandwidth_gbps": 1.8253009279176595,
      "memory_bound": false,
      "compute_bound": true,
      "arithmetic_intensity": 42.666666666666664,
      "batch_size": 1,
      "input_shape": [
        256,
        256
      ],
      "output_shape": [
        256,
        256
      ],
      "mean_latency_ms": 0.43085060001430975,
      "std_latency_ms": 0.02780729546540763,
      "min_latency_ms": 0.3928260002794559,
      "max_latency_ms": 0.45865789547971736,
      "num_trials": 10,
      "extra_params": {
        "size": 256,
        "operation": "gemm",
        "blas_level": 3,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "tf32"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 10.492117895225212,
          "efficiency": 0.17486863158708685,
          "mean_latency_ms": 3.198060900103883,
          "std_latency_ms": 2.2407844503765775,
          "min_latency_ms": 1.5568700000585523,
          "max_latency_ms": 5.43884535048046,
          "speedup_vs_fp32": null,
          "test_size": 256,
          "num_trials": 10,
          "arithmetic_intensity": 85.33333333333333,
          "achieved_bandwidth_gbps": 0.12295450658467046
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 62.49039861067262,
          "efficiency": 0.03323957372908118,
          "mean_latency_ms": 0.5369533999783016,
          "std_latency_ms": 0.0273720571547852,
          "min_latency_ms": 0.5141779997757112,
          "max_latency_ms": 0.5643254571330868,
          "speedup_vs_fp32": 1.0,
          "test_size": 256,
          "num_trials": 10,
          "arithmetic_intensity": 42.666666666666664,
          "achieved_bandwidth_gbps": 1.4646187174376395
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 62.91750139754796,
          "efficiency": 0.008366689015631378,
          "mean_latency_ms": 0.5333083999630617,
          "std_latency_ms": 0.02987659268848235,
          "min_latency_ms": 0.4795830000148271,
          "max_latency_ms": 0.563184992651544,
          "speedup_vs_fp32": 1.0068346945510185,
          "test_size": 256,
          "num_trials": 10,
          "arithmetic_intensity": 85.33333333333333,
          "achieved_bandwidth_gbps": 0.7373144695025151
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 75.67669141886009,
          "efficiency": 0.010063389816337778,
          "mean_latency_ms": 0.44339190008031437,
          "std_latency_ms": 0.014693696971947714,
          "min_latency_ms": 0.420667000071262,
          "max_latency_ms": 0.4580855970522621,
          "speedup_vs_fp32": 1.2110131012340095,
          "test_size": 256,
          "num_trials": 10,
          "arithmetic_intensity": 85.33333333333333,
          "achieved_bandwidth_gbps": 0.8868362275647668
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 77.87950625782014,
          "efficiency": 0.02071263464303727,
          "mean_latency_ms": 0.43085060001430975,
          "std_latency_ms": 0.02780729546540763,
          "min_latency_ms": 0.3928260002794559,
          "max_latency_ms": 0.45865789547971736,
          "speedup_vs_fp32": 1.246263553910492,
          "test_size": 256,
          "num_trials": 10,
          "arithmetic_intensity": 42.666666666666664,
          "achieved_bandwidth_gbps": 1.8253009279176595
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmm_cuda\" not implemented for 'Long'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmm_cuda\" not implemented for 'Int'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmm_cuda\" not implemented for 'Short'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmm_cuda\" not implemented for 'Char'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas3_gemm_best_precision=fp16_blas_level=3_device=cuda_framework=pytorch_operation=gemm_size=512": {
      "operation_type": "blas3_gemm",
      "measured_gflops": 499.25392594304327,
      "efficiency": 0.06639014972646852,
      "achieved_bandwidth_gbps": 2.9253159723225193,
      "memory_bound": false,
      "compute_bound": true,
      "arithmetic_intensity": 170.66666666666666,
      "batch_size": 1,
      "input_shape": [
        512,
        512
      ],
      "output_shape": [
        512,
        512
      ],
      "mean_latency_ms": 0.5376732000513584,
      "std_latency_ms": 0.015722431059959793,
      "min_latency_ms": 0.5237780001152714,
      "max_latency_ms": 0.5533956311113182,
      "num_trials": 10,
      "extra_params": {
        "size": 512,
        "operation": "gemm",
        "blas_level": 3,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "fp16"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 22.695649444179576,
          "efficiency": 0.3782608240696596,
          "mean_latency_ms": 11.827617299968551,
          "std_latency_ms": 1.2640362399455733,
          "min_latency_ms": 11.09576199996809,
          "max_latency_ms": 13.091653539914125,
          "speedup_vs_fp32": null,
          "test_size": 512,
          "num_trials": 10,
          "arithmetic_intensity": 170.66666666666666,
          "achieved_bandwidth_gbps": 0.1329823209619897
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 487.93343314429217,
          "efficiency": 0.2595390601831341,
          "mean_latency_ms": 0.5501477000052546,
          "std_latency_ms": 0.017699897739245567,
          "min_latency_ms": 0.5121290000715817,
          "max_latency_ms": 0.5678475977445001,
          "speedup_vs_fp32": 1.0,
          "test_size": 512,
          "num_trials": 10,
          "arithmetic_intensity": 85.33333333333333,
          "achieved_bandwidth_gbps": 5.717969919659674
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 499.25392594304327,
          "efficiency": 0.06639014972646852,
          "mean_latency_ms": 0.5376732000513584,
          "std_latency_ms": 0.015722431059959793,
          "min_latency_ms": 0.5237780001152714,
          "max_latency_ms": 0.5533956311113182,
          "speedup_vs_fp32": 1.023200895920988,
          "test_size": 512,
          "num_trials": 10,
          "arithmetic_intensity": 170.66666666666666,
          "achieved_bandwidth_gbps": 2.9253159723225193
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 497.1645655536338,
          "efficiency": 0.06611230924915343,
          "mean_latency_ms": 0.5399328001203685,
          "std_latency_ms": 0.02325979647647944,
          "min_latency_ms": 0.510177000251133,
          "max_latency_ms": 0.563192596596848,
          "speedup_vs_fp32": 1.0189188356080772,
          "test_size": 512,
          "num_trials": 10,
          "arithmetic_intensity": 170.66666666666666,
          "achieved_bandwidth_gbps": 2.913073626290823
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 498.22767586948635,
          "efficiency": 0.13250736060358678,
          "mean_latency_ms": 0.5387807000715839,
          "std_latency_ms": 0.02089660379647793,
          "min_latency_ms": 0.5130260001351417,
          "max_latency_ms": 0.5596773038680618,
          "speedup_vs_fp32": 1.0210976375585847,
          "test_size": 512,
          "num_trials": 10,
          "arithmetic_intensity": 85.33333333333333,
          "achieved_bandwidth_gbps": 5.838605576595543
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmm_cuda\" not implemented for 'Long'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmm_cuda\" not implemented for 'Int'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmm_cuda\" not implemented for 'Short'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmm_cuda\" not implemented for 'Char'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas3_gemm_best_precision=fp16_blas_level=3_device=cuda_framework=pytorch_operation=gemm_size=1024": {
      "operation_type": "blas3_gemm",
      "measured_gflops": 2842.1699547270123,
      "efficiency": 0.3779481322775282,
      "achieved_bandwidth_gbps": 8.326669789239293,
      "memory_bound": false,
      "compute_bound": true,
      "arithmetic_intensity": 341.3333333333333,
      "batch_size": 1,
      "input_shape": [
        1024,
        1024
      ],
      "output_shape": [
        1024,
        1024
      ],
      "mean_latency_ms": 0.7555788999979995,
      "std_latency_ms": 0.005252440345916984,
      "min_latency_ms": 0.7494249998671876,
      "max_latency_ms": 0.7608313403439165,
      "num_trials": 10,
      "extra_params": {
        "size": 1024,
        "operation": "gemm",
        "blas_level": 3,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "fp16"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 23.890089027835092,
          "efficiency": 0.3981681504639182,
          "mean_latency_ms": 89.89014839994525,
          "std_latency_ms": 4.281611700707021,
          "min_latency_ms": 86.67426800002431,
          "max_latency_ms": 94.17176010065226,
          "speedup_vs_fp32": null,
          "test_size": 1024,
          "num_trials": 10,
          "arithmetic_intensity": 341.3333333333333,
          "achieved_bandwidth_gbps": 0.06999049519873562
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 827.4659474525313,
          "efficiency": 0.4401414614109209,
          "mean_latency_ms": 2.5952531999791972,
          "std_latency_ms": 0.0036914158895617784,
          "min_latency_ms": 2.5886160001391545,
          "max_latency_ms": 2.598944615868759,
          "speedup_vs_fp32": 1.0,
          "test_size": 1024,
          "num_trials": 10,
          "arithmetic_intensity": 170.66666666666666,
          "achieved_bandwidth_gbps": 4.848433285854675
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 2842.1699547270123,
          "efficiency": 0.3779481322775282,
          "mean_latency_ms": 0.7555788999979995,
          "std_latency_ms": 0.005252440345916984,
          "min_latency_ms": 0.7494249998671876,
          "max_latency_ms": 0.7608313403439165,
          "speedup_vs_fp32": 3.434787816316825,
          "test_size": 1024,
          "num_trials": 10,
          "arithmetic_intensity": 341.3333333333333,
          "achieved_bandwidth_gbps": 8.326669789239293
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 2593.9824801328377,
          "efficiency": 0.34494447874106887,
          "mean_latency_ms": 0.8278712999981508,
          "std_latency_ms": 0.010674713709969167,
          "min_latency_ms": 0.8087560004241823,
          "max_latency_ms": 0.83854601370812,
          "speedup_vs_fp32": 3.1348510329866417,
          "test_size": 1024,
          "num_trials": 10,
          "arithmetic_intensity": 341.3333333333333,
          "achieved_bandwidth_gbps": 7.599558047264175
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1566.0946552756668,
          "efficiency": 0.416514535977571,
          "mean_latency_ms": 1.371234899988849,
          "std_latency_ms": 0.006220319773854756,
          "min_latency_ms": 1.35868000006667,
          "max_latency_ms": 1.377455219762704,
          "speedup_vs_fp32": 1.8926394011706542,
          "test_size": 1024,
          "num_trials": 10,
          "arithmetic_intensity": 170.66666666666666,
          "achieved_bandwidth_gbps": 9.17633587075586
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmm_cuda\" not implemented for 'Long'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmm_cuda\" not implemented for 'Int'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmm_cuda\" not implemented for 'Short'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmm_cuda\" not implemented for 'Char'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas3_gemm_best_precision=bf16_blas_level=3_device=cuda_framework=pytorch_operation=gemm_size=2048": {
      "operation_type": "blas3_gemm",
      "measured_gflops": 6314.757934627888,
      "efficiency": 0.8397284487537086,
      "achieved_bandwidth_gbps": 9.25013369330257,
      "memory_bound": false,
      "compute_bound": true,
      "arithmetic_intensity": 682.6666666666666,
      "batch_size": 1,
      "input_shape": [
        2048,
        2048
      ],
      "output_shape": [
        2048,
        2048
      ],
      "mean_latency_ms": 2.7205903000321996,
      "std_latency_ms": 0.19221753012994186,
      "min_latency_ms": 2.6148550000471005,
      "max_latency_ms": 2.9128078301621416,
      "num_trials": 10,
      "extra_params": {
        "size": 2048,
        "operation": "gemm",
        "blas_level": 3,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "bf16"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 24.350634670145705,
          "efficiency": 0.4058439111690951,
          "mean_latency_ms": 705.5203864999385,
          "std_latency_ms": 6.882435972672317,
          "min_latency_ms": 696.9718350001131,
          "max_latency_ms": 712.4028224726108,
          "speedup_vs_fp32": null,
          "test_size": 2048,
          "num_trials": 10,
          "arithmetic_intensity": 682.6666666666666,
          "achieved_bandwidth_gbps": 0.03566987500509625
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1010.611714639407,
          "efficiency": 0.5375594226805356,
          "mean_latency_ms": 16.99947559991415,
          "std_latency_ms": 0.0952776142611993,
          "min_latency_ms": 16.84792700007165,
          "max_latency_ms": 17.09475321417535,
          "speedup_vs_fp32": 1.0,
          "test_size": 2048,
          "num_trials": 10,
          "arithmetic_intensity": 341.3333333333333,
          "achieved_bandwidth_gbps": 2.9607765077326373
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 5081.672740877603,
          "efficiency": 0.6757543538401068,
          "mean_latency_ms": 3.3807507999881636,
          "std_latency_ms": 0.767585690281319,
          "min_latency_ms": 2.93039600001066,
          "max_latency_ms": 4.148336490269482,
          "speedup_vs_fp32": 5.028313710662633,
          "test_size": 2048,
          "num_trials": 10,
          "arithmetic_intensity": 682.6666666666666,
          "achieved_bandwidth_gbps": 7.443856554019926
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 6314.757934627888,
          "efficiency": 0.8397284487537086,
          "mean_latency_ms": 2.7205903000321996,
          "std_latency_ms": 0.19221753012994186,
          "min_latency_ms": 2.6148550000471005,
          "max_latency_ms": 2.9128078301621416,
          "speedup_vs_fp32": 6.248451154042912,
          "test_size": 2048,
          "num_trials": 10,
          "arithmetic_intensity": 682.6666666666666,
          "achieved_bandwidth_gbps": 9.25013369330257
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 3009.6508893365435,
          "efficiency": 0.8004390663129105,
          "mean_latency_ms": 5.708259800121596,
          "std_latency_ms": 0.30521240098024,
          "min_latency_ms": 5.600005999895075,
          "max_latency_ms": 6.013472201101836,
          "speedup_vs_fp32": 2.9780486864932167,
          "test_size": 2048,
          "num_trials": 10,
          "arithmetic_intensity": 341.3333333333333,
          "achieved_bandwidth_gbps": 8.817336589853154
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmm_cuda\" not implemented for 'Long'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmm_cuda\" not implemented for 'Int'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmm_cuda\" not implemented for 'Short'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmm_cuda\" not implemented for 'Char'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    }
  },
  "fusion_profiles": {},
  "precision_matrix": {
    "hardware_name": "Jetson Orin Nano (GPU)",
    "supported_precisions": [
      "fp64",
      "fp32",
      "tf32",
      "fp16",
      "bf16",
      "int64",
      "int32",
      "int16",
      "int8"
    ],
    "unsupported_precisions": [
      "fp8",
      "fp4",
      "int4"
    ],
    "peak_gflops_by_precision": {
      "fp64": 24.350634670145705,
      "fp32": 1010.611714639407,
      "fp16": 5081.672740877603,
      "bf16": 6314.757934627888,
      "tf32": 3009.6508893365435,
      "int64": 2.6613060865367024,
      "int32": 4.774913559047975,
      "int16": 11.593866171410173,
      "int8": 16.70947355280789
    },
    "speedup_vs_fp32": {
      "fp32": 1.0,
      "fp16": 5.028313710662633,
      "bf16": 6.248451154042912,
      "tf32": 2.9780486864932167,
      "int64": 0.4222916320467024,
      "int32": 0.757675357198898,
      "int16": 1.8396954382752972,
      "int8": 2.651431525653312
    },
    "theoretical_peaks": {
      "fp64": 60.0,
      "fp32": 1880.0,
      "fp16": 7520.0,
      "fp8": 0.0,
      "fp4": 0.0,
      "bf16": 7520.0,
      "tf32": 3760.0,
      "int64": 0.0,
      "int32": 1880.0,
      "int16": 7520.0,
      "int8": 15040.0,
      "int4": 0.0
    }
  }
}