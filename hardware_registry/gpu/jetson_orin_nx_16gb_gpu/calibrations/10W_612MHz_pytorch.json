{
  "metadata": {
    "hardware_name": "Jetson Orin NX 16GB (GPU)",
    "calibration_date": "2026-01-28T09:56:46.035468",
    "calibration_tool_version": "1.0.0",
    "cpu_model": "aarch64",
    "cpu_count": 4,
    "total_memory_gb": 15.28970718383789,
    "python_version": "3.10.12",
    "pytorch_version": "2.4.0a0+3bcc3cddb5.nv24.07",
    "numpy_version": "1.26.4",
    "num_warmup_runs": 3,
    "num_measurement_runs": 10,
    "device_type": "cuda",
    "platform_architecture": "aarch64",
    "framework": "pytorch",
    "gpu_clock": {
      "sm_clock_mhz": 612,
      "query_method": "sysfs_under_load",
      "max_sm_clock_mhz": 612,
      "nvpmodel_mode": 10,
      "power_mode_name": "10W"
    },
    "cpu_clock": {
      "current_freq_mhz": 960.0000000000002,
      "query_method": "sysfs",
      "min_freq_mhz": 729.6,
      "max_freq_mhz": 1190.4,
      "base_freq_mhz": 1984.0,
      "per_core_freq_mhz": [
        1190.4,
        1190.4,
        1190.4,
        1190.4,
        729.6,
        729.6,
        729.6,
        729.6
      ],
      "governor": "schedutil",
      "driver": "tegra194"
    },
    "preflight": {
      "timestamp": "2026-01-28T09:56:44.812040",
      "passed": false,
      "forced": true,
      "checks": [
        {
          "name": "CPU Governor",
          "status": "passed",
          "message": "schedutil (Jetson default)",
          "current_value": "schedutil",
          "expected_value": "schedutil or performance"
        },
        {
          "name": "CPU Frequency",
          "status": "passed",
          "message": "960 MHz idle (DVFS will boost under load)",
          "current_value": "960 MHz (idle)",
          "expected_value": "Up to 1190 MHz under load"
        },
        {
          "name": "Turbo Boost",
          "status": "skipped",
          "message": "Could not determine (not Intel pstate)"
        },
        {
          "name": "System Load",
          "status": "failed",
          "message": "53.4% (high - will affect results)",
          "current_value": "53.4%",
          "expected_value": "< 5%"
        },
        {
          "name": "Thermal State",
          "status": "passed",
          "message": "42\u00b0C (cool)",
          "current_value": "42\u00b0C",
          "expected_value": "< 80\u00b0C"
        },
        {
          "name": "GPU Power Mode",
          "status": "passed",
          "message": "10W (power-limited profile)"
        }
      ]
    }
  },
  "theoretical_peak_gflops": 1882.0,
  "theoretical_bandwidth_gbps": 102.0,
  "best_measured_gflops": 2170.3080723067374,
  "avg_measured_gflops": 86.52746864527921,
  "worst_measured_gflops": 0.005521291626612448,
  "measured_bandwidth_gbps": 60.49383719135949,
  "bandwidth_efficiency": 0.5930768352094068,
  "best_efficiency": 0.5930768352094068,
  "avg_efficiency": 0.22361606094006475,
  "worst_efficiency": 1.4672579395728004e-06,
  "operation_profiles": {
    "stream_copy_device=cuda_flops_per_element=0_framework=pytorch_kernel=copy_num_arrays=2_num_memory_ops=2_size_mb=8": {
      "operation_type": "stream_copy",
      "measured_gflops": 0.0,
      "efficiency": 0.16704962825930644,
      "achieved_bandwidth_gbps": 17.039062082449256,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.0,
      "batch_size": 1,
      "input_shape": [
        2097152
      ],
      "output_shape": [
        2097152
      ],
      "mean_latency_ms": 0.9846326000115369,
      "std_latency_ms": 0.46817096226879684,
      "min_latency_ms": 0.6041429951437749,
      "max_latency_ms": 1.9737769980565645,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 8,
        "kernel": "copy",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 2,
        "num_memory_ops": 2,
        "flops_per_element": 0
      },
      "precision_results": {}
    },
    "stream_copy_device=cuda_flops_per_element=0_framework=pytorch_kernel=copy_num_arrays=2_num_memory_ops=2_size_mb=16": {
      "operation_type": "stream_copy",
      "measured_gflops": 0.0,
      "efficiency": 0.2965043998478565,
      "achieved_bandwidth_gbps": 30.24344878448136,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.0,
      "batch_size": 1,
      "input_shape": [
        4194304
      ],
      "output_shape": [
        4194304
      ],
      "mean_latency_ms": 1.1094777000835165,
      "std_latency_ms": 0.026792321436848402,
      "min_latency_ms": 1.0860109978239052,
      "max_latency_ms": 1.1804780006059445,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 16,
        "kernel": "copy",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 2,
        "num_memory_ops": 2,
        "flops_per_element": 0
      },
      "precision_results": {}
    },
    "stream_copy_device=cuda_flops_per_element=0_framework=pytorch_kernel=copy_num_arrays=2_num_memory_ops=2_size_mb=32": {
      "operation_type": "stream_copy",
      "measured_gflops": 0.0,
      "efficiency": 0.31035110660673265,
      "achieved_bandwidth_gbps": 31.65581287388673,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.0,
      "batch_size": 1,
      "input_shape": [
        8388608
      ],
      "output_shape": [
        8388608
      ],
      "mean_latency_ms": 2.1199539012741297,
      "std_latency_ms": 0.033223463296727,
      "min_latency_ms": 2.089589004754089,
      "max_latency_ms": 2.191511004639324,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 32,
        "kernel": "copy",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 2,
        "num_memory_ops": 2,
        "flops_per_element": 0
      },
      "precision_results": {}
    },
    "stream_copy_device=cuda_flops_per_element=0_framework=pytorch_kernel=copy_num_arrays=2_num_memory_ops=2_size_mb=64": {
      "operation_type": "stream_copy",
      "measured_gflops": 0.0,
      "efficiency": 0.31879586956054645,
      "achieved_bandwidth_gbps": 32.51717869517574,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.0,
      "batch_size": 1,
      "input_shape": [
        16777216
      ],
      "output_shape": [
        16777216
      ],
      "mean_latency_ms": 4.127594501915155,
      "std_latency_ms": 0.07099876253522798,
      "min_latency_ms": 4.066950001288205,
      "max_latency_ms": 4.2764270037878305,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 64,
        "kernel": "copy",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 2,
        "num_memory_ops": 2,
        "flops_per_element": 0
      },
      "precision_results": {}
    },
    "stream_copy_device=cuda_flops_per_element=0_framework=pytorch_kernel=copy_num_arrays=2_num_memory_ops=2_size_mb=128": {
      "operation_type": "stream_copy",
      "measured_gflops": 0.0,
      "efficiency": 0.31871568880299417,
      "achieved_bandwidth_gbps": 32.509000257905406,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.0,
      "batch_size": 1,
      "input_shape": [
        33554432
      ],
      "output_shape": [
        33554432
      ],
      "mean_latency_ms": 8.257265799329616,
      "std_latency_ms": 0.4596678105911781,
      "min_latency_ms": 8.03706499573309,
      "max_latency_ms": 9.557103003317025,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 128,
        "kernel": "copy",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 2,
        "num_memory_ops": 2,
        "flops_per_element": 0
      },
      "precision_results": {}
    },
    "stream_copy_device=cuda_flops_per_element=0_framework=pytorch_kernel=copy_num_arrays=2_num_memory_ops=2_size_mb=256": {
      "operation_type": "stream_copy",
      "measured_gflops": 0.0,
      "efficiency": 0.2986510512874064,
      "achieved_bandwidth_gbps": 30.46240723131545,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.0,
      "batch_size": 1,
      "input_shape": [
        67108864
      ],
      "output_shape": [
        67108864
      ],
      "mean_latency_ms": 17.62404749970301,
      "std_latency_ms": 0.046046235325375856,
      "min_latency_ms": 17.56888799718581,
      "max_latency_ms": 17.71269900200423,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 256,
        "kernel": "copy",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 2,
        "num_memory_ops": 2,
        "flops_per_element": 0
      },
      "precision_results": {}
    },
    "stream_copy_device=cuda_flops_per_element=0_framework=pytorch_kernel=copy_num_arrays=2_num_memory_ops=2_size_mb=512": {
      "operation_type": "stream_copy",
      "measured_gflops": 0.0,
      "efficiency": 0.3000140432118887,
      "achieved_bandwidth_gbps": 30.601432407612645,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.0,
      "batch_size": 1,
      "input_shape": [
        134217728
      ],
      "output_shape": [
        134217728
      ],
      "mean_latency_ms": 35.08795959933195,
      "std_latency_ms": 0.08573687177433839,
      "min_latency_ms": 34.994027999346144,
      "max_latency_ms": 35.27656300138915,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 512,
        "kernel": "copy",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 2,
        "num_memory_ops": 2,
        "flops_per_element": 0
      },
      "precision_results": {}
    },
    "stream_scale_device=cuda_flops_per_element=1_framework=pytorch_kernel=scale_num_arrays=2_num_memory_ops=2_size_mb=8": {
      "operation_type": "stream_scale",
      "measured_gflops": 4.932846875223602,
      "efficiency": 0.38688995099792955,
      "achieved_bandwidth_gbps": 39.46277500178881,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.5,
      "batch_size": 1,
      "input_shape": [
        2097152
      ],
      "output_shape": [
        2097152
      ],
      "mean_latency_ms": 0.4251402999216225,
      "std_latency_ms": 0.052524389042483445,
      "min_latency_ms": 0.3895129993907176,
      "max_latency_ms": 0.5327499966369942,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 8,
        "kernel": "scale",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 2,
        "num_memory_ops": 2,
        "flops_per_element": 1
      },
      "precision_results": {}
    },
    "stream_scale_device=cuda_flops_per_element=1_framework=pytorch_kernel=scale_num_arrays=2_num_memory_ops=2_size_mb=16": {
      "operation_type": "stream_scale",
      "measured_gflops": 5.452879241944259,
      "efficiency": 0.4276768032897458,
      "achieved_bandwidth_gbps": 43.62303393555407,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.5,
      "batch_size": 1,
      "input_shape": [
        4194304
      ],
      "output_shape": [
        4194304
      ],
      "mean_latency_ms": 0.7691906997933984,
      "std_latency_ms": 0.0987577952436609,
      "min_latency_ms": 0.6707050051772967,
      "max_latency_ms": 0.9702969982754439,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 16,
        "kernel": "scale",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 2,
        "num_memory_ops": 2,
        "flops_per_element": 1
      },
      "precision_results": {}
    },
    "stream_scale_device=cuda_flops_per_element=1_framework=pytorch_kernel=scale_num_arrays=2_num_memory_ops=2_size_mb=32": {
      "operation_type": "stream_scale",
      "measured_gflops": 6.60487186476993,
      "efficiency": 0.5180291658643082,
      "achieved_bandwidth_gbps": 52.83897491815944,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.5,
      "batch_size": 1,
      "input_shape": [
        8388608
      ],
      "output_shape": [
        8388608
      ],
      "mean_latency_ms": 1.2700637002126314,
      "std_latency_ms": 0.06779071225610518,
      "min_latency_ms": 1.2127349982620217,
      "max_latency_ms": 1.429219999408815,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 32,
        "kernel": "scale",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 2,
        "num_memory_ops": 2,
        "flops_per_element": 1
      },
      "precision_results": {}
    },
    "stream_scale_device=cuda_flops_per_element=1_framework=pytorch_kernel=scale_num_arrays=2_num_memory_ops=2_size_mb=64": {
      "operation_type": "stream_scale",
      "measured_gflops": 7.199016896804651,
      "efficiency": 0.5646287762199727,
      "achieved_bandwidth_gbps": 57.59213517443721,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.5,
      "batch_size": 1,
      "input_shape": [
        16777216
      ],
      "output_shape": [
        16777216
      ],
      "mean_latency_ms": 2.330487098515732,
      "std_latency_ms": 0.039979328840080874,
      "min_latency_ms": 2.2919609982636757,
      "max_latency_ms": 2.4106199998641387,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 64,
        "kernel": "scale",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 2,
        "num_memory_ops": 2,
        "flops_per_element": 1
      },
      "precision_results": {}
    },
    "stream_scale_device=cuda_flops_per_element=1_framework=pytorch_kernel=scale_num_arrays=2_num_memory_ops=2_size_mb=128": {
      "operation_type": "stream_scale",
      "measured_gflops": 7.421054610716943,
      "efficiency": 0.5820434988797603,
      "achieved_bandwidth_gbps": 59.36843688573554,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.5,
      "batch_size": 1,
      "input_shape": [
        33554432
      ],
      "output_shape": [
        33554432
      ],
      "mean_latency_ms": 4.52151799981948,
      "std_latency_ms": 0.0372893838986382,
      "min_latency_ms": 4.45323099847883,
      "max_latency_ms": 4.5841469982406124,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 128,
        "kernel": "scale",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 2,
        "num_memory_ops": 2,
        "flops_per_element": 1
      },
      "precision_results": {}
    },
    "stream_scale_device=cuda_flops_per_element=1_framework=pytorch_kernel=scale_num_arrays=2_num_memory_ops=2_size_mb=256": {
      "operation_type": "stream_scale",
      "measured_gflops": 6.41692182201884,
      "efficiency": 0.5032879860406934,
      "achieved_bandwidth_gbps": 51.33537457615072,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.5,
      "batch_size": 1,
      "input_shape": [
        67108864
      ],
      "output_shape": [
        67108864
      ],
      "mean_latency_ms": 10.458108398597687,
      "std_latency_ms": 0.44488913837784105,
      "min_latency_ms": 10.215328002232127,
      "max_latency_ms": 11.653731999103911,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 256,
        "kernel": "scale",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 2,
        "num_memory_ops": 2,
        "flops_per_element": 1
      },
      "precision_results": {}
    },
    "stream_scale_device=cuda_flops_per_element=1_framework=pytorch_kernel=scale_num_arrays=2_num_memory_ops=2_size_mb=512": {
      "operation_type": "stream_scale",
      "measured_gflops": 6.647635082991256,
      "efficiency": 0.5213831437640201,
      "achieved_bandwidth_gbps": 53.18108066393005,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.5,
      "batch_size": 1,
      "input_shape": [
        134217728
      ],
      "output_shape": [
        134217728
      ],
      "mean_latency_ms": 20.190297199587803,
      "std_latency_ms": 0.03860476054246265,
      "min_latency_ms": 20.15509599732468,
      "max_latency_ms": 20.296027993026655,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 512,
        "kernel": "scale",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 2,
        "num_memory_ops": 2,
        "flops_per_element": 1
      },
      "precision_results": {}
    },
    "stream_add_device=cuda_flops_per_element=1_framework=pytorch_kernel=add_num_arrays=3_num_memory_ops=3_size_mb=8": {
      "operation_type": "stream_add",
      "measured_gflops": 3.492837460396349,
      "efficiency": 0.41092205416427635,
      "achieved_bandwidth_gbps": 41.91404952475619,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.3333333333333333,
      "batch_size": 1,
      "input_shape": [
        2097152
      ],
      "output_shape": [
        2097152
      ],
      "mean_latency_ms": 0.6004149989166763,
      "std_latency_ms": 0.10102756125257902,
      "min_latency_ms": 0.5268289969535545,
      "max_latency_ms": 0.8001800015335903,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 8,
        "kernel": "add",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 3,
        "num_memory_ops": 3,
        "flops_per_element": 1
      },
      "precision_results": {}
    },
    "stream_add_device=cuda_flops_per_element=1_framework=pytorch_kernel=add_num_arrays=3_num_memory_ops=3_size_mb=16": {
      "operation_type": "stream_add",
      "measured_gflops": 4.234991260285107,
      "efficiency": 0.4982342659158949,
      "achieved_bandwidth_gbps": 50.81989512342128,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.3333333333333333,
      "batch_size": 1,
      "input_shape": [
        4194304
      ],
      "output_shape": [
        4194304
      ],
      "mean_latency_ms": 0.9903925987600815,
      "std_latency_ms": 0.04943848350110108,
      "min_latency_ms": 0.9401829956914298,
      "max_latency_ms": 1.0918350017163903,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 16,
        "kernel": "add",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 3,
        "num_memory_ops": 3,
        "flops_per_element": 1
      },
      "precision_results": {}
    },
    "stream_add_device=cuda_flops_per_element=1_framework=pytorch_kernel=add_num_arrays=3_num_memory_ops=3_size_mb=32": {
      "operation_type": "stream_add",
      "measured_gflops": 4.8531294226849075,
      "efficiency": 0.5709564026688128,
      "achieved_bandwidth_gbps": 58.2375530722189,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.3333333333333333,
      "batch_size": 1,
      "input_shape": [
        8388608
      ],
      "output_shape": [
        8388608
      ],
      "mean_latency_ms": 1.7284945999563206,
      "std_latency_ms": 0.03016212660940289,
      "min_latency_ms": 1.6895779990591109,
      "max_latency_ms": 1.7877249993034638,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 32,
        "kernel": "add",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 3,
        "num_memory_ops": 3,
        "flops_per_element": 1
      },
      "precision_results": {}
    },
    "stream_add_device=cuda_flops_per_element=1_framework=pytorch_kernel=add_num_arrays=3_num_memory_ops=3_size_mb=64": {
      "operation_type": "stream_add",
      "measured_gflops": 5.000056027238442,
      "efficiency": 0.5882418855574637,
      "achieved_bandwidth_gbps": 60.0006723268613,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.3333333333333333,
      "batch_size": 1,
      "input_shape": [
        16777216
      ],
      "output_shape": [
        16777216
      ],
      "mean_latency_ms": 3.355405601178063,
      "std_latency_ms": 0.04385812808852424,
      "min_latency_ms": 3.298994000942912,
      "max_latency_ms": 3.406709998671431,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 64,
        "kernel": "add",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 3,
        "num_memory_ops": 3,
        "flops_per_element": 1
      },
      "precision_results": {}
    },
    "stream_add_device=cuda_flops_per_element=1_framework=pytorch_kernel=add_num_arrays=3_num_memory_ops=3_size_mb=128": {
      "operation_type": "stream_add",
      "measured_gflops": 4.902876328494448,
      "efficiency": 0.5768089798228762,
      "achieved_bandwidth_gbps": 58.83451594193337,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.3333333333333333,
      "batch_size": 1,
      "input_shape": [
        33554432
      ],
      "output_shape": [
        33554432
      ],
      "mean_latency_ms": 6.843825899704825,
      "std_latency_ms": 0.16633368149606845,
      "min_latency_ms": 6.703176004521083,
      "max_latency_ms": 7.233844997244887,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 128,
        "kernel": "add",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 3,
        "num_memory_ops": 3,
        "flops_per_element": 1
      },
      "precision_results": {}
    },
    "stream_add_device=cuda_flops_per_element=1_framework=pytorch_kernel=add_num_arrays=3_num_memory_ops=3_size_mb=256": {
      "operation_type": "stream_add",
      "measured_gflops": 5.041153099279958,
      "efficiency": 0.5930768352094068,
      "achieved_bandwidth_gbps": 60.49383719135949,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.3333333333333333,
      "batch_size": 1,
      "input_shape": [
        67108864
      ],
      "output_shape": [
        67108864
      ],
      "mean_latency_ms": 13.31220510037383,
      "std_latency_ms": 0.06874228840635509,
      "min_latency_ms": 13.21620300586801,
      "max_latency_ms": 13.442991999909282,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 256,
        "kernel": "add",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 3,
        "num_memory_ops": 3,
        "flops_per_element": 1
      },
      "precision_results": {}
    },
    "stream_add_device=cuda_flops_per_element=1_framework=pytorch_kernel=add_num_arrays=3_num_memory_ops=3_size_mb=512": {
      "operation_type": "stream_add",
      "measured_gflops": 4.978734597080973,
      "efficiency": 0.5857334820095264,
      "achieved_bandwidth_gbps": 59.74481516497169,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.3333333333333333,
      "batch_size": 1,
      "input_shape": [
        134217728
      ],
      "output_shape": [
        134217728
      ],
      "mean_latency_ms": 26.958201001252746,
      "std_latency_ms": 0.6447420301358497,
      "min_latency_ms": 26.549048998276703,
      "max_latency_ms": 28.32314000261249,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 512,
        "kernel": "add",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 3,
        "num_memory_ops": 3,
        "flops_per_element": 1
      },
      "precision_results": {}
    },
    "stream_triad_device=cuda_flops_per_element=2_framework=pytorch_kernel=triad_num_arrays=3_num_memory_ops=3_size_mb=8": {
      "operation_type": "stream_triad",
      "measured_gflops": 4.772279535664972,
      "efficiency": 0.28072232562735133,
      "achieved_bandwidth_gbps": 28.633677213989834,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.6666666666666666,
      "batch_size": 1,
      "input_shape": [
        2097152
      ],
      "output_shape": [
        2097152
      ],
      "mean_latency_ms": 0.8788890023424756,
      "std_latency_ms": 0.046270678979260606,
      "min_latency_ms": 0.8381010047742166,
      "max_latency_ms": 1.004025005386211,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 8,
        "kernel": "triad",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 3,
        "num_memory_ops": 3,
        "flops_per_element": 2
      },
      "precision_results": {}
    },
    "stream_triad_device=cuda_flops_per_element=2_framework=pytorch_kernel=triad_num_arrays=3_num_memory_ops=3_size_mb=16": {
      "operation_type": "stream_triad",
      "measured_gflops": 5.37674861091055,
      "efficiency": 0.31627933005356174,
      "achieved_bandwidth_gbps": 32.2604916654633,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.6666666666666666,
      "batch_size": 1,
      "input_shape": [
        4194304
      ],
      "output_shape": [
        4194304
      ],
      "mean_latency_ms": 1.5601636987412348,
      "std_latency_ms": 0.04054682163564563,
      "min_latency_ms": 1.491684997745324,
      "max_latency_ms": 1.6297370020765811,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 16,
        "kernel": "triad",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 3,
        "num_memory_ops": 3,
        "flops_per_element": 2
      },
      "precision_results": {}
    },
    "stream_triad_device=cuda_flops_per_element=2_framework=pytorch_kernel=triad_num_arrays=3_num_memory_ops=3_size_mb=32": {
      "operation_type": "stream_triad",
      "measured_gflops": 5.217355556163792,
      "efficiency": 0.3069032680096348,
      "achieved_bandwidth_gbps": 31.30413333698275,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.6666666666666666,
      "batch_size": 1,
      "input_shape": [
        8388608
      ],
      "output_shape": [
        8388608
      ],
      "mean_latency_ms": 3.215655099484138,
      "std_latency_ms": 0.21251663247527627,
      "min_latency_ms": 2.8584719984792173,
      "max_latency_ms": 3.5250489963800646,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 32,
        "kernel": "triad",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 3,
        "num_memory_ops": 3,
        "flops_per_element": 2
      },
      "precision_results": {}
    },
    "stream_triad_device=cuda_flops_per_element=2_framework=pytorch_kernel=triad_num_arrays=3_num_memory_ops=3_size_mb=64": {
      "operation_type": "stream_triad",
      "measured_gflops": 5.442231137081347,
      "efficiency": 0.3201312433577263,
      "achieved_bandwidth_gbps": 32.65338682248808,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.6666666666666666,
      "batch_size": 1,
      "input_shape": [
        16777216
      ],
      "output_shape": [
        16777216
      ],
      "mean_latency_ms": 6.165565400442574,
      "std_latency_ms": 0.39728980298489464,
      "min_latency_ms": 5.5401700010406785,
      "max_latency_ms": 6.505443001515232,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 64,
        "kernel": "triad",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 3,
        "num_memory_ops": 3,
        "flops_per_element": 2
      },
      "precision_results": {}
    },
    "stream_triad_device=cuda_flops_per_element=2_framework=pytorch_kernel=triad_num_arrays=3_num_memory_ops=3_size_mb=128": {
      "operation_type": "stream_triad",
      "measured_gflops": 5.59160042147701,
      "efficiency": 0.3289176718515889,
      "achieved_bandwidth_gbps": 33.54960252886207,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.6666666666666666,
      "batch_size": 1,
      "input_shape": [
        33554432
      ],
      "output_shape": [
        33554432
      ],
      "mean_latency_ms": 12.00172740209382,
      "std_latency_ms": 0.5509642277198507,
      "min_latency_ms": 11.275802004092839,
      "max_latency_ms": 13.23706700350158,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 128,
        "kernel": "triad",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 3,
        "num_memory_ops": 3,
        "flops_per_element": 2
      },
      "precision_results": {}
    },
    "stream_triad_device=cuda_flops_per_element=2_framework=pytorch_kernel=triad_num_arrays=3_num_memory_ops=3_size_mb=256": {
      "operation_type": "stream_triad",
      "measured_gflops": 5.781280913155514,
      "efficiency": 0.3400753478326773,
      "achieved_bandwidth_gbps": 34.68768547893308,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.6666666666666666,
      "batch_size": 1,
      "input_shape": [
        67108864
      ],
      "output_shape": [
        67108864
      ],
      "mean_latency_ms": 23.215915299078915,
      "std_latency_ms": 0.05120663278735242,
      "min_latency_ms": 23.158434996730648,
      "max_latency_ms": 23.2981830049539,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 256,
        "kernel": "triad",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 3,
        "num_memory_ops": 3,
        "flops_per_element": 2
      },
      "precision_results": {}
    },
    "stream_triad_device=cuda_flops_per_element=2_framework=pytorch_kernel=triad_num_arrays=3_num_memory_ops=3_size_mb=512": {
      "operation_type": "stream_triad",
      "measured_gflops": 5.756421664678015,
      "efficiency": 0.33861303909870677,
      "achieved_bandwidth_gbps": 34.53852998806809,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.6666666666666666,
      "batch_size": 1,
      "input_shape": [
        134217728
      ],
      "output_shape": [
        134217728
      ],
      "mean_latency_ms": 46.632347600098,
      "std_latency_ms": 0.9287589592808854,
      "min_latency_ms": 46.0556490070303,
      "max_latency_ms": 49.12519700155826,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 512,
        "kernel": "triad",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 3,
        "num_memory_ops": 3,
        "flops_per_element": 2
      },
      "precision_results": {}
    },
    "blas1_dot_best_precision=tf32_blas_level=1_device=cuda_framework=pytorch_operation=dot_size=1000": {
      "operation_type": "blas1_dot",
      "measured_gflops": 0.010841371834915917,
      "efficiency": 2.8810448671049472e-06,
      "achieved_bandwidth_gbps": 0.043365487339663666,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.25,
      "batch_size": 1,
      "input_shape": [
        1000
      ],
      "output_shape": [
        1000
      ],
      "mean_latency_ms": 0.1844784987042658,
      "std_latency_ms": 0.012308036821547215,
      "min_latency_ms": 0.153859997226391,
      "max_latency_ms": 0.19678653552581302,
      "num_trials": 10,
      "extra_params": {
        "size": 1000,
        "operation": "dot",
        "blas_level": 1,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "tf32"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.010349636600437173,
          "efficiency": 0.00017541756949893513,
          "mean_latency_ms": 0.19324349996168166,
          "std_latency_ms": 0.017353939863258182,
          "min_latency_ms": 0.1688679985818453,
          "max_latency_ms": 0.21059743982493984,
          "speedup_vs_fp32": null,
          "test_size": 1000,
          "num_trials": 10,
          "arithmetic_intensity": 0.5,
          "achieved_bandwidth_gbps": 0.020699273200874346
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.010358572313473376,
          "efficiency": 5.5040235459475956e-06,
          "mean_latency_ms": 0.1930768004967831,
          "std_latency_ms": 0.026276899544808413,
          "min_latency_ms": 0.1456359968869947,
          "max_latency_ms": 0.21935370004159152,
          "speedup_vs_fp32": 1.0,
          "test_size": 1000,
          "num_trials": 10,
          "arithmetic_intensity": 0.25,
          "achieved_bandwidth_gbps": 0.0414342892538935
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.010841371834915917,
          "efficiency": 2.8810448671049472e-06,
          "mean_latency_ms": 0.1844784987042658,
          "std_latency_ms": 0.012308036821547215,
          "min_latency_ms": 0.153859997226391,
          "max_latency_ms": 0.19678653552581302,
          "speedup_vs_fp32": 1.046608693440752,
          "test_size": 1000,
          "num_trials": 10,
          "arithmetic_intensity": 0.25,
          "achieved_bandwidth_gbps": 0.043365487339663666
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.010458763245557775,
          "efficiency": 1.3896841942011395e-06,
          "mean_latency_ms": 0.1912271989567671,
          "std_latency_ms": 0.008961886692606917,
          "min_latency_ms": 0.17942900012712926,
          "max_latency_ms": 0.20018908564937402,
          "speedup_vs_fp32": 1.009672272302823,
          "test_size": 1000,
          "num_trials": 10,
          "arithmetic_intensity": 0.5,
          "achieved_bandwidth_gbps": 0.02091752649111555
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.010162183364974374,
          "efficiency": 1.3502768223457845e-06,
          "mean_latency_ms": 0.19680810000863858,
          "std_latency_ms": 0.0222028916978503,
          "min_latency_ms": 0.17328399553662166,
          "max_latency_ms": 0.21901099170648888,
          "speedup_vs_fp32": 0.9810409250854426,
          "test_size": 1000,
          "num_trials": 10,
          "arithmetic_intensity": 0.5,
          "achieved_bandwidth_gbps": 0.020324366729948747
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Long'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Int'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Short'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Char'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas1_dot_best_precision=fp16_blas_level=1_device=cuda_framework=pytorch_operation=dot_size=10000": {
      "operation_type": "blas1_dot",
      "measured_gflops": 0.1142190104721405,
      "efficiency": 1.517658922032162e-05,
      "achieved_bandwidth_gbps": 0.228438020944281,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.5,
      "batch_size": 1,
      "input_shape": [
        10000
      ],
      "output_shape": [
        10000
      ],
      "mean_latency_ms": 0.17510219986434095,
      "std_latency_ms": 0.025724674729921942,
      "min_latency_ms": 0.14630799705628306,
      "max_latency_ms": 0.20082687459426288,
      "num_trials": 10,
      "extra_params": {
        "size": 10000,
        "operation": "dot",
        "blas_level": 1,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "fp16"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.10708575695293698,
          "efficiency": 0.0018150128297107963,
          "mean_latency_ms": 0.1867662009317428,
          "std_latency_ms": 0.015031240045366916,
          "min_latency_ms": 0.15558700397377834,
          "max_latency_ms": 0.2017974409771097,
          "speedup_vs_fp32": null,
          "test_size": 10000,
          "num_trials": 10,
          "arithmetic_intensity": 0.5,
          "achieved_bandwidth_gbps": 0.21417151390587397
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.10480164507504275,
          "efficiency": 5.5686315130203374e-05,
          "mean_latency_ms": 0.19083669903920963,
          "std_latency_ms": 0.014840874298503467,
          "min_latency_ms": 0.17242100147996098,
          "max_latency_ms": 0.2056775733377131,
          "speedup_vs_fp32": 1.0,
          "test_size": 10000,
          "num_trials": 10,
          "arithmetic_intensity": 0.25,
          "achieved_bandwidth_gbps": 0.419206580300171
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.1077838249313853,
          "efficiency": 2.864305738277579e-05,
          "mean_latency_ms": 0.1855565991718322,
          "std_latency_ms": 0.01654527415533043,
          "min_latency_ms": 0.16323599993484095,
          "max_latency_ms": 0.20210187332716265,
          "speedup_vs_fp32": 1.0284554679862818,
          "test_size": 10000,
          "num_trials": 10,
          "arithmetic_intensity": 0.25,
          "achieved_bandwidth_gbps": 0.4311352997255412
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.1142190104721405,
          "efficiency": 1.517658922032162e-05,
          "mean_latency_ms": 0.17510219986434095,
          "std_latency_ms": 0.025724674729921942,
          "min_latency_ms": 0.14630799705628306,
          "max_latency_ms": 0.20082687459426288,
          "speedup_vs_fp32": 1.0898589463014106,
          "test_size": 10000,
          "num_trials": 10,
          "arithmetic_intensity": 0.5,
          "achieved_bandwidth_gbps": 0.228438020944281
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.1076649357646941,
          "efficiency": 1.4305731565864219e-05,
          "mean_latency_ms": 0.18576150032458827,
          "std_latency_ms": 0.023284107700330476,
          "min_latency_ms": 0.1480999999330379,
          "max_latency_ms": 0.20904560802491876,
          "speedup_vs_fp32": 1.0273210471801384,
          "test_size": 10000,
          "num_trials": 10,
          "arithmetic_intensity": 0.5,
          "achieved_bandwidth_gbps": 0.2153298715293882
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Long'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Int'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Short'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Char'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas1_dot_best_precision=tf32_blas_level=1_device=cuda_framework=pytorch_operation=dot_size=100000": {
      "operation_type": "blas1_dot",
      "measured_gflops": 1.2005306489995031,
      "efficiency": 0.00031903551660895647,
      "achieved_bandwidth_gbps": 4.8021225959980125,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.25,
      "batch_size": 1,
      "input_shape": [
        100000
      ],
      "output_shape": [
        100000
      ],
      "mean_latency_ms": 0.1665929979935754,
      "std_latency_ms": 0.018744000379081558,
      "min_latency_ms": 0.1453160002711229,
      "max_latency_ms": 0.18533699837265696,
      "num_trials": 10,
      "extra_params": {
        "size": 100000,
        "operation": "dot",
        "blas_level": 1,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "tf32"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.0787876340294345,
          "efficiency": 0.018284536169990415,
          "mean_latency_ms": 0.18539330048952252,
          "std_latency_ms": 0.01603715630800156,
          "min_latency_ms": 0.15635599993402138,
          "max_latency_ms": 0.20143045679752408,
          "speedup_vs_fp32": null,
          "test_size": 100000,
          "num_trials": 10,
          "arithmetic_intensity": 0.5,
          "achieved_bandwidth_gbps": 2.157575268058869
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.0762414831300038,
          "efficiency": 0.0005718605117587692,
          "mean_latency_ms": 0.18583190030767582,
          "std_latency_ms": 0.012965885172747738,
          "min_latency_ms": 0.15923600585665554,
          "max_latency_ms": 0.19879778548042357,
          "speedup_vs_fp32": 1.0,
          "test_size": 100000,
          "num_trials": 10,
          "arithmetic_intensity": 0.25,
          "achieved_bandwidth_gbps": 4.304965932520015
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.2005306489995031,
          "efficiency": 0.00031903551660895647,
          "mean_latency_ms": 0.1665929979935754,
          "std_latency_ms": 0.018744000379081558,
          "min_latency_ms": 0.1453160002711229,
          "max_latency_ms": 0.18533699837265696,
          "speedup_vs_fp32": 1.115484459405925,
          "test_size": 100000,
          "num_trials": 10,
          "arithmetic_intensity": 0.25,
          "achieved_bandwidth_gbps": 4.8021225959980125
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.0975044852332976,
          "efficiency": 0.00014582839293559628,
          "mean_latency_ms": 0.18223160150228068,
          "std_latency_ms": 0.023051115092363694,
          "min_latency_ms": 0.14473999908659607,
          "max_latency_ms": 0.20528271659464437,
          "speedup_vs_fp32": 1.019756720435506,
          "test_size": 100000,
          "num_trials": 10,
          "arithmetic_intensity": 0.5,
          "achieved_bandwidth_gbps": 2.195008970466595
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.1183199304888567,
          "efficiency": 0.00014859419751379972,
          "mean_latency_ms": 0.17883969921967946,
          "std_latency_ms": 0.028970504202285013,
          "min_latency_ms": 0.1439080006093718,
          "max_latency_ms": 0.20781020342196446,
          "speedup_vs_fp32": 1.0390975891734606,
          "test_size": 100000,
          "num_trials": 10,
          "arithmetic_intensity": 0.5,
          "achieved_bandwidth_gbps": 2.2366398609777134
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Long'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Int'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Short'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Char'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas1_dot_best_precision=bf16_blas_level=1_device=cuda_framework=pytorch_operation=dot_size=1000000": {
      "operation_type": "blas1_dot",
      "measured_gflops": 8.866030312042778,
      "efficiency": 0.0011780534562905631,
      "achieved_bandwidth_gbps": 17.732060624085555,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.5,
      "batch_size": 1,
      "input_shape": [
        1000000
      ],
      "output_shape": [
        1000000
      ],
      "mean_latency_ms": 0.22558009950444102,
      "std_latency_ms": 0.00887568015769213,
      "min_latency_ms": 0.20426099945325404,
      "max_latency_ms": 0.23445577966213316,
      "num_trials": 10,
      "extra_params": {
        "size": 1000000,
        "operation": "dot",
        "blas_level": 1,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "bf16"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 4.756167928328198,
          "efficiency": 0.08061301573437624,
          "mean_latency_ms": 0.42050659903907217,
          "std_latency_ms": 0.014284689561301836,
          "min_latency_ms": 0.3946659999201074,
          "max_latency_ms": 0.434791288600374,
          "speedup_vs_fp32": null,
          "test_size": 1000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.5,
          "achieved_bandwidth_gbps": 9.512335856656396
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 7.885636168601727,
          "efficiency": 0.004190029845165636,
          "mean_latency_ms": 0.2536257008614484,
          "std_latency_ms": 0.019339403421372105,
          "min_latency_ms": 0.22461399930762127,
          "max_latency_ms": 0.2729651042828205,
          "speedup_vs_fp32": 1.0,
          "test_size": 1000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.25,
          "achieved_bandwidth_gbps": 31.54254467440691
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 6.104374389710589,
          "efficiency": 0.0016222095109515251,
          "mean_latency_ms": 0.3276339019066654,
          "std_latency_ms": 0.045631199779036076,
          "min_latency_ms": 0.25667900627013296,
          "max_latency_ms": 0.3732651016857015,
          "speedup_vs_fp32": 0.7741131164555124,
          "test_size": 1000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.25,
          "achieved_bandwidth_gbps": 24.417497558842356
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 8.783552638703092,
          "efficiency": 0.001167094424488851,
          "mean_latency_ms": 0.22769829956814647,
          "std_latency_ms": 0.015910981016929497,
          "min_latency_ms": 0.19590900046750903,
          "max_latency_ms": 0.24360928058507597,
          "speedup_vs_fp32": 1.1138673470222482,
          "test_size": 1000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.5,
          "achieved_bandwidth_gbps": 17.567105277406185
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 8.866030312042778,
          "efficiency": 0.0011780534562905631,
          "mean_latency_ms": 0.22558009950444102,
          "std_latency_ms": 0.00887568015769213,
          "min_latency_ms": 0.20426099945325404,
          "max_latency_ms": 0.23445577966213316,
          "speedup_vs_fp32": 1.124326575875348,
          "test_size": 1000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.5,
          "achieved_bandwidth_gbps": 17.732060624085555
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Long'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Int'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Short'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Char'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas1_dot_best_precision=bf16_blas_level=1_device=cuda_framework=pytorch_operation=dot_size=10000000": {
      "operation_type": "blas1_dot",
      "measured_gflops": 15.700759840368368,
      "efficiency": 0.0020862024767962224,
      "achieved_bandwidth_gbps": 31.401519680736737,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.5,
      "batch_size": 1,
      "input_shape": [
        10000000
      ],
      "output_shape": [
        10000000
      ],
      "mean_latency_ms": 1.2738237004668918,
      "std_latency_ms": 0.012357126255474967,
      "min_latency_ms": 1.2616309977602214,
      "max_latency_ms": 1.2861808267223667,
      "num_trials": 10,
      "extra_params": {
        "size": 10000000,
        "operation": "dot",
        "blas_level": 1,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "bf16"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 5.683484311863088,
          "efficiency": 0.09633024257395065,
          "mean_latency_ms": 3.518968101707287,
          "std_latency_ms": 0.897604833244533,
          "min_latency_ms": 2.818247005052399,
          "max_latency_ms": 4.41657293495182,
          "speedup_vs_fp32": null,
          "test_size": 10000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.5,
          "achieved_bandwidth_gbps": 11.366968623726176
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 10.893297216911577,
          "efficiency": 0.005788149424501369,
          "mean_latency_ms": 1.8359913992753718,
          "std_latency_ms": 0.5709593561953257,
          "min_latency_ms": 1.5124849960557185,
          "max_latency_ms": 2.4069507554706977,
          "speedup_vs_fp32": 1.0,
          "test_size": 10000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.25,
          "achieved_bandwidth_gbps": 43.57318886764631
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 13.042980069453934,
          "efficiency": 0.003466112163022571,
          "mean_latency_ms": 1.533391900738934,
          "std_latency_ms": 0.04993509037702804,
          "min_latency_ms": 1.4719410028192215,
          "max_latency_ms": 1.5833269911159622,
          "speedup_vs_fp32": 1.1973399614218758,
          "test_size": 10000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.25,
          "achieved_bandwidth_gbps": 52.17192027781574
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 15.253495173143195,
          "efficiency": 0.0020267732092935416,
          "mean_latency_ms": 1.3111748994560912,
          "std_latency_ms": 0.058804239018150975,
          "min_latency_ms": 1.256766998267267,
          "max_latency_ms": 1.3699791384742421,
          "speedup_vs_fp32": 1.4002642973389652,
          "test_size": 10000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.5,
          "achieved_bandwidth_gbps": 30.50699034628639
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 15.700759840368368,
          "efficiency": 0.0020862024767962224,
          "mean_latency_ms": 1.2738237004668918,
          "std_latency_ms": 0.012357126255474967,
          "min_latency_ms": 1.2616309977602214,
          "max_latency_ms": 1.2861808267223667,
          "speedup_vs_fp32": 1.4413230014502243,
          "test_size": 10000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.5,
          "achieved_bandwidth_gbps": 31.401519680736737
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Long'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Int'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Short'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Char'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas1_axpy_best_precision=int32_blas_level=1_device=cuda_framework=pytorch_operation=axpy_size=1000": {
      "operation_type": "blas1_axpy",
      "measured_gflops": 0.01012366555824305,
      "efficiency": 5.379205928928294e-06,
      "achieved_bandwidth_gbps": 0.03037099667472915,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.3333333333333333,
      "batch_size": 1,
      "input_shape": [
        1000
      ],
      "output_shape": [
        1000
      ],
      "mean_latency_ms": 0.19755690154852346,
      "std_latency_ms": 0.011556828486679278,
      "min_latency_ms": 0.1816360017983243,
      "max_latency_ms": 0.20911373003520273,
      "num_trials": 10,
      "extra_params": {
        "size": 1000,
        "operation": "axpy",
        "blas_level": 1,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "int32"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.009070763700298655,
          "efficiency": 0.0001537417576321806,
          "mean_latency_ms": 0.22048860118957236,
          "std_latency_ms": 0.02419076343658434,
          "min_latency_ms": 0.1975090053747408,
          "max_latency_ms": 0.2446793646261567,
          "speedup_vs_fp32": null,
          "test_size": 1000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 0.027212291100895968
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.009337604332811847,
          "efficiency": 4.961532589166762e-06,
          "mean_latency_ms": 0.21418770047603175,
          "std_latency_ms": 0.018263200042805065,
          "min_latency_ms": 0.18813300266629085,
          "max_latency_ms": 0.23245090051883682,
          "speedup_vs_fp32": 1.0,
          "test_size": 1000,
          "num_trials": 10,
          "arithmetic_intensity": 0.16666666666666666,
          "achieved_bandwidth_gbps": 0.056025625996871074
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.009927322006994178,
          "efficiency": 2.6381403154382616e-06,
          "mean_latency_ms": 0.2014642013818957,
          "std_latency_ms": 0.02708101132558133,
          "min_latency_ms": 0.1744050023262389,
          "max_latency_ms": 0.22854521270747702,
          "speedup_vs_fp32": 1.0631551362815936,
          "test_size": 1000,
          "num_trials": 10,
          "arithmetic_intensity": 0.16666666666666666,
          "achieved_bandwidth_gbps": 0.05956393204196507
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.009912821750301526,
          "efficiency": 1.3171434693464692e-06,
          "mean_latency_ms": 0.2017588987655472,
          "std_latency_ms": 0.01790406577610956,
          "min_latency_ms": 0.1787250002962537,
          "max_latency_ms": 0.21966296454165676,
          "speedup_vs_fp32": 1.061602247962938,
          "test_size": 1000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 0.029738465250904577
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.009791686794041542,
          "efficiency": 1.3010479396813104e-06,
          "mean_latency_ms": 0.2042548992903903,
          "std_latency_ms": 0.022317788777804232,
          "min_latency_ms": 0.18515600095270202,
          "max_latency_ms": 0.22657268806819456,
          "speedup_vs_fp32": 1.0486294390986426,
          "test_size": 1000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 0.029375060382124625
        },
        "int64": {
          "precision": "int64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.009586096351666391,
          "efficiency": 0.0,
          "mean_latency_ms": 0.20863549943896942,
          "std_latency_ms": 0.010605334967528877,
          "min_latency_ms": 0.19341299775987864,
          "max_latency_ms": 0.2192408344064983,
          "speedup_vs_fp32": 1.0266119670525509,
          "test_size": 1000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 0.02875828905499917
        },
        "int32": {
          "precision": "int32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.01012366555824305,
          "efficiency": 5.379205928928294e-06,
          "mean_latency_ms": 0.19755690154852346,
          "std_latency_ms": 0.011556828486679278,
          "min_latency_ms": 0.1816360017983243,
          "max_latency_ms": 0.20911373003520273,
          "speedup_vs_fp32": 1.0841823231542405,
          "test_size": 1000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 0.03037099667472915
        },
        "int16": {
          "precision": "int16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.008930389360501053,
          "efficiency": 1.1866050173400283e-06,
          "mean_latency_ms": 0.22395440100808628,
          "std_latency_ms": 0.013301655096920072,
          "min_latency_ms": 0.20429300639079884,
          "max_latency_ms": 0.23725605610500636,
          "speedup_vs_fp32": 0.95638978074067,
          "test_size": 1000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 0.02679116808150316
        },
        "int8": {
          "precision": "int8",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.00919270997913221,
          "efficiency": 6.106895621558632e-07,
          "mean_latency_ms": 0.2175637004256714,
          "std_latency_ms": 0.01762025913390038,
          "min_latency_ms": 0.18909299978986382,
          "max_latency_ms": 0.2351839595595718,
          "speedup_vs_fp32": 0.9844827057866988,
          "test_size": 1000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 0.027578129937396625
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas1_axpy_best_precision=tf32_blas_level=1_device=cuda_framework=pytorch_operation=axpy_size=10000": {
      "operation_type": "blas1_axpy",
      "measured_gflops": 0.10053145915246023,
      "efficiency": 2.6715774422657516e-05,
      "achieved_bandwidth_gbps": 0.6031887549147614,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.16666666666666666,
      "batch_size": 1,
      "input_shape": [
        10000
      ],
      "output_shape": [
        10000
      ],
      "mean_latency_ms": 0.19894270080840215,
      "std_latency_ms": 0.012302414641976877,
      "min_latency_ms": 0.1832690031733364,
      "max_latency_ms": 0.21124511545037902,
      "num_trials": 10,
      "extra_params": {
        "size": 10000,
        "operation": "axpy",
        "blas_level": 1,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "tf32"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.0906313052097693,
          "efficiency": 0.0015361238171147339,
          "mean_latency_ms": 0.22067430181778036,
          "std_latency_ms": 0.014374872313160833,
          "min_latency_ms": 0.19280500418972224,
          "max_latency_ms": 0.2350491741309412,
          "speedup_vs_fp32": null,
          "test_size": 10000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 0.27189391562930787
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.09050404434434296,
          "efficiency": 4.8089290299863426e-05,
          "mean_latency_ms": 0.22098459958215244,
          "std_latency_ms": 0.012754260371567731,
          "min_latency_ms": 0.20240499725332484,
          "max_latency_ms": 0.23373885995372018,
          "speedup_vs_fp32": 1.0,
          "test_size": 10000,
          "num_trials": 10,
          "arithmetic_intensity": 0.16666666666666666,
          "achieved_bandwidth_gbps": 0.5430242660660578
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.10053145915246023,
          "efficiency": 2.6715774422657516e-05,
          "mean_latency_ms": 0.19894270080840215,
          "std_latency_ms": 0.012302414641976877,
          "min_latency_ms": 0.1832690031733364,
          "max_latency_ms": 0.21124511545037902,
          "speedup_vs_fp32": 1.110795212310797,
          "test_size": 10000,
          "num_trials": 10,
          "arithmetic_intensity": 0.16666666666666666,
          "achieved_bandwidth_gbps": 0.6031887549147614
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.09213435220955833,
          "efficiency": 1.2242140872915005e-05,
          "mean_latency_ms": 0.21707429987145588,
          "std_latency_ms": 0.024621146698512522,
          "min_latency_ms": 0.18986099894391373,
          "max_latency_ms": 0.2416954465699684,
          "speedup_vs_fp32": 1.0180136465395127,
          "test_size": 10000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 0.276403056628675
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.09709251547949163,
          "efficiency": 1.2900945453028386e-05,
          "mean_latency_ms": 0.20598910123226233,
          "std_latency_ms": 0.01235565628913845,
          "min_latency_ms": 0.18957300198962912,
          "max_latency_ms": 0.21834475752140078,
          "speedup_vs_fp32": 1.07279753278297,
          "test_size": 10000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 0.29127754643847487
        },
        "int64": {
          "precision": "int64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.10048953411482794,
          "efficiency": 0.0,
          "mean_latency_ms": 0.19902570129488595,
          "std_latency_ms": 0.015626574492425334,
          "min_latency_ms": 0.18160499894293025,
          "max_latency_ms": 0.21465227578731128,
          "speedup_vs_fp32": 1.1103319729281151,
          "test_size": 10000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 0.30146860234448386
        },
        "int32": {
          "precision": "int32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.09638721464917283,
          "efficiency": 5.121531065312052e-05,
          "mean_latency_ms": 0.207496399525553,
          "std_latency_ms": 0.014112991077588264,
          "min_latency_ms": 0.19014899589819834,
          "max_latency_ms": 0.22160939060314125,
          "speedup_vs_fp32": 1.065004501704322,
          "test_size": 10000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 0.28916164394751853
        },
        "int16": {
          "precision": "int16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.09417233331242464,
          "efficiency": 1.2512932940795196e-05,
          "mean_latency_ms": 0.21237660039332695,
          "std_latency_ms": 0.010004199254473399,
          "min_latency_ms": 0.2013809935306199,
          "max_latency_ms": 0.22238079964780036,
          "speedup_vs_fp32": 1.0405317684381579,
          "test_size": 10000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 0.2825169999372739
        },
        "int8": {
          "precision": "int8",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.0949492687126976,
          "efficiency": 6.307664167454833e-06,
          "mean_latency_ms": 0.21063879976281896,
          "std_latency_ms": 0.013604054911567574,
          "min_latency_ms": 0.19818099826807156,
          "max_latency_ms": 0.22424285467438654,
          "speedup_vs_fp32": 1.0491163063546838,
          "test_size": 10000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 0.2848478061380928
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas1_axpy_best_precision=fp16_blas_level=1_device=cuda_framework=pytorch_operation=axpy_size=100000": {
      "operation_type": "blas1_axpy",
      "measured_gflops": 1.0413298586059292,
      "efficiency": 0.00013836431817777428,
      "achieved_bandwidth_gbps": 3.1239895758177876,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.3333333333333333,
      "batch_size": 1,
      "input_shape": [
        100000
      ],
      "output_shape": [
        100000
      ],
      "mean_latency_ms": 0.19206210054107942,
      "std_latency_ms": 0.01225488150931213,
      "min_latency_ms": 0.17718799790600315,
      "max_latency_ms": 0.20431698205039156,
      "num_trials": 10,
      "extra_params": {
        "size": 100000,
        "operation": "axpy",
        "blas_level": 1,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "fp16"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.9306459373366075,
          "efficiency": 0.015773659954857754,
          "mean_latency_ms": 0.21490450017154217,
          "std_latency_ms": 0.012954860065928211,
          "min_latency_ms": 0.1978290019906126,
          "max_latency_ms": 0.2278593602374704,
          "speedup_vs_fp32": null,
          "test_size": 100000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 2.7919378120098224
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.9332166817540902,
          "efficiency": 0.0004958643367450001,
          "mean_latency_ms": 0.2143124998838175,
          "std_latency_ms": 0.013194973543192032,
          "min_latency_ms": 0.18998899759026244,
          "max_latency_ms": 0.22750747342700955,
          "speedup_vs_fp32": 1.0,
          "test_size": 100000,
          "num_trials": 10,
          "arithmetic_intensity": 0.16666666666666666,
          "achieved_bandwidth_gbps": 5.599300090524541
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.9366992671390146,
          "efficiency": 0.00024892353631119176,
          "mean_latency_ms": 0.21351570030674338,
          "std_latency_ms": 0.010993650603343081,
          "min_latency_ms": 0.2004530033445917,
          "max_latency_ms": 0.22450935091008647,
          "speedup_vs_fp32": 1.0037318078995099,
          "test_size": 100000,
          "num_trials": 10,
          "arithmetic_intensity": 0.16666666666666666,
          "achieved_bandwidth_gbps": 5.620195602834087
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.0413298586059292,
          "efficiency": 0.00013836431817777428,
          "mean_latency_ms": 0.19206210054107942,
          "std_latency_ms": 0.01225488150931213,
          "min_latency_ms": 0.17718799790600315,
          "max_latency_ms": 0.20431698205039156,
          "speedup_vs_fp32": 1.1158500260074944,
          "test_size": 100000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 3.1239895758177876
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.9699292882502147,
          "efficiency": 0.00012887713104573674,
          "mean_latency_ms": 0.2062005987681914,
          "std_latency_ms": 0.008114738582562274,
          "min_latency_ms": 0.19360500300535932,
          "max_latency_ms": 0.2143153373507537,
          "speedup_vs_fp32": 1.0393398523771766,
          "test_size": 100000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 2.909787864750644
        },
        "int64": {
          "precision": "int64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.9645871117575741,
          "efficiency": 0.0,
          "mean_latency_ms": 0.20734260033350438,
          "std_latency_ms": 0.023600715564459668,
          "min_latency_ms": 0.1741480009513907,
          "max_latency_ms": 0.23094331589796405,
          "speedup_vs_fp32": 1.0336153763823848,
          "test_size": 100000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 2.893761335272722
        },
        "int32": {
          "precision": "int32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.9294146746876449,
          "efficiency": 0.000493844141704381,
          "mean_latency_ms": 0.21518919966183603,
          "std_latency_ms": 0.056703224879095716,
          "min_latency_ms": 0.17856399790616706,
          "max_latency_ms": 0.27189242454093177,
          "speedup_vs_fp32": 0.9959259118050708,
          "test_size": 100000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 2.788244024062935
        },
        "int16": {
          "precision": "int16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.9654956048382699,
          "efficiency": 0.00012828801552461732,
          "mean_latency_ms": 0.20714749916805886,
          "std_latency_ms": 0.009930707425822876,
          "min_latency_ms": 0.19590900046750903,
          "max_latency_ms": 0.21707820659388175,
          "speedup_vs_fp32": 1.03458888349864,
          "test_size": 100000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 2.8964868145148097
        },
        "int8": {
          "precision": "int8",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.9661971108293046,
          "efficiency": 6.41863489556437e-05,
          "mean_latency_ms": 0.20699710003100336,
          "std_latency_ms": 0.013115333426824654,
          "min_latency_ms": 0.18995699792867526,
          "max_latency_ms": 0.22011243345782802,
          "speedup_vs_fp32": 1.0353405910117506,
          "test_size": 100000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 2.898591332487914
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas1_axpy_best_precision=int8_blas_level=1_device=cuda_framework=pytorch_operation=axpy_size=1000000": {
      "operation_type": "blas1_axpy",
      "measured_gflops": 5.072965730447415,
      "efficiency": 0.00033700695744684885,
      "achieved_bandwidth_gbps": 15.218897191342247,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.3333333333333333,
      "batch_size": 1,
      "input_shape": [
        1000000
      ],
      "output_shape": [
        1000000
      ],
      "mean_latency_ms": 0.3942467003071215,
      "std_latency_ms": 0.0203751695846713,
      "min_latency_ms": 0.36800900124944746,
      "max_latency_ms": 0.4146218698917928,
      "num_trials": 10,
      "extra_params": {
        "size": 1000000,
        "operation": "axpy",
        "blas_level": 1,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "int8"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.3649372731268583,
          "efficiency": 0.0231345300529976,
          "mean_latency_ms": 1.4652687998022884,
          "std_latency_ms": 0.015349277532983388,
          "min_latency_ms": 1.4457330034929328,
          "max_latency_ms": 1.4806180773352717,
          "speedup_vs_fp32": null,
          "test_size": 1000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 4.094811819380575
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 2.63139094327176,
          "efficiency": 0.0013981885989754303,
          "mean_latency_ms": 0.7600542994623538,
          "std_latency_ms": 0.03366985890828369,
          "min_latency_ms": 0.7206259979284368,
          "max_latency_ms": 0.7937241583706375,
          "speedup_vs_fp32": 1.0,
          "test_size": 1000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.16666666666666666,
          "achieved_bandwidth_gbps": 15.78834565963056
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 2.6406861875307603,
          "efficiency": 0.0007017502491445018,
          "mean_latency_ms": 0.7573789000161923,
          "std_latency_ms": 0.05713755104989196,
          "min_latency_ms": 0.7113140018191189,
          "max_latency_ms": 0.8145164510660843,
          "speedup_vs_fp32": 1.003532445181803,
          "test_size": 1000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.16666666666666666,
          "achieved_bandwidth_gbps": 15.844117125184562
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 4.17655815262595,
          "efficiency": 0.0005549505916324674,
          "mean_latency_ms": 0.4788631995324977,
          "std_latency_ms": 0.03573565441817002,
          "min_latency_ms": 0.4501549992710352,
          "max_latency_ms": 0.5145988539506677,
          "speedup_vs_fp32": 1.5872054904289497,
          "test_size": 1000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 12.52967445787785
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 4.293302078414326,
          "efficiency": 0.0005704626731881912,
          "mean_latency_ms": 0.4658419005863834,
          "std_latency_ms": 0.026105324817524783,
          "min_latency_ms": 0.42625000060070306,
          "max_latency_ms": 0.49194722540390823,
          "speedup_vs_fp32": 1.6315713517947343,
          "test_size": 1000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 12.87990623524298
        },
        "int64": {
          "precision": "int64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.4705237924087355,
          "efficiency": 0.0,
          "mean_latency_ms": 1.360059599392116,
          "std_latency_ms": 0.024073864593539045,
          "min_latency_ms": 1.3325140025699511,
          "max_latency_ms": 1.384133463985655,
          "speedup_vs_fp32": 0.5588389654409727,
          "test_size": 1000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 4.411571377226207
        },
        "int32": {
          "precision": "int32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 2.7238485984316836,
          "efficiency": 0.0014473159396555173,
          "mean_latency_ms": 0.7342552009504288,
          "std_latency_ms": 0.008791260530866435,
          "min_latency_ms": 0.7212980053736828,
          "max_latency_ms": 0.7430464614812953,
          "speedup_vs_fp32": 1.0351364191612538,
          "test_size": 1000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 8.171545795295051
        },
        "int16": {
          "precision": "int16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 4.012175348005659,
          "efficiency": 0.000533108603242846,
          "mean_latency_ms": 0.4984826999134384,
          "std_latency_ms": 0.05608959412176632,
          "min_latency_ms": 0.43197799823246896,
          "max_latency_ms": 0.5545722940352047,
          "speedup_vs_fp32": 1.5247355617242835,
          "test_size": 1000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 12.036526044016977
        },
        "int8": {
          "precision": "int8",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 5.072965730447415,
          "efficiency": 0.00033700695744684885,
          "mean_latency_ms": 0.3942467003071215,
          "std_latency_ms": 0.0203751695846713,
          "min_latency_ms": 0.36800900124944746,
          "max_latency_ms": 0.4146218698917928,
          "speedup_vs_fp32": 1.9278647072258692,
          "test_size": 1000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 15.218897191342247
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas1_axpy_best_precision=int8_blas_level=1_device=cuda_framework=pytorch_operation=axpy_size=10000000": {
      "operation_type": "blas1_axpy",
      "measured_gflops": 8.249921130807724,
      "efficiency": 0.0005480582695016093,
      "achieved_bandwidth_gbps": 24.749763392423173,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.3333333333333333,
      "batch_size": 1,
      "input_shape": [
        10000000
      ],
      "output_shape": [
        10000000
      ],
      "mean_latency_ms": 2.42426559998421,
      "std_latency_ms": 0.01638612989598849,
      "min_latency_ms": 2.389338995271828,
      "max_latency_ms": 2.4406517298801984,
      "num_trials": 10,
      "extra_params": {
        "size": 10000000,
        "operation": "axpy",
        "blas_level": 1,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "int8"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.5196988569899885,
          "efficiency": 0.025757607745593027,
          "mean_latency_ms": 13.160502100799931,
          "std_latency_ms": 0.03790250194255001,
          "min_latency_ms": 13.123657001415268,
          "max_latency_ms": 13.198404602742482,
          "speedup_vs_fp32": null,
          "test_size": 10000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 4.559096570969966
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 2.9021728044326505,
          "efficiency": 0.0015420684401873806,
          "mean_latency_ms": 6.891388400254073,
          "std_latency_ms": 0.8487556306574339,
          "min_latency_ms": 5.7676959986565635,
          "max_latency_ms": 7.740144030911506,
          "speedup_vs_fp32": 1.0,
          "test_size": 10000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.16666666666666666,
          "achieved_bandwidth_gbps": 17.413036826595903
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 3.001363249200185,
          "efficiency": 0.0007975985249003946,
          "mean_latency_ms": 6.663638600002741,
          "std_latency_ms": 0.46940627319508393,
          "min_latency_ms": 5.78398400102742,
          "max_latency_ms": 7.133044873197825,
          "speedup_vs_fp32": 1.0341779940243514,
          "test_size": 10000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.16666666666666666,
          "achieved_bandwidth_gbps": 18.008179495201112
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 5.8422911477705615,
          "efficiency": 0.00077628104541198,
          "mean_latency_ms": 3.4233145001053344,
          "std_latency_ms": 0.11465018355137246,
          "min_latency_ms": 3.235921001760289,
          "max_latency_ms": 3.537964683656707,
          "speedup_vs_fp32": 2.013074872332655,
          "test_size": 10000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 17.526873443311683
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 5.7260530792734725,
          "efficiency": 0.0007608361784843838,
          "mean_latency_ms": 3.492807300790446,
          "std_latency_ms": 0.17763624452913138,
          "min_latency_ms": 3.2384490041295066,
          "max_latency_ms": 3.670443545319577,
          "speedup_vs_fp32": 1.9730227884872162,
          "test_size": 10000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 17.178159237820417
        },
        "int64": {
          "precision": "int64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.570812938228363,
          "efficiency": 0.0,
          "mean_latency_ms": 12.732260801567463,
          "std_latency_ms": 0.09557959544014055,
          "min_latency_ms": 12.651581004320178,
          "max_latency_ms": 12.827840397007604,
          "speedup_vs_fp32": 0.541254103073798,
          "test_size": 10000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 4.712438814685089
        },
        "int32": {
          "precision": "int32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 3.01465768781282,
          "efficiency": 0.0016018372411332731,
          "mean_latency_ms": 6.634252399817342,
          "std_latency_ms": 0.46552608501716575,
          "min_latency_ms": 5.7298719984828494,
          "max_latency_ms": 7.099778484834507,
          "speedup_vs_fp32": 1.0387588510265018,
          "test_size": 10000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 9.04397306343846
        },
        "int16": {
          "precision": "int16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 5.880367976009685,
          "efficiency": 0.000781340416690099,
          "mean_latency_ms": 3.4011476971500088,
          "std_latency_ms": 0.12537971146018467,
          "min_latency_ms": 3.2155049993889406,
          "max_latency_ms": 3.5265274086101934,
          "speedup_vs_fp32": 2.0261949829549333,
          "test_size": 10000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 17.641103928029057
        },
        "int8": {
          "precision": "int8",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 8.249921130807724,
          "efficiency": 0.0005480582695016093,
          "mean_latency_ms": 2.42426559998421,
          "std_latency_ms": 0.01638612989598849,
          "min_latency_ms": 2.389338995271828,
          "max_latency_ms": 2.4406517298801984,
          "speedup_vs_fp32": 2.842670539192966,
          "test_size": 10000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 24.749763392423173
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas2_gemv_best_precision=tf32_blas_level=2_device=cuda_framework=pytorch_operation=gemv_size=32": {
      "operation_type": "blas2_gemv",
      "measured_gflops": 0.005521291626612448,
      "efficiency": 1.4672579395728004e-06,
      "achieved_bandwidth_gbps": 0.011732744706551453,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.47058823529411764,
      "batch_size": 1,
      "input_shape": [
        32,
        32
      ],
      "output_shape": [
        32
      ],
      "mean_latency_ms": 0.3709276992594823,
      "std_latency_ms": 0.03158039400774256,
      "min_latency_ms": 0.3361039998708293,
      "max_latency_ms": 0.40250809326722486,
      "num_trials": 10,
      "extra_params": {
        "size": 32,
        "operation": "gemv",
        "blas_level": 2,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "tf32"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.005375621560615898,
          "efficiency": 9.111222984094743e-05,
          "mean_latency_ms": 0.3809791996900458,
          "std_latency_ms": 0.02658163099963997,
          "min_latency_ms": 0.3535449941409752,
          "max_latency_ms": 0.40756083068968574,
          "speedup_vs_fp32": null,
          "test_size": 32,
          "num_trials": 10,
          "arithmetic_intensity": 0.9411764705882353,
          "achieved_bandwidth_gbps": 0.0057115979081543925
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.003861466125978997,
          "efficiency": 2.051788589786927e-06,
          "mean_latency_ms": 0.5303685007675085,
          "std_latency_ms": 0.21977186058469184,
          "min_latency_ms": 0.37236099888104945,
          "max_latency_ms": 0.7501403613522004,
          "speedup_vs_fp32": 1.0,
          "test_size": 32,
          "num_trials": 10,
          "arithmetic_intensity": 0.47058823529411764,
          "achieved_bandwidth_gbps": 0.00820561551770537
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.005521291626612448,
          "efficiency": 1.4672579395728004e-06,
          "mean_latency_ms": 0.3709276992594823,
          "std_latency_ms": 0.03158039400774256,
          "min_latency_ms": 0.3361039998708293,
          "max_latency_ms": 0.40250809326722486,
          "speedup_vs_fp32": 1.4298433409700404,
          "test_size": 32,
          "num_trials": 10,
          "arithmetic_intensity": 0.47058823529411764,
          "achieved_bandwidth_gbps": 0.011732744706551453
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.005415976335314074,
          "efficiency": 7.196354418434858e-07,
          "mean_latency_ms": 0.3781405001063831,
          "std_latency_ms": 0.01996069816326599,
          "min_latency_ms": 0.35421700158622116,
          "max_latency_ms": 0.3981011982696491,
          "speedup_vs_fp32": 1.4025699458754055,
          "test_size": 32,
          "num_trials": 10,
          "arithmetic_intensity": 0.9411764705882353,
          "achieved_bandwidth_gbps": 0.005754474856271204
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.005306840610791529,
          "efficiency": 7.051342825925496e-07,
          "mean_latency_ms": 0.38591699849348515,
          "std_latency_ms": 0.021054283410562827,
          "min_latency_ms": 0.36151299718767405,
          "max_latency_ms": 0.40697128190404797,
          "speedup_vs_fp32": 1.374307177030094,
          "test_size": 32,
          "num_trials": 10,
          "arithmetic_intensity": 0.9411764705882353,
          "achieved_bandwidth_gbps": 0.005638518148965999
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Long'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Int'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Short'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Char'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas2_gemv_best_precision=fp64_blas_level=2_device=cuda_framework=pytorch_operation=gemv_size=64": {
      "operation_type": "blas2_gemv",
      "measured_gflops": 0.022115693328764393,
      "efficiency": 0.00037484225980956596,
      "achieved_bandwidth_gbps": 0.02280680874528828,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.9696969696969697,
      "batch_size": 1,
      "input_shape": [
        64,
        64
      ],
      "output_shape": [
        64
      ],
      "mean_latency_ms": 0.3704156988533214,
      "std_latency_ms": 0.016419470424492436,
      "min_latency_ms": 0.3438810017541982,
      "max_latency_ms": 0.3868351692778138,
      "num_trials": 10,
      "extra_params": {
        "size": 64,
        "operation": "gemv",
        "blas_level": 2,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "fp64"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.022115693328764393,
          "efficiency": 0.00037484225980956596,
          "mean_latency_ms": 0.3704156988533214,
          "std_latency_ms": 0.016419470424492436,
          "min_latency_ms": 0.3438810017541982,
          "max_latency_ms": 0.3868351692778138,
          "speedup_vs_fp32": null,
          "test_size": 64,
          "num_trials": 10,
          "arithmetic_intensity": 0.9696969696969697,
          "achieved_bandwidth_gbps": 0.02280680874528828
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.021691623547443282,
          "efficiency": 1.1525836103848715e-05,
          "mean_latency_ms": 0.37765730085084215,
          "std_latency_ms": 0.01985379149976227,
          "min_latency_ms": 0.35501700040185824,
          "max_latency_ms": 0.39751109235060444,
          "speedup_vs_fp32": 1.0,
          "test_size": 64,
          "num_trials": 10,
          "arithmetic_intensity": 0.48484848484848486,
          "achieved_bandwidth_gbps": 0.04473897356660177
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.021931538831577467,
          "efficiency": 5.8282059079398e-06,
          "mean_latency_ms": 0.3735260012035724,
          "std_latency_ms": 0.014479320467872186,
          "min_latency_ms": 0.3591130007407628,
          "max_latency_ms": 0.3880053216714446,
          "speedup_vs_fp32": 1.0110602732713598,
          "test_size": 64,
          "num_trials": 10,
          "arithmetic_intensity": 0.48484848484848486,
          "achieved_bandwidth_gbps": 0.04523379884012853
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.021945833605222217,
          "efficiency": 2.9160023392535502e-06,
          "mean_latency_ms": 0.3732826990017202,
          "std_latency_ms": 0.017345713900947697,
          "min_latency_ms": 0.3401360008865595,
          "max_latency_ms": 0.39062841290266787,
          "speedup_vs_fp32": 1.0117192729821691,
          "test_size": 64,
          "num_trials": 10,
          "arithmetic_intensity": 0.9696969696969697,
          "achieved_bandwidth_gbps": 0.022631640905385407
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.021998070399259283,
          "efficiency": 2.9229431835316615e-06,
          "mean_latency_ms": 0.3723962989170104,
          "std_latency_ms": 0.013085214507479547,
          "min_latency_ms": 0.3552089983713813,
          "max_latency_ms": 0.38548151342449,
          "speedup_vs_fp32": 1.01412742808973,
          "test_size": 64,
          "num_trials": 10,
          "arithmetic_intensity": 0.9696969696969697,
          "achieved_bandwidth_gbps": 0.02268551009923614
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Long'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Int'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Short'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Char'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas2_gemv_best_precision=fp32_blas_level=2_device=cuda_framework=pytorch_operation=gemv_size=128": {
      "operation_type": "blas2_gemv",
      "measured_gflops": 0.05729457621376716,
      "efficiency": 3.0443451760768947e-05,
      "achieved_bandwidth_gbps": 0.11637960793421454,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.49230769230769234,
      "batch_size": 1,
      "input_shape": [
        128,
        128
      ],
      "output_shape": [
        128
      ],
      "mean_latency_ms": 0.5719215005228762,
      "std_latency_ms": 0.034393445230419685,
      "min_latency_ms": 0.5203330001677386,
      "max_latency_ms": 0.6063149457532958,
      "num_trials": 10,
      "extra_params": {
        "size": 128,
        "operation": "gemv",
        "blas_level": 2,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "fp32"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.054735173708504,
          "efficiency": 0.0009277148086187118,
          "mean_latency_ms": 0.5986644013319165,
          "std_latency_ms": 0.05823376678276389,
          "min_latency_ms": 0.5317570030456409,
          "max_latency_ms": 0.6568981681146804,
          "speedup_vs_fp32": null,
          "test_size": 128,
          "num_trials": 10,
          "arithmetic_intensity": 0.9846153846153847,
          "achieved_bandwidth_gbps": 0.05559041079769938
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.05729457621376716,
          "efficiency": 3.0443451760768947e-05,
          "mean_latency_ms": 0.5719215005228762,
          "std_latency_ms": 0.034393445230419685,
          "min_latency_ms": 0.5203330001677386,
          "max_latency_ms": 0.6063149457532958,
          "speedup_vs_fp32": 1.0,
          "test_size": 128,
          "num_trials": 10,
          "arithmetic_intensity": 0.49230769230769234,
          "achieved_bandwidth_gbps": 0.11637960793421454
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.05679974485478967,
          "efficiency": 1.5094271818971477e-05,
          "mean_latency_ms": 0.576903999899514,
          "std_latency_ms": 0.051034672110100494,
          "min_latency_ms": 0.5253580020507798,
          "max_latency_ms": 0.6279386720096145,
          "speedup_vs_fp32": 0.9913633821614936,
          "test_size": 128,
          "num_trials": 10,
          "arithmetic_intensity": 0.49230769230769234,
          "achieved_bandwidth_gbps": 0.11537448173629151
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.05683096268119741,
          "efficiency": 7.551283906616717e-06,
          "mean_latency_ms": 0.5765871006587986,
          "std_latency_ms": 0.04040028289758901,
          "min_latency_ms": 0.5210369999986142,
          "max_latency_ms": 0.6169873835563876,
          "speedup_vs_fp32": 0.9919082474606323,
          "test_size": 128,
          "num_trials": 10,
          "arithmetic_intensity": 0.9846153846153847,
          "achieved_bandwidth_gbps": 0.05771894647309113
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.05520642504689204,
          "efficiency": 7.335427191986718e-06,
          "mean_latency_ms": 0.593554101214977,
          "std_latency_ms": 0.05107935623458432,
          "min_latency_ms": 0.5234690033830702,
          "max_latency_ms": 0.6446334574495614,
          "speedup_vs_fp32": 0.9635541214392758,
          "test_size": 128,
          "num_trials": 10,
          "arithmetic_intensity": 0.9846153846153847,
          "achieved_bandwidth_gbps": 0.05606902543824973
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Long'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Int'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Short'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Char'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas2_gemv_best_precision=fp16_blas_level=2_device=cuda_framework=pytorch_operation=gemv_size=256": {
      "operation_type": "blas2_gemv",
      "measured_gflops": 0.3391204846229484,
      "efficiency": 4.505985711173909e-05,
      "achieved_bandwidth_gbps": 0.34176986340906523,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.9922480620155039,
      "batch_size": 1,
      "input_shape": [
        256,
        256
      ],
      "output_shape": [
        256
      ],
      "mean_latency_ms": 0.3865056991344318,
      "std_latency_ms": 0.022383764978074244,
      "min_latency_ms": 0.3489360024104826,
      "max_latency_ms": 0.40888946411250604,
      "num_trials": 10,
      "extra_params": {
        "size": 256,
        "operation": "gemv",
        "blas_level": 2,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "fp16"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.23371608418401513,
          "efficiency": 0.003961289562440935,
          "mean_latency_ms": 0.5608172003121581,
          "std_latency_ms": 0.03938669069652911,
          "min_latency_ms": 0.5195650010136887,
          "max_latency_ms": 0.6002038910086872,
          "speedup_vs_fp32": null,
          "test_size": 256,
          "num_trials": 10,
          "arithmetic_intensity": 0.9922480620155039,
          "achieved_bandwidth_gbps": 0.23554199109170273
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.22822060499807148,
          "efficiency": 0.00012126493358027177,
          "mean_latency_ms": 0.5743214991525747,
          "std_latency_ms": 0.04899068139138782,
          "min_latency_ms": 0.5265090003376827,
          "max_latency_ms": 0.6233121805439625,
          "speedup_vs_fp32": 1.0,
          "test_size": 256,
          "num_trials": 10,
          "arithmetic_intensity": 0.49612403100775193,
          "achieved_bandwidth_gbps": 0.4600071569492379
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.23145893364394532,
          "efficiency": 6.150915058303092e-05,
          "mean_latency_ms": 0.5662862000463065,
          "std_latency_ms": 0.053119951993504125,
          "min_latency_ms": 0.5014520065742545,
          "max_latency_ms": 0.6194061520398106,
          "speedup_vs_fp32": 1.0141894665729294,
          "test_size": 256,
          "num_trials": 10,
          "arithmetic_intensity": 0.49612403100775193,
          "achieved_bandwidth_gbps": 0.4665344131260773
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.3391204846229484,
          "efficiency": 4.505985711173909e-05,
          "mean_latency_ms": 0.3865056991344318,
          "std_latency_ms": 0.022383764978074244,
          "min_latency_ms": 0.3489360024104826,
          "max_latency_ms": 0.40888946411250604,
          "speedup_vs_fp32": 1.4859328088531447,
          "test_size": 256,
          "num_trials": 10,
          "arithmetic_intensity": 0.9922480620155039,
          "achieved_bandwidth_gbps": 0.34176986340906523
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.33347945724484807,
          "efficiency": 4.431031852841457e-05,
          "mean_latency_ms": 0.39304370075115,
          "std_latency_ms": 0.021722052324337004,
          "min_latency_ms": 0.36279300547903404,
          "max_latency_ms": 0.414765753075487,
          "speedup_vs_fp32": 1.4612153764453741,
          "test_size": 256,
          "num_trials": 10,
          "arithmetic_intensity": 0.9922480620155039,
          "achieved_bandwidth_gbps": 0.33608476550457345
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Long'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Int'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Short'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Char'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas2_gemv_best_precision=fp32_blas_level=2_device=cuda_framework=pytorch_operation=gemv_size=512": {
      "operation_type": "blas2_gemv",
      "measured_gflops": 1.4013726975445109,
      "efficiency": 0.0007446188616070727,
      "achieved_bandwidth_gbps": 2.8136936192885886,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.4980544747081712,
      "batch_size": 1,
      "input_shape": [
        512,
        512
      ],
      "output_shape": [
        512
      ],
      "mean_latency_ms": 0.37412460005725734,
      "std_latency_ms": 0.010883576236916003,
      "min_latency_ms": 0.3606809987104498,
      "max_latency_ms": 0.38500817629417333,
      "num_trials": 10,
      "extra_params": {
        "size": 512,
        "operation": "gemv",
        "blas_level": 2,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "fp32"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.376494771902271,
          "efficiency": 0.02333041986275036,
          "mean_latency_ms": 0.38088629953563213,
          "std_latency_ms": 0.014701408756343248,
          "min_latency_ms": 0.3594650042941794,
          "max_latency_ms": 0.39558770829197537,
          "speedup_vs_fp32": null,
          "test_size": 512,
          "num_trials": 10,
          "arithmetic_intensity": 0.9961089494163424,
          "achieved_bandwidth_gbps": 1.3818717046050144
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.4013726975445109,
          "efficiency": 0.0007446188616070727,
          "mean_latency_ms": 0.37412460005725734,
          "std_latency_ms": 0.010883576236916003,
          "min_latency_ms": 0.3606809987104498,
          "max_latency_ms": 0.38500817629417333,
          "speedup_vs_fp32": 1.0,
          "test_size": 512,
          "num_trials": 10,
          "arithmetic_intensity": 0.4980544747081712,
          "achieved_bandwidth_gbps": 2.8136936192885886
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.3713436722623538,
          "efficiency": 0.0003644282945156401,
          "mean_latency_ms": 0.38231700091273524,
          "std_latency_ms": 0.030522998713535254,
          "min_latency_ms": 0.360361002094578,
          "max_latency_ms": 0.4128399996262705,
          "speedup_vs_fp32": 0.9785717066310953,
          "test_size": 512,
          "num_trials": 10,
          "arithmetic_intensity": 0.4980544747081712,
          "achieved_bandwidth_gbps": 2.753400966964257
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.3145153329948522,
          "efficiency": 0.0001746632119312852,
          "mean_latency_ms": 0.3988451004261151,
          "std_latency_ms": 0.025265622106823114,
          "min_latency_ms": 0.3781850027735345,
          "max_latency_ms": 0.4241107225329382,
          "speedup_vs_fp32": 0.9380197968021995,
          "test_size": 512,
          "num_trials": 10,
          "arithmetic_intensity": 0.9961089494163424,
          "achieved_bandwidth_gbps": 1.3196501585143632
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.303731024779953,
          "efficiency": 0.0001732302716954495,
          "mean_latency_ms": 0.402144299732754,
          "std_latency_ms": 0.01008071461453725,
          "min_latency_ms": 0.38855399907333776,
          "max_latency_ms": 0.41222501434729125,
          "speedup_vs_fp32": 0.9303242649613155,
          "test_size": 512,
          "num_trials": 10,
          "arithmetic_intensity": 0.9961089494163424,
          "achieved_bandwidth_gbps": 1.3088237240954999
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Long'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Int'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Short'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Char'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas2_gemv_best_precision=tf32_blas_level=2_device=cuda_framework=pytorch_operation=gemv_size=1024": {
      "operation_type": "blas2_gemv",
      "measured_gflops": 3.601619972282741,
      "efficiency": 0.000957113997417683,
      "achieved_bandwidth_gbps": 7.217308772582212,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.49902534113060426,
      "batch_size": 1,
      "input_shape": [
        1024,
        1024
      ],
      "output_shape": [
        1024
      ],
      "mean_latency_ms": 0.5822802006150596,
      "std_latency_ms": 0.05459861731532946,
      "min_latency_ms": 0.5233409974607639,
      "max_latency_ms": 0.636878817930389,
      "num_trials": 10,
      "extra_params": {
        "size": 1024,
        "operation": "gemv",
        "blas_level": 2,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "tf32"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.6751710521113583,
          "efficiency": 0.028392729696802683,
          "mean_latency_ms": 1.2519031995907426,
          "std_latency_ms": 0.3307003824465324,
          "min_latency_ms": 0.932727001782041,
          "max_latency_ms": 1.582603582037275,
          "speedup_vs_fp32": null,
          "test_size": 1024,
          "num_trials": 10,
          "arithmetic_intensity": 0.9980506822612085,
          "achieved_bandwidth_gbps": 1.6784428705725134
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 2.021461018787684,
          "efficiency": 0.0010741025604610434,
          "mean_latency_ms": 1.0374437006248627,
          "std_latency_ms": 0.28633086347114406,
          "min_latency_ms": 0.6323350025922991,
          "max_latency_ms": 1.3237745640960068,
          "speedup_vs_fp32": 1.0,
          "test_size": 1024,
          "num_trials": 10,
          "arithmetic_intensity": 0.49902534113060426,
          "achieved_bandwidth_gbps": 4.050818369680007
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 3.601619972282741,
          "efficiency": 0.000957113997417683,
          "mean_latency_ms": 0.5822802006150596,
          "std_latency_ms": 0.05459861731532946,
          "min_latency_ms": 0.5233409974607639,
          "max_latency_ms": 0.636878817930389,
          "speedup_vs_fp32": 1.78169152845832,
          "test_size": 1024,
          "num_trials": 10,
          "arithmetic_intensity": 0.49902534113060426,
          "achieved_bandwidth_gbps": 7.217308772582212
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 3.4388961332216312,
          "efficiency": 0.00045693544156545727,
          "mean_latency_ms": 0.6098328994994517,
          "std_latency_ms": 0.04630646846707439,
          "min_latency_ms": 0.5474380013765767,
          "max_latency_ms": 0.6561393679665262,
          "speedup_vs_fp32": 1.7011933949060347,
          "test_size": 1024,
          "num_trials": 10,
          "arithmetic_intensity": 0.9980506822612085,
          "achieved_bandwidth_gbps": 3.445612727231829
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.8862554399823304,
          "efficiency": 0.0002506318681879259,
          "mean_latency_ms": 1.1118069989606738,
          "std_latency_ms": 0.6344342569907289,
          "min_latency_ms": 0.5898070012335666,
          "max_latency_ms": 1.7462412559514027,
          "speedup_vs_fp32": 0.9331149215598333,
          "test_size": 1024,
          "num_trials": 10,
          "arithmetic_intensity": 0.9980506822612085,
          "achieved_bandwidth_gbps": 1.8899395326385457
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Long'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Int'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Short'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Char'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas2_gemv_best_precision=fp16_blas_level=2_device=cuda_framework=pytorch_operation=gemv_size=2048": {
      "operation_type": "blas2_gemv",
      "measured_gflops": 16.20462866410506,
      "efficiency": 0.0021531528918555753,
      "achieved_bandwidth_gbps": 16.22045349678485,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.9990243902439024,
      "batch_size": 1,
      "input_shape": [
        2048,
        2048
      ],
      "output_shape": [
        2048
      ],
      "mean_latency_ms": 0.5176674007088877,
      "std_latency_ms": 0.014267954857248454,
      "min_latency_ms": 0.5016760042053647,
      "max_latency_ms": 0.5319353555661361,
      "num_trials": 10,
      "extra_params": {
        "size": 2048,
        "operation": "gemv",
        "blas_level": 2,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "fp16"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 2.5866640001501913,
          "efficiency": 0.043841762714410024,
          "mean_latency_ms": 3.2430218998342752,
          "std_latency_ms": 0.06897242232012395,
          "min_latency_ms": 3.173359000356868,
          "max_latency_ms": 3.311994322154399,
          "speedup_vs_fp32": null,
          "test_size": 2048,
          "num_trials": 10,
          "arithmetic_intensity": 0.9990243902439024,
          "achieved_bandwidth_gbps": 2.589190039212838
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 8.686635169456633,
          "efficiency": 0.004615640366342526,
          "mean_latency_ms": 0.9656912989157718,
          "std_latency_ms": 0.29676294535257836,
          "min_latency_ms": 0.7731709993095137,
          "max_latency_ms": 1.2624542442683502,
          "speedup_vs_fp32": 1.0,
          "test_size": 2048,
          "num_trials": 10,
          "arithmetic_intensity": 0.4995121951219512,
          "achieved_bandwidth_gbps": 17.390236423228608
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 9.546783700716665,
          "efficiency": 0.002537014004973868,
          "mean_latency_ms": 0.8786842001427431,
          "std_latency_ms": 0.1269759550703011,
          "min_latency_ms": 0.7931400032248348,
          "max_latency_ms": 1.0056601552130442,
          "speedup_vs_fp32": 1.0990197601810685,
          "test_size": 2048,
          "num_trials": 10,
          "arithmetic_intensity": 0.4995121951219512,
          "achieved_bandwidth_gbps": 19.112213463348795
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 16.20462866410506,
          "efficiency": 0.0021531528918555753,
          "mean_latency_ms": 0.5176674007088877,
          "std_latency_ms": 0.014267954857248454,
          "min_latency_ms": 0.5016760042053647,
          "max_latency_ms": 0.5319353555661361,
          "speedup_vs_fp32": 1.8654667023524476,
          "test_size": 2048,
          "num_trials": 10,
          "arithmetic_intensity": 0.9990243902439024,
          "achieved_bandwidth_gbps": 16.22045349678485
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 16.156791977072796,
          "efficiency": 0.002146796701710443,
          "mean_latency_ms": 0.5192000993702095,
          "std_latency_ms": 0.013266293895729222,
          "min_latency_ms": 0.5015169954276644,
          "max_latency_ms": 0.5324663932659387,
          "speedup_vs_fp32": 1.8599597729028878,
          "test_size": 2048,
          "num_trials": 10,
          "arithmetic_intensity": 0.9990243902439024,
          "achieved_bandwidth_gbps": 16.17257009423791
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Long'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Int'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Short'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Char'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas3_gemm_best_precision=fp16_blas_level=3_device=cuda_framework=pytorch_operation=gemm_size=32": {
      "operation_type": "blas3_gemm",
      "measured_gflops": 0.17717503538752555,
      "efficiency": 2.3541726732331323e-05,
      "achieved_bandwidth_gbps": 0.01661015956758052,
      "memory_bound": false,
      "compute_bound": true,
      "arithmetic_intensity": 10.666666666666666,
      "batch_size": 1,
      "input_shape": [
        32,
        32
      ],
      "output_shape": [
        32,
        32
      ],
      "mean_latency_ms": 0.36989409854868427,
      "std_latency_ms": 0.018013900378489878,
      "min_latency_ms": 0.3471769960015081,
      "max_latency_ms": 0.38790799892717415,
      "num_trials": 10,
      "extra_params": {
        "size": 32,
        "operation": "gemm",
        "blas_level": 3,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "fp16"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.16362258676335328,
          "efficiency": 0.002773264182429717,
          "mean_latency_ms": 0.4005314993264619,
          "std_latency_ms": 0.027522331424698857,
          "min_latency_ms": 0.3726490031112917,
          "max_latency_ms": 0.42805383075116077,
          "speedup_vs_fp32": null,
          "test_size": 32,
          "num_trials": 10,
          "arithmetic_intensity": 2.6666666666666665,
          "achieved_bandwidth_gbps": 0.06135847003625748
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.10991860435564504,
          "efficiency": 5.8405209540725314e-05,
          "mean_latency_ms": 0.5962229995930102,
          "std_latency_ms": 0.03326560855994591,
          "min_latency_ms": 0.5573259986704215,
          "max_latency_ms": 0.629488608152956,
          "speedup_vs_fp32": 1.0,
          "test_size": 32,
          "num_trials": 10,
          "arithmetic_intensity": 5.333333333333333,
          "achieved_bandwidth_gbps": 0.020609738316683446
        },
        "tf32": {
          "precision": "tf32",
          "supported": false,
          "failure_reason": "Timeout: GEMM benchmark exceeded 5s timeout",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.17717503538752555,
          "efficiency": 2.3541726732331323e-05,
          "mean_latency_ms": 0.36989409854868427,
          "std_latency_ms": 0.018013900378489878,
          "min_latency_ms": 0.3471769960015081,
          "max_latency_ms": 0.38790799892717415,
          "speedup_vs_fp32": 1.6118748634605133,
          "test_size": 32,
          "num_trials": 10,
          "arithmetic_intensity": 10.666666666666666,
          "achieved_bandwidth_gbps": 0.01661015956758052
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.1663214326208538,
          "efficiency": 2.2099579141755755e-05,
          "mean_latency_ms": 0.39403219998348504,
          "std_latency_ms": 0.01796865234803821,
          "min_latency_ms": 0.3753690034500323,
          "max_latency_ms": 0.4120008523315233,
          "speedup_vs_fp32": 1.5131326820955229,
          "test_size": 32,
          "num_trials": 10,
          "arithmetic_intensity": 10.666666666666666,
          "achieved_bandwidth_gbps": 0.015592634308205044
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'Lo",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'In",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'Sh",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'Ch",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas3_gemm_best_precision=fp32_blas_level=3_device=cuda_framework=pytorch_operation=gemm_size=64": {
      "operation_type": "blas3_gemm",
      "measured_gflops": 0.9192957989922492,
      "efficiency": 0.000488467480867295,
      "achieved_bandwidth_gbps": 0.08618398115552336,
      "memory_bound": false,
      "compute_bound": true,
      "arithmetic_intensity": 10.666666666666666,
      "batch_size": 1,
      "input_shape": [
        64,
        64
      ],
      "output_shape": [
        64,
        64
      ],
      "mean_latency_ms": 0.5703148002794478,
      "std_latency_ms": 0.24018582448069176,
      "min_latency_ms": 0.38170500192791224,
      "max_latency_ms": 0.8105006247601396,
      "num_trials": 10,
      "extra_params": {
        "size": 64,
        "operation": "gemm",
        "blas_level": 3,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "fp32"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.61749839546115,
          "efficiency": 0.010466074499341525,
          "mean_latency_ms": 0.8490515989251435,
          "std_latency_ms": 0.19816435966386228,
          "min_latency_ms": 0.6194399975356646,
          "max_latency_ms": 1.0472159585890057,
          "speedup_vs_fp32": null,
          "test_size": 64,
          "num_trials": 10,
          "arithmetic_intensity": 5.333333333333333,
          "achieved_bandwidth_gbps": 0.11578094914896563
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.9192957989922492,
          "efficiency": 0.000488467480867295,
          "mean_latency_ms": 0.5703148002794478,
          "std_latency_ms": 0.24018582448069176,
          "min_latency_ms": 0.38170500192791224,
          "max_latency_ms": 0.8105006247601396,
          "speedup_vs_fp32": 1.0,
          "test_size": 64,
          "num_trials": 10,
          "arithmetic_intensity": 10.666666666666666,
          "achieved_bandwidth_gbps": 0.08618398115552336
        },
        "tf32": {
          "precision": "tf32",
          "supported": false,
          "failure_reason": "Skipped (poor performance at size 32: Timeout (>5s))",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp16": {
          "precision": "fp16",
          "supported": false,
          "failure_reason": "Timeout: GEMM benchmark exceeded 5s timeout",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.8441885085449273,
          "efficiency": 0.00011216961314708043,
          "mean_latency_ms": 0.6210555991856381,
          "std_latency_ms": 0.027150830378747767,
          "min_latency_ms": 0.5914389985264279,
          "max_latency_ms": 0.6482064295643859,
          "speedup_vs_fp32": 0.9182991040210822,
          "test_size": 64,
          "num_trials": 10,
          "arithmetic_intensity": 21.333333333333332,
          "achieved_bandwidth_gbps": 0.03957133633804347
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "Timeout: GEMM benchmark exceeded 5s timeout",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'In",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'Sh",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'Ch",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas3_gemm_best_precision=bf16_blas_level=3_device=cuda_framework=pytorch_operation=gemm_size=128": {
      "operation_type": "blas3_gemm",
      "measured_gflops": 7.420274092454892,
      "efficiency": 0.0009859519123644554,
      "achieved_bandwidth_gbps": 0.17391267404191155,
      "memory_bound": false,
      "compute_bound": true,
      "arithmetic_intensity": 42.666666666666664,
      "batch_size": 1,
      "input_shape": [
        128,
        128
      ],
      "output_shape": [
        128,
        128
      ],
      "mean_latency_ms": 0.5652492007357068,
      "std_latency_ms": 0.12080209602806986,
      "min_latency_ms": 0.37860099837416783,
      "max_latency_ms": 0.6860512967637767,
      "num_trials": 10,
      "extra_params": {
        "size": 128,
        "operation": "gemm",
        "blas_level": 3,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "bf16"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 3.2651030265615875,
          "efficiency": 0.05534072926375572,
          "mean_latency_ms": 1.2845854987972416,
          "std_latency_ms": 0.11619259226444272,
          "min_latency_ms": 1.200860999233555,
          "max_latency_ms": 1.4007780910616843,
          "speedup_vs_fp32": null,
          "test_size": 128,
          "num_trials": 10,
          "arithmetic_intensity": 10.666666666666666,
          "achieved_bandwidth_gbps": 0.30610340874014885
        },
        "fp32": {
          "precision": "fp32",
          "supported": false,
          "failure_reason": "Timeout: GEMM benchmark exceeded 5s timeout",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "tf32": {
          "precision": "tf32",
          "supported": false,
          "failure_reason": "Skipped (poor performance at size 32: Timeout (>5s))",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp16": {
          "precision": "fp16",
          "supported": false,
          "failure_reason": "Skipped (poor performance at size 64: Timeout (>5s))",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 7.420274092454892,
          "efficiency": 0.0009859519123644554,
          "mean_latency_ms": 0.5652492007357068,
          "std_latency_ms": 0.12080209602806986,
          "min_latency_ms": 0.37860099837416783,
          "max_latency_ms": 0.6860512967637767,
          "speedup_vs_fp32": null,
          "test_size": 128,
          "num_trials": 10,
          "arithmetic_intensity": 42.666666666666664,
          "achieved_bandwidth_gbps": 0.17391267404191155
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "Skipped (poor performance at size 64: Timeout (>5s))",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'In",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "Timeout: GEMM benchmark exceeded 5s timeout",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'Ch",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas3_gemm_best_precision=bf16_blas_level=3_device=cuda_framework=pytorch_operation=gemm_size=256": {
      "operation_type": "blas3_gemm",
      "measured_gflops": 88.65433083952256,
      "efficiency": 0.011779741009769142,
      "achieved_bandwidth_gbps": 1.038917939525655,
      "memory_bound": false,
      "compute_bound": true,
      "arithmetic_intensity": 85.33333333333333,
      "batch_size": 1,
      "input_shape": [
        256,
        256
      ],
      "output_shape": [
        256,
        256
      ],
      "mean_latency_ms": 0.3784861008170992,
      "std_latency_ms": 0.02399835638454456,
      "min_latency_ms": 0.34221600071759894,
      "max_latency_ms": 0.4024844572016438,
      "num_trials": 10,
      "extra_params": {
        "size": 256,
        "operation": "gemm",
        "blas_level": 3,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "bf16"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 5.504855108536896,
          "efficiency": 0.09330262895825248,
          "mean_latency_ms": 6.095425099920249,
          "std_latency_ms": 1.9839233673385357,
          "min_latency_ms": 4.4751200039172545,
          "max_latency_ms": 8.079348467258784,
          "speedup_vs_fp32": null,
          "test_size": 256,
          "num_trials": 10,
          "arithmetic_intensity": 21.333333333333332,
          "achieved_bandwidth_gbps": 0.25804008321266697
        },
        "fp32": {
          "precision": "fp32",
          "supported": false,
          "failure_reason": "Skipped (poor performance at size 128: Timeout (>5s))",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "tf32": {
          "precision": "tf32",
          "supported": false,
          "failure_reason": "Skipped (poor performance at size 32: Timeout (>5s))",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp16": {
          "precision": "fp16",
          "supported": false,
          "failure_reason": "Skipped (poor performance at size 64: Timeout (>5s))",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 88.65433083952256,
          "efficiency": 0.011779741009769142,
          "mean_latency_ms": 0.3784861008170992,
          "std_latency_ms": 0.02399835638454456,
          "min_latency_ms": 0.34221600071759894,
          "max_latency_ms": 0.4024844572016438,
          "speedup_vs_fp32": null,
          "test_size": 256,
          "num_trials": 10,
          "arithmetic_intensity": 85.33333333333333,
          "achieved_bandwidth_gbps": 1.038917939525655
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "Skipped (poor performance at size 64: Timeout (>5s))",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'In",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "Skipped (poor performance at size 128: Timeout (>5s))",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'Ch",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas3_gemm_best_precision=bf16_blas_level=3_device=cuda_framework=pytorch_operation=gemm_size=512": {
      "operation_type": "blas3_gemm",
      "measured_gflops": 426.4412942755268,
      "efficiency": 0.05666240955029588,
      "achieved_bandwidth_gbps": 2.4986794586456647,
      "memory_bound": false,
      "compute_bound": true,
      "arithmetic_intensity": 170.66666666666666,
      "batch_size": 1,
      "input_shape": [
        512,
        512
      ],
      "output_shape": [
        512,
        512
      ],
      "mean_latency_ms": 0.6294781007454731,
      "std_latency_ms": 0.235359865098976,
      "min_latency_ms": 0.44119499943917617,
      "max_latency_ms": 0.864837965844449,
      "num_trials": 10,
      "extra_params": {
        "size": 512,
        "operation": "gemm",
        "blas_level": 3,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "bf16"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 8.177437308940661,
          "efficiency": 0.13860063235492645,
          "mean_latency_ms": 32.826354499411536,
          "std_latency_ms": 0.04103481855408365,
          "min_latency_ms": 32.77985400200123,
          "max_latency_ms": 32.86738931796562,
          "speedup_vs_fp32": null,
          "test_size": 512,
          "num_trials": 10,
          "arithmetic_intensity": 42.666666666666664,
          "achieved_bandwidth_gbps": 0.1916586869282967
        },
        "fp32": {
          "precision": "fp32",
          "supported": false,
          "failure_reason": "Skipped (poor performance at size 128: Timeout (>5s))",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "tf32": {
          "precision": "tf32",
          "supported": false,
          "failure_reason": "Skipped (poor performance at size 32: Timeout (>5s))",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp16": {
          "precision": "fp16",
          "supported": false,
          "failure_reason": "Skipped (poor performance at size 64: Timeout (>5s))",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 426.4412942755268,
          "efficiency": 0.05666240955029588,
          "mean_latency_ms": 0.6294781007454731,
          "std_latency_ms": 0.235359865098976,
          "min_latency_ms": 0.44119499943917617,
          "max_latency_ms": 0.864837965844449,
          "speedup_vs_fp32": null,
          "test_size": 512,
          "num_trials": 10,
          "arithmetic_intensity": 170.66666666666666,
          "achieved_bandwidth_gbps": 2.4986794586456647
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "Skipped (poor performance at size 64: Timeout (>5s))",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'In",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "Skipped (poor performance at size 128: Timeout (>5s))",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'Ch",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas3_gemm_best_precision=bf16_blas_level=3_device=cuda_framework=pytorch_operation=gemm_size=1024": {
      "operation_type": "blas3_gemm",
      "measured_gflops": 1022.6997978518681,
      "efficiency": 0.13588889155618764,
      "achieved_bandwidth_gbps": 2.996190814019145,
      "memory_bound": false,
      "compute_bound": true,
      "arithmetic_intensity": 341.3333333333333,
      "batch_size": 1,
      "input_shape": [
        1024,
        1024
      ],
      "output_shape": [
        1024,
        1024
      ],
      "mean_latency_ms": 2.0998181993491016,
      "std_latency_ms": 0.018131823798601343,
      "min_latency_ms": 2.073810996080283,
      "max_latency_ms": 2.117950023147703,
      "num_trials": 10,
      "extra_params": {
        "size": 1024,
        "operation": "gemm",
        "blas_level": 3,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "bf16"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": false,
          "failure_reason": "Timeout: GEMM benchmark exceeded 5s timeout",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp32": {
          "precision": "fp32",
          "supported": false,
          "failure_reason": "Skipped (poor performance at size 128: Timeout (>5s))",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "tf32": {
          "precision": "tf32",
          "supported": false,
          "failure_reason": "Skipped (poor performance at size 32: Timeout (>5s))",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp16": {
          "precision": "fp16",
          "supported": false,
          "failure_reason": "Skipped (poor performance at size 64: Timeout (>5s))",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1022.6997978518681,
          "efficiency": 0.13588889155618764,
          "mean_latency_ms": 2.0998181993491016,
          "std_latency_ms": 0.018131823798601343,
          "min_latency_ms": 2.073810996080283,
          "max_latency_ms": 2.117950023147703,
          "speedup_vs_fp32": null,
          "test_size": 1024,
          "num_trials": 10,
          "arithmetic_intensity": 341.3333333333333,
          "achieved_bandwidth_gbps": 2.996190814019145
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "Skipped (poor performance at size 64: Timeout (>5s))",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'In",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "Skipped (poor performance at size 128: Timeout (>5s))",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'Ch",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas3_gemm_best_precision=bf16_blas_level=3_device=cuda_framework=pytorch_operation=gemm_size=2048": {
      "operation_type": "blas3_gemm",
      "measured_gflops": 2170.3080723067374,
      "efficiency": 0.2883747106439991,
      "achieved_bandwidth_gbps": 3.179162215293072,
      "memory_bound": false,
      "compute_bound": true,
      "arithmetic_intensity": 682.6666666666666,
      "batch_size": 1,
      "input_shape": [
        2048,
        2048
      ],
      "output_shape": [
        2048,
        2048
      ],
      "mean_latency_ms": 7.915866601251764,
      "std_latency_ms": 2.462295555241657,
      "min_latency_ms": 6.031668999639805,
      "max_latency_ms": 10.37816215649342,
      "num_trials": 10,
      "extra_params": {
        "size": 2048,
        "operation": "gemm",
        "blas_level": 3,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "bf16"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": false,
          "failure_reason": "Skipped (poor performance at size 1K: Timeout (>5s))",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp32": {
          "precision": "fp32",
          "supported": false,
          "failure_reason": "Skipped (poor performance at size 128: Timeout (>5s))",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "tf32": {
          "precision": "tf32",
          "supported": false,
          "failure_reason": "Skipped (poor performance at size 32: Timeout (>5s))",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp16": {
          "precision": "fp16",
          "supported": false,
          "failure_reason": "Skipped (poor performance at size 64: Timeout (>5s))",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 2170.3080723067374,
          "efficiency": 0.2883747106439991,
          "mean_latency_ms": 7.915866601251764,
          "std_latency_ms": 2.462295555241657,
          "min_latency_ms": 6.031668999639805,
          "max_latency_ms": 10.37816215649342,
          "speedup_vs_fp32": null,
          "test_size": 2048,
          "num_trials": 10,
          "arithmetic_intensity": 682.6666666666666,
          "achieved_bandwidth_gbps": 3.179162215293072
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "Skipped (poor performance at size 64: Timeout (>5s))",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "Timeout: GEMM benchmark exceeded 5s timeout",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "Skipped (poor performance at size 128: Timeout (>5s))",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'Ch",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    }
  },
  "fusion_profiles": {},
  "precision_matrix": {
    "hardware_name": "Jetson Orin NX 16GB (GPU)",
    "supported_precisions": [
      "fp64",
      "fp32",
      "tf32",
      "fp16",
      "bf16",
      "int64",
      "int32",
      "int16",
      "int8"
    ],
    "unsupported_precisions": [
      "fp8",
      "fp4",
      "int4"
    ],
    "peak_gflops_by_precision": {
      "fp64": 8.177437308940661,
      "fp32": 10.893297216911577,
      "tf32": 13.042980069453934,
      "fp16": 16.20462866410506,
      "bf16": 2170.3080723067374,
      "int64": 1.570812938228363,
      "int32": 3.01465768781282,
      "int16": 5.880367976009685,
      "int8": 8.249921130807724
    },
    "speedup_vs_fp32": {
      "fp32": 1.0,
      "tf32": 1.0990197601810685,
      "fp16": 1.6118748634605133,
      "bf16": 0.9182991040210822,
      "int64": 0.541254103073798,
      "int32": 1.0387588510265018,
      "int16": 2.0261949829549333,
      "int8": 2.842670539192966
    },
    "theoretical_peaks": {
      "fp64": 59.0,
      "fp32": 1882.0,
      "fp16": 7526.0,
      "fp8": 0.0,
      "fp4": 0.0,
      "bf16": 7526.0,
      "tf32": 3763.0,
      "int64": 0.0,
      "int32": 1882.0,
      "int16": 7526.0,
      "int8": 15053.0,
      "int4": 0.0
    }
  }
}