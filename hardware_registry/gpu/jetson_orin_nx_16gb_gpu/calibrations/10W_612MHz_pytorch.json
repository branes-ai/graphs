{
  "metadata": {
    "hardware_name": "Jetson Orin NX 16GB (GPU)",
    "calibration_date": "2026-01-28T10:03:22.255751",
    "calibration_tool_version": "1.0.0",
    "cpu_model": "aarch64",
    "cpu_count": 4,
    "total_memory_gb": 15.28970718383789,
    "python_version": "3.10.12",
    "pytorch_version": "2.4.0a0+3bcc3cddb5.nv24.07",
    "numpy_version": "1.26.4",
    "num_warmup_runs": 3,
    "num_measurement_runs": 10,
    "device_type": "cuda",
    "platform_architecture": "aarch64",
    "framework": "pytorch",
    "gpu_clock": {
      "sm_clock_mhz": 612,
      "query_method": "sysfs_under_load",
      "max_sm_clock_mhz": 612,
      "nvpmodel_mode": 10,
      "power_mode_name": "10W"
    },
    "cpu_clock": {
      "current_freq_mhz": 960.0000000000002,
      "query_method": "sysfs",
      "min_freq_mhz": 729.6,
      "max_freq_mhz": 1190.4,
      "base_freq_mhz": 1984.0,
      "per_core_freq_mhz": [
        1190.4,
        1190.4,
        1190.4,
        1190.4,
        729.6,
        729.6,
        729.6,
        729.6
      ],
      "governor": "schedutil",
      "driver": "tegra194"
    },
    "preflight": {
      "timestamp": "2026-01-28T10:03:21.020625",
      "passed": false,
      "forced": true,
      "checks": [
        {
          "name": "CPU Governor",
          "status": "passed",
          "message": "schedutil (Jetson default)",
          "current_value": "schedutil",
          "expected_value": "schedutil or performance"
        },
        {
          "name": "CPU Frequency",
          "status": "passed",
          "message": "960 MHz idle (DVFS will boost under load)",
          "current_value": "960 MHz (idle)",
          "expected_value": "Up to 1190 MHz under load"
        },
        {
          "name": "Turbo Boost",
          "status": "skipped",
          "message": "Could not determine (not Intel pstate)"
        },
        {
          "name": "System Load",
          "status": "failed",
          "message": "53.4% (high - will affect results)",
          "current_value": "53.4%",
          "expected_value": "< 5%"
        },
        {
          "name": "Thermal State",
          "status": "passed",
          "message": "43\u00b0C (cool)",
          "current_value": "43\u00b0C",
          "expected_value": "< 80\u00b0C"
        },
        {
          "name": "GPU Power Mode",
          "status": "passed",
          "message": "10W (power-limited profile)"
        }
      ]
    }
  },
  "theoretical_peak_gflops": 1882.0,
  "theoretical_bandwidth_gbps": 102.0,
  "best_measured_gflops": 87.8337919608208,
  "avg_measured_gflops": 6.768179231234109,
  "worst_measured_gflops": 0.005942124057552732,
  "measured_bandwidth_gbps": 60.313335823607545,
  "bandwidth_efficiency": 0.5913072139569368,
  "best_efficiency": 0.5913072139569368,
  "avg_efficiency": 0.22990728581143666,
  "worst_efficiency": 0.0,
  "operation_profiles": {
    "stream_copy_device=cuda_flops_per_element=0_framework=pytorch_kernel=copy_num_arrays=2_num_memory_ops=2_size_mb=8": {
      "operation_type": "stream_copy",
      "measured_gflops": 0.0,
      "efficiency": 0.18990162003509106,
      "achieved_bandwidth_gbps": 19.369965243579287,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.0,
      "batch_size": 1,
      "input_shape": [
        2097152
      ],
      "output_shape": [
        2097152
      ],
      "mean_latency_ms": 0.8661459010909311,
      "std_latency_ms": 0.1343269069735203,
      "min_latency_ms": 0.6263830000534654,
      "max_latency_ms": 1.1282839986961335,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 8,
        "kernel": "copy",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 2,
        "num_memory_ops": 2,
        "flops_per_element": 0
      },
      "precision_results": {}
    },
    "stream_copy_device=cuda_flops_per_element=0_framework=pytorch_kernel=copy_num_arrays=2_num_memory_ops=2_size_mb=16": {
      "operation_type": "stream_copy",
      "measured_gflops": 0.0,
      "efficiency": 0.22204543527850745,
      "achieved_bandwidth_gbps": 22.64863439840776,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.0,
      "batch_size": 1,
      "input_shape": [
        4194304
      ],
      "output_shape": [
        4194304
      ],
      "mean_latency_ms": 1.4815211994573474,
      "std_latency_ms": 0.12974253945593986,
      "min_latency_ms": 1.2784310019924305,
      "max_latency_ms": 1.6335129985236563,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 16,
        "kernel": "copy",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 2,
        "num_memory_ops": 2,
        "flops_per_element": 0
      },
      "precision_results": {}
    },
    "stream_copy_device=cuda_flops_per_element=0_framework=pytorch_kernel=copy_num_arrays=2_num_memory_ops=2_size_mb=32": {
      "operation_type": "stream_copy",
      "measured_gflops": 0.0,
      "efficiency": 0.2778960723472468,
      "achieved_bandwidth_gbps": 28.34539937941917,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.0,
      "batch_size": 1,
      "input_shape": [
        8388608
      ],
      "output_shape": [
        8388608
      ],
      "mean_latency_ms": 2.3675398995692376,
      "std_latency_ms": 0.11326082546122272,
      "min_latency_ms": 2.26767199637834,
      "max_latency_ms": 2.5824640033533797,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 32,
        "kernel": "copy",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 2,
        "num_memory_ops": 2,
        "flops_per_element": 0
      },
      "precision_results": {}
    },
    "stream_copy_device=cuda_flops_per_element=0_framework=pytorch_kernel=copy_num_arrays=2_num_memory_ops=2_size_mb=64": {
      "operation_type": "stream_copy",
      "measured_gflops": 0.0,
      "efficiency": 0.29962922150431487,
      "achieved_bandwidth_gbps": 30.562180593440118,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.0,
      "batch_size": 1,
      "input_shape": [
        16777216
      ],
      "output_shape": [
        16777216
      ],
      "mean_latency_ms": 4.39162799884798,
      "std_latency_ms": 0.16208720915742764,
      "min_latency_ms": 4.2481680065975524,
      "max_latency_ms": 4.605105001246557,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 64,
        "kernel": "copy",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 2,
        "num_memory_ops": 2,
        "flops_per_element": 0
      },
      "precision_results": {}
    },
    "stream_copy_device=cuda_flops_per_element=0_framework=pytorch_kernel=copy_num_arrays=2_num_memory_ops=2_size_mb=128": {
      "operation_type": "stream_copy",
      "measured_gflops": 0.0,
      "efficiency": 0.3163246966190832,
      "achieved_bandwidth_gbps": 32.265119055146485,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.0,
      "batch_size": 1,
      "input_shape": [
        33554432
      ],
      "output_shape": [
        33554432
      ],
      "mean_latency_ms": 8.319679699343396,
      "std_latency_ms": 0.1860568422456115,
      "min_latency_ms": 8.004613002412952,
      "max_latency_ms": 8.515376997820567,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 128,
        "kernel": "copy",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 2,
        "num_memory_ops": 2,
        "flops_per_element": 0
      },
      "precision_results": {}
    },
    "stream_copy_device=cuda_flops_per_element=0_framework=pytorch_kernel=copy_num_arrays=2_num_memory_ops=2_size_mb=256": {
      "operation_type": "stream_copy",
      "measured_gflops": 0.0,
      "efficiency": 0.29374170787042597,
      "achieved_bandwidth_gbps": 29.96165420278345,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.0,
      "batch_size": 1,
      "input_shape": [
        67108864
      ],
      "output_shape": [
        67108864
      ],
      "mean_latency_ms": 17.918600500706816,
      "std_latency_ms": 0.5941543075192148,
      "min_latency_ms": 17.59368000057293,
      "max_latency_ms": 19.519968001986854,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 256,
        "kernel": "copy",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 2,
        "num_memory_ops": 2,
        "flops_per_element": 0
      },
      "precision_results": {}
    },
    "stream_copy_device=cuda_flops_per_element=0_framework=pytorch_kernel=copy_num_arrays=2_num_memory_ops=2_size_mb=512": {
      "operation_type": "stream_copy",
      "measured_gflops": 0.0,
      "efficiency": 0.29817228760357695,
      "achieved_bandwidth_gbps": 30.41357333556485,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.0,
      "batch_size": 1,
      "input_shape": [
        134217728
      ],
      "output_shape": [
        134217728
      ],
      "mean_latency_ms": 35.30469149918645,
      "std_latency_ms": 0.9391380262148891,
      "min_latency_ms": 34.88114599895198,
      "max_latency_ms": 37.95888400054537,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 512,
        "kernel": "copy",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 2,
        "num_memory_ops": 2,
        "flops_per_element": 0
      },
      "precision_results": {}
    },
    "stream_scale_device=cuda_flops_per_element=1_framework=pytorch_kernel=scale_num_arrays=2_num_memory_ops=2_size_mb=8": {
      "operation_type": "stream_scale",
      "measured_gflops": 5.3349397352443635,
      "efficiency": 0.4184266459015187,
      "achieved_bandwidth_gbps": 42.67951788195491,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.5,
      "batch_size": 1,
      "input_shape": [
        2097152
      ],
      "output_shape": [
        2097152
      ],
      "mean_latency_ms": 0.3930975988623686,
      "std_latency_ms": 0.017121974901276454,
      "min_latency_ms": 0.3778329992201179,
      "max_latency_ms": 0.4298979984014295,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 8,
        "kernel": "scale",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 2,
        "num_memory_ops": 2,
        "flops_per_element": 1
      },
      "precision_results": {}
    },
    "stream_scale_device=cuda_flops_per_element=1_framework=pytorch_kernel=scale_num_arrays=2_num_memory_ops=2_size_mb=16": {
      "operation_type": "stream_scale",
      "measured_gflops": 6.109266380032062,
      "efficiency": 0.47915814745349505,
      "achieved_bandwidth_gbps": 48.87413104025649,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.5,
      "batch_size": 1,
      "input_shape": [
        4194304
      ],
      "output_shape": [
        4194304
      ],
      "mean_latency_ms": 0.6865478993859142,
      "std_latency_ms": 0.028984663616657316,
      "min_latency_ms": 0.6491999956779182,
      "max_latency_ms": 0.7333300018217415,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 16,
        "kernel": "scale",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 2,
        "num_memory_ops": 2,
        "flops_per_element": 1
      },
      "precision_results": {}
    },
    "stream_scale_device=cuda_flops_per_element=1_framework=pytorch_kernel=scale_num_arrays=2_num_memory_ops=2_size_mb=32": {
      "operation_type": "stream_scale",
      "measured_gflops": 6.756907434987884,
      "efficiency": 0.5299535243127752,
      "achieved_bandwidth_gbps": 54.05525947990307,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.5,
      "batch_size": 1,
      "input_shape": [
        8388608
      ],
      "output_shape": [
        8388608
      ],
      "mean_latency_ms": 1.2414862983860075,
      "std_latency_ms": 0.028412863344758614,
      "min_latency_ms": 1.1903649938176386,
      "max_latency_ms": 1.2940470041939989,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 32,
        "kernel": "scale",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 2,
        "num_memory_ops": 2,
        "flops_per_element": 1
      },
      "precision_results": {}
    },
    "stream_scale_device=cuda_flops_per_element=1_framework=pytorch_kernel=scale_num_arrays=2_num_memory_ops=2_size_mb=64": {
      "operation_type": "stream_scale",
      "measured_gflops": 7.21730476157512,
      "efficiency": 0.5660631185549113,
      "achieved_bandwidth_gbps": 57.73843809260096,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.5,
      "batch_size": 1,
      "input_shape": [
        16777216
      ],
      "output_shape": [
        16777216
      ],
      "mean_latency_ms": 2.324581897846656,
      "std_latency_ms": 0.03683858089111833,
      "min_latency_ms": 2.279863998410292,
      "max_latency_ms": 2.3774669971317053,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 64,
        "kernel": "scale",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 2,
        "num_memory_ops": 2,
        "flops_per_element": 1
      },
      "precision_results": {}
    },
    "stream_scale_device=cuda_flops_per_element=1_framework=pytorch_kernel=scale_num_arrays=2_num_memory_ops=2_size_mb=128": {
      "operation_type": "stream_scale",
      "measured_gflops": 7.44552999689741,
      "efficiency": 0.5839631370115616,
      "achieved_bandwidth_gbps": 59.56423997517928,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.5,
      "batch_size": 1,
      "input_shape": [
        33554432
      ],
      "output_shape": [
        33554432
      ],
      "mean_latency_ms": 4.5066545986628626,
      "std_latency_ms": 0.05738740813377951,
      "min_latency_ms": 4.4273090024944395,
      "max_latency_ms": 4.599056999722961,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 128,
        "kernel": "scale",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 2,
        "num_memory_ops": 2,
        "flops_per_element": 1
      },
      "precision_results": {}
    },
    "stream_scale_device=cuda_flops_per_element=1_framework=pytorch_kernel=scale_num_arrays=2_num_memory_ops=2_size_mb=256": {
      "operation_type": "stream_scale",
      "measured_gflops": 6.529536680893744,
      "efficiency": 0.5121205239916662,
      "achieved_bandwidth_gbps": 52.236293447149954,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.5,
      "batch_size": 1,
      "input_shape": [
        67108864
      ],
      "output_shape": [
        67108864
      ],
      "mean_latency_ms": 10.277737499563955,
      "std_latency_ms": 0.04646179524774449,
      "min_latency_ms": 10.220699005003553,
      "max_latency_ms": 10.350174001359846,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 256,
        "kernel": "scale",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 2,
        "num_memory_ops": 2,
        "flops_per_element": 1
      },
      "precision_results": {}
    },
    "stream_scale_device=cuda_flops_per_element=1_framework=pytorch_kernel=scale_num_arrays=2_num_memory_ops=2_size_mb=512": {
      "operation_type": "stream_scale",
      "measured_gflops": 6.506884256675288,
      "efficiency": 0.51034386326865,
      "achieved_bandwidth_gbps": 52.0550740534023,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.5,
      "batch_size": 1,
      "input_shape": [
        134217728
      ],
      "output_shape": [
        134217728
      ],
      "mean_latency_ms": 20.62703479969059,
      "std_latency_ms": 0.6387545386069632,
      "min_latency_ms": 20.177072001388296,
      "max_latency_ms": 21.849464996194,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 512,
        "kernel": "scale",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 2,
        "num_memory_ops": 2,
        "flops_per_element": 1
      },
      "precision_results": {}
    },
    "stream_add_device=cuda_flops_per_element=1_framework=pytorch_kernel=add_num_arrays=3_num_memory_ops=3_size_mb=8": {
      "operation_type": "stream_add",
      "measured_gflops": 4.00814567600301,
      "efficiency": 0.4715465501180012,
      "achieved_bandwidth_gbps": 48.09774811203612,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.3333333333333333,
      "batch_size": 1,
      "input_shape": [
        2097152
      ],
      "output_shape": [
        2097152
      ],
      "mean_latency_ms": 0.5232224997598678,
      "std_latency_ms": 0.02754106419452409,
      "min_latency_ms": 0.49732399929780513,
      "max_latency_ms": 0.5874060007045045,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 8,
        "kernel": "add",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 3,
        "num_memory_ops": 3,
        "flops_per_element": 1
      },
      "precision_results": {}
    },
    "stream_add_device=cuda_flops_per_element=1_framework=pytorch_kernel=add_num_arrays=3_num_memory_ops=3_size_mb=16": {
      "operation_type": "stream_add",
      "measured_gflops": 4.503477167974943,
      "efficiency": 0.5298208432911697,
      "achieved_bandwidth_gbps": 54.04172601569931,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.3333333333333333,
      "batch_size": 1,
      "input_shape": [
        4194304
      ],
      "output_shape": [
        4194304
      ],
      "mean_latency_ms": 0.9313478993135504,
      "std_latency_ms": 0.041411077325687044,
      "min_latency_ms": 0.9013659946504049,
      "max_latency_ms": 1.0448889952385798,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 16,
        "kernel": "add",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 3,
        "num_memory_ops": 3,
        "flops_per_element": 1
      },
      "precision_results": {}
    },
    "stream_add_device=cuda_flops_per_element=1_framework=pytorch_kernel=add_num_arrays=3_num_memory_ops=3_size_mb=32": {
      "operation_type": "stream_add",
      "measured_gflops": 4.7355629835248765,
      "efficiency": 0.5571250568852796,
      "achieved_bandwidth_gbps": 56.826755802298514,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.3333333333333333,
      "batch_size": 1,
      "input_shape": [
        8388608
      ],
      "output_shape": [
        8388608
      ],
      "mean_latency_ms": 1.7714067005726974,
      "std_latency_ms": 0.1467633913280993,
      "min_latency_ms": 1.7017689970089123,
      "max_latency_ms": 2.182390002417378,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 32,
        "kernel": "add",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 3,
        "num_memory_ops": 3,
        "flops_per_element": 1
      },
      "precision_results": {}
    },
    "stream_add_device=cuda_flops_per_element=1_framework=pytorch_kernel=add_num_arrays=3_num_memory_ops=3_size_mb=64": {
      "operation_type": "stream_add",
      "measured_gflops": 4.805516434427412,
      "efficiency": 0.5653548746385191,
      "achieved_bandwidth_gbps": 57.666197213128946,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.3333333333333333,
      "batch_size": 1,
      "input_shape": [
        16777216
      ],
      "output_shape": [
        16777216
      ],
      "mean_latency_ms": 3.4912409995740745,
      "std_latency_ms": 0.46730317828800993,
      "min_latency_ms": 3.2674399990355596,
      "max_latency_ms": 4.764340999827255,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 64,
        "kernel": "add",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 3,
        "num_memory_ops": 3,
        "flops_per_element": 1
      },
      "precision_results": {}
    },
    "stream_add_device=cuda_flops_per_element=1_framework=pytorch_kernel=add_num_arrays=3_num_memory_ops=3_size_mb=128": {
      "operation_type": "stream_add",
      "measured_gflops": 5.01588277556969,
      "efficiency": 0.5901038559493753,
      "achieved_bandwidth_gbps": 60.190593306836284,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.3333333333333333,
      "batch_size": 1,
      "input_shape": [
        33554432
      ],
      "output_shape": [
        33554432
      ],
      "mean_latency_ms": 6.689636401279131,
      "std_latency_ms": 0.01237131965703656,
      "min_latency_ms": 6.666724002570845,
      "max_latency_ms": 6.706789004965685,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 128,
        "kernel": "add",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 3,
        "num_memory_ops": 3,
        "flops_per_element": 1
      },
      "precision_results": {}
    },
    "stream_add_device=cuda_flops_per_element=1_framework=pytorch_kernel=add_num_arrays=3_num_memory_ops=3_size_mb=256": {
      "operation_type": "stream_add",
      "measured_gflops": 4.857924618313552,
      "efficiency": 0.5715205433310061,
      "achieved_bandwidth_gbps": 58.295095419762625,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.3333333333333333,
      "batch_size": 1,
      "input_shape": [
        67108864
      ],
      "output_shape": [
        67108864
      ],
      "mean_latency_ms": 13.814307399297832,
      "std_latency_ms": 0.609903461391676,
      "min_latency_ms": 13.386377002461813,
      "max_latency_ms": 14.98078399890801,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 256,
        "kernel": "add",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 3,
        "num_memory_ops": 3,
        "flops_per_element": 1
      },
      "precision_results": {}
    },
    "stream_add_device=cuda_flops_per_element=1_framework=pytorch_kernel=add_num_arrays=3_num_memory_ops=3_size_mb=512": {
      "operation_type": "stream_add",
      "measured_gflops": 5.026111318633962,
      "efficiency": 0.5913072139569368,
      "achieved_bandwidth_gbps": 60.313335823607545,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.3333333333333333,
      "batch_size": 1,
      "input_shape": [
        134217728
      ],
      "output_shape": [
        134217728
      ],
      "mean_latency_ms": 26.70408980047796,
      "std_latency_ms": 0.23262686728258514,
      "min_latency_ms": 26.569101006316487,
      "max_latency_ms": 27.349791998858564,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 512,
        "kernel": "add",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 3,
        "num_memory_ops": 3,
        "flops_per_element": 1
      },
      "precision_results": {}
    },
    "stream_triad_device=cuda_flops_per_element=2_framework=pytorch_kernel=triad_num_arrays=3_num_memory_ops=3_size_mb=8": {
      "operation_type": "stream_triad",
      "measured_gflops": 3.9383420858629794,
      "efficiency": 0.23166718152135174,
      "achieved_bandwidth_gbps": 23.630052515177876,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.6666666666666666,
      "batch_size": 1,
      "input_shape": [
        2097152
      ],
      "output_shape": [
        2097152
      ],
      "mean_latency_ms": 1.0649923009623308,
      "std_latency_ms": 0.422525219977132,
      "min_latency_ms": 0.8181320008588955,
      "max_latency_ms": 2.227574004791677,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 8,
        "kernel": "triad",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 3,
        "num_memory_ops": 3,
        "flops_per_element": 2
      },
      "precision_results": {}
    },
    "stream_triad_device=cuda_flops_per_element=2_framework=pytorch_kernel=triad_num_arrays=3_num_memory_ops=3_size_mb=16": {
      "operation_type": "stream_triad",
      "measured_gflops": 5.075365961086259,
      "efficiency": 0.29855093888742695,
      "achieved_bandwidth_gbps": 30.45219576651755,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.6666666666666666,
      "batch_size": 1,
      "input_shape": [
        4194304
      ],
      "output_shape": [
        4194304
      ],
      "mean_latency_ms": 1.6528084997844417,
      "std_latency_ms": 0.17608594439817854,
      "min_latency_ms": 1.548453998111654,
      "max_latency_ms": 2.1338129954528995,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 16,
        "kernel": "triad",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 3,
        "num_memory_ops": 3,
        "flops_per_element": 2
      },
      "precision_results": {}
    },
    "stream_triad_device=cuda_flops_per_element=2_framework=pytorch_kernel=triad_num_arrays=3_num_memory_ops=3_size_mb=32": {
      "operation_type": "stream_triad",
      "measured_gflops": 5.163725572486824,
      "efficiency": 0.30374856308746023,
      "achieved_bandwidth_gbps": 30.982353434920945,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.6666666666666666,
      "batch_size": 1,
      "input_shape": [
        8388608
      ],
      "output_shape": [
        8388608
      ],
      "mean_latency_ms": 3.2490526005858555,
      "std_latency_ms": 0.15894677392948092,
      "min_latency_ms": 3.1163000021479093,
      "max_latency_ms": 3.6655619987868704,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 32,
        "kernel": "triad",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 3,
        "num_memory_ops": 3,
        "flops_per_element": 2
      },
      "precision_results": {}
    },
    "stream_triad_device=cuda_flops_per_element=2_framework=pytorch_kernel=triad_num_arrays=3_num_memory_ops=3_size_mb=64": {
      "operation_type": "stream_triad",
      "measured_gflops": 5.346306470784885,
      "efficiency": 0.3144886159285227,
      "achieved_bandwidth_gbps": 32.07783882470931,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.6666666666666666,
      "batch_size": 1,
      "input_shape": [
        16777216
      ],
      "output_shape": [
        16777216
      ],
      "mean_latency_ms": 6.27618939979584,
      "std_latency_ms": 0.07473818141458202,
      "min_latency_ms": 6.174807997012977,
      "max_latency_ms": 6.413596995116677,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 64,
        "kernel": "triad",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 3,
        "num_memory_ops": 3,
        "flops_per_element": 2
      },
      "precision_results": {}
    },
    "stream_triad_device=cuda_flops_per_element=2_framework=pytorch_kernel=triad_num_arrays=3_num_memory_ops=3_size_mb=128": {
      "operation_type": "stream_triad",
      "measured_gflops": 5.726700223973038,
      "efficiency": 0.3368647190572375,
      "achieved_bandwidth_gbps": 34.36020134383823,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.6666666666666666,
      "batch_size": 1,
      "input_shape": [
        33554432
      ],
      "output_shape": [
        33554432
      ],
      "mean_latency_ms": 11.718592099350644,
      "std_latency_ms": 0.10981795640357243,
      "min_latency_ms": 11.542875996383373,
      "max_latency_ms": 11.871364004036877,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 128,
        "kernel": "triad",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 3,
        "num_memory_ops": 3,
        "flops_per_element": 2
      },
      "precision_results": {}
    },
    "stream_triad_device=cuda_flops_per_element=2_framework=pytorch_kernel=triad_num_arrays=3_num_memory_ops=3_size_mb=256": {
      "operation_type": "stream_triad",
      "measured_gflops": 5.62500469678081,
      "efficiency": 0.3308826292224006,
      "achieved_bandwidth_gbps": 33.75002818068486,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.6666666666666666,
      "batch_size": 1,
      "input_shape": [
        67108864
      ],
      "output_shape": [
        67108864
      ],
      "mean_latency_ms": 23.86090949876234,
      "std_latency_ms": 0.9016342107730008,
      "min_latency_ms": 23.282267997274175,
      "max_latency_ms": 26.202338995062746,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 256,
        "kernel": "triad",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 3,
        "num_memory_ops": 3,
        "flops_per_element": 2
      },
      "precision_results": {}
    },
    "stream_triad_device=cuda_flops_per_element=2_framework=pytorch_kernel=triad_num_arrays=3_num_memory_ops=3_size_mb=512": {
      "operation_type": "stream_triad",
      "measured_gflops": 5.75504117849883,
      "efficiency": 0.3385318340293429,
      "achieved_bandwidth_gbps": 34.53024707099298,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.6666666666666666,
      "batch_size": 1,
      "input_shape": [
        134217728
      ],
      "output_shape": [
        134217728
      ],
      "mean_latency_ms": 46.643533499445766,
      "std_latency_ms": 1.033410293954201,
      "min_latency_ms": 45.984746000613086,
      "max_latency_ms": 49.27292299544206,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 512,
        "kernel": "triad",
        "framework": "pytorch",
        "device": "cuda",
        "num_arrays": 3,
        "num_memory_ops": 3,
        "flops_per_element": 2
      },
      "precision_results": {}
    },
    "blas1_dot_best_precision=fp64_blas_level=1_device=cuda_framework=pytorch_operation=dot_size=1000": {
      "operation_type": "blas1_dot",
      "measured_gflops": 0.01142776169032483,
      "efficiency": 0.0001936908761072005,
      "achieved_bandwidth_gbps": 0.02285552338064966,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.5,
      "batch_size": 1,
      "input_shape": [
        1000
      ],
      "output_shape": [
        1000
      ],
      "mean_latency_ms": 0.1750123999954667,
      "std_latency_ms": 0.017968109937815026,
      "min_latency_ms": 0.15193999570328742,
      "max_latency_ms": 0.19298050993328172,
      "num_trials": 10,
      "extra_params": {
        "size": 1000,
        "operation": "dot",
        "blas_level": 1,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "fp64"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.01142776169032483,
          "efficiency": 0.0001936908761072005,
          "mean_latency_ms": 0.1750123999954667,
          "std_latency_ms": 0.017968109937815026,
          "min_latency_ms": 0.15193999570328742,
          "max_latency_ms": 0.19298050993328172,
          "speedup_vs_fp32": null,
          "test_size": 1000,
          "num_trials": 10,
          "arithmetic_intensity": 0.5,
          "achieved_bandwidth_gbps": 0.02285552338064966
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.010934339196668095,
          "efficiency": 5.809957065179646e-06,
          "mean_latency_ms": 0.18291000160388649,
          "std_latency_ms": 0.026520529329148407,
          "min_latency_ms": 0.14214799739420414,
          "max_latency_ms": 0.2094305309330349,
          "speedup_vs_fp32": 1.0,
          "test_size": 1000,
          "num_trials": 10,
          "arithmetic_intensity": 0.25,
          "achieved_bandwidth_gbps": 0.04373735678667238
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.010363558767914591,
          "efficiency": 2.754068234896251e-06,
          "mean_latency_ms": 0.1929839010699652,
          "std_latency_ms": 0.00932668578324428,
          "min_latency_ms": 0.17210000078193843,
          "max_latency_ms": 0.2023105868532095,
          "speedup_vs_fp32": 0.9477992754306148,
          "test_size": 1000,
          "num_trials": 10,
          "arithmetic_intensity": 0.25,
          "achieved_bandwidth_gbps": 0.041454235071658366
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.010543107006949418,
          "efficiency": 1.4008911781755804e-06,
          "mean_latency_ms": 0.1896974012197461,
          "std_latency_ms": 0.02044225985285158,
          "min_latency_ms": 0.1498280034866184,
          "max_latency_ms": 0.21013966107259768,
          "speedup_vs_fp32": 0.9642198597755324,
          "test_size": 1000,
          "num_trials": 10,
          "arithmetic_intensity": 0.5,
          "achieved_bandwidth_gbps": 0.021086214013898836
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.010659264843271163,
          "efficiency": 1.4163253844367743e-06,
          "mean_latency_ms": 0.18763020052574575,
          "std_latency_ms": 0.01652427834845202,
          "min_latency_ms": 0.1668519980739802,
          "max_latency_ms": 0.20415447887419777,
          "speedup_vs_fp32": 0.9748430747894896,
          "test_size": 1000,
          "num_trials": 10,
          "arithmetic_intensity": 0.5,
          "achieved_bandwidth_gbps": 0.021318529686542326
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Long'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Int'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Short'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Char'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas1_dot_best_precision=tf32_blas_level=1_device=cuda_framework=pytorch_operation=dot_size=10000": {
      "operation_type": "blas1_dot",
      "measured_gflops": 0.11845148384710734,
      "efficiency": 3.147793883792382e-05,
      "achieved_bandwidth_gbps": 0.47380593538842936,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.25,
      "batch_size": 1,
      "input_shape": [
        10000
      ],
      "output_shape": [
        10000
      ],
      "mean_latency_ms": 0.16884549986571074,
      "std_latency_ms": 0.031143294751614738,
      "min_latency_ms": 0.1464669985580258,
      "max_latency_ms": 0.19998879461732547,
      "num_trials": 10,
      "extra_params": {
        "size": 10000,
        "operation": "dot",
        "blas_level": 1,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "tf32"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.10677646028817324,
          "efficiency": 0.0018097705133588685,
          "mean_latency_ms": 0.18730720184976235,
          "std_latency_ms": 0.04302715866989886,
          "min_latency_ms": 0.15536400314886123,
          "max_latency_ms": 0.23033436051966122,
          "speedup_vs_fp32": null,
          "test_size": 10000,
          "num_trials": 10,
          "arithmetic_intensity": 0.5,
          "achieved_bandwidth_gbps": 0.21355292057634648
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.08967294865361523,
          "efficiency": 4.7647687913716916e-05,
          "mean_latency_ms": 0.22303270161501132,
          "std_latency_ms": 0.10524766900351801,
          "min_latency_ms": 0.15389200416393578,
          "max_latency_ms": 0.3282803706185293,
          "speedup_vs_fp32": 1.0,
          "test_size": 10000,
          "num_trials": 10,
          "arithmetic_intensity": 0.25,
          "achieved_bandwidth_gbps": 0.35869179461446093
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.11845148384710734,
          "efficiency": 3.147793883792382e-05,
          "mean_latency_ms": 0.16884549986571074,
          "std_latency_ms": 0.031143294751614738,
          "min_latency_ms": 0.1464669985580258,
          "max_latency_ms": 0.19998879461732547,
          "speedup_vs_fp32": 1.3209277226363614,
          "test_size": 10000,
          "num_trials": 10,
          "arithmetic_intensity": 0.25,
          "achieved_bandwidth_gbps": 0.47380593538842936
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.10888993713047733,
          "efficiency": 1.4468500814573124e-05,
          "mean_latency_ms": 0.18367170123383403,
          "std_latency_ms": 0.020628820622087558,
          "min_latency_ms": 0.1509159992565401,
          "max_latency_ms": 0.2043005218559216,
          "speedup_vs_fp32": 1.2143008428449547,
          "test_size": 10000,
          "num_trials": 10,
          "arithmetic_intensity": 0.5,
          "achieved_bandwidth_gbps": 0.21777987426095466
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.11479408843361572,
          "efficiency": 1.5253001386342773e-05,
          "mean_latency_ms": 0.17422499950043857,
          "std_latency_ms": 0.021472120260562968,
          "min_latency_ms": 0.1261790021089837,
          "max_latency_ms": 0.19569711976100154,
          "speedup_vs_fp32": 1.280141783639092,
          "test_size": 10000,
          "num_trials": 10,
          "arithmetic_intensity": 0.5,
          "achieved_bandwidth_gbps": 0.22958817686723143
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Long'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Int'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Short'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Char'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas1_dot_best_precision=fp32_blas_level=1_device=cuda_framework=pytorch_operation=dot_size=100000": {
      "operation_type": "blas1_dot",
      "measured_gflops": 1.196714051676716,
      "efficiency": 0.0006358735662469268,
      "achieved_bandwidth_gbps": 4.786856206706864,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.25,
      "batch_size": 1,
      "input_shape": [
        100000
      ],
      "output_shape": [
        100000
      ],
      "mean_latency_ms": 0.1671243015152868,
      "std_latency_ms": 0.023685469478399657,
      "min_latency_ms": 0.14134800585452467,
      "max_latency_ms": 0.19080977099368646,
      "num_trials": 10,
      "extra_params": {
        "size": 100000,
        "operation": "dot",
        "blas_level": 1,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "fp32"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.1405454180672474,
          "efficiency": 0.019331278272326228,
          "mean_latency_ms": 0.175354700331809,
          "std_latency_ms": 0.026120365812656577,
          "min_latency_ms": 0.14374699821928516,
          "max_latency_ms": 0.2014750661444656,
          "speedup_vs_fp32": null,
          "test_size": 100000,
          "num_trials": 10,
          "arithmetic_intensity": 0.5,
          "achieved_bandwidth_gbps": 2.281090836134495
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.196714051676716,
          "efficiency": 0.0006358735662469268,
          "mean_latency_ms": 0.1671243015152868,
          "std_latency_ms": 0.023685469478399657,
          "min_latency_ms": 0.14134800585452467,
          "max_latency_ms": 0.19080977099368646,
          "speedup_vs_fp32": 1.0,
          "test_size": 100000,
          "num_trials": 10,
          "arithmetic_intensity": 0.25,
          "achieved_bandwidth_gbps": 4.786856206706864
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.044182490163924,
          "efficiency": 0.0002774867101153133,
          "mean_latency_ms": 0.19153740067849867,
          "std_latency_ms": 0.011744070427998259,
          "min_latency_ms": 0.17280400061281398,
          "max_latency_ms": 0.20328147110649694,
          "speedup_vs_fp32": 0.8725413466156932,
          "test_size": 100000,
          "num_trials": 10,
          "arithmetic_intensity": 0.25,
          "achieved_bandwidth_gbps": 4.176729960655696
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.0761858883949071,
          "efficiency": 0.00014299573324407481,
          "mean_latency_ms": 0.18584150020615198,
          "std_latency_ms": 0.05269869740763508,
          "min_latency_ms": 0.14429200382437557,
          "max_latency_ms": 0.23854019761378706,
          "speedup_vs_fp32": 0.8992840744930363,
          "test_size": 100000,
          "num_trials": 10,
          "arithmetic_intensity": 0.5,
          "achieved_bandwidth_gbps": 2.1523717767898143
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.1595688477921458,
          "efficiency": 0.0001540750528557196,
          "mean_latency_ms": 0.17247790019609965,
          "std_latency_ms": 0.019585933529102092,
          "min_latency_ms": 0.1434599980711937,
          "max_latency_ms": 0.19206383372520175,
          "speedup_vs_fp32": 0.9689606687307414,
          "test_size": 100000,
          "num_trials": 10,
          "arithmetic_intensity": 0.5,
          "achieved_bandwidth_gbps": 2.3191376955842915
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Long'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Int'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Short'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Char'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas1_dot_best_precision=bf16_blas_level=1_device=cuda_framework=pytorch_operation=dot_size=1000000": {
      "operation_type": "blas1_dot",
      "measured_gflops": 9.35451063961004,
      "efficiency": 0.0012429591601926708,
      "achieved_bandwidth_gbps": 18.70902127922008,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.5,
      "batch_size": 1,
      "input_shape": [
        1000000
      ],
      "output_shape": [
        1000000
      ],
      "mean_latency_ms": 0.21380060134106316,
      "std_latency_ms": 0.02783075686375687,
      "min_latency_ms": 0.19062900537392125,
      "max_latency_ms": 0.24163135820482,
      "num_trials": 10,
      "extra_params": {
        "size": 1000000,
        "operation": "dot",
        "blas_level": 1,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "bf16"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 3.757473848374775,
          "efficiency": 0.06368599743008094,
          "mean_latency_ms": 0.5322725002770312,
          "std_latency_ms": 0.27902962598085196,
          "min_latency_ms": 0.4033379955217242,
          "max_latency_ms": 0.8113021262578832,
          "speedup_vs_fp32": null,
          "test_size": 1000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.5,
          "achieved_bandwidth_gbps": 7.51494769674955
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 8.068901965344159,
          "efficiency": 0.004287408058099978,
          "mean_latency_ms": 0.24786520007182844,
          "std_latency_ms": 0.009070405906329857,
          "min_latency_ms": 0.23597400286234915,
          "max_latency_ms": 0.2569356059781583,
          "speedup_vs_fp32": 1.0,
          "test_size": 1000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.25,
          "achieved_bandwidth_gbps": 32.275607861376635
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 7.861143863254041,
          "efficiency": 0.0020890629453239546,
          "mean_latency_ms": 0.2544159011449665,
          "std_latency_ms": 0.014256635093395371,
          "min_latency_ms": 0.23904599947854877,
          "max_latency_ms": 0.26867253623836185,
          "speedup_vs_fp32": 0.9742519982294447,
          "test_size": 1000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.25,
          "achieved_bandwidth_gbps": 31.444575453016164
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 9.201777884329248,
          "efficiency": 0.0012226651454064906,
          "mean_latency_ms": 0.21734930196544155,
          "std_latency_ms": 0.05161701468415433,
          "min_latency_ms": 0.19475699809845537,
          "max_latency_ms": 0.2689663166495959,
          "speedup_vs_fp32": 1.1404002581578978,
          "test_size": 1000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.5,
          "achieved_bandwidth_gbps": 18.403555768658496
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 9.35451063961004,
          "efficiency": 0.0012429591601926708,
          "mean_latency_ms": 0.21380060134106316,
          "std_latency_ms": 0.02783075686375687,
          "min_latency_ms": 0.19062900537392125,
          "max_latency_ms": 0.24163135820482,
          "speedup_vs_fp32": 1.1593288256304954,
          "test_size": 1000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.5,
          "achieved_bandwidth_gbps": 18.70902127922008
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Long'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Int'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Short'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Char'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas1_dot_best_precision=fp16_blas_level=1_device=cuda_framework=pytorch_operation=dot_size=10000000": {
      "operation_type": "blas1_dot",
      "measured_gflops": 16.399361156255786,
      "efficiency": 0.0021790275254126744,
      "achieved_bandwidth_gbps": 32.79872231251157,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.5,
      "batch_size": 1,
      "input_shape": [
        10000000
      ],
      "output_shape": [
        10000000
      ],
      "mean_latency_ms": 1.2195597017125692,
      "std_latency_ms": 0.036807795221539874,
      "min_latency_ms": 1.1918700038222596,
      "max_latency_ms": 1.256367496934109,
      "num_trials": 10,
      "extra_params": {
        "size": 10000000,
        "operation": "dot",
        "blas_level": 1,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "fp16"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 6.577733732704199,
          "efficiency": 0.11148701241871524,
          "mean_latency_ms": 3.04056090026279,
          "std_latency_ms": 0.05611196558719602,
          "min_latency_ms": 2.981673002068419,
          "max_latency_ms": 3.096672865849986,
          "speedup_vs_fp32": null,
          "test_size": 10000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.5,
          "achieved_bandwidth_gbps": 13.155467465408398
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 12.761795475208192,
          "efficiency": 0.006780975279069177,
          "mean_latency_ms": 1.5671775996452197,
          "std_latency_ms": 0.04556376885637359,
          "min_latency_ms": 1.5229170021484606,
          "max_latency_ms": 1.6127413685015934,
          "speedup_vs_fp32": 1.0,
          "test_size": 10000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.25,
          "achieved_bandwidth_gbps": 51.04718190083277
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 11.632707497678757,
          "efficiency": 0.003091338691915694,
          "mean_latency_ms": 1.7192901999806054,
          "std_latency_ms": 0.45700896082965814,
          "min_latency_ms": 1.5334130002884194,
          "max_latency_ms": 2.1762991608102635,
          "speedup_vs_fp32": 0.9115259306793572,
          "test_size": 10000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.25,
          "achieved_bandwidth_gbps": 46.53082999071503
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 16.399361156255786,
          "efficiency": 0.0021790275254126744,
          "mean_latency_ms": 1.2195597017125692,
          "std_latency_ms": 0.036807795221539874,
          "min_latency_ms": 1.1918700038222596,
          "max_latency_ms": 1.256367496934109,
          "speedup_vs_fp32": 1.2850355726287999,
          "test_size": 10000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.5,
          "achieved_bandwidth_gbps": 32.79872231251157
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 16.006981597879083,
          "efficiency": 0.0021268909909485894,
          "mean_latency_ms": 1.2494548005633987,
          "std_latency_ms": 0.059473866019540376,
          "min_latency_ms": 1.2127020017942414,
          "max_latency_ms": 1.3089286665829392,
          "speedup_vs_fp32": 1.2542891499064672,
          "test_size": 10000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.5,
          "achieved_bandwidth_gbps": 32.013963195758166
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Long'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Int'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Short'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: \"dot\" not implemented for 'Char'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas1_axpy_best_precision=int64_blas_level=1_device=cuda_framework=pytorch_operation=axpy_size=1000": {
      "operation_type": "blas1_axpy",
      "measured_gflops": 0.01121371038225781,
      "efficiency": 0.0,
      "achieved_bandwidth_gbps": 0.033641131146773424,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.3333333333333333,
      "batch_size": 1,
      "input_shape": [
        1000
      ],
      "output_shape": [
        1000
      ],
      "mean_latency_ms": 0.17835309918154962,
      "std_latency_ms": 0.011471838884609576,
      "min_latency_ms": 0.1594600034877658,
      "max_latency_ms": 0.1898249380661592,
      "num_trials": 10,
      "extra_params": {
        "size": 1000,
        "operation": "axpy",
        "blas_level": 1,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "int64"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.010800739855685016,
          "efficiency": 0.0001830633873844918,
          "mean_latency_ms": 0.18517249991418794,
          "std_latency_ms": 0.028065118518974377,
          "min_latency_ms": 0.15693200111854821,
          "max_latency_ms": 0.2132376184331623,
          "speedup_vs_fp32": null,
          "test_size": 1000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 0.032402219567055045
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.01082749688129043,
          "efficiency": 5.753186440643162e-06,
          "mean_latency_ms": 0.18471489966032095,
          "std_latency_ms": 0.017761479927828568,
          "min_latency_ms": 0.164995995874051,
          "max_latency_ms": 0.2024763795881495,
          "speedup_vs_fp32": 1.0,
          "test_size": 1000,
          "num_trials": 10,
          "arithmetic_intensity": 0.16666666666666666,
          "achieved_bandwidth_gbps": 0.06496498128774258
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.010511549834739342,
          "efficiency": 2.793396182497832e-06,
          "mean_latency_ms": 0.19026689988095313,
          "std_latency_ms": 0.01594363406202784,
          "min_latency_ms": 0.1660839989199303,
          "max_latency_ms": 0.20621053394298097,
          "speedup_vs_fp32": 0.9708199364991705,
          "test_size": 1000,
          "num_trials": 10,
          "arithmetic_intensity": 0.16666666666666666,
          "achieved_bandwidth_gbps": 0.06306929900843605
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.010278844496662397,
          "efficiency": 1.3657779028251924e-06,
          "mean_latency_ms": 0.19457439993857406,
          "std_latency_ms": 0.017545941849172866,
          "min_latency_ms": 0.1775090058799833,
          "max_latency_ms": 0.2121203417877469,
          "speedup_vs_fp32": 0.9493278649125185,
          "test_size": 1000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 0.030836533489987192
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.01071096725532468,
          "efficiency": 1.423195223933654e-06,
          "mean_latency_ms": 0.18672449950827286,
          "std_latency_ms": 0.015261639762419194,
          "min_latency_ms": 0.1674919985816814,
          "max_latency_ms": 0.20198613927069206,
          "speedup_vs_fp32": 0.9892376209161409,
          "test_size": 1000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 0.03213290176597404
        },
        "int64": {
          "precision": "int64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.01121371038225781,
          "efficiency": 0.0,
          "mean_latency_ms": 0.17835309918154962,
          "std_latency_ms": 0.011471838884609576,
          "min_latency_ms": 0.1594600034877658,
          "max_latency_ms": 0.1898249380661592,
          "speedup_vs_fp32": 1.0356696940393255,
          "test_size": 1000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 0.033641131146773424
        },
        "int32": {
          "precision": "int32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.010398382866046142,
          "efficiency": 5.52517686824981e-06,
          "mean_latency_ms": 0.19233759958297014,
          "std_latency_ms": 0.010693521281022573,
          "min_latency_ms": 0.17977999959839508,
          "max_latency_ms": 0.20303112086399272,
          "speedup_vs_fp32": 0.960368123865657,
          "test_size": 1000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 0.031195148598138423
        },
        "int16": {
          "precision": "int16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.009779449044457695,
          "efficiency": 1.2994218767549422e-06,
          "mean_latency_ms": 0.20451049858820625,
          "std_latency_ms": 0.015231094205210783,
          "min_latency_ms": 0.18086800264427438,
          "max_latency_ms": 0.21974159279341704,
          "speedup_vs_fp32": 0.9032049744901125,
          "test_size": 1000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 0.02933834713337308
        },
        "int8": {
          "precision": "int8",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.010088526871396712,
          "efficiency": 6.702004166210531e-07,
          "mean_latency_ms": 0.19824499904643744,
          "std_latency_ms": 0.019920941976473188,
          "min_latency_ms": 0.1749479997670278,
          "max_latency_ms": 0.21816594102291062,
          "speedup_vs_fp32": 0.9317506143852478,
          "test_size": 1000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 0.030265580614190143
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas1_axpy_best_precision=bf16_blas_level=1_device=cuda_framework=pytorch_operation=axpy_size=10000": {
      "operation_type": "blas1_axpy",
      "measured_gflops": 0.1114312912474854,
      "efficiency": 1.4806177417949163e-05,
      "achieved_bandwidth_gbps": 0.33429387374245617,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.3333333333333333,
      "batch_size": 1,
      "input_shape": [
        10000
      ],
      "output_shape": [
        10000
      ],
      "mean_latency_ms": 0.17948279855772853,
      "std_latency_ms": 0.008080592094839347,
      "min_latency_ms": 0.16787599452072755,
      "max_latency_ms": 0.18756339065256789,
      "num_trials": 10,
      "extra_params": {
        "size": 10000,
        "operation": "axpy",
        "blas_level": 1,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "bf16"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.09815835271289339,
          "efficiency": 0.001663700893438871,
          "mean_latency_ms": 0.20375240055727772,
          "std_latency_ms": 0.01504975549126826,
          "min_latency_ms": 0.17984499572776258,
          "max_latency_ms": 0.21880215604854597,
          "speedup_vs_fp32": null,
          "test_size": 10000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 0.29447505813868013
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.10226370931914538,
          "efficiency": 5.433778391027916e-05,
          "mean_latency_ms": 0.19557280029403046,
          "std_latency_ms": 0.01463264068441993,
          "min_latency_ms": 0.17210099758813158,
          "max_latency_ms": 0.2102054409784504,
          "speedup_vs_fp32": 1.0,
          "test_size": 10000,
          "num_trials": 10,
          "arithmetic_intensity": 0.16666666666666666,
          "achieved_bandwidth_gbps": 0.6135822559148723
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.10883317227408372,
          "efficiency": 2.8921916628775903e-05,
          "mean_latency_ms": 0.18376750012976117,
          "std_latency_ms": 0.009883336063432458,
          "min_latency_ms": 0.17616400145925581,
          "max_latency_ms": 0.19365083619319362,
          "speedup_vs_fp32": 1.0642404133262593,
          "test_size": 10000,
          "num_trials": 10,
          "arithmetic_intensity": 0.16666666666666666,
          "achieved_bandwidth_gbps": 0.6529990336445024
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.10745022274005049,
          "efficiency": 1.427720206484859e-05,
          "mean_latency_ms": 0.1861326993093826,
          "std_latency_ms": 0.007291860088586121,
          "min_latency_ms": 0.17581300198799,
          "max_latency_ms": 0.1934245593979687,
          "speedup_vs_fp32": 1.0507170476744492,
          "test_size": 10000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 0.32235066822015146
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.1114312912474854,
          "efficiency": 1.4806177417949163e-05,
          "mean_latency_ms": 0.17948279855772853,
          "std_latency_ms": 0.008080592094839347,
          "min_latency_ms": 0.16787599452072755,
          "max_latency_ms": 0.18756339065256789,
          "speedup_vs_fp32": 1.0896464834825201,
          "test_size": 10000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 0.33429387374245617
        },
        "int64": {
          "precision": "int64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.10797392864795297,
          "efficiency": 0.0,
          "mean_latency_ms": 0.18522989994380623,
          "std_latency_ms": 0.015595414743608415,
          "min_latency_ms": 0.1648359975661151,
          "max_latency_ms": 0.20082531468741466,
          "speedup_vs_fp32": 1.0558381792213998,
          "test_size": 10000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 0.32392178594385884
        },
        "int32": {
          "precision": "int32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.1057072948041308,
          "efficiency": 5.6167531776902656e-05,
          "mean_latency_ms": 0.1892017011414282,
          "std_latency_ms": 0.014347358873322395,
          "min_latency_ms": 0.17520500114187598,
          "max_latency_ms": 0.2035490600147506,
          "speedup_vs_fp32": 1.0336735828175236,
          "test_size": 10000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 0.31712188441239236
        },
        "int16": {
          "precision": "int16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.10265675714081814,
          "efficiency": 1.3640281310233608e-05,
          "mean_latency_ms": 0.19482399948174134,
          "std_latency_ms": 0.019642829913235637,
          "min_latency_ms": 0.1726119953673333,
          "max_latency_ms": 0.21446682939497697,
          "speedup_vs_fp32": 1.0038434731567005,
          "test_size": 10000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 0.3079702714224544
        },
        "int8": {
          "precision": "int8",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.10921149733269507,
          "efficiency": 7.255131690207604e-06,
          "mean_latency_ms": 0.18313090185984038,
          "std_latency_ms": 0.00761502528362994,
          "min_latency_ms": 0.16976400365820155,
          "max_latency_ms": 0.19074592714347033,
          "speedup_vs_fp32": 1.0679399178829605,
          "test_size": 10000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 0.3276344919980852
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas1_axpy_best_precision=int16_blas_level=1_device=cuda_framework=pytorch_operation=axpy_size=100000": {
      "operation_type": "blas1_axpy",
      "measured_gflops": 1.101253661297675,
      "efficiency": 0.00014632655611183565,
      "achieved_bandwidth_gbps": 3.303760983893025,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.3333333333333333,
      "batch_size": 1,
      "input_shape": [
        100000
      ],
      "output_shape": [
        100000
      ],
      "mean_latency_ms": 0.18161120096920058,
      "std_latency_ms": 0.00860383357212978,
      "min_latency_ms": 0.17293299606535584,
      "max_latency_ms": 0.19021503454133037,
      "num_trials": 10,
      "extra_params": {
        "size": 100000,
        "operation": "axpy",
        "blas_level": 1,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "int16"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.9432734148398277,
          "efficiency": 0.015987684997285215,
          "mean_latency_ms": 0.21202760181040503,
          "std_latency_ms": 0.04057729485203787,
          "min_latency_ms": 0.18646800162969157,
          "max_latency_ms": 0.2526048966624429,
          "speedup_vs_fp32": null,
          "test_size": 100000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 2.8298202445194836
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.0712252313872692,
          "efficiency": 0.0005691951282610357,
          "mean_latency_ms": 0.18670209974516183,
          "std_latency_ms": 0.0068705499178248345,
          "min_latency_ms": 0.1786600041668862,
          "max_latency_ms": 0.19357264966298668,
          "speedup_vs_fp32": 1.0,
          "test_size": 100000,
          "num_trials": 10,
          "arithmetic_intensity": 0.16666666666666666,
          "achieved_bandwidth_gbps": 6.427351388323615
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.0760017681668348,
          "efficiency": 0.0002859425373815665,
          "mean_latency_ms": 0.18587330050650053,
          "std_latency_ms": 0.005291579950157327,
          "min_latency_ms": 0.1726120026432909,
          "max_latency_ms": 0.19116488045665786,
          "speedup_vs_fp32": 1.0044589472312744,
          "test_size": 100000,
          "num_trials": 10,
          "arithmetic_intensity": 0.16666666666666666,
          "achieved_bandwidth_gbps": 6.456010609001009
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.064346686127797,
          "efficiency": 0.00014142262637892598,
          "mean_latency_ms": 0.18790869798976928,
          "std_latency_ms": 0.006909453857230951,
          "min_latency_ms": 0.17398899944964796,
          "max_latency_ms": 0.19481815184700024,
          "speedup_vs_fp32": 0.9935788057843221,
          "test_size": 100000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 3.1930400583833913
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.0537063590501474,
          "efficiency": 0.0001400088173066898,
          "mean_latency_ms": 0.1898062000691425,
          "std_latency_ms": 0.018437757406054932,
          "min_latency_ms": 0.17053199553629383,
          "max_latency_ms": 0.20824395747519744,
          "speedup_vs_fp32": 0.9836459487474597,
          "test_size": 100000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 3.1611190771504427
        },
        "int64": {
          "precision": "int64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.0685524491192484,
          "efficiency": 0.0,
          "mean_latency_ms": 0.18716909980867058,
          "std_latency_ms": 0.011814588160335968,
          "min_latency_ms": 0.1744679975672625,
          "max_latency_ms": 0.19898368796900656,
          "speedup_vs_fp32": 0.9975049296919944,
          "test_size": 100000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 3.205657347357745
        },
        "int32": {
          "precision": "int32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.0656169567496363,
          "efficiency": 0.0005662151736182977,
          "mean_latency_ms": 0.1876847010862548,
          "std_latency_ms": 0.019285286926223277,
          "min_latency_ms": 0.1684200033196248,
          "max_latency_ms": 0.20696998801247807,
          "speedup_vs_fp32": 0.994764616746032,
          "test_size": 100000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 3.1968508702489093
        },
        "int16": {
          "precision": "int16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.101253661297675,
          "efficiency": 0.00014632655611183565,
          "mean_latency_ms": 0.18161120096920058,
          "std_latency_ms": 0.00860383357212978,
          "min_latency_ms": 0.17293299606535584,
          "max_latency_ms": 0.19021503454133037,
          "speedup_vs_fp32": 1.028031854581616,
          "test_size": 100000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 3.303760983893025
        },
        "int8": {
          "precision": "int8",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.0648555668582396,
          "efficiency": 7.074042163410879e-05,
          "mean_latency_ms": 0.1878188988484908,
          "std_latency_ms": 0.014922055439928793,
          "min_latency_ms": 0.17174799722852185,
          "max_latency_ms": 0.2027409542884196,
          "speedup_vs_fp32": 0.9940538512887894,
          "test_size": 100000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 3.1945667005747183
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas1_axpy_best_precision=int8_blas_level=1_device=cuda_framework=pytorch_operation=axpy_size=1000000": {
      "operation_type": "blas1_axpy",
      "measured_gflops": 5.441417284618228,
      "efficiency": 0.0003614839091621755,
      "achieved_bandwidth_gbps": 16.324251853854683,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.3333333333333333,
      "batch_size": 1,
      "input_shape": [
        1000000
      ],
      "output_shape": [
        1000000
      ],
      "mean_latency_ms": 0.3675513005873654,
      "std_latency_ms": 0.023828590256979053,
      "min_latency_ms": 0.3351760024088435,
      "max_latency_ms": 0.39137989084434444,
      "num_trials": 10,
      "extra_params": {
        "size": 1000000,
        "operation": "axpy",
        "blas_level": 1,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "int8"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.3295594234876547,
          "efficiency": 0.022534905482841604,
          "mean_latency_ms": 1.504257699707523,
          "std_latency_ms": 0.050699508680983954,
          "min_latency_ms": 1.4447070061578415,
          "max_latency_ms": 1.554957208388507,
          "speedup_vs_fp32": null,
          "test_size": 1000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 3.9886782704629646
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 2.2271645486633447,
          "efficiency": 0.00118340305455013,
          "mean_latency_ms": 0.8980027996585704,
          "std_latency_ms": 0.17371444621727075,
          "min_latency_ms": 0.7479220003006049,
          "max_latency_ms": 1.0717172458758413,
          "speedup_vs_fp32": 1.0,
          "test_size": 1000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.16666666666666666,
          "achieved_bandwidth_gbps": 13.362987291980069
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 2.298160330669063,
          "efficiency": 0.0006107255728591717,
          "mean_latency_ms": 0.8702613013156224,
          "std_latency_ms": 0.21496570206966775,
          "min_latency_ms": 0.6967209992581047,
          "max_latency_ms": 1.0852270033852902,
          "speedup_vs_fp32": 1.0318772055025422,
          "test_size": 1000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.16666666666666666,
          "achieved_bandwidth_gbps": 13.78896198401438
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 3.5118802531192146,
          "efficiency": 0.00046663303921328923,
          "mean_latency_ms": 0.5694954998034518,
          "std_latency_ms": 0.18523028592470733,
          "min_latency_ms": 0.4341550011304207,
          "max_latency_ms": 0.7547257857281592,
          "speedup_vs_fp32": 1.5768391496833518,
          "test_size": 1000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 10.535640759357642
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 3.9660915083286814,
          "efficiency": 0.0005269853186724264,
          "mean_latency_ms": 0.504274799459381,
          "std_latency_ms": 0.10418553328533664,
          "min_latency_ms": 0.42471399501664564,
          "max_latency_ms": 0.6084603327447177,
          "speedup_vs_fp32": 1.7807806390906191,
          "test_size": 1000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 11.898274524986045
        },
        "int64": {
          "precision": "int64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.41376866332664,
          "efficiency": 0.0,
          "mean_latency_ms": 1.4146586014248896,
          "std_latency_ms": 0.08891019679570554,
          "min_latency_ms": 1.3409290040726773,
          "max_latency_ms": 1.5035687982205952,
          "speedup_vs_fp32": 0.6347841088684388,
          "test_size": 1000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 4.24130598997992
        },
        "int32": {
          "precision": "int32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 2.6495200290544907,
          "efficiency": 0.0014078214819630663,
          "mean_latency_ms": 0.7548537010734435,
          "std_latency_ms": 0.03476741202145533,
          "min_latency_ms": 0.7273130031535402,
          "max_latency_ms": 0.7896211130948988,
          "speedup_vs_fp32": 1.1896382019211948,
          "test_size": 1000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 7.9485600871634725
        },
        "int16": {
          "precision": "int16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 4.234110772504097,
          "efficiency": 0.0005625977640850515,
          "mean_latency_ms": 0.47235419842763804,
          "std_latency_ms": 0.020732607272560877,
          "min_latency_ms": 0.44279499707045034,
          "max_latency_ms": 0.4930868057001989,
          "speedup_vs_fp32": 1.901121663886596,
          "test_size": 1000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 12.70233231751229
        },
        "int8": {
          "precision": "int8",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 5.441417284618228,
          "efficiency": 0.0003614839091621755,
          "mean_latency_ms": 0.3675513005873654,
          "std_latency_ms": 0.023828590256979053,
          "min_latency_ms": 0.3351760024088435,
          "max_latency_ms": 0.39137989084434444,
          "speedup_vs_fp32": 2.4432039778488526,
          "test_size": 1000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 16.324251853854683
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas1_axpy_best_precision=int8_blas_level=1_device=cuda_framework=pytorch_operation=axpy_size=10000000": {
      "operation_type": "blas1_axpy",
      "measured_gflops": 8.511368102679423,
      "efficiency": 0.000565426699174877,
      "achieved_bandwidth_gbps": 25.53410430803827,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.3333333333333333,
      "batch_size": 1,
      "input_shape": [
        10000000
      ],
      "output_shape": [
        10000000
      ],
      "mean_latency_ms": 2.349798499926692,
      "std_latency_ms": 0.028165552783794026,
      "min_latency_ms": 2.322489002835937,
      "max_latency_ms": 2.3779640527104857,
      "num_trials": 10,
      "extra_params": {
        "size": 10000000,
        "operation": "axpy",
        "blas_level": 1,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "int8"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.5236686266095776,
          "efficiency": 0.02582489197643352,
          "mean_latency_ms": 13.12621369943372,
          "std_latency_ms": 0.017026015466413948,
          "min_latency_ms": 13.100833995849825,
          "max_latency_ms": 13.143239714900133,
          "speedup_vs_fp32": null,
          "test_size": 10000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 4.571005879828732
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 3.054400164134545,
          "efficiency": 0.0016229543911448166,
          "mean_latency_ms": 6.547930501983501,
          "std_latency_ms": 0.04851995450751248,
          "min_latency_ms": 6.46201400377322,
          "max_latency_ms": 6.596450456491014,
          "speedup_vs_fp32": 1.0,
          "test_size": 10000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.16666666666666666,
          "achieved_bandwidth_gbps": 18.32640098480727
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 3.0425403584152853,
          "efficiency": 0.0008085411529139743,
          "mean_latency_ms": 6.573454299359582,
          "std_latency_ms": 0.09940669905548828,
          "min_latency_ms": 6.444574995839503,
          "max_latency_ms": 6.672860998415071,
          "speedup_vs_fp32": 0.9961171408191631,
          "test_size": 10000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.16666666666666666,
          "achieved_bandwidth_gbps": 18.25524215049171
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 5.8225364820698085,
          "efficiency": 0.0007736561894857571,
          "mean_latency_ms": 3.434929100330919,
          "std_latency_ms": 0.045385391936598136,
          "min_latency_ms": 3.3831230030045845,
          "max_latency_ms": 3.4803144922675173,
          "speedup_vs_fp32": 1.9062782114928307,
          "test_size": 10000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 17.467609446209423
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 5.853894749361577,
          "efficiency": 0.0007778228473773023,
          "mean_latency_ms": 3.4165287994255777,
          "std_latency_ms": 0.020553137390595333,
          "min_latency_ms": 3.3795080016716383,
          "max_latency_ms": 3.437081936816173,
          "speedup_vs_fp32": 1.9165447992372866,
          "test_size": 10000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 17.561684248084727
        },
        "int64": {
          "precision": "int64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.5516096640324248,
          "efficiency": 0.0,
          "mean_latency_ms": 12.889839799026959,
          "std_latency_ms": 0.42820037849871373,
          "min_latency_ms": 12.615765997907147,
          "max_latency_ms": 13.318040177525672,
          "speedup_vs_fp32": 0.5079916123145144,
          "test_size": 10000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 4.654828992097275
        },
        "int32": {
          "precision": "int32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 3.0649392590099014,
          "efficiency": 0.0016285543352868763,
          "mean_latency_ms": 6.525414799398277,
          "std_latency_ms": 0.049000199453800235,
          "min_latency_ms": 6.467967003118247,
          "max_latency_ms": 6.5744149988520775,
          "speedup_vs_fp32": 1.0034504630398822,
          "test_size": 10000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 9.194817777029705
        },
        "int16": {
          "precision": "int16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 5.677116174230484,
          "efficiency": 0.000754333799392836,
          "mean_latency_ms": 3.5229154003900476,
          "std_latency_ms": 0.19531532263711726,
          "min_latency_ms": 3.380435002327431,
          "max_latency_ms": 3.718230723027165,
          "speedup_vs_fp32": 1.8586681080273835,
          "test_size": 10000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 17.03134852269145
        },
        "int8": {
          "precision": "int8",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 8.511368102679423,
          "efficiency": 0.000565426699174877,
          "mean_latency_ms": 2.349798499926692,
          "std_latency_ms": 0.028165552783794026,
          "min_latency_ms": 2.322489002835937,
          "max_latency_ms": 2.3779640527104857,
          "speedup_vs_fp32": 2.786592340657202,
          "test_size": 10000000,
          "num_trials": 10,
          "arithmetic_intensity": 0.3333333333333333,
          "achieved_bandwidth_gbps": 25.53410430803827
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas2_gemv_best_precision=bf16_blas_level=2_device=cuda_framework=pytorch_operation=gemv_size=32": {
      "operation_type": "blas2_gemv",
      "measured_gflops": 0.005942124057552732,
      "efficiency": 7.895461144768445e-07,
      "achieved_bandwidth_gbps": 0.0063135068111497775,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.9411764705882353,
      "batch_size": 1,
      "input_shape": [
        32,
        32
      ],
      "output_shape": [
        32
      ],
      "mean_latency_ms": 0.34465790013200603,
      "std_latency_ms": 0.021554802454620207,
      "min_latency_ms": 0.30167100339895114,
      "max_latency_ms": 0.36621270258662625,
      "num_trials": 10,
      "extra_params": {
        "size": 32,
        "operation": "gemv",
        "blas_level": 2,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "bf16"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.0058214828764648835,
          "efficiency": 9.866920129601497e-05,
          "mean_latency_ms": 0.35180039922124706,
          "std_latency_ms": 0.02828301293988801,
          "min_latency_ms": 0.32029500289354473,
          "max_latency_ms": 0.38008341216113506,
          "speedup_vs_fp32": null,
          "test_size": 32,
          "num_trials": 10,
          "arithmetic_intensity": 0.9411764705882353,
          "achieved_bandwidth_gbps": 0.006185325556243939
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.005888863219893682,
          "efficiency": 3.1290452815588108e-06,
          "mean_latency_ms": 0.34777510081767105,
          "std_latency_ms": 0.014000761925284533,
          "min_latency_ms": 0.329672999214381,
          "max_latency_ms": 0.3617758627429556,
          "speedup_vs_fp32": 1.0,
          "test_size": 32,
          "num_trials": 10,
          "arithmetic_intensity": 0.47058823529411764,
          "achieved_bandwidth_gbps": 0.012513834342274073
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.005786056058461983,
          "efficiency": 1.537617873627952e-06,
          "mean_latency_ms": 0.35395439990679733,
          "std_latency_ms": 0.024220993174297736,
          "min_latency_ms": 0.3369679980096407,
          "max_latency_ms": 0.37817539308109505,
          "speedup_vs_fp32": 0.9825421040372619,
          "test_size": 32,
          "num_trials": 10,
          "arithmetic_intensity": 0.47058823529411764,
          "achieved_bandwidth_gbps": 0.012295369124231712
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.005770618497671633,
          "efficiency": 7.667577063076844e-07,
          "mean_latency_ms": 0.35490129885147326,
          "std_latency_ms": 0.01559381093170792,
          "min_latency_ms": 0.3275279959780164,
          "max_latency_ms": 0.3704951097831812,
          "speedup_vs_fp32": 0.9799206200234715,
          "test_size": 32,
          "num_trials": 10,
          "arithmetic_intensity": 0.9411764705882353,
          "achieved_bandwidth_gbps": 0.00613128215377611
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.005942124057552732,
          "efficiency": 7.895461144768445e-07,
          "mean_latency_ms": 0.34465790013200603,
          "std_latency_ms": 0.021554802454620207,
          "min_latency_ms": 0.30167100339895114,
          "max_latency_ms": 0.36621270258662625,
          "speedup_vs_fp32": 1.0090443326106004,
          "test_size": 32,
          "num_trials": 10,
          "arithmetic_intensity": 0.9411764705882353,
          "achieved_bandwidth_gbps": 0.0063135068111497775
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Long'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Int'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Short'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Char'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas2_gemv_best_precision=bf16_blas_level=2_device=cuda_framework=pytorch_operation=gemv_size=64": {
      "operation_type": "blas2_gemv",
      "measured_gflops": 0.023904980145003047,
      "efficiency": 3.1763194452568493e-06,
      "achieved_bandwidth_gbps": 0.024652010774534393,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.9696969696969697,
      "batch_size": 1,
      "input_shape": [
        64,
        64
      ],
      "output_shape": [
        64
      ],
      "mean_latency_ms": 0.34269009847776033,
      "std_latency_ms": 0.012528027562099284,
      "min_latency_ms": 0.3278479998698458,
      "max_latency_ms": 0.35521812603985964,
      "num_trials": 10,
      "extra_params": {
        "size": 64,
        "operation": "gemv",
        "blas_level": 2,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "bf16"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.02262187902692559,
          "efficiency": 0.00038342167842246767,
          "mean_latency_ms": 0.3621273011958692,
          "std_latency_ms": 0.01608598023240609,
          "min_latency_ms": 0.34020000020973384,
          "max_latency_ms": 0.3782132814282753,
          "speedup_vs_fp32": null,
          "test_size": 64,
          "num_trials": 10,
          "arithmetic_intensity": 0.9696969696969697,
          "achieved_bandwidth_gbps": 0.02332881274651702
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.023507016063868572,
          "efficiency": 1.2490444242225597e-05,
          "mean_latency_ms": 0.3484917004243471,
          "std_latency_ms": 0.013451676550744533,
          "min_latency_ms": 0.33072799851652235,
          "max_latency_ms": 0.3619433769750916,
          "speedup_vs_fp32": 1.0,
          "test_size": 64,
          "num_trials": 10,
          "arithmetic_intensity": 0.48484848484848486,
          "achieved_bandwidth_gbps": 0.04848322063172893
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.020572323528521664,
          "efficiency": 5.4670006719430415e-06,
          "mean_latency_ms": 0.398204898374388,
          "std_latency_ms": 0.19018391863310233,
          "min_latency_ms": 0.31367199699161574,
          "max_latency_ms": 0.5883888170074904,
          "speedup_vs_fp32": 0.8751567392742087,
          "test_size": 64,
          "num_trials": 10,
          "arithmetic_intensity": 0.48484848484848486,
          "achieved_bandwidth_gbps": 0.04243041727757593
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.01427779651997968,
          "efficiency": 1.8971294871086474e-06,
          "mean_latency_ms": 0.5737580017012078,
          "std_latency_ms": 0.4240043960631164,
          "min_latency_ms": 0.32167100289370865,
          "max_latency_ms": 0.9977623977643242,
          "speedup_vs_fp32": 0.6073844711377616,
          "test_size": 64,
          "num_trials": 10,
          "arithmetic_intensity": 0.9696969696969697,
          "achieved_bandwidth_gbps": 0.014723977661229045
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.023904980145003047,
          "efficiency": 3.1763194452568493e-06,
          "mean_latency_ms": 0.34269009847776033,
          "std_latency_ms": 0.012528027562099284,
          "min_latency_ms": 0.3278479998698458,
          "max_latency_ms": 0.35521812603985964,
          "speedup_vs_fp32": 1.016929587322066,
          "test_size": 64,
          "num_trials": 10,
          "arithmetic_intensity": 0.9696969696969697,
          "achieved_bandwidth_gbps": 0.024652010774534393
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Long'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Int'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Short'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Char'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas2_gemv_best_precision=bf16_blas_level=2_device=cuda_framework=pytorch_operation=gemv_size=128": {
      "operation_type": "blas2_gemv",
      "measured_gflops": 0.09519681442825531,
      "efficiency": 1.264905852089494e-05,
      "achieved_bandwidth_gbps": 0.0966842646536968,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.9846153846153847,
      "batch_size": 1,
      "input_shape": [
        128,
        128
      ],
      "output_shape": [
        128
      ],
      "mean_latency_ms": 0.3442131986957975,
      "std_latency_ms": 0.027841964566607168,
      "min_latency_ms": 0.30746399716008455,
      "max_latency_ms": 0.3720551632624046,
      "num_trials": 10,
      "extra_params": {
        "size": 128,
        "operation": "gemv",
        "blas_level": 2,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "bf16"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.06181966155020749,
          "efficiency": 0.0010477908737323302,
          "mean_latency_ms": 0.5300579003232997,
          "std_latency_ms": 0.030834743067589404,
          "min_latency_ms": 0.47201200504787266,
          "max_latency_ms": 0.5608926433908891,
          "speedup_vs_fp32": null,
          "test_size": 128,
          "num_trials": 10,
          "arithmetic_intensity": 0.9846153846153847,
          "achieved_bandwidth_gbps": 0.06278559376192948
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.05826942931595338,
          "efficiency": 3.096143959402411e-05,
          "mean_latency_ms": 0.5623531993478537,
          "std_latency_ms": 0.03199031750374135,
          "min_latency_ms": 0.5180610023671761,
          "max_latency_ms": 0.594343516851595,
          "speedup_vs_fp32": 1.0,
          "test_size": 128,
          "num_trials": 10,
          "arithmetic_intensity": 0.49230769230769234,
          "achieved_bandwidth_gbps": 0.11835977829803031
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.060354516630015904,
          "efficiency": 1.603893612277861e-05,
          "mean_latency_ms": 0.5429253986221738,
          "std_latency_ms": 0.01956566438902834,
          "min_latency_ms": 0.5195960038690828,
          "max_latency_ms": 0.5624910630112021,
          "speedup_vs_fp32": 1.0357835547480068,
          "test_size": 128,
          "num_trials": 10,
          "arithmetic_intensity": 0.49230769230769234,
          "achieved_bandwidth_gbps": 0.1225951119047198
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.05687861924670633,
          "efficiency": 7.557616163527282e-06,
          "mean_latency_ms": 0.5761039989010897,
          "std_latency_ms": 0.03496513478643758,
          "min_latency_ms": 0.5112450016895309,
          "max_latency_ms": 0.6110691336875272,
          "speedup_vs_fp32": 0.9761313936729038,
          "test_size": 128,
          "num_trials": 10,
          "arithmetic_intensity": 0.9846153846153847,
          "achieved_bandwidth_gbps": 0.05776734767243611
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.09519681442825531,
          "efficiency": 1.264905852089494e-05,
          "mean_latency_ms": 0.3442131986957975,
          "std_latency_ms": 0.027841964566607168,
          "min_latency_ms": 0.30746399716008455,
          "max_latency_ms": 0.3720551632624046,
          "speedup_vs_fp32": 1.6337351428666167,
          "test_size": 128,
          "num_trials": 10,
          "arithmetic_intensity": 0.9846153846153847,
          "achieved_bandwidth_gbps": 0.0966842646536968
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Long'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Int'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Short'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Char'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas2_gemv_best_precision=fp32_blas_level=2_device=cuda_framework=pytorch_operation=gemv_size=256": {
      "operation_type": "blas2_gemv",
      "measured_gflops": 0.377840062528399,
      "efficiency": 0.00020076517668884115,
      "achieved_bandwidth_gbps": 0.7615838760338043,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.49612403100775193,
      "batch_size": 1,
      "input_shape": [
        256,
        256
      ],
      "output_shape": [
        256
      ],
      "mean_latency_ms": 0.34689810054260306,
      "std_latency_ms": 0.013054308710715286,
      "min_latency_ms": 0.33088799682445824,
      "max_latency_ms": 0.35995240925331834,
      "num_trials": 10,
      "extra_params": {
        "size": 256,
        "operation": "gemv",
        "blas_level": 2,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "fp32"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.376752482415523,
          "efficiency": 0.006385635295178356,
          "mean_latency_ms": 0.34789949932019226,
          "std_latency_ms": 0.011895943640542937,
          "min_latency_ms": 0.33399200037820265,
          "max_latency_ms": 0.3597954429607352,
          "speedup_vs_fp32": null,
          "test_size": 256,
          "num_trials": 10,
          "arithmetic_intensity": 0.9922480620155039,
          "achieved_bandwidth_gbps": 0.3796958611843943
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.377840062528399,
          "efficiency": 0.00020076517668884115,
          "mean_latency_ms": 0.34689810054260306,
          "std_latency_ms": 0.013054308710715286,
          "min_latency_ms": 0.33088799682445824,
          "max_latency_ms": 0.35995240925331834,
          "speedup_vs_fp32": 1.0,
          "test_size": 256,
          "num_trials": 10,
          "arithmetic_intensity": 0.49612403100775193,
          "achieved_bandwidth_gbps": 0.7615838760338043
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.36719371407216406,
          "efficiency": 9.758004625887963e-05,
          "mean_latency_ms": 0.3569560016330797,
          "std_latency_ms": 0.018586316447892673,
          "min_latency_ms": 0.33024800359271467,
          "max_latency_ms": 0.3755423180809724,
          "speedup_vs_fp32": 0.9718231349397081,
          "test_size": 256,
          "num_trials": 10,
          "arithmetic_intensity": 0.49612403100775193,
          "achieved_bandwidth_gbps": 0.7401248299267057
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.34616540677977264,
          "efficiency": 4.599593499598361e-05,
          "mean_latency_ms": 0.378639798873337,
          "std_latency_ms": 0.014102795226805158,
          "min_latency_ms": 0.3638809939729981,
          "max_latency_ms": 0.3927425941001421,
          "speedup_vs_fp32": 0.916169144328771,
          "test_size": 256,
          "num_trials": 10,
          "arithmetic_intensity": 0.9922480620155039,
          "achieved_bandwidth_gbps": 0.3488698240202396
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.3596838624391123,
          "efficiency": 4.7792168806685135e-05,
          "mean_latency_ms": 0.36440889816731215,
          "std_latency_ms": 0.009597553724782614,
          "min_latency_ms": 0.3516889992170036,
          "max_latency_ms": 0.37400645189209475,
          "speedup_vs_fp32": 0.9519473928524399,
          "test_size": 256,
          "num_trials": 10,
          "arithmetic_intensity": 0.9922480620155039,
          "achieved_bandwidth_gbps": 0.3624938926144179
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Long'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Int'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Short'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Char'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas2_gemv_best_precision=tf32_blas_level=2_device=cuda_framework=pytorch_operation=gemv_size=512": {
      "operation_type": "blas2_gemv",
      "measured_gflops": 1.524352697276842,
      "efficiency": 0.0004050897415032798,
      "achieved_bandwidth_gbps": 3.0606144000011586,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.4980544747081712,
      "batch_size": 1,
      "input_shape": [
        512,
        512
      ],
      "output_shape": [
        512
      ],
      "mean_latency_ms": 0.34394139947835356,
      "std_latency_ms": 0.02253080178459795,
      "min_latency_ms": 0.3264400002080947,
      "max_latency_ms": 0.3664722012629515,
      "num_trials": 10,
      "extra_params": {
        "size": 512,
        "operation": "gemv",
        "blas_level": 2,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "tf32"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.5194199206319694,
          "efficiency": 0.025752880010711347,
          "mean_latency_ms": 0.3450580006756354,
          "std_latency_ms": 0.017274926911832696,
          "min_latency_ms": 0.3174150042468682,
          "max_latency_ms": 0.3623329275874681,
          "speedup_vs_fp32": null,
          "test_size": 512,
          "num_trials": 10,
          "arithmetic_intensity": 0.9961089494163424,
          "achieved_bandwidth_gbps": 1.525355154696938
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.5216499797392264,
          "efficiency": 0.0008085281507647324,
          "mean_latency_ms": 0.3445522997935768,
          "std_latency_ms": 0.014528416228241242,
          "min_latency_ms": 0.3276559946243651,
          "max_latency_ms": 0.35908071602181807,
          "speedup_vs_fp32": 1.0,
          "test_size": 512,
          "num_trials": 10,
          "arithmetic_intensity": 0.4980544747081712,
          "achieved_bandwidth_gbps": 3.055187849945165
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.524352697276842,
          "efficiency": 0.0004050897415032798,
          "mean_latency_ms": 0.34394139947835356,
          "std_latency_ms": 0.02253080178459795,
          "min_latency_ms": 0.3264400002080947,
          "max_latency_ms": 0.3664722012629515,
          "speedup_vs_fp32": 1.0017761755815084,
          "test_size": 512,
          "num_trials": 10,
          "arithmetic_intensity": 0.4980544747081712,
          "achieved_bandwidth_gbps": 3.0606144000011586
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.2927641552404596,
          "efficiency": 0.00017177307404204884,
          "mean_latency_ms": 0.40555579907959327,
          "std_latency_ms": 0.10425117750009023,
          "min_latency_ms": 0.34547999530332163,
          "max_latency_ms": 0.5098069765796835,
          "speedup_vs_fp32": 0.8495805030418413,
          "test_size": 512,
          "num_trials": 10,
          "arithmetic_intensity": 0.9961089494163424,
          "achieved_bandwidth_gbps": 1.2978140152218678
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.423398736447246,
          "efficiency": 0.00018913084459835848,
          "mean_latency_ms": 0.3683352995722089,
          "std_latency_ms": 0.013875092871627982,
          "min_latency_ms": 0.3492559990263544,
          "max_latency_ms": 0.38221039244383687,
          "speedup_vs_fp32": 0.9354311145137213,
          "test_size": 512,
          "num_trials": 10,
          "arithmetic_intensity": 0.9961089494163424,
          "achieved_bandwidth_gbps": 1.428958887761493
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Long'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Int'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Short'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Char'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas2_gemv_best_precision=tf32_blas_level=2_device=cuda_framework=pytorch_operation=gemv_size=1024": {
      "operation_type": "blas2_gemv",
      "measured_gflops": 3.7233547173689354,
      "efficiency": 0.0009894644478790687,
      "achieved_bandwidth_gbps": 7.461253789102593,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.49902534113060426,
      "batch_size": 1,
      "input_shape": [
        1024,
        1024
      ],
      "output_shape": [
        1024
      ],
      "mean_latency_ms": 0.5632426022202708,
      "std_latency_ms": 0.03941836152836925,
      "min_latency_ms": 0.51025200082222,
      "max_latency_ms": 0.60266096374864,
      "num_trials": 10,
      "extra_params": {
        "size": 1024,
        "operation": "gemv",
        "blas_level": 2,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "tf32"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 2.836998328065076,
          "efficiency": 0.048084717424831794,
          "mean_latency_ms": 0.7392150990199298,
          "std_latency_ms": 0.025236866453869626,
          "min_latency_ms": 0.6826409953646362,
          "max_latency_ms": 0.7644519654737993,
          "speedup_vs_fp32": null,
          "test_size": 1024,
          "num_trials": 10,
          "arithmetic_intensity": 0.9980506822612085,
          "achieved_bandwidth_gbps": 2.842539340424578
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 3.7041389948811427,
          "efficiency": 0.001968192877195081,
          "mean_latency_ms": 0.5661644994688686,
          "std_latency_ms": 0.029825078015934522,
          "min_latency_ms": 0.5402370006777346,
          "max_latency_ms": 0.5959895774848031,
          "speedup_vs_fp32": 1.0,
          "test_size": 1024,
          "num_trials": 10,
          "arithmetic_intensity": 0.49902534113060426,
          "achieved_bandwidth_gbps": 7.42274728271104
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 3.7233547173689354,
          "efficiency": 0.0009894644478790687,
          "mean_latency_ms": 0.5632426022202708,
          "std_latency_ms": 0.03941836152836925,
          "min_latency_ms": 0.51025200082222,
          "max_latency_ms": 0.60266096374864,
          "speedup_vs_fp32": 1.005187635376088,
          "test_size": 1024,
          "num_trials": 10,
          "arithmetic_intensity": 0.49902534113060426,
          "achieved_bandwidth_gbps": 7.461253789102593
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 3.6126991717850236,
          "efficiency": 0.0004800291219485814,
          "mean_latency_ms": 0.5804945001727901,
          "std_latency_ms": 0.02610643560827189,
          "min_latency_ms": 0.5380619986681268,
          "max_latency_ms": 0.606600935781062,
          "speedup_vs_fp32": 0.975314149057991,
          "test_size": 1024,
          "num_trials": 10,
          "arithmetic_intensity": 0.9980506822612085,
          "achieved_bandwidth_gbps": 3.619755224854916
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 3.57207679513782,
          "efficiency": 0.0004746315167602737,
          "mean_latency_ms": 0.5870960005267989,
          "std_latency_ms": 0.0256649910450667,
          "min_latency_ms": 0.5366850018617697,
          "max_latency_ms": 0.6127609915718656,
          "speedup_vs_fp32": 0.964347396270544,
          "test_size": 1024,
          "num_trials": 10,
          "arithmetic_intensity": 0.9980506822612085,
          "achieved_bandwidth_gbps": 3.579053507628324
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Long'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Int'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Short'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Char'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas2_gemv_best_precision=bf16_blas_level=2_device=cuda_framework=pytorch_operation=gemv_size=2048": {
      "operation_type": "blas2_gemv",
      "measured_gflops": 21.23449325180423,
      "efficiency": 0.0028214846202237885,
      "achieved_bandwidth_gbps": 21.25523006162044,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.9990243902439024,
      "batch_size": 1,
      "input_shape": [
        2048,
        2048
      ],
      "output_shape": [
        2048
      ],
      "mean_latency_ms": 0.3950463004002813,
      "std_latency_ms": 0.015335184878397108,
      "min_latency_ms": 0.3802330029429868,
      "max_latency_ms": 0.41038148527867846,
      "num_trials": 10,
      "extra_params": {
        "size": 2048,
        "operation": "gemv",
        "blas_level": 2,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "bf16"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 3.445864192072654,
          "efficiency": 0.0584044778317399,
          "mean_latency_ms": 2.434398900368251,
          "std_latency_ms": 0.037969039008501015,
          "min_latency_ms": 2.4073229942587204,
          "max_latency_ms": 2.4723679393767517,
          "speedup_vs_fp32": null,
          "test_size": 2048,
          "num_trials": 10,
          "arithmetic_intensity": 0.9990243902439024,
          "achieved_bandwidth_gbps": 3.4492292938227247
        },
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 13.135778501709881,
          "efficiency": 0.006979691021099831,
          "mean_latency_ms": 0.6386076012859121,
          "std_latency_ms": 0.020649177351766298,
          "min_latency_ms": 0.6207840051501989,
          "max_latency_ms": 0.6592567786376784,
          "speedup_vs_fp32": 1.0,
          "test_size": 2048,
          "num_trials": 10,
          "arithmetic_intensity": 0.4995121951219512,
          "achieved_bandwidth_gbps": 26.297212820805917
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 13.04231651409981,
          "efficiency": 0.003465935826229022,
          "mean_latency_ms": 0.6431838999560568,
          "std_latency_ms": 0.01847479090385664,
          "min_latency_ms": 0.6221910007297993,
          "max_latency_ms": 0.6616586908599135,
          "speedup_vs_fp32": 0.9928849296904705,
          "test_size": 2048,
          "num_trials": 10,
          "arithmetic_intensity": 0.4995121951219512,
          "achieved_bandwidth_gbps": 26.110106302641224
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 21.00544912083554,
          "efficiency": 0.0027910509063028884,
          "mean_latency_ms": 0.39935389868333004,
          "std_latency_ms": 0.016243424430366027,
          "min_latency_ms": 0.3787609966821037,
          "max_latency_ms": 0.41559732311369607,
          "speedup_vs_fp32": 1.599101957916028,
          "test_size": 2048,
          "num_trials": 10,
          "arithmetic_intensity": 0.9990243902439024,
          "achieved_bandwidth_gbps": 21.025962254742605
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 21.23449325180423,
          "efficiency": 0.0028214846202237885,
          "mean_latency_ms": 0.3950463004002813,
          "std_latency_ms": 0.015335184878397108,
          "min_latency_ms": 0.3802330029429868,
          "max_latency_ms": 0.41038148527867846,
          "speedup_vs_fp32": 1.616538620001863,
          "test_size": 2048,
          "num_trials": 10,
          "arithmetic_intensity": 0.9990243902439024,
          "achieved_bandwidth_gbps": 21.25523006162044
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Long'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Int'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Short'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "RuntimeError: \"addmv_impl_cuda\" not implemented for 'Char'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas3_gemm_best_precision=fp16_blas_level=3_device=cuda_framework=pytorch_operation=gemm_size=32": {
      "operation_type": "blas3_gemm",
      "measured_gflops": 0.1646128989842933,
      "efficiency": 2.1872561650849493e-05,
      "achieved_bandwidth_gbps": 0.015432459279777495,
      "memory_bound": false,
      "compute_bound": true,
      "arithmetic_intensity": 10.666666666666666,
      "batch_size": 1,
      "input_shape": [
        32,
        32
      ],
      "output_shape": [
        32,
        32
      ],
      "mean_latency_ms": 0.3981218993430957,
      "std_latency_ms": 0.029801740717434317,
      "min_latency_ms": 0.36199299938743934,
      "max_latency_ms": 0.42792364006053,
      "num_trials": 10,
      "extra_params": {
        "size": 32,
        "operation": "gemm",
        "blas_level": 3,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "fp16"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": false,
          "failure_reason": "Timeout: GEMM benchmark exceeded 5s timeout",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp32": {
          "precision": "fp32",
          "supported": false,
          "failure_reason": "Timeout: GEMM benchmark exceeded 5s timeout",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.11173887275732446,
          "efficiency": 2.9694093212151065e-05,
          "mean_latency_ms": 0.5865103019459639,
          "std_latency_ms": 0.0518746143729183,
          "min_latency_ms": 0.5286209998303093,
          "max_latency_ms": 0.6383849163188822,
          "speedup_vs_fp32": null,
          "test_size": 32,
          "num_trials": 10,
          "arithmetic_intensity": 5.333333333333333,
          "achieved_bandwidth_gbps": 0.020951038641998335
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.1646128989842933,
          "efficiency": 2.1872561650849493e-05,
          "mean_latency_ms": 0.3981218993430957,
          "std_latency_ms": 0.029801740717434317,
          "min_latency_ms": 0.36199299938743934,
          "max_latency_ms": 0.42792364006053,
          "speedup_vs_fp32": null,
          "test_size": 32,
          "num_trials": 10,
          "arithmetic_intensity": 10.666666666666666,
          "achieved_bandwidth_gbps": 0.015432459279777495
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.10616967075052242,
          "efficiency": 1.4107051654334629e-05,
          "mean_latency_ms": 0.6172760971821845,
          "std_latency_ms": 0.052939836627830396,
          "min_latency_ms": 0.5544139930862002,
          "max_latency_ms": 0.6702159338100149,
          "speedup_vs_fp32": null,
          "test_size": 32,
          "num_trials": 10,
          "arithmetic_intensity": 10.666666666666666,
          "achieved_bandwidth_gbps": 0.009953406632861476
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'Lo",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "Timeout: GEMM benchmark exceeded 5s timeout",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'Sh",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "Timeout: GEMM benchmark exceeded 5s timeout",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas3_gemm_best_precision=tf32_blas_level=3_device=cuda_framework=pytorch_operation=gemm_size=64": {
      "operation_type": "blas3_gemm",
      "measured_gflops": 1.1186858305354637,
      "efficiency": 0.00029728563128765973,
      "achieved_bandwidth_gbps": 0.1048767966126997,
      "memory_bound": false,
      "compute_bound": true,
      "arithmetic_intensity": 10.666666666666666,
      "batch_size": 1,
      "input_shape": [
        64,
        64
      ],
      "output_shape": [
        64,
        64
      ],
      "mean_latency_ms": 0.4686642001615837,
      "std_latency_ms": 0.1181053866924255,
      "min_latency_ms": 0.3775770019274205,
      "max_latency_ms": 0.5867695868540093,
      "num_trials": 10,
      "extra_params": {
        "size": 64,
        "operation": "gemm",
        "blas_level": 3,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "tf32"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": false,
          "failure_reason": "Skipped (poor performance at size 32: Timeout (>5s))",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp32": {
          "precision": "fp32",
          "supported": false,
          "failure_reason": "Skipped (poor performance at size 32: Timeout (>5s))",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 1.1186858305354637,
          "efficiency": 0.00029728563128765973,
          "mean_latency_ms": 0.4686642001615837,
          "std_latency_ms": 0.1181053866924255,
          "min_latency_ms": 0.3775770019274205,
          "max_latency_ms": 0.5867695868540093,
          "speedup_vs_fp32": null,
          "test_size": 64,
          "num_trials": 10,
          "arithmetic_intensity": 10.666666666666666,
          "achieved_bandwidth_gbps": 0.1048767966126997
        },
        "fp16": {
          "precision": "fp16",
          "supported": false,
          "failure_reason": "Timeout: GEMM benchmark exceeded 5s timeout",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.9777512232902964,
          "efficiency": 0.00012991645273588843,
          "mean_latency_ms": 0.5362181989767123,
          "std_latency_ms": 0.10957494281972709,
          "min_latency_ms": 0.3892579989042133,
          "max_latency_ms": 0.6457931417964394,
          "speedup_vs_fp32": null,
          "test_size": 64,
          "num_trials": 10,
          "arithmetic_intensity": 21.333333333333332,
          "achieved_bandwidth_gbps": 0.04583208859173264
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'Lo",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "Skipped (poor performance at size 32: Timeout (>5s))",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'Sh",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "Skipped (poor performance at size 32: Timeout (>5s))",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas3_gemm_best_precision=tf32_blas_level=3_device=cuda_framework=pytorch_operation=gemm_size=128": {
      "operation_type": "blas3_gemm",
      "measured_gflops": 10.420726820350756,
      "efficiency": 0.002769260382766611,
      "achieved_bandwidth_gbps": 0.4884715697039417,
      "memory_bound": false,
      "compute_bound": true,
      "arithmetic_intensity": 21.333333333333332,
      "batch_size": 1,
      "input_shape": [
        128,
        128
      ],
      "output_shape": [
        128,
        128
      ],
      "mean_latency_ms": 0.4024963011033833,
      "std_latency_ms": 0.025380888691753697,
      "min_latency_ms": 0.3777050005737692,
      "max_latency_ms": 0.427877189795137,
      "num_trials": 10,
      "extra_params": {
        "size": 128,
        "operation": "gemm",
        "blas_level": 3,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "tf32"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": false,
          "failure_reason": "Skipped (poor performance at size 32: Timeout (>5s))",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp32": {
          "precision": "fp32",
          "supported": false,
          "failure_reason": "Skipped (poor performance at size 32: Timeout (>5s))",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "tf32": {
          "precision": "tf32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 10.420726820350756,
          "efficiency": 0.002769260382766611,
          "mean_latency_ms": 0.4024963011033833,
          "std_latency_ms": 0.025380888691753697,
          "min_latency_ms": 0.3777050005737692,
          "max_latency_ms": 0.427877189795137,
          "speedup_vs_fp32": null,
          "test_size": 128,
          "num_trials": 10,
          "arithmetic_intensity": 21.333333333333332,
          "achieved_bandwidth_gbps": 0.4884715697039417
        },
        "fp16": {
          "precision": "fp16",
          "supported": false,
          "failure_reason": "Skipped (poor performance at size 64: Timeout (>5s))",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 7.095998132144874,
          "efficiency": 0.0009428644873963426,
          "mean_latency_ms": 0.5910802006837912,
          "std_latency_ms": 0.19968995586399943,
          "min_latency_ms": 0.39959399873623624,
          "max_latency_ms": 0.7907701565477906,
          "speedup_vs_fp32": null,
          "test_size": 128,
          "num_trials": 10,
          "arithmetic_intensity": 42.666666666666664,
          "achieved_bandwidth_gbps": 0.1663124562221455
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "Timeout: GEMM benchmark exceeded 5s timeout",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "Skipped (poor performance at size 32: Timeout (>5s))",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "RuntimeError: RuntimeError: \"addmm_cuda\" not implemented for 'Sh",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "Skipped (poor performance at size 32: Timeout (>5s))",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "blas3_gemm_best_precision=bf16_blas_level=3_device=cuda_framework=pytorch_operation=gemm_size=256": {
      "operation_type": "blas3_gemm",
      "measured_gflops": 87.8337919608208,
      "efficiency": 0.011670713786981238,
      "achieved_bandwidth_gbps": 1.0293022495408686,
      "memory_bound": false,
      "compute_bound": true,
      "arithmetic_intensity": 85.33333333333333,
      "batch_size": 1,
      "input_shape": [
        256,
        256
      ],
      "output_shape": [
        256,
        256
      ],
      "mean_latency_ms": 0.3820218989858404,
      "std_latency_ms": 0.017312621139369558,
      "min_latency_ms": 0.3551439949660562,
      "max_latency_ms": 0.3993345201252099,
      "num_trials": 10,
      "extra_params": {
        "size": 256,
        "operation": "gemm",
        "blas_level": 3,
        "framework": "pytorch",
        "device": "cuda",
        "best_precision": "bf16"
      },
      "precision_results": {
        "fp64": {
          "precision": "fp64",
          "supported": false,
          "failure_reason": "Skipped (poor performance at size 32: Timeout (>5s))",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp32": {
          "precision": "fp32",
          "supported": false,
          "failure_reason": "Skipped (poor performance at size 32: Timeout (>5s))",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "tf32": {
          "precision": "tf32",
          "supported": false,
          "failure_reason": "Timeout: GEMM benchmark exceeded 5s timeout",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp16": {
          "precision": "fp16",
          "supported": false,
          "failure_reason": "Skipped (poor performance at size 64: Timeout (>5s))",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp8": {
          "precision": "fp8",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "fp4": {
          "precision": "fp4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "bf16": {
          "precision": "bf16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 87.8337919608208,
          "efficiency": 0.011670713786981238,
          "mean_latency_ms": 0.3820218989858404,
          "std_latency_ms": 0.017312621139369558,
          "min_latency_ms": 0.3551439949660562,
          "max_latency_ms": 0.3993345201252099,
          "speedup_vs_fp32": null,
          "test_size": 256,
          "num_trials": 10,
          "arithmetic_intensity": 85.33333333333333,
          "achieved_bandwidth_gbps": 1.0293022495408686
        },
        "int64": {
          "precision": "int64",
          "supported": false,
          "failure_reason": "Skipped (poor performance at size 128: Timeout (>5s))",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int32": {
          "precision": "int32",
          "supported": false,
          "failure_reason": "Skipped (poor performance at size 32: Timeout (>5s))",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int16": {
          "precision": "int16",
          "supported": false,
          "failure_reason": "Timeout: GEMM benchmark exceeded 5s timeout",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "Skipped (poor performance at size 32: Timeout (>5s))",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int4": {
          "precision": "int4",
          "supported": false,
          "failure_reason": "PyTorch does not support this precision",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 0,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    }
  },
  "fusion_profiles": {},
  "precision_matrix": {
    "hardware_name": "Jetson Orin NX 16GB (GPU)",
    "supported_precisions": [
      "fp64",
      "fp32",
      "tf32",
      "fp16",
      "bf16",
      "int64",
      "int32",
      "int16",
      "int8"
    ],
    "unsupported_precisions": [
      "fp8",
      "fp4",
      "int4"
    ],
    "peak_gflops_by_precision": {
      "fp64": 6.577733732704199,
      "fp32": 13.135778501709881,
      "tf32": 13.04231651409981,
      "fp16": 21.00544912083554,
      "bf16": 87.8337919608208,
      "int64": 1.5516096640324248,
      "int32": 3.0649392590099014,
      "int16": 5.677116174230484,
      "int8": 8.511368102679423
    },
    "speedup_vs_fp32": {
      "fp32": 1.0,
      "tf32": 0.9928849296904705,
      "fp16": 1.599101957916028,
      "bf16": 1.616538620001863,
      "int64": 0.5079916123145144,
      "int32": 1.0034504630398822,
      "int16": 1.8586681080273835,
      "int8": 2.786592340657202
    },
    "theoretical_peaks": {
      "fp64": 59.0,
      "fp32": 1882.0,
      "fp16": 7526.0,
      "fp8": 0.0,
      "fp4": 0.0,
      "bf16": 7526.0,
      "tf32": 3763.0,
      "int64": 0.0,
      "int32": 1882.0,
      "int16": 7526.0,
      "int8": 15053.0,
      "int4": 0.0
    }
  }
}