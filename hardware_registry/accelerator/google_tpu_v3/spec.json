{
  "id": "google_tpu_v3",
  "vendor": "Google",
  "model": "Google TPU v3",
  "device_type": "tpu",
  "product_category": "datacenter",
  "ops_per_clock": {
    "fp64": 0,
    "fp32": 65536,
    "fp16": 131072,
    "fp8": 0,
    "fp4": 0,
    "bf16": 131072,
    "tf32": 0,
    "int64": 0,
    "int32": 65536,
    "int16": 131072,
    "int8": 262144,
    "int4": 0
  },
  "ops_per_clock_notes": {
    "bf16": "2 TensorCores x 2 MXUs/TC x 128x128 systolic x 2 (MAC) = 131,072 BF16 ops/clock",
    "int8": "2 TensorCores x 2 MXUs/TC x 128x128 systolic x 2 (MAC) x 2 = 262,144 INT8 ops/clock",
    "note": "First TPU with BF16 and HBM. 4 MXUs total (2 per TensorCore). 123 TFLOPS BF16 confirmed by Google Cloud docs."
  },
  "theoretical_peaks": {
    "fp64": 0.0,
    "fp32": 61500.0,
    "fp16": 123000.0,
    "fp8": 0.0,
    "fp4": 0.0,
    "bf16": 123000.0,
    "tf32": 0.0,
    "int64": 0.0,
    "int32": 61500.0,
    "int16": 123000.0,
    "int8": 246000.0,
    "int4": 0.0
  },
  "theoretical_peaks_notes": "123 TFLOPS BF16 confirmed by Google Cloud. 246 TOPS INT8 (2x BF16). Clock ~940 MHz estimated.",
  "peak_bandwidth_gbps": 900.0,
  "architecture": "TPU v3",
  "compute_units": 4,
  "memory_gb": 32,
  "tdp_watts": 220,
  "base_clock_mhz": 940.0,
  "boost_clock_mhz": 940.0,
  "platform": "custom",
  "notes": "Google TPU v3 (2018). First TPU with HBM and BF16 support. 2 TensorCores with 2 MXUs each (4 MXUs total, 128x128). 32GB HBM2 at 900 GB/s. Liquid cooling required. 220W average power."
}