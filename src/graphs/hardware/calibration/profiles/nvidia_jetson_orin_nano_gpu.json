{
  "metadata": {
    "hardware_name": "NVIDIA-Jetson-Orin-Nano-GPU",
    "calibration_date": "2025-11-16T08:54:27.815465",
    "calibration_tool_version": "1.0.0",
    "cpu_model": "aarch64",
    "cpu_count": 6,
    "total_memory_gb": 7.441219329833984,
    "python_version": "3.10.12",
    "pytorch_version": "2.8.0",
    "numpy_version": "1.26.4",
    "num_warmup_runs": 3,
    "num_measurement_runs": 10,
    "device_type": "cuda",
    "platform_architecture": "aarch64"
  },
  "theoretical_peak_gflops": 1280.0,
  "theoretical_bandwidth_gbps": 68.0,
  "best_measured_gflops": 114.52374220968021,
  "avg_measured_gflops": 105.27536379553791,
  "worst_measured_gflops": 86.54375210898793,
  "measured_bandwidth_gbps": 13.185827838299534,
  "bandwidth_efficiency": 0.19390923291616963,
  "best_efficiency": 0.08947167360131267,
  "avg_efficiency": 0.08224637796526399,
  "worst_efficiency": 0.06761230633514682,
  "operation_profiles": {
    "add_operation=memory_copy_size_mb=64": {
      "operation_type": "add",
      "measured_gflops": 0.0,
      "efficiency": 0.19363626861072297,
      "achieved_bandwidth_gbps": 13.167266265529163,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.0,
      "batch_size": 1,
      "input_shape": [
        16777216
      ],
      "output_shape": [
        16777216
      ],
      "mean_latency_ms": 10.193287299989606,
      "std_latency_ms": 0.01858975875190359,
      "min_latency_ms": 10.16749800010075,
      "max_latency_ms": 10.223946999758482,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 64,
        "operation": "memory_copy"
      },
      "precision_results": {}
    },
    "add_operation=memory_copy_size_mb=128": {
      "operation_type": "add",
      "measured_gflops": 0.0,
      "efficiency": 0.19390923291616963,
      "achieved_bandwidth_gbps": 13.185827838299534,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.0,
      "batch_size": 1,
      "input_shape": [
        33554432
      ],
      "output_shape": [
        33554432
      ],
      "mean_latency_ms": 20.357876599928204,
      "std_latency_ms": 0.013306353778813321,
      "min_latency_ms": 20.338899999842397,
      "max_latency_ms": 20.380756999657024,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 128,
        "operation": "memory_copy"
      },
      "precision_results": {}
    },
    "add_operation=memory_copy_size_mb=256": {
      "operation_type": "add",
      "measured_gflops": 0.0,
      "efficiency": 0.19364280835931555,
      "achieved_bandwidth_gbps": 13.167710968433457,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.0,
      "batch_size": 1,
      "input_shape": [
        67108864
      ],
      "output_shape": [
        67108864
      ],
      "mean_latency_ms": 40.77177219996884,
      "std_latency_ms": 0.019188077053422452,
      "min_latency_ms": 40.74858600006337,
      "max_latency_ms": 40.80864899970038,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 256,
        "operation": "memory_copy"
      },
      "precision_results": {}
    },
    "add_operation=memory_copy_size_mb=512": {
      "operation_type": "add",
      "measured_gflops": 0.0,
      "efficiency": 0.19373256602535283,
      "achieved_bandwidth_gbps": 13.173814489723991,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.0,
      "batch_size": 1,
      "input_shape": [
        134217728
      ],
      "output_shape": [
        134217728
      ],
      "mean_latency_ms": 81.50576469993212,
      "std_latency_ms": 0.030506936370045607,
      "min_latency_ms": 81.46599700012302,
      "max_latency_ms": 81.57150399983948,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 512,
        "operation": "memory_copy"
      },
      "precision_results": {}
    },
    "matmul_device=cuda_matrix_size=256_small": {
      "operation_type": "matmul",
      "measured_gflops": 86.54375210898793,
      "efficiency": 0.06761230633514682,
      "achieved_bandwidth_gbps": 0.0,
      "memory_bound": false,
      "compute_bound": true,
      "arithmetic_intensity": 42.666666666666664,
      "batch_size": 1,
      "input_shape": [
        256,
        256
      ],
      "output_shape": [
        256,
        256
      ],
      "mean_latency_ms": 0.38771639988226525,
      "std_latency_ms": 0.0069125481560668315,
      "min_latency_ms": 0.38199199980226695,
      "max_latency_ms": 0.40378399990004255,
      "num_trials": 10,
      "extra_params": {
        "matrix_size": 256,
        "device": "cuda"
      },
      "precision_results": {
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 86.54375210898793,
          "efficiency": 0.06761230633514682,
          "mean_latency_ms": 0.38771639988226525,
          "std_latency_ms": 0.0069125481560668315,
          "min_latency_ms": 0.38199199980226695,
          "max_latency_ms": 0.40378399990004255,
          "speedup_vs_fp32": 1.0,
          "test_size": 256,
          "num_trials": 10,
          "arithmetic_intensity": 42.666666666666664,
          "achieved_bandwidth_gbps": null
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 0.3327548114587843,
          "efficiency": 0.00012998234822608762,
          "mean_latency_ms": 100.83830750004381,
          "std_latency_ms": 0.3705921176897832,
          "min_latency_ms": 100.27324700013196,
          "max_latency_ms": 101.5580719999889,
          "speedup_vs_fp32": 0.0038449316484422034,
          "test_size": 256,
          "num_trials": 10,
          "arithmetic_intensity": 85.33333333333333,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "int8 not supported on cuda",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 256,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "matmul_device=cuda_matrix_size=1024_medium": {
      "operation_type": "matmul",
      "measured_gflops": 106.61754963596756,
      "efficiency": 0.08329496065309966,
      "achieved_bandwidth_gbps": 0.0,
      "memory_bound": false,
      "compute_bound": true,
      "arithmetic_intensity": 170.66666666666666,
      "batch_size": 1,
      "input_shape": [
        1024,
        1024
      ],
      "output_shape": [
        1024,
        1024
      ],
      "mean_latency_ms": 20.141933999912,
      "std_latency_ms": 1.079495049998928,
      "min_latency_ms": 19.584483000016917,
      "max_latency_ms": 23.332909000146174,
      "num_trials": 10,
      "extra_params": {
        "matrix_size": 1024,
        "device": "cuda"
      },
      "precision_results": {
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 106.61754963596756,
          "efficiency": 0.08329496065309966,
          "mean_latency_ms": 20.141933999912,
          "std_latency_ms": 1.079495049998928,
          "min_latency_ms": 19.584483000016917,
          "max_latency_ms": 23.332909000146174,
          "speedup_vs_fp32": 1.0,
          "test_size": 1024,
          "num_trials": 10,
          "arithmetic_intensity": 170.66666666666666,
          "achieved_bandwidth_gbps": null
        },
        "fp16": {
          "precision": "fp16",
          "supported": false,
          "failure_reason": "Skipped: throughput <50.0 GOPS on smaller matrix",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 1024,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "int8 not supported on cuda",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 1024,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "matmul_device=cuda_matrix_size=2048_medium": {
      "operation_type": "matmul",
      "measured_gflops": 113.41641122751594,
      "efficiency": 0.08860657127149682,
      "achieved_bandwidth_gbps": 0.0,
      "memory_bound": false,
      "compute_bound": true,
      "arithmetic_intensity": 341.3333333333333,
      "batch_size": 1,
      "input_shape": [
        2048,
        2048
      ],
      "output_shape": [
        2048,
        2048
      ],
      "mean_latency_ms": 151.47604299995692,
      "std_latency_ms": 2.7966571959852744,
      "min_latency_ms": 148.85609099974317,
      "max_latency_ms": 156.57003499973143,
      "num_trials": 10,
      "extra_params": {
        "matrix_size": 2048,
        "device": "cuda"
      },
      "precision_results": {
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 113.41641122751594,
          "efficiency": 0.08860657127149682,
          "mean_latency_ms": 151.47604299995692,
          "std_latency_ms": 2.7966571959852744,
          "min_latency_ms": 148.85609099974317,
          "max_latency_ms": 156.57003499973143,
          "speedup_vs_fp32": 1.0,
          "test_size": 2048,
          "num_trials": 10,
          "arithmetic_intensity": 341.3333333333333,
          "achieved_bandwidth_gbps": null
        },
        "fp16": {
          "precision": "fp16",
          "supported": false,
          "failure_reason": "Skipped: throughput <50.0 GOPS on smaller matrix",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 2048,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "int8 not supported on cuda",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 2048,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "matmul_device=cuda_matrix_size=4096_large": {
      "operation_type": "matmul",
      "measured_gflops": 114.52374220968021,
      "efficiency": 0.08947167360131267,
      "achieved_bandwidth_gbps": 0.0,
      "memory_bound": false,
      "compute_bound": true,
      "arithmetic_intensity": 682.6666666666666,
      "batch_size": 1,
      "input_shape": [
        4096,
        4096
      ],
      "output_shape": [
        4096,
        4096
      ],
      "mean_latency_ms": 1200.091359400085,
      "std_latency_ms": 2.0488303759371247,
      "min_latency_ms": 1195.5098769999495,
      "max_latency_ms": 1202.3621650000678,
      "num_trials": 10,
      "extra_params": {
        "matrix_size": 4096,
        "device": "cuda"
      },
      "precision_results": {
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 114.52374220968021,
          "efficiency": 0.08947167360131267,
          "mean_latency_ms": 1200.091359400085,
          "std_latency_ms": 2.0488303759371247,
          "min_latency_ms": 1195.5098769999495,
          "max_latency_ms": 1202.3621650000678,
          "speedup_vs_fp32": 1.0,
          "test_size": 4096,
          "num_trials": 10,
          "arithmetic_intensity": 682.6666666666666,
          "achieved_bandwidth_gbps": null
        },
        "fp16": {
          "precision": "fp16",
          "supported": false,
          "failure_reason": "Skipped: throughput <50.0 GOPS on smaller matrix",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 4096,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "int8 not supported on cuda",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 4096,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    }
  },
  "fusion_profiles": {},
  "precision_matrix": {
    "hardware_name": "NVIDIA-Jetson-Orin-Nano-GPU",
    "supported_precisions": [
      "fp64",
      "fp32",
      "fp16",
      "bf16"
    ],
    "unsupported_precisions": [
      "int32",
      "int16",
      "int8",
      "fp8_e4m3",
      "fp8_e5m2"
    ],
    "peak_gflops_by_precision": {
      "fp32": 114.52374220968021,
      "fp16": 0.3327548114587843
    },
    "speedup_vs_fp32": {
      "fp32": 1.0,
      "fp16": 0.0038449316484422034
    },
    "theoretical_peaks": {
      "fp32": 1280.0,
      "fp16": 2560.0,
      "int8": 5120.0
    }
  }
}