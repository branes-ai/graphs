{
  "metadata": {
    "hardware_name": "NVIDIA-Jetson-Orin-Nano",
    "calibration_date": "2025-11-15T09:19:03.428098",
    "calibration_tool_version": "1.0.0",
    "cpu_model": "x86_64",
    "cpu_count": 12,
    "total_memory_gb": 31.089431762695312,
    "python_version": "3.11.14",
    "pytorch_version": "2.7.1+cu126",
    "numpy_version": "2.2.6",
    "num_warmup_runs": 3,
    "num_measurement_runs": 10
  },
  "theoretical_peak_gflops": 2600.0,
  "theoretical_bandwidth_gbps": 102.4,
  "best_measured_gflops": 824.9755397119193,
  "avg_measured_gflops": 730.898270905746,
  "worst_measured_gflops": 570.6232788357306,
  "measured_bandwidth_gbps": 53.244299361303625,
  "bandwidth_efficiency": 0.5199638609502307,
  "best_efficiency": 0.31729828450458436,
  "avg_efficiency": 0.2811147195791331,
  "worst_efficiency": 0.2194704918598964,
  "operation_profiles": {
    "add_operation=memory_copy_size_mb=64": {
      "operation_type": "add",
      "measured_gflops": 0.0,
      "efficiency": 0.47154027844393015,
      "achieved_bandwidth_gbps": 48.28572451265845,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.0,
      "batch_size": 1,
      "input_shape": [
        16777216
      ],
      "output_shape": [
        16777216
      ],
      "mean_latency_ms": 2.77965650002443,
      "std_latency_ms": 0.01324971848847081,
      "min_latency_ms": 2.7676680001604836,
      "max_latency_ms": 2.8141060001871665,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 64,
        "operation": "memory_copy"
      }
    },
    "add_operation=memory_copy_size_mb=128": {
      "operation_type": "add",
      "measured_gflops": 0.0,
      "efficiency": 0.4467998123560982,
      "achieved_bandwidth_gbps": 45.75230078526446,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.0,
      "batch_size": 1,
      "input_shape": [
        33554432
      ],
      "output_shape": [
        33554432
      ],
      "mean_latency_ms": 5.867146600121487,
      "std_latency_ms": 0.021615286669541767,
      "min_latency_ms": 5.845233999934862,
      "max_latency_ms": 5.912554999667918,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 128,
        "operation": "memory_copy"
      }
    },
    "add_operation=memory_copy_size_mb=256": {
      "operation_type": "add",
      "measured_gflops": 0.0,
      "efficiency": 0.5199638609502307,
      "achieved_bandwidth_gbps": 53.244299361303625,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.0,
      "batch_size": 1,
      "input_shape": [
        67108864
      ],
      "output_shape": [
        67108864
      ],
      "mean_latency_ms": 10.08316229981574,
      "std_latency_ms": 0.030372125017070564,
      "min_latency_ms": 10.048152999843296,
      "max_latency_ms": 10.139553000044543,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 256,
        "operation": "memory_copy"
      }
    },
    "add_operation=memory_copy_size_mb=512": {
      "operation_type": "add",
      "measured_gflops": 0.0,
      "efficiency": 0.5145718188990221,
      "achieved_bandwidth_gbps": 52.69215425525987,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.0,
      "batch_size": 1,
      "input_shape": [
        134217728
      ],
      "output_shape": [
        134217728
      ],
      "mean_latency_ms": 20.377641399863933,
      "std_latency_ms": 0.11386019622371191,
      "min_latency_ms": 20.256857000276796,
      "max_latency_ms": 20.61548900019261,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 512,
        "operation": "memory_copy"
      }
    },
    "matmul_cpp_gflops=None_implementation=numpy_blas_matrix_size=512_small": {
      "operation_type": "matmul",
      "measured_gflops": 570.6232788357306,
      "efficiency": 0.2194704918598964,
      "achieved_bandwidth_gbps": 6.686991548856218,
      "memory_bound": false,
      "compute_bound": true,
      "arithmetic_intensity": 85.33333333333333,
      "batch_size": 1,
      "input_shape": [
        512,
        512
      ],
      "output_shape": [
        512,
        512
      ],
      "mean_latency_ms": 0.47042500009411015,
      "std_latency_ms": 0.0025554355608384724,
      "min_latency_ms": 0.46609800028818427,
      "max_latency_ms": 0.4736030005005887,
      "num_trials": 10,
      "extra_params": {
        "matrix_size": 512,
        "implementation": "numpy_blas",
        "cpp_gflops": null
      }
    },
    "matmul_cpp_gflops=None_implementation=numpy_blas_matrix_size=1024_medium": {
      "operation_type": "matmul",
      "measured_gflops": 742.9950766566175,
      "efficiency": 0.2857673371756221,
      "achieved_bandwidth_gbps": 4.353486777284869,
      "memory_bound": false,
      "compute_bound": true,
      "arithmetic_intensity": 170.66666666666666,
      "batch_size": 1,
      "input_shape": [
        1024,
        1024
      ],
      "output_shape": [
        1024,
        1024
      ],
      "mean_latency_ms": 2.8903066998282156,
      "std_latency_ms": 0.005533731863354399,
      "min_latency_ms": 2.877242000067781,
      "max_latency_ms": 2.897399999710615,
      "num_trials": 10,
      "extra_params": {
        "matrix_size": 1024,
        "implementation": "numpy_blas",
        "cpp_gflops": null
      }
    },
    "matmul_cpp_gflops=None_implementation=numpy_blas_matrix_size=2048_medium": {
      "operation_type": "matmul",
      "measured_gflops": 784.9991884187165,
      "efficiency": 0.30192276477642943,
      "achieved_bandwidth_gbps": 2.2998023098204583,
      "memory_bound": false,
      "compute_bound": true,
      "arithmetic_intensity": 341.3333333333333,
      "batch_size": 1,
      "input_shape": [
        2048,
        2048
      ],
      "output_shape": [
        2048,
        2048
      ],
      "mean_latency_ms": 21.885206300157733,
      "std_latency_ms": 0.6488709165836691,
      "min_latency_ms": 21.584346999588888,
      "max_latency_ms": 23.758268000165117,
      "num_trials": 10,
      "extra_params": {
        "matrix_size": 2048,
        "implementation": "numpy_blas",
        "cpp_gflops": null
      }
    },
    "matmul_cpp_gflops=None_implementation=numpy_blas_matrix_size=4096_large": {
      "operation_type": "matmul",
      "measured_gflops": 824.9755397119193,
      "efficiency": 0.31729828450458436,
      "achieved_bandwidth_gbps": 1.2084602632498818,
      "memory_bound": false,
      "compute_bound": true,
      "arithmetic_intensity": 682.6666666666666,
      "batch_size": 1,
      "input_shape": [
        4096,
        4096
      ],
      "output_shape": [
        4096,
        4096
      ],
      "mean_latency_ms": 166.5976103000503,
      "std_latency_ms": 0.728829846635822,
      "min_latency_ms": 165.883790999942,
      "max_latency_ms": 168.58308500013663,
      "num_trials": 10,
      "extra_params": {
        "matrix_size": 4096,
        "implementation": "numpy_blas",
        "cpp_gflops": null
      }
    }
  },
  "fusion_profiles": {}
}