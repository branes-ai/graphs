{
  "metadata": {
    "hardware_name": "NVIDIA-Jetson-Orin-Nano-GPU",
    "calibration_date": "2025-11-16T11:04:44.917259",
    "calibration_tool_version": "1.0.0",
    "cpu_model": "aarch64",
    "cpu_count": 4,
    "total_memory_gb": 7.441211700439453,
    "python_version": "3.10.12",
    "pytorch_version": "2.8.0",
    "numpy_version": "1.26.4",
    "num_warmup_runs": 3,
    "num_measurement_runs": 10,
    "device_type": "cuda",
    "platform_architecture": "aarch64",
    "framework": "pytorch"
  },
  "theoretical_peak_gflops": 1280.0,
  "theoretical_bandwidth_gbps": 68.0,
  "best_measured_gflops": 269.95398905237363,
  "avg_measured_gflops": 215.45718918994254,
  "worst_measured_gflops": 98.40955962827069,
  "measured_bandwidth_gbps": 26.543814177498756,
  "bandwidth_efficiency": 0.39035020849262875,
  "best_efficiency": 0.2109015539471669,
  "avg_efficiency": 0.1683259290546426,
  "worst_efficiency": 0.07688246845958648,
  "operation_profiles": {
    "add_device=cuda_framework=pytorch_operation=memory_copy_size_mb=64": {
      "operation_type": "add",
      "measured_gflops": 0.0,
      "efficiency": 0.34860937889421445,
      "achieved_bandwidth_gbps": 23.705437764806582,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.0,
      "batch_size": 1,
      "input_shape": [
        16777216
      ],
      "output_shape": [
        16777216
      ],
      "mean_latency_ms": 5.661896200004435,
      "std_latency_ms": 0.5686212737289468,
      "min_latency_ms": 5.214422000022978,
      "max_latency_ms": 6.345662000001084,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 64,
        "operation": "memory_copy",
        "framework": "pytorch",
        "device": "cuda"
      },
      "precision_results": {}
    },
    "add_device=cuda_framework=pytorch_operation=memory_copy_size_mb=128": {
      "operation_type": "add",
      "measured_gflops": 0.0,
      "efficiency": 0.39035020849262875,
      "achieved_bandwidth_gbps": 26.543814177498756,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.0,
      "batch_size": 1,
      "input_shape": [
        33554432
      ],
      "output_shape": [
        33554432
      ],
      "mean_latency_ms": 10.112919499999862,
      "std_latency_ms": 0.6651365170677469,
      "min_latency_ms": 9.751032999986364,
      "max_latency_ms": 11.946977999997443,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 128,
        "operation": "memory_copy",
        "framework": "pytorch",
        "device": "cuda"
      },
      "precision_results": {}
    },
    "add_device=cuda_framework=pytorch_operation=memory_copy_size_mb=256": {
      "operation_type": "add",
      "measured_gflops": 0.0,
      "efficiency": 0.36996328228129094,
      "achieved_bandwidth_gbps": 25.157503195127784,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.0,
      "batch_size": 1,
      "input_shape": [
        67108864
      ],
      "output_shape": [
        67108864
      ],
      "mean_latency_ms": 21.340389299999174,
      "std_latency_ms": 0.12105547582896524,
      "min_latency_ms": 21.265478000003668,
      "max_latency_ms": 21.57316299999934,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 256,
        "operation": "memory_copy",
        "framework": "pytorch",
        "device": "cuda"
      },
      "precision_results": {}
    },
    "add_device=cuda_framework=pytorch_operation=memory_copy_size_mb=512": {
      "operation_type": "add",
      "measured_gflops": 0.0,
      "efficiency": 0.36449028044842097,
      "achieved_bandwidth_gbps": 24.785339070492626,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.0,
      "batch_size": 1,
      "input_shape": [
        134217728
      ],
      "output_shape": [
        134217728
      ],
      "mean_latency_ms": 43.321651600010114,
      "std_latency_ms": 1.5939291909484175,
      "min_latency_ms": 42.530438000000004,
      "max_latency_ms": 47.5804400000186,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 512,
        "operation": "memory_copy",
        "framework": "pytorch",
        "device": "cuda"
      },
      "precision_results": {}
    },
    "matmul_device=cuda_matrix_size=256_small": {
      "operation_type": "matmul",
      "measured_gflops": 98.40955962827069,
      "efficiency": 0.07688246845958648,
      "achieved_bandwidth_gbps": 0.0,
      "memory_bound": false,
      "compute_bound": true,
      "arithmetic_intensity": 42.666666666666664,
      "batch_size": 1,
      "input_shape": [
        256,
        256
      ],
      "output_shape": [
        256,
        256
      ],
      "mean_latency_ms": 0.340967200003206,
      "std_latency_ms": 0.00559221495941374,
      "min_latency_ms": 0.3364540000063698,
      "max_latency_ms": 0.3550810000092497,
      "num_trials": 10,
      "extra_params": {
        "matrix_size": 256,
        "device": "cuda"
      },
      "precision_results": {
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 98.40955962827069,
          "efficiency": 0.07688246845958648,
          "mean_latency_ms": 0.340967200003206,
          "std_latency_ms": 0.00559221495941374,
          "min_latency_ms": 0.3364540000063698,
          "max_latency_ms": 0.3550810000092497,
          "speedup_vs_fp32": 1.0,
          "test_size": 256,
          "num_trials": 10,
          "arithmetic_intensity": 42.666666666666664,
          "achieved_bandwidth_gbps": null
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 205.0929183549595,
          "efficiency": 0.026985910309863092,
          "mean_latency_ms": 0.16360599999813985,
          "std_latency_ms": 0.0051407445803118654,
          "min_latency_ms": 0.15665800000874697,
          "max_latency_ms": 0.17134800000917494,
          "speedup_vs_fp32": 2.084075156211158,
          "test_size": 256,
          "num_trials": 10,
          "arithmetic_intensity": 85.33333333333333,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "Runtime error: \"normal_kernel_cuda\" not implemented for 'Char'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 256,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "matmul_device=cuda_matrix_size=1024_medium": {
      "operation_type": "matmul",
      "measured_gflops": 226.3390542268673,
      "efficiency": 0.17682738611474008,
      "achieved_bandwidth_gbps": 0.0,
      "memory_bound": false,
      "compute_bound": true,
      "arithmetic_intensity": 170.66666666666666,
      "batch_size": 1,
      "input_shape": [
        1024,
        1024
      ],
      "output_shape": [
        1024,
        1024
      ],
      "mean_latency_ms": 9.487905900002147,
      "std_latency_ms": 1.502066499447279,
      "min_latency_ms": 8.19092200001137,
      "max_latency_ms": 12.224247999995441,
      "num_trials": 10,
      "extra_params": {
        "matrix_size": 1024,
        "device": "cuda"
      },
      "precision_results": {
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 226.3390542268673,
          "efficiency": 0.17682738611474008,
          "mean_latency_ms": 9.487905900002147,
          "std_latency_ms": 1.502066499447279,
          "min_latency_ms": 8.19092200001137,
          "max_latency_ms": 12.224247999995441,
          "speedup_vs_fp32": 1.0,
          "test_size": 1024,
          "num_trials": 10,
          "arithmetic_intensity": 170.66666666666666,
          "achieved_bandwidth_gbps": null
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 2118.1126274367134,
          "efficiency": 0.27869902992588336,
          "mean_latency_ms": 1.0138666000017338,
          "std_latency_ms": 0.008939863231568182,
          "min_latency_ms": 1.0033789999965848,
          "max_latency_ms": 1.030614000001151,
          "speedup_vs_fp32": 9.358140311541895,
          "test_size": 1024,
          "num_trials": 10,
          "arithmetic_intensity": 341.3333333333333,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "Runtime error: \"normal_kernel_cuda\" not implemented for 'Char'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 1024,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "matmul_device=cuda_matrix_size=2048_medium": {
      "operation_type": "matmul",
      "measured_gflops": 267.12615385225854,
      "efficiency": 0.20869230769707697,
      "achieved_bandwidth_gbps": 0.0,
      "memory_bound": false,
      "compute_bound": true,
      "arithmetic_intensity": 341.3333333333333,
      "batch_size": 1,
      "input_shape": [
        2048,
        2048
      ],
      "output_shape": [
        2048,
        2048
      ],
      "mean_latency_ms": 64.31369200000461,
      "std_latency_ms": 1.86616599795761,
      "min_latency_ms": 63.559342000019114,
      "max_latency_ms": 69.61298900000656,
      "num_trials": 10,
      "extra_params": {
        "matrix_size": 2048,
        "device": "cuda"
      },
      "precision_results": {
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 267.12615385225854,
          "efficiency": 0.20869230769707697,
          "mean_latency_ms": 64.31369200000461,
          "std_latency_ms": 1.86616599795761,
          "min_latency_ms": 63.559342000019114,
          "max_latency_ms": 69.61298900000656,
          "speedup_vs_fp32": 1.0,
          "test_size": 2048,
          "num_trials": 10,
          "arithmetic_intensity": 341.3333333333333,
          "achieved_bandwidth_gbps": null
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 2912.3861597135133,
          "efficiency": 0.3832087052254623,
          "mean_latency_ms": 5.898898099999883,
          "std_latency_ms": 0.01919383304793391,
          "min_latency_ms": 5.8786710000049425,
          "max_latency_ms": 5.9441509999942355,
          "speedup_vs_fp32": 10.90266197342956,
          "test_size": 2048,
          "num_trials": 10,
          "arithmetic_intensity": 682.6666666666666,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "Runtime error: \"normal_kernel_cuda\" not implemented for 'Char'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 2048,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "matmul_device=cuda_matrix_size=4096_large": {
      "operation_type": "matmul",
      "measured_gflops": 269.95398905237363,
      "efficiency": 0.2109015539471669,
      "achieved_bandwidth_gbps": 0.0,
      "memory_bound": false,
      "compute_bound": true,
      "arithmetic_intensity": 682.6666666666666,
      "batch_size": 1,
      "input_shape": [
        4096,
        4096
      ],
      "output_shape": [
        4096,
        4096
      ],
      "mean_latency_ms": 509.1199206000084,
      "std_latency_ms": 2.2155145394786366,
      "min_latency_ms": 504.29901800001176,
      "max_latency_ms": 510.75167600001237,
      "num_trials": 10,
      "extra_params": {
        "matrix_size": 4096,
        "device": "cuda"
      },
      "precision_results": {
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 269.95398905237363,
          "efficiency": 0.2109015539471669,
          "mean_latency_ms": 509.1199206000084,
          "std_latency_ms": 2.2155145394786366,
          "min_latency_ms": 504.29901800001176,
          "max_latency_ms": 510.75167600001237,
          "speedup_vs_fp32": 1.0,
          "test_size": 4096,
          "num_trials": 10,
          "arithmetic_intensity": 682.6666666666666,
          "achieved_bandwidth_gbps": null
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 3152.8167478381984,
          "efficiency": 0.4148443089260787,
          "mean_latency_ms": 43.59243320000701,
          "std_latency_ms": 1.554097680430497,
          "min_latency_ms": 42.893545000026734,
          "max_latency_ms": 47.70221900000138,
          "speedup_vs_fp32": 11.679089310388083,
          "test_size": 4096,
          "num_trials": 10,
          "arithmetic_intensity": 1365.3333333333333,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "Runtime error: \"normal_kernel_cuda\" not implemented for 'Char'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 4096,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    }
  },
  "fusion_profiles": {},
  "precision_matrix": {
    "hardware_name": "NVIDIA-Jetson-Orin-Nano-GPU",
    "supported_precisions": [
      "fp64",
      "fp32",
      "fp16",
      "bf16"
    ],
    "unsupported_precisions": [
      "int32",
      "int16",
      "int8",
      "fp8_e4m3",
      "fp8_e5m2"
    ],
    "peak_gflops_by_precision": {
      "fp32": 269.95398905237363,
      "fp16": 3152.8167478381984
    },
    "speedup_vs_fp32": {
      "fp32": 1.0,
      "fp16": 11.679089310388083
    },
    "theoretical_peaks": {
      "fp32": 1280.0,
      "fp16": 7600.0,
      "int8": 15200.0
    }
  }
}