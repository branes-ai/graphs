{
  "metadata": {
    "hardware_name": "NVIDIA-Jetson-Orin-Nano-GPU",
    "calibration_date": "2025-11-16T10:55:50.389665",
    "calibration_tool_version": "1.0.0",
    "cpu_model": "aarch64",
    "cpu_count": 6,
    "total_memory_gb": 7.441219329833984,
    "python_version": "3.10.12",
    "pytorch_version": "2.8.0",
    "numpy_version": "1.26.4",
    "num_warmup_runs": 3,
    "num_measurement_runs": 10,
    "device_type": "cuda",
    "platform_architecture": "aarch64",
    "framework": "pytorch"
  },
  "theoretical_peak_gflops": 1280.0,
  "theoretical_bandwidth_gbps": 68.0,
  "best_measured_gflops": 800.7202199510207,
  "avg_measured_gflops": 594.650762936719,
  "worst_measured_gflops": 200.99611418802635,
  "measured_bandwidth_gbps": 50.05633363053244,
  "bandwidth_efficiency": 0.736122553390183,
  "best_efficiency": 0.6255626718367349,
  "avg_efficiency": 0.46457090854431177,
  "worst_efficiency": 0.15702821420939558,
  "operation_profiles": {
    "add_device=cuda_framework=pytorch_operation=memory_copy_size_mb=64": {
      "operation_type": "add",
      "measured_gflops": 0.0,
      "efficiency": 0.5167861609043181,
      "achieved_bandwidth_gbps": 35.141458941493624,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.0,
      "batch_size": 1,
      "input_shape": [
        16777216
      ],
      "output_shape": [
        16777216
      ],
      "mean_latency_ms": 3.819355599989649,
      "std_latency_ms": 1.3470903798404426,
      "min_latency_ms": 2.5975850003305823,
      "max_latency_ms": 7.128039998860913,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 64,
        "operation": "memory_copy",
        "framework": "pytorch",
        "device": "cuda"
      },
      "precision_results": {}
    },
    "add_device=cuda_framework=pytorch_operation=memory_copy_size_mb=128": {
      "operation_type": "add",
      "measured_gflops": 0.0,
      "efficiency": 0.531607326676482,
      "achieved_bandwidth_gbps": 36.14929821400078,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.0,
      "batch_size": 1,
      "input_shape": [
        33554432
      ],
      "output_shape": [
        33554432
      ],
      "mean_latency_ms": 7.425744599822792,
      "std_latency_ms": 1.3154057370084289,
      "min_latency_ms": 4.910044999633101,
      "max_latency_ms": 8.133498999086441,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 128,
        "operation": "memory_copy",
        "framework": "pytorch",
        "device": "cuda"
      },
      "precision_results": {}
    },
    "add_device=cuda_framework=pytorch_operation=memory_copy_size_mb=256": {
      "operation_type": "add",
      "measured_gflops": 0.0,
      "efficiency": 0.736122553390183,
      "achieved_bandwidth_gbps": 50.05633363053244,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.0,
      "batch_size": 1,
      "input_shape": [
        67108864
      ],
      "output_shape": [
        67108864
      ],
      "mean_latency_ms": 10.725334299604583,
      "std_latency_ms": 0.10994257261840595,
      "min_latency_ms": 10.654443000021274,
      "max_latency_ms": 11.029266999685206,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 256,
        "operation": "memory_copy",
        "framework": "pytorch",
        "device": "cuda"
      },
      "precision_results": {}
    },
    "add_device=cuda_framework=pytorch_operation=memory_copy_size_mb=512": {
      "operation_type": "add",
      "measured_gflops": 0.0,
      "efficiency": 0.7238272742828117,
      "achieved_bandwidth_gbps": 49.220254651231194,
      "memory_bound": true,
      "compute_bound": false,
      "arithmetic_intensity": 0.0,
      "batch_size": 1,
      "input_shape": [
        134217728
      ],
      "output_shape": [
        134217728
      ],
      "mean_latency_ms": 21.81503999945562,
      "std_latency_ms": 1.577097688737598,
      "min_latency_ms": 21.2586449997616,
      "max_latency_ms": 26.296948999515735,
      "num_trials": 10,
      "extra_params": {
        "size_mb": 512,
        "operation": "memory_copy",
        "framework": "pytorch",
        "device": "cuda"
      },
      "precision_results": {}
    },
    "matmul_device=cuda_matrix_size=256_small": {
      "operation_type": "matmul",
      "measured_gflops": 200.99611418802635,
      "efficiency": 0.15702821420939558,
      "achieved_bandwidth_gbps": 0.0,
      "memory_bound": false,
      "compute_bound": true,
      "arithmetic_intensity": 42.666666666666664,
      "batch_size": 1,
      "input_shape": [
        256,
        256
      ],
      "output_shape": [
        256,
        256
      ],
      "mean_latency_ms": 0.16694070000085048,
      "std_latency_ms": 0.003200260029115718,
      "min_latency_ms": 0.1616669997019926,
      "max_latency_ms": 0.17248299991479144,
      "num_trials": 10,
      "extra_params": {
        "matrix_size": 256,
        "device": "cuda"
      },
      "precision_results": {
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 200.99611418802635,
          "efficiency": 0.15702821420939558,
          "mean_latency_ms": 0.16694070000085048,
          "std_latency_ms": 0.003200260029115718,
          "min_latency_ms": 0.1616669997019926,
          "max_latency_ms": 0.17248299991479144,
          "speedup_vs_fp32": 1.0,
          "test_size": 256,
          "num_trials": 10,
          "arithmetic_intensity": 42.666666666666664,
          "achieved_bandwidth_gbps": null
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 305.99583196127844,
          "efficiency": 0.04026260946858927,
          "mean_latency_ms": 0.10965650017169537,
          "std_latency_ms": 0.004242182110622828,
          "min_latency_ms": 0.1022100004774984,
          "max_latency_ms": 0.11622700003499631,
          "speedup_vs_fp32": 1.5223967547702326,
          "test_size": 256,
          "num_trials": 10,
          "arithmetic_intensity": 85.33333333333333,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "Runtime error: \"normal_kernel_cuda\" not implemented for 'Char'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 256,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "matmul_device=cuda_matrix_size=1024_medium": {
      "operation_type": "matmul",
      "measured_gflops": 578.1717275969751,
      "efficiency": 0.45169666218513677,
      "achieved_bandwidth_gbps": 0.0,
      "memory_bound": false,
      "compute_bound": true,
      "arithmetic_intensity": 170.66666666666666,
      "batch_size": 1,
      "input_shape": [
        1024,
        1024
      ],
      "output_shape": [
        1024,
        1024
      ],
      "mean_latency_ms": 3.714266100359964,
      "std_latency_ms": 0.616346912899518,
      "min_latency_ms": 2.848278001692961,
      "max_latency_ms": 4.191088000879972,
      "num_trials": 10,
      "extra_params": {
        "matrix_size": 1024,
        "device": "cuda"
      },
      "precision_results": {
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 578.1717275969751,
          "efficiency": 0.45169666218513677,
          "mean_latency_ms": 3.714266100359964,
          "std_latency_ms": 0.616346912899518,
          "min_latency_ms": 2.848278001692961,
          "max_latency_ms": 4.191088000879972,
          "speedup_vs_fp32": 1.0,
          "test_size": 1024,
          "num_trials": 10,
          "arithmetic_intensity": 170.66666666666666,
          "achieved_bandwidth_gbps": null
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 3883.406935932337,
          "efficiency": 0.5109745968332022,
          "mean_latency_ms": 0.5529895999643486,
          "std_latency_ms": 0.015157703815690671,
          "min_latency_ms": 0.5395629996201023,
          "max_latency_ms": 0.5891629989491776,
          "speedup_vs_fp32": 6.716701544838138,
          "test_size": 1024,
          "num_trials": 10,
          "arithmetic_intensity": 341.3333333333333,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "Runtime error: \"normal_kernel_cuda\" not implemented for 'Char'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 1024,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "matmul_device=cuda_matrix_size=2048_medium": {
      "operation_type": "matmul",
      "measured_gflops": 798.7149900108542,
      "efficiency": 0.6239960859459799,
      "achieved_bandwidth_gbps": 0.0,
      "memory_bound": false,
      "compute_bound": true,
      "arithmetic_intensity": 341.3333333333333,
      "batch_size": 1,
      "input_shape": [
        2048,
        2048
      ],
      "output_shape": [
        2048,
        2048
      ],
      "mean_latency_ms": 21.509386200159497,
      "std_latency_ms": 0.10864256576805138,
      "min_latency_ms": 21.44687300096848,
      "max_latency_ms": 21.74611000009463,
      "num_trials": 10,
      "extra_params": {
        "matrix_size": 2048,
        "device": "cuda"
      },
      "precision_results": {
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 798.7149900108542,
          "efficiency": 0.6239960859459799,
          "mean_latency_ms": 21.509386200159497,
          "std_latency_ms": 0.10864256576805138,
          "min_latency_ms": 21.44687300096848,
          "max_latency_ms": 21.74611000009463,
          "speedup_vs_fp32": 1.0,
          "test_size": 2048,
          "num_trials": 10,
          "arithmetic_intensity": 341.3333333333333,
          "achieved_bandwidth_gbps": null
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 5591.849789339638,
          "efficiency": 0.7357697091236366,
          "mean_latency_ms": 3.072305199748371,
          "std_latency_ms": 0.01228717618245006,
          "min_latency_ms": 3.058554000745062,
          "max_latency_ms": 3.101882999544614,
          "speedup_vs_fp32": 7.001057773140887,
          "test_size": 2048,
          "num_trials": 10,
          "arithmetic_intensity": 682.6666666666666,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "Runtime error: \"normal_kernel_cuda\" not implemented for 'Char'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 2048,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    },
    "matmul_device=cuda_matrix_size=4096_large": {
      "operation_type": "matmul",
      "measured_gflops": 800.7202199510207,
      "efficiency": 0.6255626718367349,
      "achieved_bandwidth_gbps": 0.0,
      "memory_bound": false,
      "compute_bound": true,
      "arithmetic_intensity": 682.6666666666666,
      "batch_size": 1,
      "input_shape": [
        4096,
        4096
      ],
      "output_shape": [
        4096,
        4096
      ],
      "mean_latency_ms": 171.64416489995347,
      "std_latency_ms": 2.7603519472545943,
      "min_latency_ms": 168.87474299983296,
      "max_latency_ms": 175.0009389998013,
      "num_trials": 10,
      "extra_params": {
        "matrix_size": 4096,
        "device": "cuda"
      },
      "precision_results": {
        "fp32": {
          "precision": "fp32",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 800.7202199510207,
          "efficiency": 0.6255626718367349,
          "mean_latency_ms": 171.64416489995347,
          "std_latency_ms": 2.7603519472545943,
          "min_latency_ms": 168.87474299983296,
          "max_latency_ms": 175.0009389998013,
          "speedup_vs_fp32": 1.0,
          "test_size": 4096,
          "num_trials": 10,
          "arithmetic_intensity": 682.6666666666666,
          "achieved_bandwidth_gbps": null
        },
        "fp16": {
          "precision": "fp16",
          "supported": true,
          "failure_reason": null,
          "measured_gops": 5908.04753256123,
          "efficiency": 0.7773746753370039,
          "mean_latency_ms": 23.263007400419156,
          "std_latency_ms": 1.5962156129296916,
          "min_latency_ms": 22.564079001313075,
          "max_latency_ms": 27.777010000136215,
          "speedup_vs_fp32": 7.378416811957888,
          "test_size": 4096,
          "num_trials": 10,
          "arithmetic_intensity": 1365.3333333333333,
          "achieved_bandwidth_gbps": null
        },
        "int8": {
          "precision": "int8",
          "supported": false,
          "failure_reason": "Runtime error: \"normal_kernel_cuda\" not implemented for 'Char'",
          "measured_gops": null,
          "efficiency": null,
          "mean_latency_ms": null,
          "std_latency_ms": null,
          "min_latency_ms": null,
          "max_latency_ms": null,
          "speedup_vs_fp32": null,
          "test_size": 4096,
          "num_trials": 0,
          "arithmetic_intensity": null,
          "achieved_bandwidth_gbps": null
        }
      }
    }
  },
  "fusion_profiles": {},
  "precision_matrix": {
    "hardware_name": "NVIDIA-Jetson-Orin-Nano-GPU",
    "supported_precisions": [
      "fp64",
      "fp32",
      "fp16",
      "bf16"
    ],
    "unsupported_precisions": [
      "int32",
      "int16",
      "int8",
      "fp8_e4m3",
      "fp8_e5m2"
    ],
    "peak_gflops_by_precision": {
      "fp32": 800.7202199510207,
      "fp16": 5908.04753256123
    },
    "speedup_vs_fp32": {
      "fp32": 1.0,
      "fp16": 7.378416811957888
    },
    "theoretical_peaks": {
      "fp32": 1280.0,
      "fp16": 7600.0,
      "int8": 15200.0
    }
  }
}