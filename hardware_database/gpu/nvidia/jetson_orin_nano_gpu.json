{
  "id": "jetson_orin_nano_gpu",
  "system": {
    "vendor": "NVIDIA",
    "model": "Jetson Orin Nano (GPU)",
    "architecture": "Ampere",
    "device_type": "gpu",
    "platform": "aarch64",
    "os_compatibility": [
      "linux"
    ],
    "isa_extensions": [
      "CUDA",
      "Tensor Cores",
      "NVDEC",
      "NVENC"
    ],
    "special_features": [
      "CUDA Compute Capability 8.7",
      "INT8 Tensor Core acceleration",
      "FP16 Tensor Core acceleration",
      "Unified memory with CPU",
      "Hardware video decode/encode"
    ],
    "tdp_watts": 7.0,
    "max_power_watts": 15.0,
    "release_date": "2022-09-20",
    "manufacturer_url": "https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/jetson-orin/",
    "notes": "Ampere GPU with 1024 CUDA cores (8 SMs) and 32 Tensor Cores (Gen 3). Shares unified LPDDR5 memory with CPU in Jetson Orin Nano SoC (memory channels are shared between CPU and GPU)."
  },
  "detection_patterns": [
    "NVIDIA.*NVIDIA\\-Jetson\\-Orin\\-Nano\\-GPU",
    "Jetson.*Orin.*Nano.*GPU",
    "Orin.*Nano.*Ampere",
    "Jetson.*Orin.*Nano.*iGPU"
  ],
  "core_info": {
    "cores": 512,
    "threads": 16384,
    "base_frequency_ghz": 0.306,
    "boost_frequency_ghz": 0.625,
    "core_clusters": [
      {
        "name": "Ampere SMs",
        "type": "compute",
        "count": 8,
        "architecture": "Ampere SM",
        "base_frequency_ghz": 0.306,
        "boost_frequency_ghz": 0.625,
        "cuda_cores_per_sm": 128,
        "tensor_cores_per_sm": 4,
        "fp32_units_per_sm": 64,
        "fp64_units_per_sm": 2,
        "int32_units_per_sm": 64,
        "load_store_units_per_sm": 32,
        "special_function_units_per_sm": 16,
        "warp_size": 32,
        "max_warps_per_sm": 48,
        "max_threads_per_sm": 1536,
        "registers_per_sm": 65536,
        "shared_memory_per_sm_kb": 100
      }
    ],
    "total_cuda_cores": 1024,
    "total_tensor_cores": 32,
    "total_sms": 8,
    "total_rt_cores": 0,
    "cuda_capability": "8.7"
  },
  "memory_subsystem": {
    "total_size_gb": 8,
    "peak_bandwidth_gbps": 68.0,
    "memory_channels": [
      {
        "name": "Unified LPDDR5 Channel 0",
        "type": "lpddr5",
        "size_gb": 4,
        "frequency_mhz": 3200,
        "data_rate_mts": 6400,
        "bus_width_bits": 64,
        "bandwidth_gbps": 34.0,
        "ecc_enabled": false,
        "numa_node": 0,
        "physical_position": 0
      },
      {
        "name": "Unified LPDDR5 Channel 1",
        "type": "lpddr5",
        "size_gb": 4,
        "frequency_mhz": 3200,
        "data_rate_mts": 6400,
        "bus_width_bits": 64,
        "bandwidth_gbps": 34.0,
        "ecc_enabled": false,
        "numa_node": 0,
        "physical_position": 1
      }
    ]
  },
  "theoretical_peaks": {
    "fp32": 640.0,
    "fp64": 20.0,
    "fp16": 1280.0,
    "fp8": 0.0,
    "fp4": 0.0,
    "bf16": 1280.0,
    "int64": 0.0,
    "int32": 640.0,
    "int16": 1280.0,
    "int8": 2560.0,
    "int4": 0.0
  },
  "onchip_memory_hierarchy": {
    "cache_levels": [
      {
        "name": "L1 Data Cache/Shared Memory",
        "level": 1,
        "cache_type": "data",
        "scope": "per_sm",
        "size_per_unit_kb": 128,
        "associativity": null,
        "line_size_bytes": 128,
        "configurable": true,
        "note": "Configurable split between L1 cache and shared memory"
      },
      {
        "name": "L1 Instruction Cache",
        "level": 1,
        "cache_type": "instruction",
        "scope": "per_sm",
        "size_per_unit_kb": 12,
        "associativity": null,
        "line_size_bytes": 128
      },
      {
        "name": "L2 Cache",
        "level": 2,
        "cache_type": "unified",
        "scope": "shared",
        "total_size_kb": 1024,
        "associativity": null,
        "line_size_bytes": 128
      }
    ]
  },
  "data_source": "migrated",
  "last_updated": "2025-11-18T19:00:00.000000Z",
  "mapper": {
    "mapper_class": "GPUMapper",
    "mapper_config": {
      "prefer_tensor_cores": true,
      "enable_unified_memory": true
    },
    "hints": {
      "preferred_block_size": [256, 1, 1],
      "max_threads_per_block": 1024,
      "warp_size": 32,
      "tensor_core_hint": "Use Tensor Cores for FP16/BF16/INT8 matrix operations (16 Gen3 Tensor Cores available)",
      "memory_hint": "Unified memory with CPU - use cudaMallocManaged for easy CPU/GPU data sharing",
      "occupancy_hint": "32 SMs Ã— 48 warps/SM = 1536 max concurrent warps. Target 50-75% occupancy for best performance.",
      "architecture_notes": "Ampere architecture with 512 CUDA cores, 16 Tensor Cores Gen 3, no RT cores. Shared LPDDR5 memory with CPU subsystem."
    }
  }
}
