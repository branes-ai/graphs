{
  "id": "amd_instinct_mi300x",
  "vendor": "AMD",
  "model": "Instinct MI300X",
  "architecture": "CDNA 3",
  "device_type": "gpu",
  "platform": "x86_64",

  "detection_patterns": [
    "AMD Instinct MI300X",
    "MI300X"
  ],
  "os_compatibility": ["linux"],

  "cuda_capability": null,

  "core_clusters": [
    {
      "name": "CU",
      "type": "data_parallel",
      "count": 304,
      "architecture": "CDNA 3",
      "base_frequency_ghz": 1.7,
      "boost_frequency_ghz": 2.1,
      "cuda_cores_per_cluster": 64,
      "tensor_cores_per_cluster": 4,
      "rt_cores_per_cluster": 0,
      "max_threads_per_cluster": 2560,
      "max_warps_per_cluster": 40,
      "shared_memory_kb": 64,
      "register_file_kb": 512,
      "l1_cache_kb": 32
    }
  ],

  "memory_type": "HBM3",
  "memory_bus_width": 8192,
  "peak_bandwidth_gbps": 5300.0,

  "isa_extensions": [],
  "special_features": [
    "Matrix Cores (MFMA)",
    "Infinity Fabric",
    "ROCm Support",
    "FP8 Support",
    "Chiplet Architecture"
  ],

  "theoretical_peaks": {
    "fp64": 81700.0,
    "fp32": 163400.0,
    "fp16": 1307000.0,
    "bf16": 1307000.0,
    "fp8": 2614000.0,
    "int8": 2614000.0
  },

  "l2_cache_kb": 262144,

  "tdp_watts": 750,
  "max_power_watts": 750,

  "release_date": "Q4 2023",
  "manufacturer_url": "https://www.amd.com/en/products/accelerators/instinct/mi300/mi300x.html",
  "notes": "8 GCDs (GPU chiplets), each with 38 CUs. Total 304 CUs across all chiplets.",

  "data_source": "manufacturer",
  "last_updated": "2025-11-18T16:00:00Z",

  "mapper_class": "GPUMapper",
  "mapper_config": {
    "wavefront_size": 64,
    "max_wavefronts_per_cu": 40,
    "max_threads_per_workgroup": 1024
  }
}
