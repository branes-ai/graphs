# GPU Efficiency Derate Table (Jetson Orin AGX 50W)

  Base peak: 958 GFLOPS (FP32 with TF32 enabled)

  Special Operation Types
  ┌─────────────────────┬────────────┬────────┬───────────────────────┐
  │       Pattern       │ Efficiency │ GFLOPS │         Notes         │
  ├─────────────────────┼────────────┼────────┼───────────────────────┤
  │ Pure Depthwise Conv │ 0.03 (3%)  │ ~29    │ Severely memory-bound │
  └─────────────────────┴────────────┴────────┴───────────────────────┘

## MBConv Blocks (EfficientNet/MobileNet fused pointwise+depthwise)
  ┌────────────┬──────────────┬────────┬────────────────────┐
  │ FLOP Range │  Efficiency  │ GFLOPS │      Example       │
  ├────────────┼──────────────┼────────┼────────────────────┤
  │ <10M       │ 0.025 (2.5%) │ ~24    │ Very small MBConv  │
  ├────────────┼──────────────┼────────┼────────────────────┤
  │ 10M-30M    │ 0.025→0.035  │ 24→34  │ EfficientNet-B0    │
  ├────────────┼──────────────┼────────┼────────────────────┤
  │ 30M-50M    │ 0.035→0.055  │ 34→53  │ EfficientNet-B1/B2 │
  ├────────────┼──────────────┼────────┼────────────────────┤
  │ >50M       │ 0.055→0.10   │ 53→96  │ Large MBConv       │
  └────────────┴──────────────┴────────┴────────────────────┘

## Standard Operations (non-MBConv)
  ┌────────────┬───────────┬─────────────┬──────────────────┐
  │ FLOP Range │ Conv2d+BN │ Conv2d only │ MatMul/Attention │
  ├────────────┼───────────┼─────────────┼──────────────────┤
  │ <1M        │ 0.01 (1%) │ 0.01 (1%)   │ 0.01 (1%)        │
  ├────────────┼───────────┼─────────────┼──────────────────┤
  │ 1M-10M     │ 0.02→0.06 │ 0.02→0.06   │ 0.02→0.06        │
  ├────────────┼───────────┼─────────────┼──────────────────┤
  │ 10M-50M    │ 0.06→0.20 │ 0.06→0.20   │ 0.06→0.20        │
  ├────────────┼───────────┼─────────────┼──────────────────┤
  │ 50M-200M   │ 0.23→0.54 │ 0.60→1.13   │ 0.35→0.80        │
  ├────────────┼───────────┼─────────────┼──────────────────┤
  │ 200M-500M  │ 0.73→0.80 │ 1.13→1.30   │ 0.60→1.15        │
  ├────────────┼───────────┼─────────────┼──────────────────┤
  │ 500M-5G    │ 0.80→4.50 │ 1.30→5.40   │ 0.90→1.40        │
  ├────────────┼───────────┼─────────────┼──────────────────┤
  │ >5G        │ 4.50→5.00 │ 5.40→5.60   │ 1.40→1.50        │
  └────────────┴───────────┴─────────────┴──────────────────┘

## CPU Efficiency (for comparison)
  ┌────────────┬────────────┐
  │ FLOP Range │ Efficiency │
  ├────────────┼────────────┤
  │ <1M        │ 0.15 (15%) │
  ├────────────┼────────────┤
  │ 1M-10M     │ 0.15→0.25  │
  ├────────────┼────────────┤
  │ 10M-100M   │ 0.25→0.70  │
  ├────────────┼────────────┤
  │ >100M      │ 0.70→1.00  │
  └────────────┴────────────┘

## Key Insights

  1. TF32 effect: Large Conv2d ops achieve >1.0x efficiency (exceeding FP32 theoretical) due to cuDNN's TF32 acceleration
  2. BatchNorm penalty: Conv2d+BN is ~0.67x of Conv2d-only due to memory traffic overhead
  3. Size scaling: Efficiency increases dramatically with operation size (better GPU occupancy)
  4. MBConv penalty: Fused pointwise+depthwise blocks achieve only 2.5-10% efficiency despite pointwise dominating FLOPs

