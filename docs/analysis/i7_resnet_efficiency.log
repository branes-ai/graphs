
================================================================================
  EFFICIENCY MEASUREMENT
================================================================================
  Model:     resnet152
  Hardware:  i7-12700K
  Thermal:   (default)
  Device:    cpu
  Precision: FP32
  Runs:      10 warmup + 50 timed
================================================================================

Step 1: Creating model...
Step 2: Tracing with symbolic_trace...
Step 3: Partitioning...
  209 subgraphs, 23.04 GFLOPs
Step 4: Loading hardware specifications...
  Theoretical peak: 720.00GFLOPS
Step 5: Measuring node times (10 warmup + 50 timed)...
  Collected times for 517 nodes
Step 6: Computing efficiency statistics...
  209 subgraphs measured

  SG   Pattern                        OpType                FLOPs  Lat(ms)     Eff Eff Std
  ---------------------------------------------------------------------------------------------------------
  0    Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     236.0M    0.665   0.495   0.023
  1    Unfused                        unfused                   0    0.899   0.000   0.000
  2    Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm      25.7M    0.215   0.166   0.006
  3    Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     231.2M    0.552   0.581   0.005
  4    Conv2d_BatchNorm2d             conv2d_batchnorm     102.8M    0.385   0.372   0.020
  5    Conv2d_BatchNorm2d             conv2d_batchnorm     102.8M    0.432   0.335   0.038
  6    add_ReLU                       activation             803K    0.125   0.009   0.000
  7    Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     102.8M    0.361   0.395   0.006
  8    Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     231.2M    0.548   0.586   0.006
  9    Conv2d_BatchNorm2d             conv2d_batchnorm     102.8M    0.378   0.379   0.024
  10   add_ReLU                       activation             803K    0.132   0.009   0.001
  11   Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     102.8M    0.356   0.401   0.004
  12   Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     231.2M    0.545   0.589   0.007
  13   Conv2d_BatchNorm2d             conv2d_batchnorm     102.8M    0.409   0.353   0.038
  14   add_ReLU                       activation             803K    0.129   0.009   0.001
  15   Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     205.5M    0.569   0.502   0.006
  16   Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     231.2M    0.569   0.564   0.007
  17   Conv2d_BatchNorm2d             conv2d_batchnorm     102.8M    0.328   0.435   0.007
  18   Conv2d_BatchNorm2d             conv2d_batchnorm     205.5M    0.660   0.435   0.033
  19   add_ReLU                       activation             401K    0.069   0.009   0.002
  20   Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     102.8M    0.338   0.424   0.022
  21   Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     231.2M    0.541   0.594   0.005
  22   Conv2d_BatchNorm2d             conv2d_batchnorm     102.8M    0.332   0.432   0.032
  23   add_ReLU                       activation             401K    0.052   0.011   0.001
  24   Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     102.8M    0.322   0.444   0.018
  25   Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     231.2M    0.536   0.600   0.004
  26   Conv2d_BatchNorm2d             conv2d_batchnorm     102.8M    0.325   0.441   0.027
  27   add_ReLU                       activation             401K    0.054   0.010   0.001
  28   Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     102.8M    0.325   0.441   0.025
  29   Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     231.2M    0.536   0.600   0.004
  30   Conv2d_BatchNorm2d             conv2d_batchnorm     102.8M    0.332   0.434   0.038
  31   add_ReLU                       activation             401K    0.055   0.010   0.001
  32   Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     102.8M    0.327   0.439   0.028
  33   Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     231.2M    0.536   0.599   0.006
  34   Conv2d_BatchNorm2d             conv2d_batchnorm     102.8M    0.329   0.436   0.030
  35   add_ReLU                       activation             401K    0.054   0.010   0.001
  36   Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     102.8M    0.322   0.444   0.019
  37   Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     231.2M    0.534   0.601   0.004
  38   Conv2d_BatchNorm2d             conv2d_batchnorm     102.8M    0.322   0.445   0.021
  39   add_ReLU                       activation             401K    0.053   0.011   0.001
  40   Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     102.8M    0.319   0.448   0.010
  41   Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     231.2M    0.535   0.600   0.005
  42   Conv2d_BatchNorm2d             conv2d_batchnorm     102.8M    0.320   0.446   0.015
  43   add_ReLU                       activation             401K    0.054   0.011   0.001
  44   Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     102.8M    0.319   0.448   0.020
  45   Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     231.2M    0.534   0.601   0.006
  46   Conv2d_BatchNorm2d             conv2d_batchnorm     102.8M    0.324   0.442   0.025
  47   add_ReLU                       activation             401K    0.055   0.010   0.001
  48   Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     205.5M    0.533   0.537   0.019
  49   Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     231.2M    0.588   0.547   0.020
  50   Conv2d_BatchNorm2d             conv2d_batchnorm     102.8M    0.327   0.437   0.016
  51   Conv2d_BatchNorm2d             conv2d_batchnorm     205.5M    0.653   0.445   0.063
  52   add_ReLU                       activation             201K    0.049   0.006   0.001
  53   Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     102.8M    0.369   0.412   0.069
  54   Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     231.2M    0.550   0.585   0.024
  55   Conv2d_BatchNorm2d             conv2d_batchnorm     102.8M    0.322   0.443   0.003
  56   add_ReLU                       activation             201K    0.047   0.006   0.001
  57   Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     102.8M    0.321   0.444   0.005
  58   Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     231.2M    0.538   0.597   0.005
  59   Conv2d_BatchNorm2d             conv2d_batchnorm     102.8M    0.319   0.447   0.004
  60   add_ReLU                       activation             201K    0.045   0.006   0.000
  61   Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     102.8M    0.331   0.434   0.030
  62   Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     231.2M    0.548   0.586   0.024
  63   Conv2d_BatchNorm2d             conv2d_batchnorm     102.8M    0.318   0.449   0.004
  64   add_ReLU                       activation             201K    0.045   0.006   0.001
  65   Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     102.8M    0.354   0.423   0.063
  66   Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     231.2M    0.544   0.591   0.021
  67   Conv2d_BatchNorm2d             conv2d_batchnorm     102.8M    0.319   0.447   0.003
  68   add_ReLU                       activation             201K    0.050   0.006   0.001
  69   Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     102.8M    0.321   0.444   0.011
  70   Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     231.2M    0.536   0.599   0.006
  71   Conv2d_BatchNorm2d             conv2d_batchnorm     102.8M    0.320   0.447   0.003
  72   add_ReLU                       activation             201K    0.050   0.006   0.001
  73   Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     102.8M    0.319   0.448   0.006
  74   Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     231.2M    0.539   0.596   0.015
  75   Conv2d_BatchNorm2d             conv2d_batchnorm     102.8M    0.318   0.449   0.004
  76   add_ReLU                       activation             201K    0.043   0.006   0.000
  77   Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     102.8M    0.319   0.448   0.004
  78   Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     231.2M    0.540   0.595   0.018
  79   Conv2d_BatchNorm2d             conv2d_batchnorm     102.8M    0.317   0.451   0.004
  80   add_ReLU                       activation             201K    0.043   0.007   0.000
  81   Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     102.8M    0.319   0.447   0.004
  82   Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     231.2M    0.536   0.599   0.005
  83   Conv2d_BatchNorm2d             conv2d_batchnorm     102.8M    0.319   0.447   0.003
  84   add_ReLU                       activation             201K    0.044   0.006   0.000
  85   Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     102.8M    0.320   0.446   0.005
  86   Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     231.2M    0.535   0.600   0.007
  87   Conv2d_BatchNorm2d             conv2d_batchnorm     102.8M    0.319   0.447   0.004
  88   add_ReLU                       activation             201K    0.045   0.006   0.000
  89   Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     102.8M    0.319   0.447   0.005
  90   Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     231.2M    0.536   0.599   0.005
  91   Conv2d_BatchNorm2d             conv2d_batchnorm     102.8M    0.318   0.448   0.003
  92   add_ReLU                       activation             201K    0.044   0.006   0.000
  93   Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     102.8M    0.320   0.447   0.004
  94   Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     231.2M    0.536   0.599   0.005
  95   Conv2d_BatchNorm2d             conv2d_batchnorm     102.8M    0.316   0.451   0.004
  96   add_ReLU                       activation             201K    0.043   0.007   0.000
  97   Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     102.8M    0.320   0.446   0.005
  98   Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     231.2M    0.534   0.601   0.005
  99   Conv2d_BatchNorm2d             conv2d_batchnorm     102.8M    0.319   0.448   0.005
  100  add_ReLU                       activation             201K    0.044   0.006   0.000
  101  Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     102.8M    0.321   0.444   0.007
  102  Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     231.2M    0.536   0.599   0.009
  103  Conv2d_BatchNorm2d             conv2d_batchnorm     102.8M    0.319   0.447   0.012
  104  add_ReLU                       activation             201K    0.045   0.006   0.000
  105  Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     102.8M    0.319   0.448   0.014
  106  Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     231.2M    0.537   0.598   0.013
  107  Conv2d_BatchNorm2d             conv2d_batchnorm     102.8M    0.319   0.448   0.010
  108  add_ReLU                       activation             201K    0.044   0.006   0.000
  109  Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     102.8M    0.321   0.445   0.011
  110  Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     231.2M    0.536   0.599   0.010
  111  Conv2d_BatchNorm2d             conv2d_batchnorm     102.8M    0.318   0.449   0.010
  112  add_ReLU                       activation             201K    0.043   0.006   0.000
  113  Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     102.8M    0.321   0.445   0.011
  114  Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     231.2M    0.536   0.599   0.008
  115  Conv2d_BatchNorm2d             conv2d_batchnorm     102.8M    0.320   0.446   0.008
  116  add_ReLU                       activation             201K    0.045   0.006   0.000
  117  Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     102.8M    0.321   0.445   0.009
  118  Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     231.2M    0.534   0.601   0.005
  119  Conv2d_BatchNorm2d             conv2d_batchnorm     102.8M    0.319   0.448   0.003
  120  add_ReLU                       activation             201K    0.045   0.006   0.000
  121  Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     102.8M    0.317   0.451   0.005
  122  Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     231.2M    0.535   0.600   0.005
  123  Conv2d_BatchNorm2d             conv2d_batchnorm     102.8M    0.317   0.450   0.004
  124  add_ReLU                       activation             201K    0.044   0.006   0.000
  125  Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     102.8M    0.319   0.447   0.005
  126  Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     231.2M    0.534   0.602   0.005
  127  Conv2d_BatchNorm2d             conv2d_batchnorm     102.8M    0.315   0.453   0.004
  128  add_ReLU                       activation             201K    0.043   0.007   0.000
  129  Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     102.8M    0.319   0.448   0.004
  130  Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     231.2M    0.535   0.601   0.005
  131  Conv2d_BatchNorm2d             conv2d_batchnorm     102.8M    0.318   0.448   0.004
  132  add_ReLU                       activation             201K    0.045   0.006   0.000
  133  Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     102.8M    0.319   0.448   0.007
  134  Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     231.2M    0.535   0.600   0.005
  135  Conv2d_BatchNorm2d             conv2d_batchnorm     102.8M    0.320   0.446   0.007
  136  add_ReLU                       activation             201K    0.045   0.006   0.000
  137  Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     102.8M    0.318   0.449   0.007
  138  Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     231.2M    0.535   0.600   0.005
  139  Conv2d_BatchNorm2d             conv2d_batchnorm     102.8M    0.318   0.449   0.004
  140  add_ReLU                       activation             201K    0.043   0.006   0.000
  141  Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     102.8M    0.319   0.447   0.004
  142  Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     231.2M    0.535   0.600   0.005
  143  Conv2d_BatchNorm2d             conv2d_batchnorm     102.8M    0.317   0.450   0.004
  144  add_ReLU                       activation             201K    0.043   0.007   0.000
  145  Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     102.8M    0.318   0.449   0.004
  146  Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     231.2M    0.534   0.601   0.005
  147  Conv2d_BatchNorm2d             conv2d_batchnorm     102.8M    0.319   0.447   0.004
  148  add_ReLU                       activation             201K    0.045   0.006   0.000
  149  Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     102.8M    0.319   0.447   0.005
  150  Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     231.2M    0.533   0.603   0.005
  151  Conv2d_BatchNorm2d             conv2d_batchnorm     102.8M    0.318   0.449   0.006
  152  add_ReLU                       activation             201K    0.045   0.006   0.000
  153  Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     102.8M    0.319   0.448   0.009
  154  Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     231.2M    0.535   0.600   0.006
  155  Conv2d_BatchNorm2d             conv2d_batchnorm     102.8M    0.318   0.449   0.004
  156  add_ReLU                       activation             201K    0.044   0.006   0.000
  157  Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     102.8M    0.318   0.448   0.004
  158  Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     231.2M    0.534   0.601   0.005
  159  Conv2d_BatchNorm2d             conv2d_batchnorm     102.8M    0.315   0.453   0.003
  160  add_ReLU                       activation             201K    0.043   0.007   0.000
  161  Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     102.8M    0.321   0.445   0.005
  162  Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     231.2M    0.534   0.601   0.004
  163  Conv2d_BatchNorm2d             conv2d_batchnorm     102.8M    0.319   0.448   0.003
  164  add_ReLU                       activation             201K    0.045   0.006   0.000
  165  Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     102.8M    0.320   0.447   0.006
  166  Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     231.2M    0.536   0.599   0.005
  167  Conv2d_BatchNorm2d             conv2d_batchnorm     102.8M    0.319   0.447   0.003
  168  add_ReLU                       activation             201K    0.045   0.006   0.000
  169  Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     102.8M    0.319   0.447   0.005
  170  Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     231.2M    0.535   0.600   0.005
  171  Conv2d_BatchNorm2d             conv2d_batchnorm     102.8M    0.318   0.449   0.004
  172  add_ReLU                       activation             201K    0.043   0.006   0.000
  173  Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     102.8M    0.320   0.446   0.004
  174  Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     231.2M    0.536   0.600   0.005
  175  Conv2d_BatchNorm2d             conv2d_batchnorm     102.8M    0.316   0.452   0.003
  176  add_ReLU                       activation             201K    0.043   0.007   0.000
  177  Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     102.8M    0.319   0.448   0.005
  178  Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     231.2M    0.534   0.601   0.005
  179  Conv2d_BatchNorm2d             conv2d_batchnorm     102.8M    0.318   0.449   0.004
  180  add_ReLU                       activation             201K    0.044   0.006   0.000
  181  Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     102.8M    0.320   0.447   0.006
  182  Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     231.2M    0.535   0.601   0.005
  183  Conv2d_BatchNorm2d             conv2d_batchnorm     102.8M    0.319   0.448   0.003
  184  add_ReLU                       activation             201K    0.045   0.006   0.000
  185  Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     102.8M    0.316   0.452   0.004
  186  Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     231.2M    0.535   0.600   0.007
  187  Conv2d_BatchNorm2d             conv2d_batchnorm     102.8M    0.317   0.451   0.004
  188  add_ReLU                       activation             201K    0.043   0.006   0.000
  189  Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     102.8M    0.319   0.447   0.005
  190  Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     231.2M    0.534   0.601   0.005
  191  Conv2d_BatchNorm2d             conv2d_batchnorm     102.8M    0.315   0.453   0.003
  192  add_ReLU                       activation             201K    0.043   0.007   0.000
  193  Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     205.5M    0.538   0.531   0.015
  194  Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     231.2M    0.884   0.366   0.029
  195  Conv2d_BatchNorm2d             conv2d_batchnorm     102.8M    0.418   0.341   0.004
  196  Conv2d_BatchNorm2d             conv2d_batchnorm     205.5M    0.855   0.336   0.023
  197  add_ReLU                       activation             100K    0.041   0.003   0.000
  198  Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     102.8M    0.436   0.327   0.004
  199  Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     231.2M    0.733   0.438   0.002
  200  Conv2d_BatchNorm2d             conv2d_batchnorm     102.8M    0.414   0.344   0.003
  201  add_ReLU                       activation             100K    0.041   0.003   0.000
  202  Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     102.8M    0.432   0.331   0.013
  203  Conv2d_BatchNorm2d_ReLU        conv2d_batchnorm     231.2M    0.729   0.441   0.014
  204  Conv2d_BatchNorm2d             conv2d_batchnorm     102.8M    0.411   0.348   0.004
  205  add_ReLU                       activation             100K    0.040   0.004   0.000
  206  Unfused                        unfused                   0    0.068   0.000   0.000
  207  Unfused                        unfused                   0    0.013   0.000   0.000
  208  Unfused                        unfused                4.1M    0.154   0.037   0.001

Summary by Operation Type:
  Operation Type       Count  Total FLOPs  Avg Eff       Eff Range
  ----------------------------------------------------------------------
  activation              50        13.1M    0.007     0.003-0.011
  conv2d_batchnorm       155       23.02G    0.484     0.166-0.603
  unfused                  4         4.1M    0.009     0.000-0.037

