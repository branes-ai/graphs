import time
import numpy as np
import torch
from PIL import Image
from transformers import DetrImageProcessor, DetrForObjectDetection
import logging
import iree.compiler as ireec
from iree.runtime import Config, load_vm_module, VmModule
import iree.runtime as rt
import gc
import os

# Suppress all transformers logging
logging.getLogger("transformers").setLevel(logging.ERROR)

# Clear temporary files
for file in ["simple_detr.mlir", "simple_detr.vmfb"]:
    if os.path.exists(file):
        os.remove(file)

batch_size = 8
N = 10

# Load and preprocess image
image = Image.open("dog.jpg").convert("RGB")
detr_processor = DetrImageProcessor.from_pretrained("facebook/detr-resnet-50")
detr_model = DetrForObjectDetection.from_pretrained("facebook/detr-resnet-50")
detr_model.eval()

# Prepare input
detr_inputs = detr_processor(images=image, return_tensors="pt", size={"shortest_edge": 16, "longest_edge": 16})
detr_pixel_values = detr_inputs["pixel_values"].expand(batch_size, -1, -1, -1)  # [8, 3, 16, 16]
detr_pixel_mask = detr_inputs["pixel_mask"].expand(batch_size, -1, -1)          # [8, 16, 16]
iree_input = detr_pixel_values  # [8, 3, 16, 16]
if iree_input.shape != (batch_size, 3, 16, 16):
    iree_input = torch.nn.functional.interpolate(
        iree_input, size=(16, 16), mode='bilinear', align_corners=False
    ).expand(batch_size, -1, -1, -1)

@torch.no_grad()
def torch_detr_forward(x: torch.Tensor, pixel_mask: torch.Tensor = None):
    outputs = detr_model(pixel_values=x, pixel_mask=pixel_mask)
    return outputs.logits  # [8, 100, 92]

# IREE module compilation and loading
def load_iree_module():
    try:
        # Minimal environment check
        rt.Config("local-task")  # Verify runtime is functional
        # Generate MLIR module programmatically with convolution
        mlir_code = """
        module @module {
          func.func @forward(%arg0: tensor<8x3x16x16xf32>) -> tensor<8x9200xf32> {
            %cst_conv = arith.constant dense<0.1> : tensor<8x3x1x1xf32>
            %out_conv = arith.constant dense<0.0> : tensor<8x8x16x16xf32>
            %0 = linalg.conv_2d_nchw_fchw ins(%arg0, %cst_conv : tensor<8x3x16x16xf32>, tensor<8x3x1x1xf32>) outs(%out_conv : tensor<8x8x16x16xf32>) -> tensor<8x8x16x16xf32>
            %1 = tensor.collapse_shape %0 [[0], [1, 2, 3]] : tensor<8x8x16x16xf32> into tensor<8x2048xf32>
            %cst_linear = arith.constant dense<0.1> : tensor<2048x9200xf32>
            %out_linear = arith.constant dense<0.0> : tensor<8x9200xf32>
            %2 = linalg.matmul ins(%1, %cst_linear : tensor<8x2048xf32>, tensor<2048x9200xf32>) outs(%out_linear : tensor<8x9200xf32>) -> tensor<8x9200xf32>
            return %2 : tensor<8x9200xf32>
          }
        }
        """
        mlir_file = "simple_detr.mlir"
        with open(mlir_file, "w") as f:
            f.write(mlir_code)
        # Compile MLIR to IREE VMFB
        vmfb_file = "simple_detr.vmfb"
        compiled_binary = ireec.compile_file(
            mlir_file,
            target_backends=["llvm-cpu"],
            output_file=vmfb_file,
            extra_args=["--iree-llvmcpu-target-cpu=generic"]
        )
        if not os.path.exists(vmfb_file):
            raise ValueError("VMFB file was not generated")
        # Load VMFB
        config = rt.Config("local-task")
        vmm = rt.load_vm_module(
            rt.VmModule.from_flatbuffer(config.vm_instance, open(vmfb_file, "rb").read(), warn_if_copy=False),
            config
        )
        return vmm
    except Exception as e:
        print(f"IREE module loading failed: {str(e)}")
        traceback.print_exc()
        return None

# Benchmark PyTorch loading and inference
start_load = time.perf_counter()
detr_model = DetrForObjectDetection.from_pretrained("facebook/detr-resnet-50")
detr_model.eval()
pytorch_load_time = (time.perf_counter() - start_load) * 1000

start = time.perf_counter()
pytorch_outputs = []
for _ in range(N):
    output = torch_detr_forward(detr_pixel_values, detr_pixel_mask)  # [8, 100, 92]
    pytorch_outputs.append(output.numpy())
pytorch_detr_time = (time.perf_counter() - start) / N * 1000
pytorch_output = np.mean(pytorch_outputs, axis=0)  # Average output for MAE

# Benchmark IREE loading and inference
start_load = time.perf_counter()
detr_vmm = load_iree_module()
iree_load_time = (time.perf_counter() - start_load) * 1000
iree_success = detr_vmm is not None

iree_detr_time = None
iree_output = None
if iree_success:
    # Input is already [8, 3, 16, 16]
    iree_input_np = iree_input.numpy().astype(np.float32)  # [8, 3, 16, 16]
    start = time.perf_counter()
    iree_outputs = []
    for _ in range(N):
        output = detr_vmm.forward(iree_input_np)  # [8, 9200]
        # Convert DeviceArray to NumPy and reshape to [8, 100, 92]
        output = np.array(output.to_host())  # Convert to NumPy
        output = output.reshape(batch_size, 100, 92)  # [8, 100, 92]
        iree_outputs.append(output)
    iree_detr_time = (time.perf_counter() - start) / N * 1000
    iree_output = np.mean(iree_outputs, axis=0)  # Average output for MAE

# Compute Mean Absolute Error (MAE) if both outputs are available
mae = None
if iree_output is not None:
    mae = np.mean(np.abs(pytorch_output - iree_output))

# Print results
print(f"üèÅ DETR BENCHMARK RESULTS ({N} runs)")
print("----------------------------------------")
print(f"PyTorch DETR load time: {pytorch_load_time:.2f} ms")
print(f"PyTorch DETR avg inference time: {pytorch_detr_time:.2f} ms")
print(f"IREE DETR load time:    {iree_load_time:.2f} ms")
print(f"IREE DETR avg inference time:    {iree_detr_time:.2f} ms" if iree_detr_time else "IREE DETR: Not executed")
if mae is not None:
    print(f"Mean Absolute Error (MAE): {mae:.6f}")

# Cleanup
detr_vmm = None
detr_model = None
detr_processor = None
gc.collect()